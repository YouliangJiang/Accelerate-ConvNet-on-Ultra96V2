{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./data')\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from dataset import flowerDataset\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "print(\"Pytorch Version: \", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_quantize(k):\n",
    "  class qfn(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "      if k == 32:\n",
    "        out = input\n",
    "      elif k == 1:\n",
    "        out = torch.sign(input)\n",
    "      else:\n",
    "        n = float(2 ** k  - 1)\n",
    "        out = torch.round(input * n) / n\n",
    "      return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "      grad_input = grad_output.clone()\n",
    "      return grad_input\n",
    "\n",
    "  return qfn().apply\n",
    "\n",
    "\n",
    "class weight_quantize_fn(nn.Module):\n",
    "  def __init__(self, w_bit):\n",
    "    super(weight_quantize_fn, self).__init__()\n",
    "    assert w_bit <= 8 or w_bit == 32\n",
    "    self.w_bit = w_bit\n",
    "    self.uniform_q = uniform_quantize(k=w_bit - 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # print('===================')\n",
    "    if self.w_bit == 32:\n",
    "      weight_q = x\n",
    "    elif self.w_bit == 1:\n",
    "      E = torch.mean(torch.abs(x)).detach()\n",
    "      weight_q = (self.uniform_q(x / E) + 1) / 2 * E\n",
    "    else:\n",
    "      weight = torch.tanh(x)\n",
    "      weight = weight / torch.max(torch.abs(weight))\n",
    "      weight_q = self.uniform_q(weight)\n",
    "    return weight_q\n",
    "\n",
    "\n",
    "def conv2d_Q_fn(w_bit):\n",
    "  class Conv2d_Q(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=True):\n",
    "      super(Conv2d_Q, self).__init__(in_channels, out_channels, kernel_size, stride,\n",
    "                                     padding, dilation, groups, bias)\n",
    "      self.w_bit = w_bit\n",
    "      self.quantize_fn = weight_quantize_fn(w_bit=w_bit)\n",
    "\n",
    "    def forward(self, input, order=None):\n",
    "      weight_q = self.quantize_fn(self.weight)\n",
    "      return F.conv2d(input, weight_q, self.bias, self.stride,\n",
    "                      self.padding, self.dilation, self.groups)\n",
    "\n",
    "  return Conv2d_Q\n",
    "\n",
    "\n",
    "class activation_quantize_fn(nn.Module):\n",
    "  def __init__(self, a_bit):\n",
    "    super(activation_quantize_fn, self).__init__()\n",
    "    assert a_bit <= 8 or a_bit == 32\n",
    "    self.a_bit = a_bit\n",
    "    self.uniform_q = uniform_quantize(k=a_bit)\n",
    "\n",
    "  def forward(self, x):\n",
    "    if self.a_bit == 32:\n",
    "      activation_q = x\n",
    "    else:\n",
    "      activation_q = self.uniform_q(torch.clamp(x, 0, 1))\n",
    "    return activation_q\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        W_BIT = 4\n",
    "        A_BIT = 4\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            conv2d_Q_fn(W_BIT)(3, 16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            activation_quantize_fn(A_BIT),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "            conv2d_Q_fn(W_BIT)(16, 32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            activation_quantize_fn(A_BIT),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "            conv2d_Q_fn(W_BIT)(32, 32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            activation_quantize_fn(A_BIT),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            \n",
    "            conv2d_Q_fn(W_BIT)(32, 32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            activation_quantize_fn(A_BIT),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            \n",
    "            conv2d_Q_fn(W_BIT)(32, 16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            activation_quantize_fn(A_BIT),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "        )\n",
    "        self.conv1 = conv2d_Q_fn(8)(16*5*5, 16, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.Outact = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = x.reshape(-1, 16*5*5, 1, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = x.squeeze(3).squeeze(2)\n",
    "        x = self.Outact(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#宏定义一些数据，如epoch数，batchsize等\n",
    "MAX_EPOCH=100\n",
    "BATCH_SIZE=36\n",
    "LR=0.0001\n",
    "log_interval=6\n",
    "val_interval=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ step 1/5 数据 ============================\n",
    "split_dir=os.path.join(\".\",\"data\",\"splitData\")\n",
    "train_dir=os.path.join(split_dir,\"train\")\n",
    "valid_dir=os.path.join(split_dir,\"valid\")\n",
    "\n",
    "#对训练集所需要做的预处理\n",
    "train_transform=transforms.Compose([\n",
    "    transforms.Resize((160,160)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "#对验证集所需要做的预处理\n",
    "valid_transform=transforms.Compose([\n",
    "    transforms.Resize((160,160)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 构建MyDataset实例\n",
    "train_data=flowerDataset(data_dir=train_dir,transform=train_transform)\n",
    "valid_data=flowerDataset(data_dir=valid_dir,transform=valid_transform)\n",
    "\n",
    "# 构建DataLoader\n",
    "# 训练集数据最好打乱\n",
    "# DataLoader的实质就是把数据集加上一个索引号，再返回\n",
    "train_loader=DataLoader(dataset=train_data,batch_size=BATCH_SIZE,shuffle=True)\n",
    "valid_loader=DataLoader(dataset=valid_data,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ step 2/5 模型 ============================\n",
    "net = ConvNet()\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    net=ConvNet()\n",
    "    x=torch.randn(2,3,160,160)\n",
    "    y=net(x)\n",
    "    print(y.size())\n",
    "    print(y)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ step 3/5 损失函数 ============================\n",
    "criterion=nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ step 4/5 优化器 ============================\n",
    "optimizer=optim.Adam(net.parameters(),lr=LR, betas=(0.9, 0.99))# 选择优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ============================ step 5/5 训练 ============================\n",
    "# 记录每一次的数据，方便绘图\n",
    "train_curve=list()\n",
    "valid_curve=list()\n",
    "net.train()\n",
    "accurancy_global=0.0\n",
    "\n",
    "for epoch in range(MAX_EPOCH):\n",
    "    loss_mean=0.\n",
    "    correct=0.\n",
    "    total=0.\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i,data in enumerate(train_loader):\n",
    "        img,label=data\n",
    "        img = Variable(img)\n",
    "        label = Variable(label)\n",
    "        if torch.cuda.is_available():\n",
    "            img=img.cuda()\n",
    "            label=label.cuda()\n",
    "            \n",
    "        # 前向传播\n",
    "        out=net(img)\n",
    "        optimizer.zero_grad()  # 归0梯度\n",
    "        loss=criterion(out,label)#得到损失函数\n",
    "\n",
    "        print_loss=loss.data.item()\n",
    "\n",
    "        loss.backward()#反向传播\n",
    "        optimizer.step()#优化\n",
    "        if (i+1)%log_interval==0:\n",
    "            print('epoch:{},loss:{:.4f}'.format(epoch+1,loss.data.item()))\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        total += label.size(0)\n",
    "\n",
    "        correct += (predicted == label).sum()\n",
    "    print(\"============================================\")\n",
    "    accurancy=correct / total\n",
    "    if accurancy>accurancy_global:\n",
    "        torch.save(net.state_dict(), './weights/convnet_best.pt')\n",
    "        print(\"准确率由：\", accurancy_global, \"上升至：\", accurancy, \"已更新并保存权值为weights/convnet_best.pt\")\n",
    "        accurancy_global=accurancy\n",
    "    print('第%d个epoch的识别准确率为：%d%%' % (epoch + 1, 100*accurancy))\n",
    "\n",
    "torch.save(net.state_dict(), './weights/convnet_last.pt')\n",
    "print(\"训练完毕，权重已保存为：weights/convnet_last.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train()\n",
    "for epoch in range(MAX_EPOCH):\n",
    "    loss_mean=0.\n",
    "    correct=0.\n",
    "    total=0.\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i,data in enumerate(train_loader):\n",
    "        img,label=data\n",
    "        img = Variable(img)\n",
    "        label = Variable(label)\n",
    "        if torch.cuda.is_available():\n",
    "            img=img.cuda()\n",
    "            label=label.cuda()\n",
    "            \n",
    "        # 前向传播\n",
    "        out=net(img)\n",
    "        optimizer.zero_grad()  # 归0梯度\n",
    "        loss=criterion(out,label)#得到损失函数\n",
    "\n",
    "        print_loss=loss.data.item()\n",
    "\n",
    "        loss.backward()#反向传播\n",
    "        optimizer.step()#优化\n",
    "        if (i+1)%log_interval==0:\n",
    "            print('epoch:{},loss:{:.4f}'.format(epoch+1,loss.data.item()))\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        total += label.size(0)\n",
    "\n",
    "        correct += (predicted == label).sum()\n",
    "    print(\"============================================\")\n",
    "    accurancy=correct / total\n",
    "    if accurancy>accurancy_global:\n",
    "        torch.save(net.state_dict(), './weights/convnet_best.pt')\n",
    "        print(\"准确率由：\", accurancy_global, \"上升至：\", accurancy, \"已更新并保存权值为weights/convnet_best.pt\")\n",
    "        accurancy_global=accurancy\n",
    "    print('第%d个epoch的识别准确率为：%d%%' % (epoch + 1, 100*accurancy))\n",
    "\n",
    "torch.save(net.state_dict(), './weights/convnet_last.pt')\n",
    "print(\"训练完毕，权重已保存为：weights/convnet_last.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# split_dir=os.path.join(\".\",\"data\",\"splitData\")\n",
    "# test_dir=os.path.join(split_dir,\"test\")\n",
    "test_dir = os.path.join(\".\", \"data\", \"rawData\")\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_data = flowerDataset(data_dir=test_dir, transform=test_transform)\n",
    "test_dataLoader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(\"./weights/convnet_best.pt\"))\n",
    "net.eval()\n",
    "correct = 0.\n",
    "total=0.\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_dataLoader):\n",
    "        img, label = data\n",
    "        img = Variable(img)\n",
    "        label = Variable(label)\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        print(\"label:\", label)\n",
    "        output = net(img)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        print(\"predict:\", predicted)\n",
    "        total += label.size(0)\n",
    "        correct += (predicted == label).sum()\n",
    "\n",
    "acc = correct/total * 100.\n",
    "print(\"Total:\", total)\n",
    "print(\"Accuracy:{}%\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Quantization import quantization, qnn_param_reader, qnn_mem_process\n",
    "import json\n",
    "\n",
    "def generate_config(model, in_shape):\n",
    "    feature_map_shape = in_shape\n",
    "    print(in_shape)\n",
    "    dic = {}\n",
    "    conv_cnt = 0\n",
    "    pool_cnt = 0\n",
    "    linear_cnt = 0\n",
    "    # cnt = 0\n",
    "    for sub_module in model.modules():\n",
    "        if type(sub_module).__base__ is torch.nn.Conv2d:\n",
    "            conv_cur = {}\n",
    "            conv_cur['in_shape'] = feature_map_shape[:]         \n",
    "            feature_map_shape[0] = sub_module.out_channels\n",
    "            feature_map_shape[1] = (feature_map_shape[1] + 2 * sub_module.padding[0] - sub_module.kernel_size[0]) // sub_module.stride[0] + 1\n",
    "            feature_map_shape[2] = (feature_map_shape[2] + 2 * sub_module.padding[0] - sub_module.kernel_size[0]) // sub_module.stride[0] + 1\n",
    "            conv_cur['out_shape'] = feature_map_shape[:]\n",
    "            conv_cur['k'] = sub_module.kernel_size[0]\n",
    "            conv_cur['s'] = sub_module.stride[0]\n",
    "            conv_cur['p'] = sub_module.padding[0]\n",
    "            \n",
    "            dic['conv_' + str(conv_cnt)] = conv_cur\n",
    "            \n",
    "            conv_cnt = conv_cnt + 1\n",
    "            # cnt = cnt + 1\n",
    "\n",
    "        elif type(sub_module) is torch.nn.MaxPool2d:\n",
    "            pool_cur = {}\n",
    "            pool_cur['in_shape'] = feature_map_shape[:]\n",
    "            pool_cur['p'] =  sub_module.kernel_size\n",
    "\n",
    "            feature_map_shape[1] = feature_map_shape[1] // sub_module.kernel_size\n",
    "            feature_map_shape[2] = feature_map_shape[2] // sub_module.kernel_size\n",
    "\n",
    "            pool_cur['out_shape'] = feature_map_shape[:]\n",
    "\n",
    "            dic['pool_' + str(pool_cnt)] = pool_cur\n",
    "\n",
    "            pool_cnt = pool_cnt + 1\n",
    "            # cnt = cnt + 1\n",
    "        elif type(sub_module) is torch.nn.Linear:\n",
    "            linear_cur = {}\n",
    "            linear_cur['in_len'] = sub_module.in_features\n",
    "            linear_cur['out_len'] = sub_module.out_features\n",
    "\n",
    "            dic['linear_' + str(linear_cnt)] = linear_cur\n",
    "            linear_cnt = linear_cnt + 1\n",
    "            # cnt = cnt + 1\n",
    "    \n",
    "    return dic\n",
    "    \n",
    "\n",
    "def generate_params(model):\n",
    "    dic = {}\n",
    "    cnt = 0\n",
    "    for sub_module in model.modules():\n",
    "        if type(sub_module).__base__ is torch.nn.Conv2d:\n",
    "            w = sub_module.weight.detach().numpy()\n",
    "            dic['arr_' + str(cnt)] = w\n",
    "            cnt = cnt + 1\n",
    "            if sub_module.bias is not None:\n",
    "                w = sub_module.bias.detach().numpy()\n",
    "                dic['arr_' + str(cnt)] = w\n",
    "                cnt = cnt + 1\n",
    "        elif type(sub_module) is torch.nn.Linear:\n",
    "            w = sub_module.weight.detach().numpy()\n",
    "            dic['arr_' + str(cnt)] = w\n",
    "            cnt = cnt + 1\n",
    "        elif type(sub_module) is torch.nn.BatchNorm2d or type(sub_module) is torch.nn.BatchNorm1d:\n",
    "            gamma = sub_module.weight.detach().numpy()\n",
    "            dic['arr_' + str(cnt)] = gamma\n",
    "            cnt = cnt + 1\n",
    "            beta = sub_module.bias.detach().numpy()\n",
    "            dic['arr_' + str(cnt)] = beta\n",
    "            cnt = cnt + 1\n",
    "            mean = sub_module.running_mean.numpy()\n",
    "            dic['arr_' + str(cnt)] = mean\n",
    "            cnt = cnt + 1\n",
    "            var = sub_module.running_var.numpy()\n",
    "            dic['arr_' + str(cnt)] = var\n",
    "            cnt = cnt + 1\n",
    "            eps = sub_module.eps\n",
    "            dic['arr_' + str(cnt)] = eps\n",
    "            cnt = cnt + 1\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "model.load_state_dict(torch.load('./weights/convnet_best.pt', map_location='cpu'))\n",
    "\n",
    "dic = generate_params(model)\n",
    "np.savez('ConvNet_4w4a.npz', **dic)\n",
    "\n",
    "dic = generate_config(model, [3, 160, 160])\n",
    "#indent参数根据数据格式缩进显示，读起来更加清晰, indent的值，代表缩进空格式\n",
    "json_str = json.dumps(dic, indent=4)\n",
    "with open('ConvNet_config.json', 'w') as json_file:\n",
    "    json_file.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv       0      1   2       3   4   5  \n",
    "w_bit   =   [4,     4,  4,      4,  4,   8]\n",
    "in_bit  =   [8,     4,  4,      4,  4,   4]\n",
    "out_bit =   [4,     4,  4,      4,  4,   32]\n",
    "l_shift =   [6,     6,  6,      6,  6,   6]\n",
    "simd    =   [3,     16,  16,    16, 8,   8]\n",
    "pe      =   [16,    8,   8,     4,  4,   2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Quantization.qnn_param_reader import QNNParamReader\n",
    "from Quantization.qnn_mem_process import QNNLayerMemProcess\n",
    "\n",
    "target_dir_hls_param = 'param/hls/'\n",
    "if not os.path.exists(target_dir_hls_param):\n",
    "    os.makedirs(target_dir_hls_param)\n",
    "    \n",
    "hls_param_file = open(target_dir_hls_param + 'param.h', 'w')\n",
    "hls_config_file = open(target_dir_hls_param + 'config.h', 'w')\n",
    "\n",
    "config_file = open('ConvNet_config.json', 'r', encoding='utf-8')\n",
    "config = json.load(config_file)\n",
    "reader = QNNParamReader('ConvNet_4w4a.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# conv_0 - 4\n",
    "for i in range(5):\n",
    "    processer = QNNLayerMemProcess('conv_' + str(i), reader, config, w_bit=w_bit[i], in_bit=in_bit[i], out_bit=out_bit[i], l_shift=l_shift[i], pe=pe[i], simd=simd[i])\n",
    "    w, inc, bias = processer.conv()\n",
    "    param_str = processer.layer_param_to_init_str(w, inc, bias)\n",
    "    config_str = processer.conv_config_str()\n",
    "    hls_param_file.write(param_str)\n",
    "    hls_config_file.write(config_str)\n",
    "\n",
    "processer = QNNLayerMemProcess('conv_' + str(5), reader, config, w_bit=w_bit[5], in_bit=in_bit[5],\n",
    "                                out_bit=out_bit[5], l_shift=l_shift[5], pe=pe[5], simd=simd[5])\n",
    "w = processer.last_conv()\n",
    "param_str = processer.last_layer_param_to_init_str(w)\n",
    "config_str = processer.last_conv_config_str()\n",
    "hls_param_file.write(param_str)\n",
    "hls_config_file.write(config_str)\n",
    "\n",
    "hls_param_file.close()\n",
    "hls_config_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
