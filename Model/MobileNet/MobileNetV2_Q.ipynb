{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "decreased-stuff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch Version:  1.7.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./data')\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from dataset import flowerDataset\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "print(\"Pytorch Version: \", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "extraordinary-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_BIT = 4\n",
    "A_BIT = 4\n",
    "\n",
    "def uniform_quantize(k):\n",
    "  class qfn(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "      if k == 32:\n",
    "        out = input\n",
    "      elif k == 1:\n",
    "        out = torch.sign(input)\n",
    "      else:\n",
    "        n = float(2 ** k  - 1)\n",
    "        out = torch.round(input * n) / n\n",
    "      return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "      grad_input = grad_output.clone()\n",
    "      return grad_input\n",
    "\n",
    "  return qfn().apply\n",
    "\n",
    "\n",
    "class weight_quantize_fn(nn.Module):\n",
    "  def __init__(self, w_bit):\n",
    "    super(weight_quantize_fn, self).__init__()\n",
    "    assert w_bit <= 8 or w_bit == 32\n",
    "    self.w_bit = w_bit\n",
    "    self.uniform_q = uniform_quantize(k=w_bit - 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    # print('===================')\n",
    "    if self.w_bit == 32:\n",
    "      weight_q = x\n",
    "    elif self.w_bit == 1:\n",
    "      E = torch.mean(torch.abs(x)).detach()\n",
    "      weight_q = (self.uniform_q(x / E) + 1) / 2 * E\n",
    "    else:\n",
    "      weight = torch.tanh(x)\n",
    "      weight = weight / torch.max(torch.abs(weight))\n",
    "      weight_q = self.uniform_q(weight)\n",
    "    return weight_q\n",
    "\n",
    "\n",
    "def conv2d_Q_fn(w_bit):\n",
    "  class Conv2d_Q(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=True):\n",
    "      super(Conv2d_Q, self).__init__(in_channels, out_channels, kernel_size, stride,\n",
    "                                     padding, dilation, groups, bias)\n",
    "      self.w_bit = w_bit\n",
    "      self.quantize_fn = weight_quantize_fn(w_bit=w_bit)\n",
    "\n",
    "    def forward(self, input, order=None):\n",
    "      weight_q = self.quantize_fn(self.weight)\n",
    "      return F.conv2d(input, weight_q, self.bias, self.stride,\n",
    "                      self.padding, self.dilation, self.groups)\n",
    "\n",
    "  return Conv2d_Q\n",
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    \"\"\"\n",
    "    This function is taken from the original tf repo.\n",
    "    It ensures that all layers have a channel number that is divisible by 8\n",
    "    It can be seen here:\n",
    "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    :param v:\n",
    "    :param divisor:\n",
    "    :param min_value:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "class activation_quantize_fn(nn.Module):\n",
    "  def __init__(self, a_bit):\n",
    "    super(activation_quantize_fn, self).__init__()\n",
    "    assert a_bit <= 8 or a_bit == 32\n",
    "    self.a_bit = a_bit\n",
    "    self.uniform_q = uniform_quantize(k=a_bit)\n",
    "\n",
    "  def forward(self, x):\n",
    "    if self.a_bit == 32:\n",
    "      activation_q = x\n",
    "    else:\n",
    "      activation_q = self.uniform_q(torch.clamp(x, 0, 1))\n",
    "    return activation_q\n",
    "\n",
    "\n",
    "def conv3x3_bn_Q(inp, oup, stride, padding):\n",
    "    return nn.Sequential(\n",
    "        conv2d_Q_fn(W_BIT)(inp, oup, kernel_size=3, stride=stride, padding=padding, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        activation_quantize_fn(A_BIT) #ReLU\n",
    "    )\n",
    "\n",
    "# the last conv block\n",
    "def conv1x1_bn_Q(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        conv2d_Q_fn(W_BIT)(inp, oup, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        activation_quantize_fn(A_BIT) #ReLU\n",
    "    )\n",
    "\n",
    "class InvertedResidual_Q(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio):\n",
    "        super(InvertedResidual_Q, self).__init__()\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = round(inp * expand_ratio)\n",
    "        self.identity = stride == 1 and inp == oup\n",
    "\n",
    "        if expand_ratio == 1: # the first bottleneck\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                conv2d_Q_fn(W_BIT)(hidden_dim, hidden_dim, kernel_size=3, stride=stride, padding=1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                activation_quantize_fn(A_BIT), #ReLU\n",
    "                # pw\n",
    "                conv2d_Q_fn(W_BIT)(hidden_dim, oup, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                conv2d_Q_fn(W_BIT)(inp, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                activation_quantize_fn(A_BIT), #ReLU\n",
    "                # dw\n",
    "                conv2d_Q_fn(W_BIT)(hidden_dim, hidden_dim, kernel_size=3, stride=stride, padding=1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                activation_quantize_fn(A_BIT), #ReLU\n",
    "                # pw\n",
    "                conv2d_Q_fn(W_BIT)(hidden_dim, oup, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.identity:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "class MobileNetV2_Q(nn.Module):\n",
    "    def __init__(self, num_classes=1000, width_mult=1.):\n",
    "        super(MobileNetV2_Q, self).__init__()\n",
    "        # setting of inverted residual blocks\n",
    "        self.cfgs = [\n",
    "            # t, c, n, s\n",
    "            [1,  16, 1, 1],\n",
    "            [6,  24, 2, 2],\n",
    "            [6,  32, 3, 2],\n",
    "            [6,  64, 4, 2],\n",
    "            [6,  96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1],\n",
    "        ]\n",
    "\n",
    "        # building first layer\n",
    "        input_channel = _make_divisible(32 * width_mult, 4 if width_mult == 0.1 else 8)\n",
    "        layers = [conv3x3_bn_Q(3, input_channel, 2, 1)]\n",
    "\n",
    "        # building inverted residual blocks\n",
    "        block = InvertedResidual_Q\n",
    "\n",
    "        for t, c, n, s in self.cfgs:\n",
    "            output_channel = _make_divisible(c * width_mult, 4 if width_mult == 0.1 else 8)\n",
    "            for i in range(n):\n",
    "                layers.append(block(input_channel, output_channel, s if i == 0 else 1, t))\n",
    "                input_channel = output_channel\n",
    "        self.features = nn.Sequential(*layers)\n",
    "\n",
    "        # building last several layers\n",
    "        output_channel = _make_divisible(1280 * width_mult, 4 if width_mult == 0.1 else 8) if width_mult > 1.0 else 1280\n",
    "        self.conv = conv1x1_bn_Q(input_channel, output_channel)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Linear(output_channel, num_classes)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "democratic-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#宏定义一些数据，如epoch数，batchsize等\n",
    "MAX_EPOCH=250\n",
    "BATCH_SIZE=3\n",
    "LR=0.0001\n",
    "log_interval=6\n",
    "val_interval=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "equipped-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ step 1/5 数据 ============================\n",
    "split_dir=os.path.join(\".\",\"data\",\"splitData\")\n",
    "train_dir=os.path.join(split_dir,\"train\")\n",
    "valid_dir=os.path.join(split_dir,\"valid\")\n",
    "\n",
    "#对训练集所需要做的预处理\n",
    "train_transform=transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "#对验证集所需要做的预处理\n",
    "valid_transform=transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 构建MyDataset实例\n",
    "train_data=flowerDataset(data_dir=train_dir,transform=train_transform)\n",
    "valid_data=flowerDataset(data_dir=valid_dir,transform=valid_transform)\n",
    "\n",
    "# 构建DataLoader\n",
    "# 训练集数据最好打乱\n",
    "# DataLoader的实质就是把数据集加上一个索引号，再返回\n",
    "train_loader=DataLoader(dataset=train_data,batch_size=BATCH_SIZE,shuffle=True)\n",
    "valid_loader=DataLoader(dataset=valid_data,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "educational-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ step 2/5 模型 ============================\n",
    "net = MobileNetV2_Q(num_classes=17, width_mult=1.)\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "expanded-frost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1000])\n",
      "tensor([[ 0.1063, -0.1091,  0.0678,  ...,  0.0661,  0.0088,  0.0955],\n",
      "        [ 0.1383, -0.0808,  0.1069,  ...,  0.0698,  0.0166,  0.0952]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    net=MobileNetV2_Q()\n",
    "    x=torch.randn(2,3,224,224)\n",
    "    y=net(x)\n",
    "    print(y.size())\n",
    "    print(y)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "underlying-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ step 3/5 损失函数 ============================\n",
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "greater-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================ step 4/5 优化器 ============================\n",
    "optimizer=optim.Adam(net.parameters(),lr=LR, betas=(0.9, 0.99))# 选择优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "forbidden-appliance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1,loss:2.9538\n",
      "epoch:1,loss:2.8270\n",
      "epoch:1,loss:2.9923\n",
      "epoch:1,loss:2.9392\n",
      "epoch:1,loss:2.9183\n",
      "epoch:1,loss:2.8458\n",
      "epoch:1,loss:2.8929\n",
      "epoch:1,loss:2.7588\n",
      "epoch:1,loss:2.6298\n",
      "epoch:1,loss:2.7325\n",
      "epoch:1,loss:2.5322\n",
      "epoch:1,loss:2.7869\n",
      "epoch:1,loss:2.6848\n",
      "epoch:1,loss:2.7512\n",
      "epoch:1,loss:2.9606\n",
      "epoch:1,loss:2.8645\n",
      "epoch:1,loss:2.7229\n",
      "epoch:1,loss:3.0160\n",
      "epoch:1,loss:2.6878\n",
      "epoch:1,loss:2.7180\n",
      "epoch:1,loss:2.8588\n",
      "epoch:1,loss:2.7943\n",
      "epoch:1,loss:2.8608\n",
      "epoch:1,loss:2.8489\n",
      "epoch:1,loss:2.8594\n",
      "epoch:1,loss:2.7971\n",
      "epoch:1,loss:2.8849\n",
      "epoch:1,loss:2.8680\n",
      "epoch:1,loss:2.7485\n",
      "epoch:1,loss:2.7330\n",
      "epoch:1,loss:2.9440\n",
      "epoch:1,loss:2.9263\n",
      "epoch:1,loss:2.8460\n",
      "epoch:1,loss:2.8862\n",
      "epoch:1,loss:2.8266\n",
      "epoch:1,loss:2.8539\n",
      "epoch:1,loss:2.8333\n",
      "epoch:1,loss:2.7962\n",
      "epoch:1,loss:2.7329\n",
      "epoch:1,loss:3.0261\n",
      "epoch:1,loss:2.9891\n",
      "epoch:1,loss:2.8130\n",
      "epoch:1,loss:2.8407\n",
      "epoch:1,loss:2.7957\n",
      "epoch:1,loss:2.7138\n",
      "epoch:1,loss:2.7205\n",
      "epoch:1,loss:2.9151\n",
      "epoch:1,loss:2.8952\n",
      "epoch:1,loss:2.7942\n",
      "epoch:1,loss:2.8611\n",
      "epoch:1,loss:2.7461\n",
      "epoch:1,loss:2.9477\n",
      "epoch:1,loss:2.9165\n",
      "epoch:1,loss:2.9497\n",
      "epoch:1,loss:2.8528\n",
      "epoch:1,loss:3.0541\n",
      "epoch:1,loss:2.9961\n",
      "epoch:1,loss:2.8905\n",
      "epoch:1,loss:2.9481\n",
      "epoch:1,loss:3.0437\n",
      "============================================\n",
      "准确率由： 0.0 上升至： tensor(0.0487) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第1个epoch的识别准确率为：4%\n",
      "epoch:2,loss:2.7445\n",
      "epoch:2,loss:2.7074\n",
      "epoch:2,loss:2.7491\n",
      "epoch:2,loss:2.7597\n",
      "epoch:2,loss:2.9878\n",
      "epoch:2,loss:2.8581\n",
      "epoch:2,loss:2.8570\n",
      "epoch:2,loss:2.8027\n",
      "epoch:2,loss:2.7767\n",
      "epoch:2,loss:2.8160\n",
      "epoch:2,loss:2.7736\n",
      "epoch:2,loss:2.7628\n",
      "epoch:2,loss:2.9201\n",
      "epoch:2,loss:2.8811\n",
      "epoch:2,loss:2.9085\n",
      "epoch:2,loss:3.0321\n",
      "epoch:2,loss:2.7183\n",
      "epoch:2,loss:2.8965\n",
      "epoch:2,loss:2.8446\n",
      "epoch:2,loss:2.9364\n",
      "epoch:2,loss:2.7208\n",
      "epoch:2,loss:2.7421\n",
      "epoch:2,loss:2.7079\n",
      "epoch:2,loss:2.7482\n",
      "epoch:2,loss:2.8878\n",
      "epoch:2,loss:2.5726\n",
      "epoch:2,loss:2.8534\n",
      "epoch:2,loss:2.9329\n",
      "epoch:2,loss:2.8305\n",
      "epoch:2,loss:2.8067\n",
      "epoch:2,loss:2.4948\n",
      "epoch:2,loss:2.8775\n",
      "epoch:2,loss:2.7310\n",
      "epoch:2,loss:2.7166\n",
      "epoch:2,loss:2.7372\n",
      "epoch:2,loss:2.4092\n",
      "epoch:2,loss:2.9192\n",
      "epoch:2,loss:2.8845\n",
      "epoch:2,loss:2.8533\n",
      "epoch:2,loss:2.8402\n",
      "epoch:2,loss:2.9722\n",
      "epoch:2,loss:2.7383\n",
      "epoch:2,loss:2.6853\n",
      "epoch:2,loss:2.6161\n",
      "epoch:2,loss:2.7603\n",
      "epoch:2,loss:2.6984\n",
      "epoch:2,loss:2.6051\n",
      "epoch:2,loss:2.7538\n",
      "epoch:2,loss:2.7539\n",
      "epoch:2,loss:2.7891\n",
      "epoch:2,loss:2.5656\n",
      "epoch:2,loss:3.1000\n",
      "epoch:2,loss:2.6268\n",
      "epoch:2,loss:3.1501\n",
      "epoch:2,loss:3.0106\n",
      "epoch:2,loss:2.9811\n",
      "epoch:2,loss:2.3546\n",
      "epoch:2,loss:2.5506\n",
      "epoch:2,loss:2.7874\n",
      "epoch:2,loss:2.7620\n",
      "============================================\n",
      "准确率由： tensor(0.0487) 上升至： tensor(0.0873) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第2个epoch的识别准确率为：8%\n",
      "epoch:3,loss:2.7002\n",
      "epoch:3,loss:2.5990\n",
      "epoch:3,loss:3.0677\n",
      "epoch:3,loss:2.5961\n",
      "epoch:3,loss:2.7040\n",
      "epoch:3,loss:3.1426\n",
      "epoch:3,loss:2.7773\n",
      "epoch:3,loss:2.7506\n",
      "epoch:3,loss:2.4101\n",
      "epoch:3,loss:2.6063\n",
      "epoch:3,loss:2.8121\n",
      "epoch:3,loss:2.8675\n",
      "epoch:3,loss:2.6005\n",
      "epoch:3,loss:3.1482\n",
      "epoch:3,loss:2.1574\n",
      "epoch:3,loss:2.9806\n",
      "epoch:3,loss:2.9411\n",
      "epoch:3,loss:2.6588\n",
      "epoch:3,loss:2.3566\n",
      "epoch:3,loss:2.2300\n",
      "epoch:3,loss:2.1659\n",
      "epoch:3,loss:2.7960\n",
      "epoch:3,loss:2.8558\n",
      "epoch:3,loss:2.5727\n",
      "epoch:3,loss:2.9408\n",
      "epoch:3,loss:3.0148\n",
      "epoch:3,loss:2.2265\n",
      "epoch:3,loss:2.4022\n",
      "epoch:3,loss:2.9925\n",
      "epoch:3,loss:3.1408\n",
      "epoch:3,loss:2.8979\n",
      "epoch:3,loss:2.6031\n",
      "epoch:3,loss:2.9555\n",
      "epoch:3,loss:2.9908\n",
      "epoch:3,loss:2.6790\n",
      "epoch:3,loss:2.2454\n",
      "epoch:3,loss:2.8977\n",
      "epoch:3,loss:2.9478\n",
      "epoch:3,loss:2.8906\n",
      "epoch:3,loss:2.9163\n",
      "epoch:3,loss:2.8527\n",
      "epoch:3,loss:2.6934\n",
      "epoch:3,loss:2.8243\n",
      "epoch:3,loss:2.7915\n",
      "epoch:3,loss:2.8127\n",
      "epoch:3,loss:2.5148\n",
      "epoch:3,loss:2.4735\n",
      "epoch:3,loss:2.6313\n",
      "epoch:3,loss:2.7625\n",
      "epoch:3,loss:2.6749\n",
      "epoch:3,loss:2.7388\n",
      "epoch:3,loss:2.4126\n",
      "epoch:3,loss:2.8120\n",
      "epoch:3,loss:2.8601\n",
      "epoch:3,loss:3.1195\n",
      "epoch:3,loss:2.7227\n",
      "epoch:3,loss:2.4417\n",
      "epoch:3,loss:3.0133\n",
      "epoch:3,loss:3.1769\n",
      "epoch:3,loss:2.6920\n",
      "============================================\n",
      "准确率由： tensor(0.0873) 上升至： tensor(0.0965) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第3个epoch的识别准确率为：9%\n",
      "epoch:4,loss:2.4095\n",
      "epoch:4,loss:2.7153\n",
      "epoch:4,loss:2.6304\n",
      "epoch:4,loss:2.3114\n",
      "epoch:4,loss:2.5877\n",
      "epoch:4,loss:2.5248\n",
      "epoch:4,loss:3.1178\n",
      "epoch:4,loss:2.7351\n",
      "epoch:4,loss:2.8793\n",
      "epoch:4,loss:2.7776\n",
      "epoch:4,loss:3.1577\n",
      "epoch:4,loss:2.8278\n",
      "epoch:4,loss:2.6099\n",
      "epoch:4,loss:2.6195\n",
      "epoch:4,loss:2.6490\n",
      "epoch:4,loss:3.1545\n",
      "epoch:4,loss:2.7064\n",
      "epoch:4,loss:2.8811\n",
      "epoch:4,loss:2.3339\n",
      "epoch:4,loss:2.5269\n",
      "epoch:4,loss:2.7267\n",
      "epoch:4,loss:2.8265\n",
      "epoch:4,loss:2.6245\n",
      "epoch:4,loss:2.6431\n",
      "epoch:4,loss:2.2304\n",
      "epoch:4,loss:2.4724\n",
      "epoch:4,loss:2.8108\n",
      "epoch:4,loss:2.4863\n",
      "epoch:4,loss:2.5807\n",
      "epoch:4,loss:2.3285\n",
      "epoch:4,loss:2.9437\n",
      "epoch:4,loss:2.5430\n",
      "epoch:4,loss:2.8717\n",
      "epoch:4,loss:2.6238\n",
      "epoch:4,loss:2.3942\n",
      "epoch:4,loss:2.5467\n",
      "epoch:4,loss:2.4870\n",
      "epoch:4,loss:3.0512\n",
      "epoch:4,loss:2.8830\n",
      "epoch:4,loss:2.5162\n",
      "epoch:4,loss:2.5626\n",
      "epoch:4,loss:2.8983\n",
      "epoch:4,loss:2.6377\n",
      "epoch:4,loss:2.1332\n",
      "epoch:4,loss:2.6358\n",
      "epoch:4,loss:2.6460\n",
      "epoch:4,loss:2.8896\n",
      "epoch:4,loss:2.2871\n",
      "epoch:4,loss:2.3156\n",
      "epoch:4,loss:2.8500\n",
      "epoch:4,loss:2.5338\n",
      "epoch:4,loss:3.1883\n",
      "epoch:4,loss:2.6283\n",
      "epoch:4,loss:2.4798\n",
      "epoch:4,loss:2.6893\n",
      "epoch:4,loss:2.7715\n",
      "epoch:4,loss:2.5380\n",
      "epoch:4,loss:2.7049\n",
      "epoch:4,loss:2.5298\n",
      "epoch:4,loss:2.9071\n",
      "============================================\n",
      "准确率由： tensor(0.0965) 上升至： tensor(0.1048) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第4个epoch的识别准确率为：10%\n",
      "epoch:5,loss:2.5503\n",
      "epoch:5,loss:2.8558\n",
      "epoch:5,loss:2.9349\n",
      "epoch:5,loss:2.3341\n",
      "epoch:5,loss:2.5724\n",
      "epoch:5,loss:2.4923\n",
      "epoch:5,loss:2.5559\n",
      "epoch:5,loss:2.8173\n",
      "epoch:5,loss:2.3657\n",
      "epoch:5,loss:3.0377\n",
      "epoch:5,loss:3.1626\n",
      "epoch:5,loss:3.0997\n",
      "epoch:5,loss:2.5448\n",
      "epoch:5,loss:2.5817\n",
      "epoch:5,loss:2.2020\n",
      "epoch:5,loss:2.6550\n",
      "epoch:5,loss:2.5290\n",
      "epoch:5,loss:2.4832\n",
      "epoch:5,loss:2.9000\n",
      "epoch:5,loss:2.5611\n",
      "epoch:5,loss:2.5961\n",
      "epoch:5,loss:2.6057\n",
      "epoch:5,loss:2.4094\n",
      "epoch:5,loss:2.8719\n",
      "epoch:5,loss:2.5519\n",
      "epoch:5,loss:2.5053\n",
      "epoch:5,loss:2.7991\n",
      "epoch:5,loss:2.7138\n",
      "epoch:5,loss:2.8126\n",
      "epoch:5,loss:2.7087\n",
      "epoch:5,loss:2.4796\n",
      "epoch:5,loss:2.6875\n",
      "epoch:5,loss:2.6316\n",
      "epoch:5,loss:2.0313\n",
      "epoch:5,loss:2.3751\n",
      "epoch:5,loss:2.5003\n",
      "epoch:5,loss:2.2811\n",
      "epoch:5,loss:2.3497\n",
      "epoch:5,loss:2.4569\n",
      "epoch:5,loss:3.4196\n",
      "epoch:5,loss:2.5698\n",
      "epoch:5,loss:2.4403\n",
      "epoch:5,loss:2.5868\n",
      "epoch:5,loss:3.0105\n",
      "epoch:5,loss:3.1392\n",
      "epoch:5,loss:2.8989\n",
      "epoch:5,loss:2.5986\n",
      "epoch:5,loss:2.5981\n",
      "epoch:5,loss:3.0794\n",
      "epoch:5,loss:2.0447\n",
      "epoch:5,loss:2.1580\n",
      "epoch:5,loss:1.9415\n",
      "epoch:5,loss:2.0708\n",
      "epoch:5,loss:2.8396\n",
      "epoch:5,loss:1.9309\n",
      "epoch:5,loss:1.8626\n",
      "epoch:5,loss:3.0344\n",
      "epoch:5,loss:2.6094\n",
      "epoch:5,loss:2.8725\n",
      "epoch:5,loss:2.7105\n",
      "============================================\n",
      "准确率由： tensor(0.1048) 上升至： tensor(0.1167) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第5个epoch的识别准确率为：11%\n",
      "epoch:6,loss:2.9812\n",
      "epoch:6,loss:3.3670\n",
      "epoch:6,loss:2.5460\n",
      "epoch:6,loss:2.8311\n",
      "epoch:6,loss:3.2139\n",
      "epoch:6,loss:2.1625\n",
      "epoch:6,loss:3.0755\n",
      "epoch:6,loss:2.1989\n",
      "epoch:6,loss:2.8971\n",
      "epoch:6,loss:2.2675\n",
      "epoch:6,loss:2.3255\n",
      "epoch:6,loss:3.3921\n",
      "epoch:6,loss:2.3760\n",
      "epoch:6,loss:2.3843\n",
      "epoch:6,loss:2.5806\n",
      "epoch:6,loss:1.9602\n",
      "epoch:6,loss:2.9847\n",
      "epoch:6,loss:2.7828\n",
      "epoch:6,loss:2.6348\n",
      "epoch:6,loss:2.3737\n",
      "epoch:6,loss:2.5769\n",
      "epoch:6,loss:3.0763\n",
      "epoch:6,loss:2.4090\n",
      "epoch:6,loss:2.7781\n",
      "epoch:6,loss:2.4212\n",
      "epoch:6,loss:2.1543\n",
      "epoch:6,loss:2.8563\n",
      "epoch:6,loss:2.3963\n",
      "epoch:6,loss:3.0072\n",
      "epoch:6,loss:2.8208\n",
      "epoch:6,loss:2.5425\n",
      "epoch:6,loss:2.3443\n",
      "epoch:6,loss:2.7331\n",
      "epoch:6,loss:2.6017\n",
      "epoch:6,loss:2.2543\n",
      "epoch:6,loss:2.6699\n",
      "epoch:6,loss:3.4317\n",
      "epoch:6,loss:2.8196\n",
      "epoch:6,loss:2.6567\n",
      "epoch:6,loss:2.6277\n",
      "epoch:6,loss:2.5899\n",
      "epoch:6,loss:2.8582\n",
      "epoch:6,loss:2.7297\n",
      "epoch:6,loss:2.8915\n",
      "epoch:6,loss:3.1699\n",
      "epoch:6,loss:2.7780\n",
      "epoch:6,loss:2.3731\n",
      "epoch:6,loss:3.1314\n",
      "epoch:6,loss:2.3757\n",
      "epoch:6,loss:3.0333\n",
      "epoch:6,loss:2.2414\n",
      "epoch:6,loss:2.1412\n",
      "epoch:6,loss:2.1431\n",
      "epoch:6,loss:2.9435\n",
      "epoch:6,loss:2.6007\n",
      "epoch:6,loss:3.0161\n",
      "epoch:6,loss:2.7207\n",
      "epoch:6,loss:2.9044\n",
      "epoch:6,loss:2.4469\n",
      "epoch:6,loss:2.1517\n",
      "============================================\n",
      "准确率由： tensor(0.1167) 上升至： tensor(0.1232) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第6个epoch的识别准确率为：12%\n",
      "epoch:7,loss:2.9364\n",
      "epoch:7,loss:2.2418\n",
      "epoch:7,loss:3.2349\n",
      "epoch:7,loss:2.3178\n",
      "epoch:7,loss:2.3346\n",
      "epoch:7,loss:2.1041\n",
      "epoch:7,loss:2.6052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7,loss:2.4407\n",
      "epoch:7,loss:2.8512\n",
      "epoch:7,loss:2.5002\n",
      "epoch:7,loss:2.2868\n",
      "epoch:7,loss:2.8579\n",
      "epoch:7,loss:2.6264\n",
      "epoch:7,loss:2.4164\n",
      "epoch:7,loss:2.2308\n",
      "epoch:7,loss:2.5432\n",
      "epoch:7,loss:2.0660\n",
      "epoch:7,loss:2.4267\n",
      "epoch:7,loss:3.6236\n",
      "epoch:7,loss:3.6331\n",
      "epoch:7,loss:2.9448\n",
      "epoch:7,loss:2.3880\n",
      "epoch:7,loss:2.9637\n",
      "epoch:7,loss:2.6526\n",
      "epoch:7,loss:2.5904\n",
      "epoch:7,loss:2.7297\n",
      "epoch:7,loss:2.4544\n",
      "epoch:7,loss:2.6050\n",
      "epoch:7,loss:2.1212\n",
      "epoch:7,loss:2.7348\n",
      "epoch:7,loss:2.9996\n",
      "epoch:7,loss:2.9841\n",
      "epoch:7,loss:2.9647\n",
      "epoch:7,loss:3.4461\n",
      "epoch:7,loss:2.5399\n",
      "epoch:7,loss:2.3471\n",
      "epoch:7,loss:2.6957\n",
      "epoch:7,loss:2.6162\n",
      "epoch:7,loss:2.7523\n",
      "epoch:7,loss:3.1150\n",
      "epoch:7,loss:2.2120\n",
      "epoch:7,loss:2.7710\n",
      "epoch:7,loss:2.3937\n",
      "epoch:7,loss:2.1308\n",
      "epoch:7,loss:2.5488\n",
      "epoch:7,loss:2.5515\n",
      "epoch:7,loss:2.5581\n",
      "epoch:7,loss:2.3707\n",
      "epoch:7,loss:2.6052\n",
      "epoch:7,loss:2.2912\n",
      "epoch:7,loss:2.9706\n",
      "epoch:7,loss:2.9026\n",
      "epoch:7,loss:2.8467\n",
      "epoch:7,loss:2.9283\n",
      "epoch:7,loss:2.7147\n",
      "epoch:7,loss:3.2492\n",
      "epoch:7,loss:2.1454\n",
      "epoch:7,loss:3.1902\n",
      "epoch:7,loss:2.8052\n",
      "epoch:7,loss:2.7439\n",
      "============================================\n",
      "准确率由： tensor(0.1232) 上升至： tensor(0.1434) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第7个epoch的识别准确率为：14%\n",
      "epoch:8,loss:2.9884\n",
      "epoch:8,loss:3.1227\n",
      "epoch:8,loss:2.5417\n",
      "epoch:8,loss:2.7515\n",
      "epoch:8,loss:2.7470\n",
      "epoch:8,loss:2.4460\n",
      "epoch:8,loss:2.2701\n",
      "epoch:8,loss:1.6903\n",
      "epoch:8,loss:3.0216\n",
      "epoch:8,loss:2.4223\n",
      "epoch:8,loss:2.2855\n",
      "epoch:8,loss:2.2434\n",
      "epoch:8,loss:2.4835\n",
      "epoch:8,loss:1.9939\n",
      "epoch:8,loss:2.7790\n",
      "epoch:8,loss:3.1507\n",
      "epoch:8,loss:2.7751\n",
      "epoch:8,loss:2.8791\n",
      "epoch:8,loss:2.8329\n",
      "epoch:8,loss:2.6092\n",
      "epoch:8,loss:2.3137\n",
      "epoch:8,loss:2.4256\n",
      "epoch:8,loss:2.0861\n",
      "epoch:8,loss:2.5536\n",
      "epoch:8,loss:2.4298\n",
      "epoch:8,loss:2.2828\n",
      "epoch:8,loss:2.1369\n",
      "epoch:8,loss:2.4779\n",
      "epoch:8,loss:2.5178\n",
      "epoch:8,loss:2.8440\n",
      "epoch:8,loss:2.7633\n",
      "epoch:8,loss:3.0444\n",
      "epoch:8,loss:2.4344\n",
      "epoch:8,loss:2.5869\n",
      "epoch:8,loss:2.0938\n",
      "epoch:8,loss:2.6954\n",
      "epoch:8,loss:2.0412\n",
      "epoch:8,loss:2.5662\n",
      "epoch:8,loss:2.9533\n",
      "epoch:8,loss:2.3118\n",
      "epoch:8,loss:3.2748\n",
      "epoch:8,loss:2.3349\n",
      "epoch:8,loss:2.4551\n",
      "epoch:8,loss:2.9808\n",
      "epoch:8,loss:2.8410\n",
      "epoch:8,loss:2.6419\n",
      "epoch:8,loss:3.6863\n",
      "epoch:8,loss:2.0726\n",
      "epoch:8,loss:2.8462\n",
      "epoch:8,loss:2.5599\n",
      "epoch:8,loss:2.2371\n",
      "epoch:8,loss:2.2417\n",
      "epoch:8,loss:2.5884\n",
      "epoch:8,loss:2.2227\n",
      "epoch:8,loss:2.3432\n",
      "epoch:8,loss:2.2807\n",
      "epoch:8,loss:2.4667\n",
      "epoch:8,loss:2.5448\n",
      "epoch:8,loss:2.5026\n",
      "epoch:8,loss:2.2405\n",
      "============================================\n",
      "第8个epoch的识别准确率为：14%\n",
      "epoch:9,loss:2.8250\n",
      "epoch:9,loss:2.3170\n",
      "epoch:9,loss:2.3186\n",
      "epoch:9,loss:2.2701\n",
      "epoch:9,loss:2.6197\n",
      "epoch:9,loss:2.2326\n",
      "epoch:9,loss:2.1471\n",
      "epoch:9,loss:2.4055\n",
      "epoch:9,loss:2.6678\n",
      "epoch:9,loss:2.4066\n",
      "epoch:9,loss:2.3538\n",
      "epoch:9,loss:2.3187\n",
      "epoch:9,loss:2.7992\n",
      "epoch:9,loss:2.9050\n",
      "epoch:9,loss:2.4108\n",
      "epoch:9,loss:2.4766\n",
      "epoch:9,loss:2.7298\n",
      "epoch:9,loss:2.6427\n",
      "epoch:9,loss:2.6449\n",
      "epoch:9,loss:2.3291\n",
      "epoch:9,loss:2.9538\n",
      "epoch:9,loss:2.2493\n",
      "epoch:9,loss:2.1703\n",
      "epoch:9,loss:2.5503\n",
      "epoch:9,loss:2.6539\n",
      "epoch:9,loss:2.3566\n",
      "epoch:9,loss:3.0046\n",
      "epoch:9,loss:2.7417\n",
      "epoch:9,loss:2.5416\n",
      "epoch:9,loss:2.9606\n",
      "epoch:9,loss:2.7812\n",
      "epoch:9,loss:2.7989\n",
      "epoch:9,loss:2.7918\n",
      "epoch:9,loss:2.6633\n",
      "epoch:9,loss:2.8822\n",
      "epoch:9,loss:2.3454\n",
      "epoch:9,loss:2.9706\n",
      "epoch:9,loss:2.0158\n",
      "epoch:9,loss:2.7821\n",
      "epoch:9,loss:2.8860\n",
      "epoch:9,loss:2.6594\n",
      "epoch:9,loss:2.6447\n",
      "epoch:9,loss:2.4086\n",
      "epoch:9,loss:2.2059\n",
      "epoch:9,loss:2.7021\n",
      "epoch:9,loss:2.6435\n",
      "epoch:9,loss:3.3357\n",
      "epoch:9,loss:2.1851\n",
      "epoch:9,loss:2.0980\n",
      "epoch:9,loss:2.9048\n",
      "epoch:9,loss:2.9404\n",
      "epoch:9,loss:3.5884\n",
      "epoch:9,loss:2.9050\n",
      "epoch:9,loss:2.0022\n",
      "epoch:9,loss:2.3887\n",
      "epoch:9,loss:2.0454\n",
      "epoch:9,loss:2.3591\n",
      "epoch:9,loss:3.0448\n",
      "epoch:9,loss:2.4449\n",
      "epoch:9,loss:2.5047\n",
      "============================================\n",
      "第9个epoch的识别准确率为：13%\n",
      "epoch:10,loss:2.9895\n",
      "epoch:10,loss:2.6037\n",
      "epoch:10,loss:2.7064\n",
      "epoch:10,loss:2.9864\n",
      "epoch:10,loss:2.8216\n",
      "epoch:10,loss:2.5718\n",
      "epoch:10,loss:2.4792\n",
      "epoch:10,loss:2.2187\n",
      "epoch:10,loss:2.7941\n",
      "epoch:10,loss:2.6097\n",
      "epoch:10,loss:2.3565\n",
      "epoch:10,loss:2.8167\n",
      "epoch:10,loss:2.7226\n",
      "epoch:10,loss:2.1209\n",
      "epoch:10,loss:2.6196\n",
      "epoch:10,loss:3.2305\n",
      "epoch:10,loss:2.7445\n",
      "epoch:10,loss:2.6223\n",
      "epoch:10,loss:2.8118\n",
      "epoch:10,loss:2.1770\n",
      "epoch:10,loss:2.3365\n",
      "epoch:10,loss:2.0930\n",
      "epoch:10,loss:2.5537\n",
      "epoch:10,loss:3.1501\n",
      "epoch:10,loss:2.8618\n",
      "epoch:10,loss:2.7070\n",
      "epoch:10,loss:2.3636\n",
      "epoch:10,loss:2.5015\n",
      "epoch:10,loss:2.8151\n",
      "epoch:10,loss:2.4418\n",
      "epoch:10,loss:2.8208\n",
      "epoch:10,loss:2.2236\n",
      "epoch:10,loss:2.1601\n",
      "epoch:10,loss:2.6853\n",
      "epoch:10,loss:3.5870\n",
      "epoch:10,loss:1.9232\n",
      "epoch:10,loss:3.1875\n",
      "epoch:10,loss:2.2997\n",
      "epoch:10,loss:2.2996\n",
      "epoch:10,loss:2.4205\n",
      "epoch:10,loss:2.0884\n",
      "epoch:10,loss:3.1285\n",
      "epoch:10,loss:1.8922\n",
      "epoch:10,loss:2.5841\n",
      "epoch:10,loss:2.4669\n",
      "epoch:10,loss:2.1880\n",
      "epoch:10,loss:3.4042\n",
      "epoch:10,loss:2.5457\n",
      "epoch:10,loss:2.9573\n",
      "epoch:10,loss:2.1261\n",
      "epoch:10,loss:3.0557\n",
      "epoch:10,loss:2.6286\n",
      "epoch:10,loss:2.7648\n",
      "epoch:10,loss:2.9821\n",
      "epoch:10,loss:3.2349\n",
      "epoch:10,loss:2.4866\n",
      "epoch:10,loss:2.6077\n",
      "epoch:10,loss:2.7496\n",
      "epoch:10,loss:2.7421\n",
      "epoch:10,loss:2.5677\n",
      "============================================\n",
      "第10个epoch的识别准确率为：13%\n",
      "epoch:11,loss:2.5276\n",
      "epoch:11,loss:2.4334\n",
      "epoch:11,loss:2.5792\n",
      "epoch:11,loss:2.1326\n",
      "epoch:11,loss:2.2692\n",
      "epoch:11,loss:2.4632\n",
      "epoch:11,loss:2.1553\n",
      "epoch:11,loss:2.2804\n",
      "epoch:11,loss:2.6757\n",
      "epoch:11,loss:3.0042\n",
      "epoch:11,loss:2.7625\n",
      "epoch:11,loss:2.4692\n",
      "epoch:11,loss:2.3768\n",
      "epoch:11,loss:2.3160\n",
      "epoch:11,loss:2.8548\n",
      "epoch:11,loss:2.7172\n",
      "epoch:11,loss:2.3423\n",
      "epoch:11,loss:2.8711\n",
      "epoch:11,loss:1.9195\n",
      "epoch:11,loss:2.4356\n",
      "epoch:11,loss:2.4775\n",
      "epoch:11,loss:3.2089\n",
      "epoch:11,loss:2.9615\n",
      "epoch:11,loss:2.2637\n",
      "epoch:11,loss:1.8336\n",
      "epoch:11,loss:2.1142\n",
      "epoch:11,loss:2.0575\n",
      "epoch:11,loss:3.0722\n",
      "epoch:11,loss:2.6185\n",
      "epoch:11,loss:2.9529\n",
      "epoch:11,loss:2.3253\n",
      "epoch:11,loss:2.8332\n",
      "epoch:11,loss:2.7176\n",
      "epoch:11,loss:2.2387\n",
      "epoch:11,loss:2.9533\n",
      "epoch:11,loss:2.4366\n",
      "epoch:11,loss:2.3909\n",
      "epoch:11,loss:2.8948\n",
      "epoch:11,loss:2.0952\n",
      "epoch:11,loss:2.4374\n",
      "epoch:11,loss:2.5539\n",
      "epoch:11,loss:3.2002\n",
      "epoch:11,loss:2.1892\n",
      "epoch:11,loss:2.0754\n",
      "epoch:11,loss:2.0958\n",
      "epoch:11,loss:2.2609\n",
      "epoch:11,loss:1.7216\n",
      "epoch:11,loss:2.3586\n",
      "epoch:11,loss:2.3513\n",
      "epoch:11,loss:3.1237\n",
      "epoch:11,loss:2.3096\n",
      "epoch:11,loss:2.8597\n",
      "epoch:11,loss:3.1439\n",
      "epoch:11,loss:3.5919\n",
      "epoch:11,loss:2.3687\n",
      "epoch:11,loss:2.0987\n",
      "epoch:11,loss:1.9560\n",
      "epoch:11,loss:1.8856\n",
      "epoch:11,loss:2.1554\n",
      "epoch:11,loss:2.5494\n",
      "============================================\n",
      "准确率由： tensor(0.1434) 上升至： tensor(0.1553) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第11个epoch的识别准确率为：15%\n",
      "epoch:12,loss:1.8271\n",
      "epoch:12,loss:2.6202\n",
      "epoch:12,loss:2.8518\n",
      "epoch:12,loss:2.1815\n",
      "epoch:12,loss:2.4001\n",
      "epoch:12,loss:2.1217\n",
      "epoch:12,loss:2.3702\n",
      "epoch:12,loss:2.5626\n",
      "epoch:12,loss:2.2668\n",
      "epoch:12,loss:2.0221\n",
      "epoch:12,loss:2.2371\n",
      "epoch:12,loss:2.9805\n",
      "epoch:12,loss:3.0049\n",
      "epoch:12,loss:2.2760\n",
      "epoch:12,loss:2.6040\n",
      "epoch:12,loss:2.5992\n",
      "epoch:12,loss:2.2216\n",
      "epoch:12,loss:2.3325\n",
      "epoch:12,loss:1.9320\n",
      "epoch:12,loss:2.2168\n",
      "epoch:12,loss:2.0594\n",
      "epoch:12,loss:2.0658\n",
      "epoch:12,loss:2.4760\n",
      "epoch:12,loss:2.2527\n",
      "epoch:12,loss:2.6589\n",
      "epoch:12,loss:2.4550\n",
      "epoch:12,loss:2.6738\n",
      "epoch:12,loss:2.3503\n",
      "epoch:12,loss:2.6876\n",
      "epoch:12,loss:2.2256\n",
      "epoch:12,loss:2.1076\n",
      "epoch:12,loss:2.7239\n",
      "epoch:12,loss:2.5573\n",
      "epoch:12,loss:2.2045\n",
      "epoch:12,loss:2.2439\n",
      "epoch:12,loss:2.4550\n",
      "epoch:12,loss:2.8193\n",
      "epoch:12,loss:1.8486\n",
      "epoch:12,loss:1.8902\n",
      "epoch:12,loss:1.8627\n",
      "epoch:12,loss:2.6527\n",
      "epoch:12,loss:2.6564\n",
      "epoch:12,loss:2.7516\n",
      "epoch:12,loss:2.2497\n",
      "epoch:12,loss:2.0816\n",
      "epoch:12,loss:2.9758\n",
      "epoch:12,loss:2.6820\n",
      "epoch:12,loss:2.4122\n",
      "epoch:12,loss:2.5407\n",
      "epoch:12,loss:1.9532\n",
      "epoch:12,loss:1.9659\n",
      "epoch:12,loss:2.7198\n",
      "epoch:12,loss:2.1357\n",
      "epoch:12,loss:2.2905\n",
      "epoch:12,loss:2.1574\n",
      "epoch:12,loss:3.5340\n",
      "epoch:12,loss:2.7239\n",
      "epoch:12,loss:1.8091\n",
      "epoch:12,loss:2.4818\n",
      "epoch:12,loss:2.5024\n",
      "============================================\n",
      "准确率由： tensor(0.1553) 上升至： tensor(0.1636) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第12个epoch的识别准确率为：16%\n",
      "epoch:13,loss:2.4000\n",
      "epoch:13,loss:2.4193\n",
      "epoch:13,loss:2.8118\n",
      "epoch:13,loss:2.4245\n",
      "epoch:13,loss:2.0152\n",
      "epoch:13,loss:2.4654\n",
      "epoch:13,loss:2.8679\n",
      "epoch:13,loss:2.6345\n",
      "epoch:13,loss:2.8138\n",
      "epoch:13,loss:2.8152\n",
      "epoch:13,loss:1.7688\n",
      "epoch:13,loss:2.8114\n",
      "epoch:13,loss:2.7785\n",
      "epoch:13,loss:2.7291\n",
      "epoch:13,loss:1.9823\n",
      "epoch:13,loss:2.4872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13,loss:2.7713\n",
      "epoch:13,loss:2.7674\n",
      "epoch:13,loss:2.3415\n",
      "epoch:13,loss:2.9060\n",
      "epoch:13,loss:2.3998\n",
      "epoch:13,loss:2.3306\n",
      "epoch:13,loss:2.2006\n",
      "epoch:13,loss:3.0779\n",
      "epoch:13,loss:2.7337\n",
      "epoch:13,loss:2.6102\n",
      "epoch:13,loss:2.5085\n",
      "epoch:13,loss:2.7207\n",
      "epoch:13,loss:2.3266\n",
      "epoch:13,loss:2.4081\n",
      "epoch:13,loss:1.9583\n",
      "epoch:13,loss:2.3495\n",
      "epoch:13,loss:1.9717\n",
      "epoch:13,loss:2.4419\n",
      "epoch:13,loss:2.7982\n",
      "epoch:13,loss:2.7063\n",
      "epoch:13,loss:2.4545\n",
      "epoch:13,loss:2.2940\n",
      "epoch:13,loss:2.3781\n",
      "epoch:13,loss:1.6091\n",
      "epoch:13,loss:2.1867\n",
      "epoch:13,loss:2.5975\n",
      "epoch:13,loss:3.1373\n",
      "epoch:13,loss:1.9162\n",
      "epoch:13,loss:2.3029\n",
      "epoch:13,loss:2.5318\n",
      "epoch:13,loss:3.0580\n",
      "epoch:13,loss:2.7936\n",
      "epoch:13,loss:2.6053\n",
      "epoch:13,loss:1.7966\n",
      "epoch:13,loss:2.6506\n",
      "epoch:13,loss:2.5048\n",
      "epoch:13,loss:2.3324\n",
      "epoch:13,loss:2.1161\n",
      "epoch:13,loss:2.5482\n",
      "epoch:13,loss:2.6814\n",
      "epoch:13,loss:2.9837\n",
      "epoch:13,loss:2.7036\n",
      "epoch:13,loss:1.9966\n",
      "epoch:13,loss:2.1557\n",
      "============================================\n",
      "准确率由： tensor(0.1636) 上升至： tensor(0.1682) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第13个epoch的识别准确率为：16%\n",
      "epoch:14,loss:2.5906\n",
      "epoch:14,loss:2.2428\n",
      "epoch:14,loss:1.8255\n",
      "epoch:14,loss:1.8244\n",
      "epoch:14,loss:2.4026\n",
      "epoch:14,loss:2.6138\n",
      "epoch:14,loss:2.4010\n",
      "epoch:14,loss:1.9543\n",
      "epoch:14,loss:2.6572\n",
      "epoch:14,loss:2.2756\n",
      "epoch:14,loss:3.3409\n",
      "epoch:14,loss:2.4007\n",
      "epoch:14,loss:2.1206\n",
      "epoch:14,loss:2.2871\n",
      "epoch:14,loss:2.4378\n",
      "epoch:14,loss:1.7930\n",
      "epoch:14,loss:2.8648\n",
      "epoch:14,loss:2.0730\n",
      "epoch:14,loss:2.1120\n",
      "epoch:14,loss:2.2495\n",
      "epoch:14,loss:1.8373\n",
      "epoch:14,loss:2.2323\n",
      "epoch:14,loss:2.6787\n",
      "epoch:14,loss:2.1813\n",
      "epoch:14,loss:2.5828\n",
      "epoch:14,loss:2.0963\n",
      "epoch:14,loss:2.3008\n",
      "epoch:14,loss:2.9802\n",
      "epoch:14,loss:2.3364\n",
      "epoch:14,loss:2.3157\n",
      "epoch:14,loss:3.4425\n",
      "epoch:14,loss:2.6774\n",
      "epoch:14,loss:2.1498\n",
      "epoch:14,loss:3.1526\n",
      "epoch:14,loss:2.1120\n",
      "epoch:14,loss:3.1519\n",
      "epoch:14,loss:3.3145\n",
      "epoch:14,loss:2.3489\n",
      "epoch:14,loss:2.2770\n",
      "epoch:14,loss:1.9641\n",
      "epoch:14,loss:2.1165\n",
      "epoch:14,loss:2.4010\n",
      "epoch:14,loss:3.2077\n",
      "epoch:14,loss:2.1540\n",
      "epoch:14,loss:2.4471\n",
      "epoch:14,loss:2.6976\n",
      "epoch:14,loss:2.1749\n",
      "epoch:14,loss:2.5505\n",
      "epoch:14,loss:2.7460\n",
      "epoch:14,loss:2.4568\n",
      "epoch:14,loss:2.2922\n",
      "epoch:14,loss:2.3605\n",
      "epoch:14,loss:2.4528\n",
      "epoch:14,loss:3.0237\n",
      "epoch:14,loss:2.4790\n",
      "epoch:14,loss:2.1831\n",
      "epoch:14,loss:3.2694\n",
      "epoch:14,loss:2.5753\n",
      "epoch:14,loss:2.1886\n",
      "epoch:14,loss:2.6885\n",
      "============================================\n",
      "准确率由： tensor(0.1682) 上升至： tensor(0.1893) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第14个epoch的识别准确率为：18%\n",
      "epoch:15,loss:2.1338\n",
      "epoch:15,loss:2.3221\n",
      "epoch:15,loss:1.8945\n",
      "epoch:15,loss:1.5411\n",
      "epoch:15,loss:2.5184\n",
      "epoch:15,loss:2.5961\n",
      "epoch:15,loss:2.4463\n",
      "epoch:15,loss:2.2419\n",
      "epoch:15,loss:3.3892\n",
      "epoch:15,loss:2.0640\n",
      "epoch:15,loss:2.7229\n",
      "epoch:15,loss:3.1644\n",
      "epoch:15,loss:2.6025\n",
      "epoch:15,loss:1.6770\n",
      "epoch:15,loss:2.4089\n",
      "epoch:15,loss:2.3035\n",
      "epoch:15,loss:2.2776\n",
      "epoch:15,loss:2.2452\n",
      "epoch:15,loss:2.8887\n",
      "epoch:15,loss:2.7047\n",
      "epoch:15,loss:2.4349\n",
      "epoch:15,loss:2.2223\n",
      "epoch:15,loss:2.2328\n",
      "epoch:15,loss:3.1390\n",
      "epoch:15,loss:3.0817\n",
      "epoch:15,loss:2.2675\n",
      "epoch:15,loss:3.0005\n",
      "epoch:15,loss:2.4223\n",
      "epoch:15,loss:3.0174\n",
      "epoch:15,loss:1.9501\n",
      "epoch:15,loss:2.5725\n",
      "epoch:15,loss:1.8232\n",
      "epoch:15,loss:2.2862\n",
      "epoch:15,loss:2.6500\n",
      "epoch:15,loss:2.3255\n",
      "epoch:15,loss:2.8166\n",
      "epoch:15,loss:2.7056\n",
      "epoch:15,loss:2.9874\n",
      "epoch:15,loss:2.9289\n",
      "epoch:15,loss:2.0702\n",
      "epoch:15,loss:2.0340\n",
      "epoch:15,loss:2.0613\n",
      "epoch:15,loss:1.9186\n",
      "epoch:15,loss:1.6158\n",
      "epoch:15,loss:2.0347\n",
      "epoch:15,loss:2.5267\n",
      "epoch:15,loss:2.3170\n",
      "epoch:15,loss:2.2359\n",
      "epoch:15,loss:2.8122\n",
      "epoch:15,loss:3.0917\n",
      "epoch:15,loss:2.4367\n",
      "epoch:15,loss:2.6437\n",
      "epoch:15,loss:2.3166\n",
      "epoch:15,loss:2.0735\n",
      "epoch:15,loss:2.7525\n",
      "epoch:15,loss:2.2413\n",
      "epoch:15,loss:2.3077\n",
      "epoch:15,loss:2.9342\n",
      "epoch:15,loss:1.7470\n",
      "epoch:15,loss:2.1190\n",
      "============================================\n",
      "第15个epoch的识别准确率为：17%\n",
      "epoch:16,loss:2.2703\n",
      "epoch:16,loss:1.9377\n",
      "epoch:16,loss:3.0221\n",
      "epoch:16,loss:2.3934\n",
      "epoch:16,loss:2.9968\n",
      "epoch:16,loss:2.7093\n",
      "epoch:16,loss:2.4459\n",
      "epoch:16,loss:2.3029\n",
      "epoch:16,loss:2.6618\n",
      "epoch:16,loss:2.6580\n",
      "epoch:16,loss:2.3482\n",
      "epoch:16,loss:2.4391\n",
      "epoch:16,loss:2.3673\n",
      "epoch:16,loss:2.4001\n",
      "epoch:16,loss:2.6456\n",
      "epoch:16,loss:3.3795\n",
      "epoch:16,loss:2.0755\n",
      "epoch:16,loss:2.9116\n",
      "epoch:16,loss:2.0384\n",
      "epoch:16,loss:2.2991\n",
      "epoch:16,loss:2.4050\n",
      "epoch:16,loss:2.7694\n",
      "epoch:16,loss:2.3165\n",
      "epoch:16,loss:2.5774\n",
      "epoch:16,loss:2.1596\n",
      "epoch:16,loss:2.1832\n",
      "epoch:16,loss:2.4154\n",
      "epoch:16,loss:2.6587\n",
      "epoch:16,loss:2.5713\n",
      "epoch:16,loss:2.1035\n",
      "epoch:16,loss:3.2457\n",
      "epoch:16,loss:2.2167\n",
      "epoch:16,loss:2.5852\n",
      "epoch:16,loss:3.2187\n",
      "epoch:16,loss:2.1982\n",
      "epoch:16,loss:2.4376\n",
      "epoch:16,loss:2.3318\n",
      "epoch:16,loss:2.1859\n",
      "epoch:16,loss:2.2929\n",
      "epoch:16,loss:2.9193\n",
      "epoch:16,loss:2.3948\n",
      "epoch:16,loss:2.5963\n",
      "epoch:16,loss:2.4534\n",
      "epoch:16,loss:2.0470\n",
      "epoch:16,loss:2.1910\n",
      "epoch:16,loss:2.5694\n",
      "epoch:16,loss:2.7648\n",
      "epoch:16,loss:2.5713\n",
      "epoch:16,loss:1.6158\n",
      "epoch:16,loss:2.8070\n",
      "epoch:16,loss:2.9218\n",
      "epoch:16,loss:2.3864\n",
      "epoch:16,loss:2.6101\n",
      "epoch:16,loss:2.5230\n",
      "epoch:16,loss:2.1121\n",
      "epoch:16,loss:2.2355\n",
      "epoch:16,loss:2.3192\n",
      "epoch:16,loss:2.0103\n",
      "epoch:16,loss:1.7781\n",
      "epoch:16,loss:2.2886\n",
      "============================================\n",
      "第16个epoch的识别准确率为：17%\n",
      "epoch:17,loss:1.6613\n",
      "epoch:17,loss:2.6133\n",
      "epoch:17,loss:2.3348\n",
      "epoch:17,loss:2.3286\n",
      "epoch:17,loss:2.6733\n",
      "epoch:17,loss:1.7361\n",
      "epoch:17,loss:2.1312\n",
      "epoch:17,loss:2.6537\n",
      "epoch:17,loss:2.1140\n",
      "epoch:17,loss:2.8902\n",
      "epoch:17,loss:2.2999\n",
      "epoch:17,loss:2.1341\n",
      "epoch:17,loss:2.5394\n",
      "epoch:17,loss:2.8520\n",
      "epoch:17,loss:2.7206\n",
      "epoch:17,loss:2.6561\n",
      "epoch:17,loss:2.9419\n",
      "epoch:17,loss:2.2267\n",
      "epoch:17,loss:3.4211\n",
      "epoch:17,loss:2.6061\n",
      "epoch:17,loss:2.9423\n",
      "epoch:17,loss:2.7466\n",
      "epoch:17,loss:2.6448\n",
      "epoch:17,loss:2.1043\n",
      "epoch:17,loss:1.4616\n",
      "epoch:17,loss:2.7360\n",
      "epoch:17,loss:2.0644\n",
      "epoch:17,loss:2.7658\n",
      "epoch:17,loss:2.6715\n",
      "epoch:17,loss:2.3776\n",
      "epoch:17,loss:2.8840\n",
      "epoch:17,loss:3.0103\n",
      "epoch:17,loss:2.4199\n",
      "epoch:17,loss:2.1099\n",
      "epoch:17,loss:2.0739\n",
      "epoch:17,loss:2.4481\n",
      "epoch:17,loss:3.0340\n",
      "epoch:17,loss:2.3037\n",
      "epoch:17,loss:2.0681\n",
      "epoch:17,loss:2.3068\n",
      "epoch:17,loss:2.3468\n",
      "epoch:17,loss:2.8973\n",
      "epoch:17,loss:2.3415\n",
      "epoch:17,loss:2.4659\n",
      "epoch:17,loss:2.6561\n",
      "epoch:17,loss:2.1021\n",
      "epoch:17,loss:2.3243\n",
      "epoch:17,loss:1.8652\n",
      "epoch:17,loss:2.0667\n",
      "epoch:17,loss:2.4362\n",
      "epoch:17,loss:2.5517\n",
      "epoch:17,loss:2.7930\n",
      "epoch:17,loss:1.6035\n",
      "epoch:17,loss:1.7909\n",
      "epoch:17,loss:2.0640\n",
      "epoch:17,loss:2.2864\n",
      "epoch:17,loss:2.8839\n",
      "epoch:17,loss:2.6500\n",
      "epoch:17,loss:2.6444\n",
      "epoch:17,loss:2.6690\n",
      "============================================\n",
      "第17个epoch的识别准确率为：18%\n",
      "epoch:18,loss:2.3231\n",
      "epoch:18,loss:2.1953\n",
      "epoch:18,loss:2.3540\n",
      "epoch:18,loss:2.6675\n",
      "epoch:18,loss:2.0468\n",
      "epoch:18,loss:2.6352\n",
      "epoch:18,loss:2.4249\n",
      "epoch:18,loss:2.1532\n",
      "epoch:18,loss:2.3446\n",
      "epoch:18,loss:2.9561\n",
      "epoch:18,loss:2.3989\n",
      "epoch:18,loss:2.6610\n",
      "epoch:18,loss:2.2344\n",
      "epoch:18,loss:2.5494\n",
      "epoch:18,loss:2.2174\n",
      "epoch:18,loss:2.4933\n",
      "epoch:18,loss:2.0537\n",
      "epoch:18,loss:2.3851\n",
      "epoch:18,loss:2.2697\n",
      "epoch:18,loss:2.5995\n",
      "epoch:18,loss:2.8783\n",
      "epoch:18,loss:2.4183\n",
      "epoch:18,loss:2.9838\n",
      "epoch:18,loss:2.3108\n",
      "epoch:18,loss:2.6900\n",
      "epoch:18,loss:3.1762\n",
      "epoch:18,loss:2.3241\n",
      "epoch:18,loss:2.1017\n",
      "epoch:18,loss:2.3124\n",
      "epoch:18,loss:2.7128\n",
      "epoch:18,loss:2.0370\n",
      "epoch:18,loss:2.7411\n",
      "epoch:18,loss:1.6732\n",
      "epoch:18,loss:2.2735\n",
      "epoch:18,loss:2.4191\n",
      "epoch:18,loss:2.1369\n",
      "epoch:18,loss:2.8840\n",
      "epoch:18,loss:1.8364\n",
      "epoch:18,loss:3.1053\n",
      "epoch:18,loss:2.5283\n",
      "epoch:18,loss:1.9241\n",
      "epoch:18,loss:1.7294\n",
      "epoch:18,loss:2.1686\n",
      "epoch:18,loss:2.7412\n",
      "epoch:18,loss:1.9426\n",
      "epoch:18,loss:1.6099\n",
      "epoch:18,loss:2.4270\n",
      "epoch:18,loss:2.0596\n",
      "epoch:18,loss:2.3742\n",
      "epoch:18,loss:1.8935\n",
      "epoch:18,loss:2.2427\n",
      "epoch:18,loss:2.0722\n",
      "epoch:18,loss:1.8130\n",
      "epoch:18,loss:2.3098\n",
      "epoch:18,loss:3.4750\n",
      "epoch:18,loss:2.3863\n",
      "epoch:18,loss:2.0767\n",
      "epoch:18,loss:2.7254\n",
      "epoch:18,loss:2.5950\n",
      "epoch:18,loss:2.0203\n",
      "============================================\n",
      "第18个epoch的识别准确率为：18%\n",
      "epoch:19,loss:1.8495\n",
      "epoch:19,loss:2.3401\n",
      "epoch:19,loss:1.8041\n",
      "epoch:19,loss:2.4178\n",
      "epoch:19,loss:2.7665\n",
      "epoch:19,loss:2.0261\n",
      "epoch:19,loss:2.6831\n",
      "epoch:19,loss:1.7427\n",
      "epoch:19,loss:2.3745\n",
      "epoch:19,loss:2.9284\n",
      "epoch:19,loss:2.3611\n",
      "epoch:19,loss:2.1094\n",
      "epoch:19,loss:2.0987\n",
      "epoch:19,loss:2.2855\n",
      "epoch:19,loss:2.0003\n",
      "epoch:19,loss:1.8262\n",
      "epoch:19,loss:2.4952\n",
      "epoch:19,loss:1.9740\n",
      "epoch:19,loss:3.3862\n",
      "epoch:19,loss:2.7771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19,loss:2.6300\n",
      "epoch:19,loss:2.1368\n",
      "epoch:19,loss:2.0044\n",
      "epoch:19,loss:2.2979\n",
      "epoch:19,loss:1.8896\n",
      "epoch:19,loss:1.9396\n",
      "epoch:19,loss:2.2967\n",
      "epoch:19,loss:3.3996\n",
      "epoch:19,loss:2.4114\n",
      "epoch:19,loss:2.4375\n",
      "epoch:19,loss:1.9431\n",
      "epoch:19,loss:2.7702\n",
      "epoch:19,loss:2.7405\n",
      "epoch:19,loss:2.0423\n",
      "epoch:19,loss:2.0797\n",
      "epoch:19,loss:2.2241\n",
      "epoch:19,loss:2.7288\n",
      "epoch:19,loss:3.4979\n",
      "epoch:19,loss:1.9656\n",
      "epoch:19,loss:2.8458\n",
      "epoch:19,loss:1.5218\n",
      "epoch:19,loss:1.5765\n",
      "epoch:19,loss:2.7524\n",
      "epoch:19,loss:2.4755\n",
      "epoch:19,loss:2.3553\n",
      "epoch:19,loss:1.4864\n",
      "epoch:19,loss:2.4704\n",
      "epoch:19,loss:2.9806\n",
      "epoch:19,loss:2.8582\n",
      "epoch:19,loss:2.3782\n",
      "epoch:19,loss:2.1704\n",
      "epoch:19,loss:2.2300\n",
      "epoch:19,loss:1.6155\n",
      "epoch:19,loss:2.0948\n",
      "epoch:19,loss:2.4201\n",
      "epoch:19,loss:2.2417\n",
      "epoch:19,loss:2.5906\n",
      "epoch:19,loss:2.3890\n",
      "epoch:19,loss:2.7603\n",
      "epoch:19,loss:2.6530\n",
      "============================================\n",
      "准确率由： tensor(0.1893) 上升至： tensor(0.1994) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第19个epoch的识别准确率为：19%\n",
      "epoch:20,loss:2.0062\n",
      "epoch:20,loss:1.8785\n",
      "epoch:20,loss:2.6037\n",
      "epoch:20,loss:2.2083\n",
      "epoch:20,loss:1.8930\n",
      "epoch:20,loss:1.9298\n",
      "epoch:20,loss:2.0696\n",
      "epoch:20,loss:2.2938\n",
      "epoch:20,loss:1.9701\n",
      "epoch:20,loss:2.3629\n",
      "epoch:20,loss:2.7357\n",
      "epoch:20,loss:2.3027\n",
      "epoch:20,loss:1.5602\n",
      "epoch:20,loss:2.0146\n",
      "epoch:20,loss:2.4158\n",
      "epoch:20,loss:2.6084\n",
      "epoch:20,loss:3.3639\n",
      "epoch:20,loss:1.9891\n",
      "epoch:20,loss:2.1637\n",
      "epoch:20,loss:2.4534\n",
      "epoch:20,loss:2.6561\n",
      "epoch:20,loss:2.5138\n",
      "epoch:20,loss:2.3147\n",
      "epoch:20,loss:2.1084\n",
      "epoch:20,loss:3.2818\n",
      "epoch:20,loss:2.0106\n",
      "epoch:20,loss:2.3223\n",
      "epoch:20,loss:2.5624\n",
      "epoch:20,loss:2.3239\n",
      "epoch:20,loss:1.9821\n",
      "epoch:20,loss:2.5996\n",
      "epoch:20,loss:1.9183\n",
      "epoch:20,loss:2.5522\n",
      "epoch:20,loss:2.8486\n",
      "epoch:20,loss:2.2860\n",
      "epoch:20,loss:1.8937\n",
      "epoch:20,loss:2.4436\n",
      "epoch:20,loss:3.1232\n",
      "epoch:20,loss:2.3561\n",
      "epoch:20,loss:2.3196\n",
      "epoch:20,loss:3.0773\n",
      "epoch:20,loss:2.3945\n",
      "epoch:20,loss:2.3981\n",
      "epoch:20,loss:2.4913\n",
      "epoch:20,loss:3.3865\n",
      "epoch:20,loss:2.4658\n",
      "epoch:20,loss:2.4570\n",
      "epoch:20,loss:2.2218\n",
      "epoch:20,loss:2.4418\n",
      "epoch:20,loss:2.2932\n",
      "epoch:20,loss:1.8458\n",
      "epoch:20,loss:2.0663\n",
      "epoch:20,loss:1.9125\n",
      "epoch:20,loss:2.3963\n",
      "epoch:20,loss:2.5716\n",
      "epoch:20,loss:2.2129\n",
      "epoch:20,loss:1.8839\n",
      "epoch:20,loss:1.8752\n",
      "epoch:20,loss:2.2294\n",
      "epoch:20,loss:3.0912\n",
      "============================================\n",
      "准确率由： tensor(0.1994) 上升至： tensor(0.2178) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第20个epoch的识别准确率为：21%\n",
      "epoch:21,loss:2.3988\n",
      "epoch:21,loss:2.3194\n",
      "epoch:21,loss:2.4972\n",
      "epoch:21,loss:1.8644\n",
      "epoch:21,loss:2.1893\n",
      "epoch:21,loss:2.4658\n",
      "epoch:21,loss:2.2525\n",
      "epoch:21,loss:2.4704\n",
      "epoch:21,loss:2.2937\n",
      "epoch:21,loss:2.1838\n",
      "epoch:21,loss:2.0432\n",
      "epoch:21,loss:3.1304\n",
      "epoch:21,loss:2.5595\n",
      "epoch:21,loss:2.3397\n",
      "epoch:21,loss:1.9808\n",
      "epoch:21,loss:2.6722\n",
      "epoch:21,loss:1.9504\n",
      "epoch:21,loss:1.9231\n",
      "epoch:21,loss:2.2268\n",
      "epoch:21,loss:1.8534\n",
      "epoch:21,loss:2.2260\n",
      "epoch:21,loss:2.1394\n",
      "epoch:21,loss:1.9198\n",
      "epoch:21,loss:2.0436\n",
      "epoch:21,loss:3.1178\n",
      "epoch:21,loss:2.8905\n",
      "epoch:21,loss:2.3486\n",
      "epoch:21,loss:2.7423\n",
      "epoch:21,loss:1.5484\n",
      "epoch:21,loss:1.8459\n",
      "epoch:21,loss:2.6831\n",
      "epoch:21,loss:2.2513\n",
      "epoch:21,loss:2.0854\n",
      "epoch:21,loss:2.7235\n",
      "epoch:21,loss:1.5632\n",
      "epoch:21,loss:2.3299\n",
      "epoch:21,loss:2.2907\n",
      "epoch:21,loss:2.1395\n",
      "epoch:21,loss:2.2288\n",
      "epoch:21,loss:2.0071\n",
      "epoch:21,loss:2.7360\n",
      "epoch:21,loss:1.7874\n",
      "epoch:21,loss:2.5800\n",
      "epoch:21,loss:2.0813\n",
      "epoch:21,loss:2.0410\n",
      "epoch:21,loss:1.6283\n",
      "epoch:21,loss:2.5109\n",
      "epoch:21,loss:1.8677\n",
      "epoch:21,loss:2.1893\n",
      "epoch:21,loss:1.8772\n",
      "epoch:21,loss:2.7118\n",
      "epoch:21,loss:2.2009\n",
      "epoch:21,loss:2.1842\n",
      "epoch:21,loss:2.6796\n",
      "epoch:21,loss:2.5420\n",
      "epoch:21,loss:2.5799\n",
      "epoch:21,loss:2.7554\n",
      "epoch:21,loss:1.9909\n",
      "epoch:21,loss:2.3700\n",
      "epoch:21,loss:1.7728\n",
      "============================================\n",
      "准确率由： tensor(0.2178) 上升至： tensor(0.2316) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第21个epoch的识别准确率为：23%\n",
      "epoch:22,loss:2.1679\n",
      "epoch:22,loss:2.3258\n",
      "epoch:22,loss:1.9985\n",
      "epoch:22,loss:2.6359\n",
      "epoch:22,loss:2.9913\n",
      "epoch:22,loss:1.8987\n",
      "epoch:22,loss:3.0041\n",
      "epoch:22,loss:2.0543\n",
      "epoch:22,loss:2.4431\n",
      "epoch:22,loss:2.2410\n",
      "epoch:22,loss:2.7744\n",
      "epoch:22,loss:1.4157\n",
      "epoch:22,loss:2.4232\n",
      "epoch:22,loss:3.2524\n",
      "epoch:22,loss:1.6705\n",
      "epoch:22,loss:3.0227\n",
      "epoch:22,loss:2.5891\n",
      "epoch:22,loss:2.5736\n",
      "epoch:22,loss:1.7993\n",
      "epoch:22,loss:1.8728\n",
      "epoch:22,loss:1.4822\n",
      "epoch:22,loss:2.0608\n",
      "epoch:22,loss:2.5023\n",
      "epoch:22,loss:2.0851\n",
      "epoch:22,loss:2.0042\n",
      "epoch:22,loss:2.3717\n",
      "epoch:22,loss:2.0541\n",
      "epoch:22,loss:2.0760\n",
      "epoch:22,loss:3.0435\n",
      "epoch:22,loss:2.4346\n",
      "epoch:22,loss:1.6615\n",
      "epoch:22,loss:1.9291\n",
      "epoch:22,loss:2.3686\n",
      "epoch:22,loss:2.8665\n",
      "epoch:22,loss:1.6747\n",
      "epoch:22,loss:2.1056\n",
      "epoch:22,loss:2.3617\n",
      "epoch:22,loss:2.4108\n",
      "epoch:22,loss:2.0743\n",
      "epoch:22,loss:1.7206\n",
      "epoch:22,loss:2.6381\n",
      "epoch:22,loss:3.1826\n",
      "epoch:22,loss:2.1948\n",
      "epoch:22,loss:2.5702\n",
      "epoch:22,loss:2.7807\n",
      "epoch:22,loss:2.5359\n",
      "epoch:22,loss:2.1185\n",
      "epoch:22,loss:2.3382\n",
      "epoch:22,loss:1.8864\n",
      "epoch:22,loss:2.7211\n",
      "epoch:22,loss:2.1907\n",
      "epoch:22,loss:2.6545\n",
      "epoch:22,loss:1.6064\n",
      "epoch:22,loss:1.8593\n",
      "epoch:22,loss:2.2043\n",
      "epoch:22,loss:2.5332\n",
      "epoch:22,loss:1.9990\n",
      "epoch:22,loss:1.9214\n",
      "epoch:22,loss:2.8128\n",
      "epoch:22,loss:2.7931\n",
      "============================================\n",
      "准确率由： tensor(0.2316) 上升至： tensor(0.2371) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第22个epoch的识别准确率为：23%\n",
      "epoch:23,loss:2.0674\n",
      "epoch:23,loss:2.5611\n",
      "epoch:23,loss:1.8282\n",
      "epoch:23,loss:2.3546\n",
      "epoch:23,loss:1.9107\n",
      "epoch:23,loss:1.9079\n",
      "epoch:23,loss:2.6491\n",
      "epoch:23,loss:1.8864\n",
      "epoch:23,loss:2.0526\n",
      "epoch:23,loss:1.3410\n",
      "epoch:23,loss:1.9504\n",
      "epoch:23,loss:2.9864\n",
      "epoch:23,loss:1.1392\n",
      "epoch:23,loss:2.4461\n",
      "epoch:23,loss:2.9197\n",
      "epoch:23,loss:2.2466\n",
      "epoch:23,loss:2.0756\n",
      "epoch:23,loss:2.3837\n",
      "epoch:23,loss:2.5784\n",
      "epoch:23,loss:1.9305\n",
      "epoch:23,loss:2.1432\n",
      "epoch:23,loss:2.5557\n",
      "epoch:23,loss:3.0216\n",
      "epoch:23,loss:2.5018\n",
      "epoch:23,loss:1.8158\n",
      "epoch:23,loss:2.2114\n",
      "epoch:23,loss:2.2291\n",
      "epoch:23,loss:1.8454\n",
      "epoch:23,loss:1.7197\n",
      "epoch:23,loss:1.5605\n",
      "epoch:23,loss:2.4319\n",
      "epoch:23,loss:3.6707\n",
      "epoch:23,loss:2.1220\n",
      "epoch:23,loss:2.0482\n",
      "epoch:23,loss:1.6354\n",
      "epoch:23,loss:1.7389\n",
      "epoch:23,loss:2.0912\n",
      "epoch:23,loss:2.4435\n",
      "epoch:23,loss:2.2346\n",
      "epoch:23,loss:2.0985\n",
      "epoch:23,loss:2.1526\n",
      "epoch:23,loss:2.5467\n",
      "epoch:23,loss:1.3473\n",
      "epoch:23,loss:2.4316\n",
      "epoch:23,loss:1.7641\n",
      "epoch:23,loss:1.8028\n",
      "epoch:23,loss:1.9440\n",
      "epoch:23,loss:1.9529\n",
      "epoch:23,loss:2.6437\n",
      "epoch:23,loss:1.8880\n",
      "epoch:23,loss:2.2136\n",
      "epoch:23,loss:2.8259\n",
      "epoch:23,loss:1.6059\n",
      "epoch:23,loss:1.3494\n",
      "epoch:23,loss:1.8379\n",
      "epoch:23,loss:2.2112\n",
      "epoch:23,loss:2.7837\n",
      "epoch:23,loss:2.5982\n",
      "epoch:23,loss:2.0089\n",
      "epoch:23,loss:1.6904\n",
      "============================================\n",
      "准确率由： tensor(0.2371) 上升至： tensor(0.2665) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第23个epoch的识别准确率为：26%\n",
      "epoch:24,loss:2.7487\n",
      "epoch:24,loss:2.7104\n",
      "epoch:24,loss:2.3354\n",
      "epoch:24,loss:2.8632\n",
      "epoch:24,loss:2.6120\n",
      "epoch:24,loss:1.6883\n",
      "epoch:24,loss:2.7172\n",
      "epoch:24,loss:2.8936\n",
      "epoch:24,loss:1.6882\n",
      "epoch:24,loss:2.2052\n",
      "epoch:24,loss:2.8586\n",
      "epoch:24,loss:2.3150\n",
      "epoch:24,loss:2.8433\n",
      "epoch:24,loss:1.8745\n",
      "epoch:24,loss:2.0446\n",
      "epoch:24,loss:2.0690\n",
      "epoch:24,loss:2.6475\n",
      "epoch:24,loss:1.7141\n",
      "epoch:24,loss:2.4585\n",
      "epoch:24,loss:2.9477\n",
      "epoch:24,loss:2.9779\n",
      "epoch:24,loss:1.8811\n",
      "epoch:24,loss:1.8141\n",
      "epoch:24,loss:1.9728\n",
      "epoch:24,loss:1.8447\n",
      "epoch:24,loss:2.3635\n",
      "epoch:24,loss:1.9969\n",
      "epoch:24,loss:2.2149\n",
      "epoch:24,loss:2.2170\n",
      "epoch:24,loss:2.3746\n",
      "epoch:24,loss:2.7938\n",
      "epoch:24,loss:1.7154\n",
      "epoch:24,loss:2.3936\n",
      "epoch:24,loss:2.9597\n",
      "epoch:24,loss:2.8803\n",
      "epoch:24,loss:3.0422\n",
      "epoch:24,loss:2.2493\n",
      "epoch:24,loss:2.0372\n",
      "epoch:24,loss:2.1929\n",
      "epoch:24,loss:1.8491\n",
      "epoch:24,loss:1.3682\n",
      "epoch:24,loss:2.0371\n",
      "epoch:24,loss:2.2334\n",
      "epoch:24,loss:1.1672\n",
      "epoch:24,loss:2.8094\n",
      "epoch:24,loss:2.3663\n",
      "epoch:24,loss:1.6500\n",
      "epoch:24,loss:2.2932\n",
      "epoch:24,loss:2.6757\n",
      "epoch:24,loss:2.9842\n",
      "epoch:24,loss:1.7950\n",
      "epoch:24,loss:2.3700\n",
      "epoch:24,loss:1.7332\n",
      "epoch:24,loss:1.9865\n",
      "epoch:24,loss:1.8810\n",
      "epoch:24,loss:2.5365\n",
      "epoch:24,loss:2.1082\n",
      "epoch:24,loss:2.0466\n",
      "epoch:24,loss:2.1325\n",
      "epoch:24,loss:1.9465\n",
      "============================================\n",
      "第24个epoch的识别准确率为：25%\n",
      "epoch:25,loss:1.7333\n",
      "epoch:25,loss:2.4221\n",
      "epoch:25,loss:2.4923\n",
      "epoch:25,loss:1.4958\n",
      "epoch:25,loss:1.8550\n",
      "epoch:25,loss:1.7994\n",
      "epoch:25,loss:3.2812\n",
      "epoch:25,loss:2.1618\n",
      "epoch:25,loss:2.0827\n",
      "epoch:25,loss:2.1550\n",
      "epoch:25,loss:2.2708\n",
      "epoch:25,loss:2.0845\n",
      "epoch:25,loss:2.8577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25,loss:2.1623\n",
      "epoch:25,loss:2.6830\n",
      "epoch:25,loss:2.9452\n",
      "epoch:25,loss:1.7779\n",
      "epoch:25,loss:1.7075\n",
      "epoch:25,loss:2.4501\n",
      "epoch:25,loss:1.7580\n",
      "epoch:25,loss:2.1191\n",
      "epoch:25,loss:1.4961\n",
      "epoch:25,loss:2.1488\n",
      "epoch:25,loss:2.2115\n",
      "epoch:25,loss:2.4132\n",
      "epoch:25,loss:1.5466\n",
      "epoch:25,loss:2.4640\n",
      "epoch:25,loss:2.3377\n",
      "epoch:25,loss:3.0791\n",
      "epoch:25,loss:2.8468\n",
      "epoch:25,loss:2.3982\n",
      "epoch:25,loss:1.9153\n",
      "epoch:25,loss:3.3826\n",
      "epoch:25,loss:2.7625\n",
      "epoch:25,loss:1.8842\n",
      "epoch:25,loss:2.5523\n",
      "epoch:25,loss:2.0929\n",
      "epoch:25,loss:2.1767\n",
      "epoch:25,loss:2.3381\n",
      "epoch:25,loss:1.6561\n",
      "epoch:25,loss:2.4069\n",
      "epoch:25,loss:2.4628\n",
      "epoch:25,loss:2.1503\n",
      "epoch:25,loss:2.2205\n",
      "epoch:25,loss:1.9645\n",
      "epoch:25,loss:2.8401\n",
      "epoch:25,loss:2.2834\n",
      "epoch:25,loss:2.3493\n",
      "epoch:25,loss:3.2391\n",
      "epoch:25,loss:2.4877\n",
      "epoch:25,loss:1.6982\n",
      "epoch:25,loss:2.1594\n",
      "epoch:25,loss:2.5453\n",
      "epoch:25,loss:2.3980\n",
      "epoch:25,loss:2.0006\n",
      "epoch:25,loss:2.1514\n",
      "epoch:25,loss:2.1519\n",
      "epoch:25,loss:2.3051\n",
      "epoch:25,loss:2.5617\n",
      "epoch:25,loss:1.6150\n",
      "============================================\n",
      "第25个epoch的识别准确率为：25%\n",
      "epoch:26,loss:1.6030\n",
      "epoch:26,loss:2.5252\n",
      "epoch:26,loss:2.5478\n",
      "epoch:26,loss:2.4640\n",
      "epoch:26,loss:2.3556\n",
      "epoch:26,loss:1.1710\n",
      "epoch:26,loss:2.4831\n",
      "epoch:26,loss:1.8738\n",
      "epoch:26,loss:2.9405\n",
      "epoch:26,loss:2.0177\n",
      "epoch:26,loss:2.5253\n",
      "epoch:26,loss:2.2840\n",
      "epoch:26,loss:1.5364\n",
      "epoch:26,loss:2.3077\n",
      "epoch:26,loss:2.8081\n",
      "epoch:26,loss:2.1814\n",
      "epoch:26,loss:1.5425\n",
      "epoch:26,loss:2.1090\n",
      "epoch:26,loss:1.9439\n",
      "epoch:26,loss:2.3382\n",
      "epoch:26,loss:2.2033\n",
      "epoch:26,loss:2.4053\n",
      "epoch:26,loss:2.7260\n",
      "epoch:26,loss:2.1490\n",
      "epoch:26,loss:2.1540\n",
      "epoch:26,loss:2.1193\n",
      "epoch:26,loss:1.5756\n",
      "epoch:26,loss:2.8513\n",
      "epoch:26,loss:2.7445\n",
      "epoch:26,loss:2.4985\n",
      "epoch:26,loss:2.6083\n",
      "epoch:26,loss:1.9467\n",
      "epoch:26,loss:2.4924\n",
      "epoch:26,loss:2.8139\n",
      "epoch:26,loss:2.9744\n",
      "epoch:26,loss:1.7112\n",
      "epoch:26,loss:2.2016\n",
      "epoch:26,loss:1.9291\n",
      "epoch:26,loss:1.9756\n",
      "epoch:26,loss:2.1784\n",
      "epoch:26,loss:2.5730\n",
      "epoch:26,loss:1.8452\n",
      "epoch:26,loss:1.4861\n",
      "epoch:26,loss:2.2561\n",
      "epoch:26,loss:3.6071\n",
      "epoch:26,loss:3.4472\n",
      "epoch:26,loss:2.5227\n",
      "epoch:26,loss:3.2855\n",
      "epoch:26,loss:2.7504\n",
      "epoch:26,loss:2.7076\n",
      "epoch:26,loss:2.4671\n",
      "epoch:26,loss:1.7220\n",
      "epoch:26,loss:2.7331\n",
      "epoch:26,loss:2.5947\n",
      "epoch:26,loss:3.8887\n",
      "epoch:26,loss:2.3832\n",
      "epoch:26,loss:2.3838\n",
      "epoch:26,loss:2.6575\n",
      "epoch:26,loss:2.3164\n",
      "epoch:26,loss:2.9448\n",
      "============================================\n",
      "第26个epoch的识别准确率为：26%\n",
      "epoch:27,loss:1.2044\n",
      "epoch:27,loss:2.3899\n",
      "epoch:27,loss:1.7850\n",
      "epoch:27,loss:1.9109\n",
      "epoch:27,loss:2.4033\n",
      "epoch:27,loss:2.0628\n",
      "epoch:27,loss:1.7347\n",
      "epoch:27,loss:2.7462\n",
      "epoch:27,loss:2.2853\n",
      "epoch:27,loss:2.2379\n",
      "epoch:27,loss:1.9871\n",
      "epoch:27,loss:2.9337\n",
      "epoch:27,loss:1.3622\n",
      "epoch:27,loss:2.3619\n",
      "epoch:27,loss:1.9143\n",
      "epoch:27,loss:2.9650\n",
      "epoch:27,loss:2.8261\n",
      "epoch:27,loss:1.6873\n",
      "epoch:27,loss:2.2668\n",
      "epoch:27,loss:2.5929\n",
      "epoch:27,loss:1.9661\n",
      "epoch:27,loss:2.5188\n",
      "epoch:27,loss:3.2945\n",
      "epoch:27,loss:1.7623\n",
      "epoch:27,loss:2.1709\n",
      "epoch:27,loss:2.6116\n",
      "epoch:27,loss:1.5031\n",
      "epoch:27,loss:1.9682\n",
      "epoch:27,loss:2.0419\n",
      "epoch:27,loss:1.7833\n",
      "epoch:27,loss:1.7140\n",
      "epoch:27,loss:1.6061\n",
      "epoch:27,loss:2.0592\n",
      "epoch:27,loss:1.8695\n",
      "epoch:27,loss:2.8880\n",
      "epoch:27,loss:1.4008\n",
      "epoch:27,loss:2.2227\n",
      "epoch:27,loss:1.9487\n",
      "epoch:27,loss:2.2029\n",
      "epoch:27,loss:2.8982\n",
      "epoch:27,loss:2.1206\n",
      "epoch:27,loss:1.8452\n",
      "epoch:27,loss:2.2625\n",
      "epoch:27,loss:1.6361\n",
      "epoch:27,loss:2.4428\n",
      "epoch:27,loss:1.8633\n",
      "epoch:27,loss:2.1128\n",
      "epoch:27,loss:2.7633\n",
      "epoch:27,loss:1.7225\n",
      "epoch:27,loss:2.0895\n",
      "epoch:27,loss:1.7425\n",
      "epoch:27,loss:2.5157\n",
      "epoch:27,loss:1.7743\n",
      "epoch:27,loss:1.9392\n",
      "epoch:27,loss:2.4447\n",
      "epoch:27,loss:2.0742\n",
      "epoch:27,loss:1.6274\n",
      "epoch:27,loss:1.5354\n",
      "epoch:27,loss:2.3034\n",
      "epoch:27,loss:1.4625\n",
      "============================================\n",
      "准确率由： tensor(0.2665) 上升至： tensor(0.2868) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第27个epoch的识别准确率为：28%\n",
      "epoch:28,loss:2.7606\n",
      "epoch:28,loss:1.6244\n",
      "epoch:28,loss:1.8819\n",
      "epoch:28,loss:1.5362\n",
      "epoch:28,loss:2.2041\n",
      "epoch:28,loss:2.1073\n",
      "epoch:28,loss:1.7155\n",
      "epoch:28,loss:2.1434\n",
      "epoch:28,loss:2.7463\n",
      "epoch:28,loss:1.6739\n",
      "epoch:28,loss:2.0077\n",
      "epoch:28,loss:2.2931\n",
      "epoch:28,loss:3.2238\n",
      "epoch:28,loss:3.3093\n",
      "epoch:28,loss:2.9341\n",
      "epoch:28,loss:1.2797\n",
      "epoch:28,loss:2.1388\n",
      "epoch:28,loss:2.8884\n",
      "epoch:28,loss:1.3670\n",
      "epoch:28,loss:2.1993\n",
      "epoch:28,loss:2.1248\n",
      "epoch:28,loss:2.3086\n",
      "epoch:28,loss:1.0015\n",
      "epoch:28,loss:2.4395\n",
      "epoch:28,loss:2.0650\n",
      "epoch:28,loss:1.8599\n",
      "epoch:28,loss:2.7598\n",
      "epoch:28,loss:2.0059\n",
      "epoch:28,loss:1.8181\n",
      "epoch:28,loss:1.2967\n",
      "epoch:28,loss:1.1008\n",
      "epoch:28,loss:1.2250\n",
      "epoch:28,loss:2.0286\n",
      "epoch:28,loss:2.4594\n",
      "epoch:28,loss:2.3784\n",
      "epoch:28,loss:2.7159\n",
      "epoch:28,loss:1.7242\n",
      "epoch:28,loss:3.2739\n",
      "epoch:28,loss:1.8897\n",
      "epoch:28,loss:2.2040\n",
      "epoch:28,loss:1.2919\n",
      "epoch:28,loss:2.9498\n",
      "epoch:28,loss:2.6855\n",
      "epoch:28,loss:2.4918\n",
      "epoch:28,loss:2.6051\n",
      "epoch:28,loss:2.5927\n",
      "epoch:28,loss:1.9653\n",
      "epoch:28,loss:2.4403\n",
      "epoch:28,loss:2.3129\n",
      "epoch:28,loss:1.6713\n",
      "epoch:28,loss:1.5167\n",
      "epoch:28,loss:2.3977\n",
      "epoch:28,loss:1.8166\n",
      "epoch:28,loss:1.5939\n",
      "epoch:28,loss:2.2485\n",
      "epoch:28,loss:1.7332\n",
      "epoch:28,loss:1.5353\n",
      "epoch:28,loss:1.9201\n",
      "epoch:28,loss:2.2613\n",
      "epoch:28,loss:2.3977\n",
      "============================================\n",
      "准确率由： tensor(0.2868) 上升至： tensor(0.3024) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第28个epoch的识别准确率为：30%\n",
      "epoch:29,loss:1.8297\n",
      "epoch:29,loss:2.4049\n",
      "epoch:29,loss:3.2163\n",
      "epoch:29,loss:1.8274\n",
      "epoch:29,loss:1.7697\n",
      "epoch:29,loss:1.9255\n",
      "epoch:29,loss:1.8657\n",
      "epoch:29,loss:2.0396\n",
      "epoch:29,loss:3.1225\n",
      "epoch:29,loss:2.8982\n",
      "epoch:29,loss:2.5722\n",
      "epoch:29,loss:2.3249\n",
      "epoch:29,loss:2.0545\n",
      "epoch:29,loss:1.8886\n",
      "epoch:29,loss:2.0948\n",
      "epoch:29,loss:1.8684\n",
      "epoch:29,loss:1.6986\n",
      "epoch:29,loss:1.9258\n",
      "epoch:29,loss:1.8887\n",
      "epoch:29,loss:2.3216\n",
      "epoch:29,loss:2.8150\n",
      "epoch:29,loss:2.1788\n",
      "epoch:29,loss:1.4153\n",
      "epoch:29,loss:2.2871\n",
      "epoch:29,loss:1.8110\n",
      "epoch:29,loss:2.0199\n",
      "epoch:29,loss:1.9653\n",
      "epoch:29,loss:1.9410\n",
      "epoch:29,loss:1.9968\n",
      "epoch:29,loss:1.6690\n",
      "epoch:29,loss:1.5200\n",
      "epoch:29,loss:1.9986\n",
      "epoch:29,loss:2.3832\n",
      "epoch:29,loss:2.0432\n",
      "epoch:29,loss:1.8619\n",
      "epoch:29,loss:2.2743\n",
      "epoch:29,loss:1.9617\n",
      "epoch:29,loss:2.1232\n",
      "epoch:29,loss:2.0669\n",
      "epoch:29,loss:1.7643\n",
      "epoch:29,loss:1.8396\n",
      "epoch:29,loss:2.5659\n",
      "epoch:29,loss:1.8607\n",
      "epoch:29,loss:1.8054\n",
      "epoch:29,loss:1.6885\n",
      "epoch:29,loss:1.6168\n",
      "epoch:29,loss:2.1067\n",
      "epoch:29,loss:2.7110\n",
      "epoch:29,loss:1.8872\n",
      "epoch:29,loss:2.5545\n",
      "epoch:29,loss:1.6160\n",
      "epoch:29,loss:2.0830\n",
      "epoch:29,loss:2.3589\n",
      "epoch:29,loss:1.9498\n",
      "epoch:29,loss:2.6086\n",
      "epoch:29,loss:3.7784\n",
      "epoch:29,loss:1.7872\n",
      "epoch:29,loss:1.9421\n",
      "epoch:29,loss:1.9768\n",
      "epoch:29,loss:2.1853\n",
      "============================================\n",
      "第29个epoch的识别准确率为：29%\n",
      "epoch:30,loss:1.4442\n",
      "epoch:30,loss:2.3184\n",
      "epoch:30,loss:1.3963\n",
      "epoch:30,loss:2.5602\n",
      "epoch:30,loss:2.4319\n",
      "epoch:30,loss:2.0598\n",
      "epoch:30,loss:3.4495\n",
      "epoch:30,loss:2.5744\n",
      "epoch:30,loss:2.6536\n",
      "epoch:30,loss:1.7584\n",
      "epoch:30,loss:1.7335\n",
      "epoch:30,loss:2.6546\n",
      "epoch:30,loss:2.4093\n",
      "epoch:30,loss:2.2715\n",
      "epoch:30,loss:1.2421\n",
      "epoch:30,loss:2.0932\n",
      "epoch:30,loss:2.6877\n",
      "epoch:30,loss:1.6575\n",
      "epoch:30,loss:1.7367\n",
      "epoch:30,loss:2.0415\n",
      "epoch:30,loss:1.9892\n",
      "epoch:30,loss:2.0854\n",
      "epoch:30,loss:3.9709\n",
      "epoch:30,loss:2.3809\n",
      "epoch:30,loss:2.7915\n",
      "epoch:30,loss:2.5573\n",
      "epoch:30,loss:1.8767\n",
      "epoch:30,loss:1.1966\n",
      "epoch:30,loss:1.9457\n",
      "epoch:30,loss:1.6993\n",
      "epoch:30,loss:1.4453\n",
      "epoch:30,loss:2.1949\n",
      "epoch:30,loss:1.7828\n",
      "epoch:30,loss:2.1941\n",
      "epoch:30,loss:2.1335\n",
      "epoch:30,loss:1.7654\n",
      "epoch:30,loss:1.4904\n",
      "epoch:30,loss:2.0296\n",
      "epoch:30,loss:3.1002\n",
      "epoch:30,loss:2.3210\n",
      "epoch:30,loss:3.0527\n",
      "epoch:30,loss:2.0442\n",
      "epoch:30,loss:3.0584\n",
      "epoch:30,loss:1.5441\n",
      "epoch:30,loss:1.5203\n",
      "epoch:30,loss:1.1996\n",
      "epoch:30,loss:1.5939\n",
      "epoch:30,loss:1.6228\n",
      "epoch:30,loss:4.0816\n",
      "epoch:30,loss:2.3249\n",
      "epoch:30,loss:2.3987\n",
      "epoch:30,loss:1.9777\n",
      "epoch:30,loss:2.5278\n",
      "epoch:30,loss:2.5301\n",
      "epoch:30,loss:2.6634\n",
      "epoch:30,loss:1.7557\n",
      "epoch:30,loss:2.1965\n",
      "epoch:30,loss:2.6088\n",
      "epoch:30,loss:1.6493\n",
      "epoch:30,loss:2.4099\n",
      "============================================\n",
      "准确率由： tensor(0.3024) 上升至： tensor(0.3162) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第30个epoch的识别准确率为：31%\n",
      "epoch:31,loss:1.8403\n",
      "epoch:31,loss:1.7919\n",
      "epoch:31,loss:1.2384\n",
      "epoch:31,loss:2.3031\n",
      "epoch:31,loss:1.5885\n",
      "epoch:31,loss:1.2830\n",
      "epoch:31,loss:1.8151\n",
      "epoch:31,loss:3.1031\n",
      "epoch:31,loss:2.2048\n",
      "epoch:31,loss:1.9092\n",
      "epoch:31,loss:3.5371\n",
      "epoch:31,loss:2.1672\n",
      "epoch:31,loss:1.7945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31,loss:1.6885\n",
      "epoch:31,loss:1.7555\n",
      "epoch:31,loss:1.5894\n",
      "epoch:31,loss:2.0129\n",
      "epoch:31,loss:1.5396\n",
      "epoch:31,loss:2.6390\n",
      "epoch:31,loss:1.9724\n",
      "epoch:31,loss:1.7899\n",
      "epoch:31,loss:2.0453\n",
      "epoch:31,loss:1.9766\n",
      "epoch:31,loss:1.7248\n",
      "epoch:31,loss:2.3223\n",
      "epoch:31,loss:1.8576\n",
      "epoch:31,loss:1.3463\n",
      "epoch:31,loss:1.8880\n",
      "epoch:31,loss:1.9941\n",
      "epoch:31,loss:2.0535\n",
      "epoch:31,loss:2.4594\n",
      "epoch:31,loss:2.3812\n",
      "epoch:31,loss:2.4023\n",
      "epoch:31,loss:2.0200\n",
      "epoch:31,loss:1.6479\n",
      "epoch:31,loss:1.8567\n",
      "epoch:31,loss:2.3033\n",
      "epoch:31,loss:2.0536\n",
      "epoch:31,loss:2.7485\n",
      "epoch:31,loss:2.6769\n",
      "epoch:31,loss:2.1401\n",
      "epoch:31,loss:1.7298\n",
      "epoch:31,loss:1.8310\n",
      "epoch:31,loss:1.9063\n",
      "epoch:31,loss:1.8486\n",
      "epoch:31,loss:1.8551\n",
      "epoch:31,loss:2.0178\n",
      "epoch:31,loss:2.0100\n",
      "epoch:31,loss:1.8185\n",
      "epoch:31,loss:2.6825\n",
      "epoch:31,loss:2.6376\n",
      "epoch:31,loss:2.1055\n",
      "epoch:31,loss:1.7982\n",
      "epoch:31,loss:2.5420\n",
      "epoch:31,loss:2.8929\n",
      "epoch:31,loss:2.3999\n",
      "epoch:31,loss:3.0631\n",
      "epoch:31,loss:1.6698\n",
      "epoch:31,loss:1.7744\n",
      "epoch:31,loss:2.2129\n",
      "============================================\n",
      "第31个epoch的识别准确率为：30%\n",
      "epoch:32,loss:2.2815\n",
      "epoch:32,loss:2.9027\n",
      "epoch:32,loss:1.7795\n",
      "epoch:32,loss:2.1739\n",
      "epoch:32,loss:2.0577\n",
      "epoch:32,loss:2.0046\n",
      "epoch:32,loss:0.9925\n",
      "epoch:32,loss:1.5850\n",
      "epoch:32,loss:0.8547\n",
      "epoch:32,loss:2.3293\n",
      "epoch:32,loss:2.0777\n",
      "epoch:32,loss:1.6906\n",
      "epoch:32,loss:1.2235\n",
      "epoch:32,loss:1.5431\n",
      "epoch:32,loss:1.7868\n",
      "epoch:32,loss:2.4767\n",
      "epoch:32,loss:2.0689\n",
      "epoch:32,loss:2.2683\n",
      "epoch:32,loss:1.8047\n",
      "epoch:32,loss:2.5148\n",
      "epoch:32,loss:2.4772\n",
      "epoch:32,loss:1.2008\n",
      "epoch:32,loss:1.6377\n",
      "epoch:32,loss:2.6594\n",
      "epoch:32,loss:2.0875\n",
      "epoch:32,loss:1.9644\n",
      "epoch:32,loss:2.1740\n",
      "epoch:32,loss:2.0034\n",
      "epoch:32,loss:1.8428\n",
      "epoch:32,loss:1.6971\n",
      "epoch:32,loss:2.6598\n",
      "epoch:32,loss:1.5814\n",
      "epoch:32,loss:2.7555\n",
      "epoch:32,loss:2.3428\n",
      "epoch:32,loss:2.0031\n",
      "epoch:32,loss:2.9628\n",
      "epoch:32,loss:1.3547\n",
      "epoch:32,loss:1.5284\n",
      "epoch:32,loss:1.6285\n",
      "epoch:32,loss:2.7021\n",
      "epoch:32,loss:2.5112\n",
      "epoch:32,loss:1.5457\n",
      "epoch:32,loss:1.9236\n",
      "epoch:32,loss:2.5218\n",
      "epoch:32,loss:1.9122\n",
      "epoch:32,loss:1.9516\n",
      "epoch:32,loss:2.4137\n",
      "epoch:32,loss:2.3225\n",
      "epoch:32,loss:1.8424\n",
      "epoch:32,loss:2.5728\n",
      "epoch:32,loss:2.3255\n",
      "epoch:32,loss:1.4873\n",
      "epoch:32,loss:2.6566\n",
      "epoch:32,loss:2.3872\n",
      "epoch:32,loss:2.2319\n",
      "epoch:32,loss:2.6289\n",
      "epoch:32,loss:1.8543\n",
      "epoch:32,loss:1.6776\n",
      "epoch:32,loss:1.8526\n",
      "epoch:32,loss:2.9675\n",
      "============================================\n",
      "准确率由： tensor(0.3162) 上升至： tensor(0.3189) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第32个epoch的识别准确率为：31%\n",
      "epoch:33,loss:2.0634\n",
      "epoch:33,loss:2.5230\n",
      "epoch:33,loss:0.9855\n",
      "epoch:33,loss:1.9635\n",
      "epoch:33,loss:2.4280\n",
      "epoch:33,loss:1.9532\n",
      "epoch:33,loss:2.2795\n",
      "epoch:33,loss:1.8516\n",
      "epoch:33,loss:2.4427\n",
      "epoch:33,loss:1.6862\n",
      "epoch:33,loss:2.1821\n",
      "epoch:33,loss:2.3859\n",
      "epoch:33,loss:1.5921\n",
      "epoch:33,loss:2.2789\n",
      "epoch:33,loss:1.5821\n",
      "epoch:33,loss:2.8029\n",
      "epoch:33,loss:3.6813\n",
      "epoch:33,loss:2.8679\n",
      "epoch:33,loss:2.2794\n",
      "epoch:33,loss:2.0293\n",
      "epoch:33,loss:1.8303\n",
      "epoch:33,loss:1.7049\n",
      "epoch:33,loss:1.6357\n",
      "epoch:33,loss:1.3262\n",
      "epoch:33,loss:1.0846\n",
      "epoch:33,loss:2.5994\n",
      "epoch:33,loss:2.2959\n",
      "epoch:33,loss:2.4600\n",
      "epoch:33,loss:2.1230\n",
      "epoch:33,loss:1.8342\n",
      "epoch:33,loss:2.8918\n",
      "epoch:33,loss:2.5589\n",
      "epoch:33,loss:1.7342\n",
      "epoch:33,loss:2.0153\n",
      "epoch:33,loss:2.3109\n",
      "epoch:33,loss:2.0550\n",
      "epoch:33,loss:2.0265\n",
      "epoch:33,loss:2.4173\n",
      "epoch:33,loss:2.4839\n",
      "epoch:33,loss:1.8213\n",
      "epoch:33,loss:1.9541\n",
      "epoch:33,loss:2.3736\n",
      "epoch:33,loss:1.3879\n",
      "epoch:33,loss:2.3331\n",
      "epoch:33,loss:2.7926\n",
      "epoch:33,loss:1.4924\n",
      "epoch:33,loss:1.8890\n",
      "epoch:33,loss:1.8667\n",
      "epoch:33,loss:1.4825\n",
      "epoch:33,loss:3.1338\n",
      "epoch:33,loss:1.9996\n",
      "epoch:33,loss:1.4571\n",
      "epoch:33,loss:1.7587\n",
      "epoch:33,loss:1.9916\n",
      "epoch:33,loss:2.3772\n",
      "epoch:33,loss:2.0272\n",
      "epoch:33,loss:1.0140\n",
      "epoch:33,loss:2.2206\n",
      "epoch:33,loss:1.8687\n",
      "epoch:33,loss:1.5745\n",
      "============================================\n",
      "第33个epoch的识别准确率为：29%\n",
      "epoch:34,loss:1.5563\n",
      "epoch:34,loss:1.9542\n",
      "epoch:34,loss:1.9553\n",
      "epoch:34,loss:2.3842\n",
      "epoch:34,loss:2.4170\n",
      "epoch:34,loss:1.9286\n",
      "epoch:34,loss:1.3933\n",
      "epoch:34,loss:1.9853\n",
      "epoch:34,loss:1.8546\n",
      "epoch:34,loss:2.7055\n",
      "epoch:34,loss:1.5104\n",
      "epoch:34,loss:1.7733\n",
      "epoch:34,loss:1.6757\n",
      "epoch:34,loss:1.9952\n",
      "epoch:34,loss:2.3872\n",
      "epoch:34,loss:2.3022\n",
      "epoch:34,loss:2.1950\n",
      "epoch:34,loss:1.8065\n",
      "epoch:34,loss:1.2585\n",
      "epoch:34,loss:1.9415\n",
      "epoch:34,loss:2.5678\n",
      "epoch:34,loss:1.6198\n",
      "epoch:34,loss:2.1055\n",
      "epoch:34,loss:2.4112\n",
      "epoch:34,loss:2.0623\n",
      "epoch:34,loss:2.1432\n",
      "epoch:34,loss:2.3962\n",
      "epoch:34,loss:1.8097\n",
      "epoch:34,loss:1.3618\n",
      "epoch:34,loss:1.6199\n",
      "epoch:34,loss:2.2643\n",
      "epoch:34,loss:2.1957\n",
      "epoch:34,loss:1.4795\n",
      "epoch:34,loss:1.3899\n",
      "epoch:34,loss:2.2350\n",
      "epoch:34,loss:2.4776\n",
      "epoch:34,loss:2.0163\n",
      "epoch:34,loss:1.1640\n",
      "epoch:34,loss:1.5356\n",
      "epoch:34,loss:1.8578\n",
      "epoch:34,loss:1.6936\n",
      "epoch:34,loss:2.6532\n",
      "epoch:34,loss:1.0062\n",
      "epoch:34,loss:1.4832\n",
      "epoch:34,loss:1.9715\n",
      "epoch:34,loss:1.8829\n",
      "epoch:34,loss:1.5851\n",
      "epoch:34,loss:2.2340\n",
      "epoch:34,loss:2.4136\n",
      "epoch:34,loss:2.6040\n",
      "epoch:34,loss:0.8884\n",
      "epoch:34,loss:0.9265\n",
      "epoch:34,loss:2.2956\n",
      "epoch:34,loss:1.1497\n",
      "epoch:34,loss:2.0476\n",
      "epoch:34,loss:1.9210\n",
      "epoch:34,loss:1.6763\n",
      "epoch:34,loss:1.9093\n",
      "epoch:34,loss:1.7881\n",
      "epoch:34,loss:2.4287\n",
      "============================================\n",
      "准确率由： tensor(0.3189) 上升至： tensor(0.3631) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第34个epoch的识别准确率为：36%\n",
      "epoch:35,loss:1.4778\n",
      "epoch:35,loss:2.3175\n",
      "epoch:35,loss:3.1705\n",
      "epoch:35,loss:2.2605\n",
      "epoch:35,loss:3.3415\n",
      "epoch:35,loss:2.5854\n",
      "epoch:35,loss:2.3889\n",
      "epoch:35,loss:1.2895\n",
      "epoch:35,loss:2.1223\n",
      "epoch:35,loss:1.3282\n",
      "epoch:35,loss:1.9367\n",
      "epoch:35,loss:2.8778\n",
      "epoch:35,loss:1.4767\n",
      "epoch:35,loss:1.7546\n",
      "epoch:35,loss:1.9197\n",
      "epoch:35,loss:1.6716\n",
      "epoch:35,loss:2.1124\n",
      "epoch:35,loss:1.0299\n",
      "epoch:35,loss:1.3400\n",
      "epoch:35,loss:2.3188\n",
      "epoch:35,loss:2.7843\n",
      "epoch:35,loss:1.7763\n",
      "epoch:35,loss:1.3875\n",
      "epoch:35,loss:1.6026\n",
      "epoch:35,loss:1.5920\n",
      "epoch:35,loss:2.2808\n",
      "epoch:35,loss:1.9699\n",
      "epoch:35,loss:1.7477\n",
      "epoch:35,loss:2.2860\n",
      "epoch:35,loss:2.0756\n",
      "epoch:35,loss:1.8614\n",
      "epoch:35,loss:1.5503\n",
      "epoch:35,loss:1.4888\n",
      "epoch:35,loss:2.4298\n",
      "epoch:35,loss:2.4662\n",
      "epoch:35,loss:1.4050\n",
      "epoch:35,loss:1.9467\n",
      "epoch:35,loss:1.8794\n",
      "epoch:35,loss:1.9761\n",
      "epoch:35,loss:1.3401\n",
      "epoch:35,loss:1.7023\n",
      "epoch:35,loss:2.1737\n",
      "epoch:35,loss:1.3322\n",
      "epoch:35,loss:1.9976\n",
      "epoch:35,loss:0.7853\n",
      "epoch:35,loss:1.6896\n",
      "epoch:35,loss:1.5814\n",
      "epoch:35,loss:1.7001\n",
      "epoch:35,loss:1.5372\n",
      "epoch:35,loss:2.3519\n",
      "epoch:35,loss:2.0185\n",
      "epoch:35,loss:1.7474\n",
      "epoch:35,loss:2.2264\n",
      "epoch:35,loss:2.7717\n",
      "epoch:35,loss:2.0273\n",
      "epoch:35,loss:2.3940\n",
      "epoch:35,loss:3.1294\n",
      "epoch:35,loss:1.7840\n",
      "epoch:35,loss:1.5514\n",
      "epoch:35,loss:2.5584\n",
      "============================================\n",
      "第35个epoch的识别准确率为：35%\n",
      "epoch:36,loss:2.1622\n",
      "epoch:36,loss:2.4399\n",
      "epoch:36,loss:1.6842\n",
      "epoch:36,loss:2.0460\n",
      "epoch:36,loss:2.3699\n",
      "epoch:36,loss:2.7744\n",
      "epoch:36,loss:1.8652\n",
      "epoch:36,loss:1.8361\n",
      "epoch:36,loss:1.7530\n",
      "epoch:36,loss:1.7659\n",
      "epoch:36,loss:2.0837\n",
      "epoch:36,loss:1.4253\n",
      "epoch:36,loss:2.0620\n",
      "epoch:36,loss:1.4567\n",
      "epoch:36,loss:2.5063\n",
      "epoch:36,loss:2.3563\n",
      "epoch:36,loss:2.9703\n",
      "epoch:36,loss:1.3926\n",
      "epoch:36,loss:2.1250\n",
      "epoch:36,loss:2.0419\n",
      "epoch:36,loss:2.0632\n",
      "epoch:36,loss:1.6978\n",
      "epoch:36,loss:1.6812\n",
      "epoch:36,loss:2.1273\n",
      "epoch:36,loss:2.1734\n",
      "epoch:36,loss:2.4287\n",
      "epoch:36,loss:1.4788\n",
      "epoch:36,loss:1.9651\n",
      "epoch:36,loss:1.3056\n",
      "epoch:36,loss:1.9764\n",
      "epoch:36,loss:1.4813\n",
      "epoch:36,loss:1.9184\n",
      "epoch:36,loss:1.3898\n",
      "epoch:36,loss:1.8720\n",
      "epoch:36,loss:2.1595\n",
      "epoch:36,loss:1.2564\n",
      "epoch:36,loss:2.2093\n",
      "epoch:36,loss:1.9533\n",
      "epoch:36,loss:2.1417\n",
      "epoch:36,loss:1.8507\n",
      "epoch:36,loss:2.1237\n",
      "epoch:36,loss:1.4924\n",
      "epoch:36,loss:1.9499\n",
      "epoch:36,loss:2.4424\n",
      "epoch:36,loss:0.9922\n",
      "epoch:36,loss:2.2376\n",
      "epoch:36,loss:2.6839\n",
      "epoch:36,loss:2.4453\n",
      "epoch:36,loss:1.4126\n",
      "epoch:36,loss:1.0387\n",
      "epoch:36,loss:1.6619\n",
      "epoch:36,loss:1.3635\n",
      "epoch:36,loss:1.9527\n",
      "epoch:36,loss:2.2948\n",
      "epoch:36,loss:2.3483\n",
      "epoch:36,loss:1.8596\n",
      "epoch:36,loss:1.9467\n",
      "epoch:36,loss:1.3503\n",
      "epoch:36,loss:1.9548\n",
      "epoch:36,loss:2.2473\n",
      "============================================\n",
      "第36个epoch的识别准确率为：35%\n",
      "epoch:37,loss:2.2533\n",
      "epoch:37,loss:1.2314\n",
      "epoch:37,loss:1.9937\n",
      "epoch:37,loss:1.6050\n",
      "epoch:37,loss:2.1787\n",
      "epoch:37,loss:1.4843\n",
      "epoch:37,loss:2.7872\n",
      "epoch:37,loss:1.6536\n",
      "epoch:37,loss:2.5305\n",
      "epoch:37,loss:1.8637\n",
      "epoch:37,loss:1.9059\n",
      "epoch:37,loss:1.7677\n",
      "epoch:37,loss:1.4657\n",
      "epoch:37,loss:2.0988\n",
      "epoch:37,loss:2.3267\n",
      "epoch:37,loss:1.4760\n",
      "epoch:37,loss:2.5937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37,loss:1.9166\n",
      "epoch:37,loss:1.6210\n",
      "epoch:37,loss:1.1680\n",
      "epoch:37,loss:2.2852\n",
      "epoch:37,loss:1.5036\n",
      "epoch:37,loss:1.8432\n",
      "epoch:37,loss:2.1251\n",
      "epoch:37,loss:1.4613\n",
      "epoch:37,loss:2.2005\n",
      "epoch:37,loss:1.7735\n",
      "epoch:37,loss:1.3163\n",
      "epoch:37,loss:1.2023\n",
      "epoch:37,loss:1.1629\n",
      "epoch:37,loss:2.3228\n",
      "epoch:37,loss:1.2089\n",
      "epoch:37,loss:2.5038\n",
      "epoch:37,loss:2.2284\n",
      "epoch:37,loss:1.2110\n",
      "epoch:37,loss:2.4164\n",
      "epoch:37,loss:1.3499\n",
      "epoch:37,loss:1.3987\n",
      "epoch:37,loss:1.1418\n",
      "epoch:37,loss:1.5064\n",
      "epoch:37,loss:2.4326\n",
      "epoch:37,loss:3.0781\n",
      "epoch:37,loss:1.8603\n",
      "epoch:37,loss:1.9733\n",
      "epoch:37,loss:2.6473\n",
      "epoch:37,loss:1.4992\n",
      "epoch:37,loss:1.9289\n",
      "epoch:37,loss:1.3429\n",
      "epoch:37,loss:1.8195\n",
      "epoch:37,loss:1.7225\n",
      "epoch:37,loss:2.2681\n",
      "epoch:37,loss:1.9640\n",
      "epoch:37,loss:1.1957\n",
      "epoch:37,loss:2.1252\n",
      "epoch:37,loss:1.9794\n",
      "epoch:37,loss:2.4715\n",
      "epoch:37,loss:1.6030\n",
      "epoch:37,loss:1.7218\n",
      "epoch:37,loss:1.4924\n",
      "epoch:37,loss:1.4720\n",
      "============================================\n",
      "第37个epoch的识别准确率为：34%\n",
      "epoch:38,loss:2.4512\n",
      "epoch:38,loss:1.0033\n",
      "epoch:38,loss:1.6036\n",
      "epoch:38,loss:1.5960\n",
      "epoch:38,loss:1.7992\n",
      "epoch:38,loss:1.4400\n",
      "epoch:38,loss:1.3997\n",
      "epoch:38,loss:2.0493\n",
      "epoch:38,loss:0.9531\n",
      "epoch:38,loss:2.8741\n",
      "epoch:38,loss:1.5515\n",
      "epoch:38,loss:1.6320\n",
      "epoch:38,loss:1.0812\n",
      "epoch:38,loss:2.3464\n",
      "epoch:38,loss:2.1458\n",
      "epoch:38,loss:1.1346\n",
      "epoch:38,loss:2.4745\n",
      "epoch:38,loss:1.9485\n",
      "epoch:38,loss:1.2912\n",
      "epoch:38,loss:1.8172\n",
      "epoch:38,loss:2.9660\n",
      "epoch:38,loss:1.5068\n",
      "epoch:38,loss:1.6568\n",
      "epoch:38,loss:1.5968\n",
      "epoch:38,loss:1.9070\n",
      "epoch:38,loss:2.3204\n",
      "epoch:38,loss:1.5588\n",
      "epoch:38,loss:1.9793\n",
      "epoch:38,loss:2.0140\n",
      "epoch:38,loss:1.5999\n",
      "epoch:38,loss:2.3558\n",
      "epoch:38,loss:1.5971\n",
      "epoch:38,loss:2.1408\n",
      "epoch:38,loss:0.9765\n",
      "epoch:38,loss:2.0788\n",
      "epoch:38,loss:1.5185\n",
      "epoch:38,loss:2.6079\n",
      "epoch:38,loss:1.5478\n",
      "epoch:38,loss:1.4431\n",
      "epoch:38,loss:1.7472\n",
      "epoch:38,loss:1.2384\n",
      "epoch:38,loss:1.6935\n",
      "epoch:38,loss:2.3069\n",
      "epoch:38,loss:1.0780\n",
      "epoch:38,loss:2.1955\n",
      "epoch:38,loss:0.9568\n",
      "epoch:38,loss:3.0834\n",
      "epoch:38,loss:2.1569\n",
      "epoch:38,loss:2.3513\n",
      "epoch:38,loss:1.9227\n",
      "epoch:38,loss:2.4290\n",
      "epoch:38,loss:2.0859\n",
      "epoch:38,loss:1.2268\n",
      "epoch:38,loss:1.8847\n",
      "epoch:38,loss:1.9485\n",
      "epoch:38,loss:1.2970\n",
      "epoch:38,loss:1.1671\n",
      "epoch:38,loss:1.2368\n",
      "epoch:38,loss:1.3238\n",
      "epoch:38,loss:2.2867\n",
      "============================================\n",
      "第38个epoch的识别准确率为：35%\n",
      "epoch:39,loss:1.7219\n",
      "epoch:39,loss:2.2140\n",
      "epoch:39,loss:1.1942\n",
      "epoch:39,loss:0.8147\n",
      "epoch:39,loss:2.9423\n",
      "epoch:39,loss:0.8154\n",
      "epoch:39,loss:3.0096\n",
      "epoch:39,loss:1.4022\n",
      "epoch:39,loss:1.1576\n",
      "epoch:39,loss:1.9684\n",
      "epoch:39,loss:1.7324\n",
      "epoch:39,loss:2.0812\n",
      "epoch:39,loss:1.7131\n",
      "epoch:39,loss:1.8852\n",
      "epoch:39,loss:1.2889\n",
      "epoch:39,loss:1.1984\n",
      "epoch:39,loss:2.5262\n",
      "epoch:39,loss:2.7072\n",
      "epoch:39,loss:1.3706\n",
      "epoch:39,loss:1.8941\n",
      "epoch:39,loss:2.2183\n",
      "epoch:39,loss:1.8965\n",
      "epoch:39,loss:2.5274\n",
      "epoch:39,loss:1.4589\n",
      "epoch:39,loss:2.3405\n",
      "epoch:39,loss:2.1182\n",
      "epoch:39,loss:2.4592\n",
      "epoch:39,loss:1.4429\n",
      "epoch:39,loss:1.6870\n",
      "epoch:39,loss:1.6761\n",
      "epoch:39,loss:2.6173\n",
      "epoch:39,loss:2.4365\n",
      "epoch:39,loss:2.4580\n",
      "epoch:39,loss:2.3930\n",
      "epoch:39,loss:1.2799\n",
      "epoch:39,loss:2.1134\n",
      "epoch:39,loss:1.7602\n",
      "epoch:39,loss:2.4221\n",
      "epoch:39,loss:2.3440\n",
      "epoch:39,loss:1.7150\n",
      "epoch:39,loss:2.0526\n",
      "epoch:39,loss:2.0797\n",
      "epoch:39,loss:2.3170\n",
      "epoch:39,loss:2.9292\n",
      "epoch:39,loss:1.7159\n",
      "epoch:39,loss:1.8767\n",
      "epoch:39,loss:2.3733\n",
      "epoch:39,loss:2.1266\n",
      "epoch:39,loss:0.8030\n",
      "epoch:39,loss:2.3154\n",
      "epoch:39,loss:1.9411\n",
      "epoch:39,loss:1.3194\n",
      "epoch:39,loss:1.5165\n",
      "epoch:39,loss:1.4634\n",
      "epoch:39,loss:1.1560\n",
      "epoch:39,loss:1.5294\n",
      "epoch:39,loss:2.2735\n",
      "epoch:39,loss:1.1448\n",
      "epoch:39,loss:1.4896\n",
      "epoch:39,loss:2.5695\n",
      "============================================\n",
      "准确率由： tensor(0.3631) 上升至： tensor(0.3658) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第39个epoch的识别准确率为：36%\n",
      "epoch:40,loss:1.2147\n",
      "epoch:40,loss:1.9333\n",
      "epoch:40,loss:0.7502\n",
      "epoch:40,loss:1.5294\n",
      "epoch:40,loss:2.0627\n",
      "epoch:40,loss:2.0694\n",
      "epoch:40,loss:1.9465\n",
      "epoch:40,loss:1.5183\n",
      "epoch:40,loss:2.2071\n",
      "epoch:40,loss:1.6399\n",
      "epoch:40,loss:1.9315\n",
      "epoch:40,loss:3.1300\n",
      "epoch:40,loss:1.1159\n",
      "epoch:40,loss:1.3605\n",
      "epoch:40,loss:1.5182\n",
      "epoch:40,loss:2.1068\n",
      "epoch:40,loss:2.1220\n",
      "epoch:40,loss:1.0751\n",
      "epoch:40,loss:2.7005\n",
      "epoch:40,loss:1.8371\n",
      "epoch:40,loss:2.4518\n",
      "epoch:40,loss:2.2380\n",
      "epoch:40,loss:1.0483\n",
      "epoch:40,loss:1.7137\n",
      "epoch:40,loss:1.7541\n",
      "epoch:40,loss:1.8149\n",
      "epoch:40,loss:2.4690\n",
      "epoch:40,loss:1.5587\n",
      "epoch:40,loss:2.0109\n",
      "epoch:40,loss:0.8190\n",
      "epoch:40,loss:1.8489\n",
      "epoch:40,loss:0.8101\n",
      "epoch:40,loss:1.3945\n",
      "epoch:40,loss:2.1761\n",
      "epoch:40,loss:1.3947\n",
      "epoch:40,loss:1.4059\n",
      "epoch:40,loss:1.8662\n",
      "epoch:40,loss:1.9227\n",
      "epoch:40,loss:2.1159\n",
      "epoch:40,loss:1.5100\n",
      "epoch:40,loss:1.4090\n",
      "epoch:40,loss:1.9345\n",
      "epoch:40,loss:1.6850\n",
      "epoch:40,loss:1.7786\n",
      "epoch:40,loss:1.4616\n",
      "epoch:40,loss:1.5722\n",
      "epoch:40,loss:2.2637\n",
      "epoch:40,loss:1.9928\n",
      "epoch:40,loss:2.5777\n",
      "epoch:40,loss:1.4114\n",
      "epoch:40,loss:2.0516\n",
      "epoch:40,loss:1.9990\n",
      "epoch:40,loss:2.6645\n",
      "epoch:40,loss:2.0561\n",
      "epoch:40,loss:1.4185\n",
      "epoch:40,loss:2.4479\n",
      "epoch:40,loss:1.6227\n",
      "epoch:40,loss:0.9774\n",
      "epoch:40,loss:2.2317\n",
      "epoch:40,loss:2.1102\n",
      "============================================\n",
      "准确率由： tensor(0.3658) 上升至： tensor(0.3750) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第40个epoch的识别准确率为：37%\n",
      "epoch:41,loss:1.2979\n",
      "epoch:41,loss:1.8204\n",
      "epoch:41,loss:2.0220\n",
      "epoch:41,loss:1.9115\n",
      "epoch:41,loss:2.2270\n",
      "epoch:41,loss:1.4990\n",
      "epoch:41,loss:3.0715\n",
      "epoch:41,loss:1.6711\n",
      "epoch:41,loss:1.4363\n",
      "epoch:41,loss:0.8900\n",
      "epoch:41,loss:1.5535\n",
      "epoch:41,loss:1.8879\n",
      "epoch:41,loss:1.4974\n",
      "epoch:41,loss:2.9371\n",
      "epoch:41,loss:2.4718\n",
      "epoch:41,loss:3.5565\n",
      "epoch:41,loss:2.3008\n",
      "epoch:41,loss:1.5310\n",
      "epoch:41,loss:2.5203\n",
      "epoch:41,loss:1.5245\n",
      "epoch:41,loss:1.5262\n",
      "epoch:41,loss:1.9736\n",
      "epoch:41,loss:1.4252\n",
      "epoch:41,loss:2.1096\n",
      "epoch:41,loss:2.2845\n",
      "epoch:41,loss:2.3448\n",
      "epoch:41,loss:3.0833\n",
      "epoch:41,loss:1.2935\n",
      "epoch:41,loss:1.3610\n",
      "epoch:41,loss:2.4913\n",
      "epoch:41,loss:1.5948\n",
      "epoch:41,loss:1.3098\n",
      "epoch:41,loss:1.4158\n",
      "epoch:41,loss:2.0131\n",
      "epoch:41,loss:2.7103\n",
      "epoch:41,loss:1.4163\n",
      "epoch:41,loss:2.6843\n",
      "epoch:41,loss:1.8611\n",
      "epoch:41,loss:2.9486\n",
      "epoch:41,loss:1.7064\n",
      "epoch:41,loss:1.1793\n",
      "epoch:41,loss:1.5190\n",
      "epoch:41,loss:1.1318\n",
      "epoch:41,loss:1.2924\n",
      "epoch:41,loss:1.6668\n",
      "epoch:41,loss:2.0531\n",
      "epoch:41,loss:1.3963\n",
      "epoch:41,loss:1.3409\n",
      "epoch:41,loss:1.9013\n",
      "epoch:41,loss:2.2094\n",
      "epoch:41,loss:1.5937\n",
      "epoch:41,loss:1.3358\n",
      "epoch:41,loss:1.1416\n",
      "epoch:41,loss:2.8291\n",
      "epoch:41,loss:1.2696\n",
      "epoch:41,loss:2.1813\n",
      "epoch:41,loss:2.3495\n",
      "epoch:41,loss:2.7195\n",
      "epoch:41,loss:2.9867\n",
      "epoch:41,loss:1.9164\n",
      "============================================\n",
      "第41个epoch的识别准确率为：36%\n",
      "epoch:42,loss:1.5564\n",
      "epoch:42,loss:1.6823\n",
      "epoch:42,loss:1.4822\n",
      "epoch:42,loss:1.7265\n",
      "epoch:42,loss:1.2599\n",
      "epoch:42,loss:1.4552\n",
      "epoch:42,loss:1.8037\n",
      "epoch:42,loss:1.7558\n",
      "epoch:42,loss:1.0096\n",
      "epoch:42,loss:2.9967\n",
      "epoch:42,loss:3.2151\n",
      "epoch:42,loss:2.1013\n",
      "epoch:42,loss:2.1722\n",
      "epoch:42,loss:2.2506\n",
      "epoch:42,loss:1.0213\n",
      "epoch:42,loss:1.5076\n",
      "epoch:42,loss:1.7823\n",
      "epoch:42,loss:1.8847\n",
      "epoch:42,loss:2.1493\n",
      "epoch:42,loss:2.3742\n",
      "epoch:42,loss:1.9081\n",
      "epoch:42,loss:2.3445\n",
      "epoch:42,loss:2.5516\n",
      "epoch:42,loss:1.6364\n",
      "epoch:42,loss:2.8078\n",
      "epoch:42,loss:0.8997\n",
      "epoch:42,loss:1.7172\n",
      "epoch:42,loss:1.8860\n",
      "epoch:42,loss:1.6089\n",
      "epoch:42,loss:2.2556\n",
      "epoch:42,loss:2.4679\n",
      "epoch:42,loss:1.5564\n",
      "epoch:42,loss:1.5575\n",
      "epoch:42,loss:0.9496\n",
      "epoch:42,loss:1.2406\n",
      "epoch:42,loss:0.7328\n",
      "epoch:42,loss:1.7158\n",
      "epoch:42,loss:2.1959\n",
      "epoch:42,loss:1.8486\n",
      "epoch:42,loss:1.3280\n",
      "epoch:42,loss:2.3267\n",
      "epoch:42,loss:2.5082\n",
      "epoch:42,loss:2.8623\n",
      "epoch:42,loss:1.8789\n",
      "epoch:42,loss:1.4029\n",
      "epoch:42,loss:1.2641\n",
      "epoch:42,loss:2.4135\n",
      "epoch:42,loss:1.6554\n",
      "epoch:42,loss:1.9237\n",
      "epoch:42,loss:1.5129\n",
      "epoch:42,loss:2.8165\n",
      "epoch:42,loss:1.0081\n",
      "epoch:42,loss:1.9710\n",
      "epoch:42,loss:1.3155\n",
      "epoch:42,loss:1.6723\n",
      "epoch:42,loss:1.4615\n",
      "epoch:42,loss:1.7449\n",
      "epoch:42,loss:1.2782\n",
      "epoch:42,loss:1.0507\n",
      "epoch:42,loss:1.6638\n",
      "============================================\n",
      "准确率由： tensor(0.3750) 上升至： tensor(0.3897) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第42个epoch的识别准确率为：38%\n",
      "epoch:43,loss:2.4066\n",
      "epoch:43,loss:1.6130\n",
      "epoch:43,loss:1.3907\n",
      "epoch:43,loss:1.7616\n",
      "epoch:43,loss:1.7794\n",
      "epoch:43,loss:1.7653\n",
      "epoch:43,loss:1.2629\n",
      "epoch:43,loss:2.3962\n",
      "epoch:43,loss:1.9416\n",
      "epoch:43,loss:2.2818\n",
      "epoch:43,loss:3.5244\n",
      "epoch:43,loss:1.7807\n",
      "epoch:43,loss:1.5927\n",
      "epoch:43,loss:2.3441\n",
      "epoch:43,loss:1.5703\n",
      "epoch:43,loss:1.6473\n",
      "epoch:43,loss:1.8021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43,loss:2.1754\n",
      "epoch:43,loss:1.5540\n",
      "epoch:43,loss:2.2185\n",
      "epoch:43,loss:1.5685\n",
      "epoch:43,loss:1.4335\n",
      "epoch:43,loss:1.7475\n",
      "epoch:43,loss:1.7160\n",
      "epoch:43,loss:2.0215\n",
      "epoch:43,loss:1.5410\n",
      "epoch:43,loss:1.6063\n",
      "epoch:43,loss:1.8347\n",
      "epoch:43,loss:1.0420\n",
      "epoch:43,loss:0.8823\n",
      "epoch:43,loss:1.0366\n",
      "epoch:43,loss:1.9120\n",
      "epoch:43,loss:2.2063\n",
      "epoch:43,loss:2.5828\n",
      "epoch:43,loss:1.4519\n",
      "epoch:43,loss:2.0743\n",
      "epoch:43,loss:1.5511\n",
      "epoch:43,loss:1.8603\n",
      "epoch:43,loss:2.0514\n",
      "epoch:43,loss:1.8115\n",
      "epoch:43,loss:1.3339\n",
      "epoch:43,loss:1.2621\n",
      "epoch:43,loss:1.5507\n",
      "epoch:43,loss:3.9255\n",
      "epoch:43,loss:1.0960\n",
      "epoch:43,loss:1.7011\n",
      "epoch:43,loss:1.5668\n",
      "epoch:43,loss:1.5198\n",
      "epoch:43,loss:1.5532\n",
      "epoch:43,loss:2.1222\n",
      "epoch:43,loss:1.5762\n",
      "epoch:43,loss:1.2487\n",
      "epoch:43,loss:3.2766\n",
      "epoch:43,loss:3.6380\n",
      "epoch:43,loss:1.0831\n",
      "epoch:43,loss:2.3920\n",
      "epoch:43,loss:2.0759\n",
      "epoch:43,loss:2.2117\n",
      "epoch:43,loss:0.8059\n",
      "epoch:43,loss:1.8589\n",
      "============================================\n",
      "准确率由： tensor(0.3897) 上升至： tensor(0.3943) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第43个epoch的识别准确率为：39%\n",
      "epoch:44,loss:1.2762\n",
      "epoch:44,loss:0.8768\n",
      "epoch:44,loss:0.7396\n",
      "epoch:44,loss:1.5617\n",
      "epoch:44,loss:1.1898\n",
      "epoch:44,loss:1.4909\n",
      "epoch:44,loss:1.5253\n",
      "epoch:44,loss:1.7863\n",
      "epoch:44,loss:2.0865\n",
      "epoch:44,loss:1.6146\n",
      "epoch:44,loss:1.5984\n",
      "epoch:44,loss:1.3671\n",
      "epoch:44,loss:1.3389\n",
      "epoch:44,loss:1.2352\n",
      "epoch:44,loss:2.0766\n",
      "epoch:44,loss:1.9686\n",
      "epoch:44,loss:0.9679\n",
      "epoch:44,loss:1.8667\n",
      "epoch:44,loss:1.2530\n",
      "epoch:44,loss:1.8816\n",
      "epoch:44,loss:1.6778\n",
      "epoch:44,loss:2.1330\n",
      "epoch:44,loss:1.8747\n",
      "epoch:44,loss:0.9888\n",
      "epoch:44,loss:1.1621\n",
      "epoch:44,loss:1.1096\n",
      "epoch:44,loss:2.1727\n",
      "epoch:44,loss:2.4255\n",
      "epoch:44,loss:1.9318\n",
      "epoch:44,loss:2.3951\n",
      "epoch:44,loss:1.6832\n",
      "epoch:44,loss:1.1934\n",
      "epoch:44,loss:1.3073\n",
      "epoch:44,loss:1.6489\n",
      "epoch:44,loss:1.8539\n",
      "epoch:44,loss:1.4208\n",
      "epoch:44,loss:2.9950\n",
      "epoch:44,loss:1.3949\n",
      "epoch:44,loss:1.6761\n",
      "epoch:44,loss:0.8606\n",
      "epoch:44,loss:2.0242\n",
      "epoch:44,loss:1.7111\n",
      "epoch:44,loss:1.3821\n",
      "epoch:44,loss:1.5026\n",
      "epoch:44,loss:1.7908\n",
      "epoch:44,loss:2.4483\n",
      "epoch:44,loss:1.7424\n",
      "epoch:44,loss:1.6250\n",
      "epoch:44,loss:1.5411\n",
      "epoch:44,loss:1.4224\n",
      "epoch:44,loss:1.8318\n",
      "epoch:44,loss:2.1993\n",
      "epoch:44,loss:1.7881\n",
      "epoch:44,loss:2.4381\n",
      "epoch:44,loss:1.5011\n",
      "epoch:44,loss:1.5470\n",
      "epoch:44,loss:2.1091\n",
      "epoch:44,loss:1.2402\n",
      "epoch:44,loss:1.9636\n",
      "epoch:44,loss:2.0621\n",
      "============================================\n",
      "第44个epoch的识别准确率为：39%\n",
      "epoch:45,loss:1.9589\n",
      "epoch:45,loss:2.6643\n",
      "epoch:45,loss:1.8240\n",
      "epoch:45,loss:1.6192\n",
      "epoch:45,loss:1.5580\n",
      "epoch:45,loss:2.5636\n",
      "epoch:45,loss:1.0324\n",
      "epoch:45,loss:2.7607\n",
      "epoch:45,loss:2.5660\n",
      "epoch:45,loss:1.5437\n",
      "epoch:45,loss:1.9826\n",
      "epoch:45,loss:2.1123\n",
      "epoch:45,loss:0.9445\n",
      "epoch:45,loss:1.3183\n",
      "epoch:45,loss:1.9948\n",
      "epoch:45,loss:1.9258\n",
      "epoch:45,loss:1.6728\n",
      "epoch:45,loss:1.3235\n",
      "epoch:45,loss:1.5861\n",
      "epoch:45,loss:2.3875\n",
      "epoch:45,loss:1.4173\n",
      "epoch:45,loss:2.2650\n",
      "epoch:45,loss:1.8718\n",
      "epoch:45,loss:1.2557\n",
      "epoch:45,loss:2.1695\n",
      "epoch:45,loss:1.8718\n",
      "epoch:45,loss:2.0063\n",
      "epoch:45,loss:2.9054\n",
      "epoch:45,loss:2.2682\n",
      "epoch:45,loss:2.3902\n",
      "epoch:45,loss:1.6791\n",
      "epoch:45,loss:2.5841\n",
      "epoch:45,loss:2.4014\n",
      "epoch:45,loss:2.0683\n",
      "epoch:45,loss:2.0718\n",
      "epoch:45,loss:1.4389\n",
      "epoch:45,loss:1.9399\n",
      "epoch:45,loss:1.2273\n",
      "epoch:45,loss:1.6692\n",
      "epoch:45,loss:1.8770\n",
      "epoch:45,loss:1.7387\n",
      "epoch:45,loss:1.9109\n",
      "epoch:45,loss:2.2845\n",
      "epoch:45,loss:3.2546\n",
      "epoch:45,loss:1.1690\n",
      "epoch:45,loss:0.9909\n",
      "epoch:45,loss:1.5765\n",
      "epoch:45,loss:1.6647\n",
      "epoch:45,loss:1.9589\n",
      "epoch:45,loss:2.6126\n",
      "epoch:45,loss:1.9811\n",
      "epoch:45,loss:1.7839\n",
      "epoch:45,loss:1.7136\n",
      "epoch:45,loss:1.0065\n",
      "epoch:45,loss:1.6508\n",
      "epoch:45,loss:2.5705\n",
      "epoch:45,loss:1.7363\n",
      "epoch:45,loss:1.8438\n",
      "epoch:45,loss:0.7991\n",
      "epoch:45,loss:2.0461\n",
      "============================================\n",
      "第45个epoch的识别准确率为：38%\n",
      "epoch:46,loss:2.2234\n",
      "epoch:46,loss:1.0205\n",
      "epoch:46,loss:1.4450\n",
      "epoch:46,loss:1.7195\n",
      "epoch:46,loss:2.1519\n",
      "epoch:46,loss:1.0635\n",
      "epoch:46,loss:1.8620\n",
      "epoch:46,loss:1.1094\n",
      "epoch:46,loss:1.7065\n",
      "epoch:46,loss:0.6473\n",
      "epoch:46,loss:1.5682\n",
      "epoch:46,loss:1.9210\n",
      "epoch:46,loss:2.4853\n",
      "epoch:46,loss:0.9774\n",
      "epoch:46,loss:2.0884\n",
      "epoch:46,loss:1.0182\n",
      "epoch:46,loss:2.4522\n",
      "epoch:46,loss:1.1990\n",
      "epoch:46,loss:1.0071\n",
      "epoch:46,loss:1.1014\n",
      "epoch:46,loss:1.6940\n",
      "epoch:46,loss:2.3183\n",
      "epoch:46,loss:2.0775\n",
      "epoch:46,loss:1.5721\n",
      "epoch:46,loss:1.8285\n",
      "epoch:46,loss:1.7834\n",
      "epoch:46,loss:1.7754\n",
      "epoch:46,loss:1.7308\n",
      "epoch:46,loss:2.9957\n",
      "epoch:46,loss:2.8273\n",
      "epoch:46,loss:1.5730\n",
      "epoch:46,loss:1.4609\n",
      "epoch:46,loss:1.7697\n",
      "epoch:46,loss:1.5629\n",
      "epoch:46,loss:1.9248\n",
      "epoch:46,loss:2.3706\n",
      "epoch:46,loss:1.5135\n",
      "epoch:46,loss:1.7116\n",
      "epoch:46,loss:1.1842\n",
      "epoch:46,loss:1.5379\n",
      "epoch:46,loss:1.0968\n",
      "epoch:46,loss:1.4847\n",
      "epoch:46,loss:1.6765\n",
      "epoch:46,loss:0.9968\n",
      "epoch:46,loss:1.5824\n",
      "epoch:46,loss:1.4619\n",
      "epoch:46,loss:1.5897\n",
      "epoch:46,loss:0.9310\n",
      "epoch:46,loss:1.0060\n",
      "epoch:46,loss:1.5674\n",
      "epoch:46,loss:1.5244\n",
      "epoch:46,loss:0.6372\n",
      "epoch:46,loss:1.8880\n",
      "epoch:46,loss:0.9141\n",
      "epoch:46,loss:1.5839\n",
      "epoch:46,loss:1.1480\n",
      "epoch:46,loss:1.7168\n",
      "epoch:46,loss:1.3259\n",
      "epoch:46,loss:2.2611\n",
      "epoch:46,loss:2.3292\n",
      "============================================\n",
      "准确率由： tensor(0.3943) 上升至： tensor(0.4044) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第46个epoch的识别准确率为：40%\n",
      "epoch:47,loss:1.1624\n",
      "epoch:47,loss:1.4649\n",
      "epoch:47,loss:1.1333\n",
      "epoch:47,loss:0.9672\n",
      "epoch:47,loss:2.2895\n",
      "epoch:47,loss:1.3235\n",
      "epoch:47,loss:2.0435\n",
      "epoch:47,loss:1.8763\n",
      "epoch:47,loss:1.7961\n",
      "epoch:47,loss:1.7838\n",
      "epoch:47,loss:2.2581\n",
      "epoch:47,loss:2.3007\n",
      "epoch:47,loss:1.2880\n",
      "epoch:47,loss:1.4333\n",
      "epoch:47,loss:2.1328\n",
      "epoch:47,loss:1.8198\n",
      "epoch:47,loss:1.3564\n",
      "epoch:47,loss:1.8858\n",
      "epoch:47,loss:1.6891\n",
      "epoch:47,loss:1.2603\n",
      "epoch:47,loss:1.0583\n",
      "epoch:47,loss:2.2970\n",
      "epoch:47,loss:1.5476\n",
      "epoch:47,loss:1.7429\n",
      "epoch:47,loss:2.0375\n",
      "epoch:47,loss:1.7801\n",
      "epoch:47,loss:1.0373\n",
      "epoch:47,loss:1.1624\n",
      "epoch:47,loss:1.2600\n",
      "epoch:47,loss:1.6713\n",
      "epoch:47,loss:1.7388\n",
      "epoch:47,loss:1.2661\n",
      "epoch:47,loss:1.1899\n",
      "epoch:47,loss:2.6917\n",
      "epoch:47,loss:1.4732\n",
      "epoch:47,loss:2.0690\n",
      "epoch:47,loss:1.5179\n",
      "epoch:47,loss:1.2478\n",
      "epoch:47,loss:1.4987\n",
      "epoch:47,loss:1.8176\n",
      "epoch:47,loss:1.4383\n",
      "epoch:47,loss:1.5426\n",
      "epoch:47,loss:1.3783\n",
      "epoch:47,loss:1.3711\n",
      "epoch:47,loss:2.1142\n",
      "epoch:47,loss:1.4807\n",
      "epoch:47,loss:1.7107\n",
      "epoch:47,loss:2.0916\n",
      "epoch:47,loss:2.3692\n",
      "epoch:47,loss:1.1369\n",
      "epoch:47,loss:2.0532\n",
      "epoch:47,loss:1.6456\n",
      "epoch:47,loss:1.8473\n",
      "epoch:47,loss:1.4983\n",
      "epoch:47,loss:1.4266\n",
      "epoch:47,loss:1.3365\n",
      "epoch:47,loss:1.0925\n",
      "epoch:47,loss:1.7028\n",
      "epoch:47,loss:1.6690\n",
      "epoch:47,loss:2.0225\n",
      "============================================\n",
      "第47个epoch的识别准确率为：39%\n",
      "epoch:48,loss:1.9231\n",
      "epoch:48,loss:1.5594\n",
      "epoch:48,loss:1.7166\n",
      "epoch:48,loss:1.3380\n",
      "epoch:48,loss:2.7201\n",
      "epoch:48,loss:2.5009\n",
      "epoch:48,loss:2.4305\n",
      "epoch:48,loss:1.7223\n",
      "epoch:48,loss:1.5262\n",
      "epoch:48,loss:2.0480\n",
      "epoch:48,loss:2.2258\n",
      "epoch:48,loss:1.4715\n",
      "epoch:48,loss:1.2319\n",
      "epoch:48,loss:1.4246\n",
      "epoch:48,loss:1.3314\n",
      "epoch:48,loss:2.7279\n",
      "epoch:48,loss:1.0842\n",
      "epoch:48,loss:2.2250\n",
      "epoch:48,loss:2.4735\n",
      "epoch:48,loss:1.9015\n",
      "epoch:48,loss:1.6863\n",
      "epoch:48,loss:1.2429\n",
      "epoch:48,loss:2.8032\n",
      "epoch:48,loss:2.3821\n",
      "epoch:48,loss:1.5514\n",
      "epoch:48,loss:2.1260\n",
      "epoch:48,loss:1.3349\n",
      "epoch:48,loss:1.4847\n",
      "epoch:48,loss:1.4255\n",
      "epoch:48,loss:1.9607\n",
      "epoch:48,loss:1.7512\n",
      "epoch:48,loss:2.7911\n",
      "epoch:48,loss:1.2084\n",
      "epoch:48,loss:1.3378\n",
      "epoch:48,loss:2.9498\n",
      "epoch:48,loss:1.9802\n",
      "epoch:48,loss:1.4196\n",
      "epoch:48,loss:1.5930\n",
      "epoch:48,loss:0.6846\n",
      "epoch:48,loss:1.1382\n",
      "epoch:48,loss:1.9782\n",
      "epoch:48,loss:2.3328\n",
      "epoch:48,loss:2.1737\n",
      "epoch:48,loss:2.3625\n",
      "epoch:48,loss:1.4051\n",
      "epoch:48,loss:1.6585\n",
      "epoch:48,loss:2.2588\n",
      "epoch:48,loss:2.4476\n",
      "epoch:48,loss:1.3497\n",
      "epoch:48,loss:1.8168\n",
      "epoch:48,loss:1.4845\n",
      "epoch:48,loss:1.9580\n",
      "epoch:48,loss:1.6367\n",
      "epoch:48,loss:1.5107\n",
      "epoch:48,loss:2.1289\n",
      "epoch:48,loss:0.9935\n",
      "epoch:48,loss:2.3052\n",
      "epoch:48,loss:1.4128\n",
      "epoch:48,loss:2.7915\n",
      "epoch:48,loss:1.8486\n",
      "============================================\n",
      "第48个epoch的识别准确率为：38%\n",
      "epoch:49,loss:2.0533\n",
      "epoch:49,loss:0.9747\n",
      "epoch:49,loss:2.2192\n",
      "epoch:49,loss:0.8076\n",
      "epoch:49,loss:2.0314\n",
      "epoch:49,loss:1.4815\n",
      "epoch:49,loss:1.7342\n",
      "epoch:49,loss:0.9414\n",
      "epoch:49,loss:2.4429\n",
      "epoch:49,loss:1.0729\n",
      "epoch:49,loss:2.0339\n",
      "epoch:49,loss:1.8531\n",
      "epoch:49,loss:1.0266\n",
      "epoch:49,loss:1.7455\n",
      "epoch:49,loss:1.0647\n",
      "epoch:49,loss:1.4515\n",
      "epoch:49,loss:1.9135\n",
      "epoch:49,loss:1.0577\n",
      "epoch:49,loss:1.7725\n",
      "epoch:49,loss:2.2188\n",
      "epoch:49,loss:1.9754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49,loss:2.1605\n",
      "epoch:49,loss:1.4668\n",
      "epoch:49,loss:0.9578\n",
      "epoch:49,loss:1.6734\n",
      "epoch:49,loss:1.4176\n",
      "epoch:49,loss:2.7698\n",
      "epoch:49,loss:1.0613\n",
      "epoch:49,loss:1.5955\n",
      "epoch:49,loss:1.9471\n",
      "epoch:49,loss:2.5036\n",
      "epoch:49,loss:2.6234\n",
      "epoch:49,loss:1.6567\n",
      "epoch:49,loss:1.6915\n",
      "epoch:49,loss:1.7358\n",
      "epoch:49,loss:1.7893\n",
      "epoch:49,loss:2.3494\n",
      "epoch:49,loss:1.6131\n",
      "epoch:49,loss:2.9206\n",
      "epoch:49,loss:1.6035\n",
      "epoch:49,loss:1.3613\n",
      "epoch:49,loss:0.7750\n",
      "epoch:49,loss:0.6331\n",
      "epoch:49,loss:1.4184\n",
      "epoch:49,loss:2.3586\n",
      "epoch:49,loss:1.5094\n",
      "epoch:49,loss:1.0127\n",
      "epoch:49,loss:1.0456\n",
      "epoch:49,loss:1.9786\n",
      "epoch:49,loss:1.5198\n",
      "epoch:49,loss:1.8999\n",
      "epoch:49,loss:1.8804\n",
      "epoch:49,loss:2.0537\n",
      "epoch:49,loss:1.5515\n",
      "epoch:49,loss:2.2087\n",
      "epoch:49,loss:2.2396\n",
      "epoch:49,loss:1.2342\n",
      "epoch:49,loss:1.5143\n",
      "epoch:49,loss:0.7754\n",
      "epoch:49,loss:2.3546\n",
      "============================================\n",
      "准确率由： tensor(0.4044) 上升至： tensor(0.4072) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第49个epoch的识别准确率为：40%\n",
      "epoch:50,loss:1.4322\n",
      "epoch:50,loss:2.1315\n",
      "epoch:50,loss:1.5686\n",
      "epoch:50,loss:1.7196\n",
      "epoch:50,loss:2.3818\n",
      "epoch:50,loss:0.9809\n",
      "epoch:50,loss:2.0403\n",
      "epoch:50,loss:1.5135\n",
      "epoch:50,loss:1.6173\n",
      "epoch:50,loss:2.2538\n",
      "epoch:50,loss:1.5742\n",
      "epoch:50,loss:2.1136\n",
      "epoch:50,loss:0.6724\n",
      "epoch:50,loss:1.4629\n",
      "epoch:50,loss:1.9077\n",
      "epoch:50,loss:2.2115\n",
      "epoch:50,loss:1.4945\n",
      "epoch:50,loss:1.9265\n",
      "epoch:50,loss:1.1280\n",
      "epoch:50,loss:1.3007\n",
      "epoch:50,loss:1.2660\n",
      "epoch:50,loss:1.6347\n",
      "epoch:50,loss:1.1196\n",
      "epoch:50,loss:1.1641\n",
      "epoch:50,loss:1.5220\n",
      "epoch:50,loss:1.3171\n",
      "epoch:50,loss:1.9581\n",
      "epoch:50,loss:0.6676\n",
      "epoch:50,loss:1.1609\n",
      "epoch:50,loss:2.4442\n",
      "epoch:50,loss:0.9190\n",
      "epoch:50,loss:1.5399\n",
      "epoch:50,loss:1.8410\n",
      "epoch:50,loss:1.3423\n",
      "epoch:50,loss:1.5006\n",
      "epoch:50,loss:2.1539\n",
      "epoch:50,loss:2.0235\n",
      "epoch:50,loss:0.7258\n",
      "epoch:50,loss:1.5939\n",
      "epoch:50,loss:1.3946\n",
      "epoch:50,loss:2.0865\n",
      "epoch:50,loss:1.2913\n",
      "epoch:50,loss:0.4144\n",
      "epoch:50,loss:1.2718\n",
      "epoch:50,loss:1.4066\n",
      "epoch:50,loss:2.0596\n",
      "epoch:50,loss:1.6710\n",
      "epoch:50,loss:2.1176\n",
      "epoch:50,loss:2.2556\n",
      "epoch:50,loss:1.2765\n",
      "epoch:50,loss:1.3689\n",
      "epoch:50,loss:2.2022\n",
      "epoch:50,loss:1.5258\n",
      "epoch:50,loss:2.1392\n",
      "epoch:50,loss:1.3903\n",
      "epoch:50,loss:1.8373\n",
      "epoch:50,loss:0.5697\n",
      "epoch:50,loss:2.1305\n",
      "epoch:50,loss:1.6961\n",
      "epoch:50,loss:1.6992\n",
      "============================================\n",
      "准确率由： tensor(0.4072) 上升至： tensor(0.4219) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第50个epoch的识别准确率为：42%\n",
      "epoch:51,loss:1.0236\n",
      "epoch:51,loss:1.8455\n",
      "epoch:51,loss:2.2963\n",
      "epoch:51,loss:1.3290\n",
      "epoch:51,loss:1.5078\n",
      "epoch:51,loss:1.6049\n",
      "epoch:51,loss:0.8754\n",
      "epoch:51,loss:1.3139\n",
      "epoch:51,loss:1.6240\n",
      "epoch:51,loss:1.2267\n",
      "epoch:51,loss:1.9114\n",
      "epoch:51,loss:1.1718\n",
      "epoch:51,loss:1.6368\n",
      "epoch:51,loss:2.3360\n",
      "epoch:51,loss:1.6241\n",
      "epoch:51,loss:1.2547\n",
      "epoch:51,loss:1.8798\n",
      "epoch:51,loss:1.4347\n",
      "epoch:51,loss:1.0377\n",
      "epoch:51,loss:1.7031\n",
      "epoch:51,loss:1.7862\n",
      "epoch:51,loss:1.0533\n",
      "epoch:51,loss:1.4757\n",
      "epoch:51,loss:1.5693\n",
      "epoch:51,loss:1.2397\n",
      "epoch:51,loss:2.1307\n",
      "epoch:51,loss:1.4719\n",
      "epoch:51,loss:1.7847\n",
      "epoch:51,loss:0.7028\n",
      "epoch:51,loss:2.3651\n",
      "epoch:51,loss:2.0061\n",
      "epoch:51,loss:0.8601\n",
      "epoch:51,loss:1.6553\n",
      "epoch:51,loss:1.2537\n",
      "epoch:51,loss:2.2788\n",
      "epoch:51,loss:0.9949\n",
      "epoch:51,loss:1.8799\n",
      "epoch:51,loss:1.4538\n",
      "epoch:51,loss:1.5612\n",
      "epoch:51,loss:1.7793\n",
      "epoch:51,loss:2.2441\n",
      "epoch:51,loss:3.4930\n",
      "epoch:51,loss:1.8249\n",
      "epoch:51,loss:1.3317\n",
      "epoch:51,loss:2.9314\n",
      "epoch:51,loss:2.4324\n",
      "epoch:51,loss:1.9304\n",
      "epoch:51,loss:0.4757\n",
      "epoch:51,loss:1.5862\n",
      "epoch:51,loss:1.6071\n",
      "epoch:51,loss:1.1014\n",
      "epoch:51,loss:1.6051\n",
      "epoch:51,loss:0.8570\n",
      "epoch:51,loss:2.2851\n",
      "epoch:51,loss:2.5061\n",
      "epoch:51,loss:0.9472\n",
      "epoch:51,loss:1.4204\n",
      "epoch:51,loss:1.8382\n",
      "epoch:51,loss:1.8751\n",
      "epoch:51,loss:1.2630\n",
      "============================================\n",
      "第51个epoch的识别准确率为：41%\n",
      "epoch:52,loss:1.7516\n",
      "epoch:52,loss:2.1117\n",
      "epoch:52,loss:0.9346\n",
      "epoch:52,loss:1.0866\n",
      "epoch:52,loss:1.8724\n",
      "epoch:52,loss:1.5745\n",
      "epoch:52,loss:1.4153\n",
      "epoch:52,loss:3.4578\n",
      "epoch:52,loss:1.4081\n",
      "epoch:52,loss:2.6178\n",
      "epoch:52,loss:2.4334\n",
      "epoch:52,loss:1.9617\n",
      "epoch:52,loss:1.8414\n",
      "epoch:52,loss:1.1920\n",
      "epoch:52,loss:0.4243\n",
      "epoch:52,loss:1.3400\n",
      "epoch:52,loss:2.6561\n",
      "epoch:52,loss:0.9439\n",
      "epoch:52,loss:1.5399\n",
      "epoch:52,loss:2.2434\n",
      "epoch:52,loss:0.8617\n",
      "epoch:52,loss:1.7584\n",
      "epoch:52,loss:2.0163\n",
      "epoch:52,loss:2.3902\n",
      "epoch:52,loss:2.6168\n",
      "epoch:52,loss:1.1669\n",
      "epoch:52,loss:1.4898\n",
      "epoch:52,loss:1.1612\n",
      "epoch:52,loss:0.7336\n",
      "epoch:52,loss:2.3116\n",
      "epoch:52,loss:0.9518\n",
      "epoch:52,loss:0.9071\n",
      "epoch:52,loss:2.2409\n",
      "epoch:52,loss:1.5815\n",
      "epoch:52,loss:2.4214\n",
      "epoch:52,loss:2.5586\n",
      "epoch:52,loss:3.3161\n",
      "epoch:52,loss:1.9533\n",
      "epoch:52,loss:2.3666\n",
      "epoch:52,loss:2.2212\n",
      "epoch:52,loss:1.7097\n",
      "epoch:52,loss:1.9228\n",
      "epoch:52,loss:1.8440\n",
      "epoch:52,loss:2.0121\n",
      "epoch:52,loss:2.7437\n",
      "epoch:52,loss:1.8723\n",
      "epoch:52,loss:1.3088\n",
      "epoch:52,loss:2.1238\n",
      "epoch:52,loss:2.0517\n",
      "epoch:52,loss:1.3061\n",
      "epoch:52,loss:2.1552\n",
      "epoch:52,loss:1.9008\n",
      "epoch:52,loss:1.4113\n",
      "epoch:52,loss:1.5613\n",
      "epoch:52,loss:1.4382\n",
      "epoch:52,loss:2.7673\n",
      "epoch:52,loss:1.5174\n",
      "epoch:52,loss:2.4212\n",
      "epoch:52,loss:1.3622\n",
      "epoch:52,loss:0.8806\n",
      "============================================\n",
      "准确率由： tensor(0.4219) 上升至： tensor(0.4320) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第52个epoch的识别准确率为：43%\n",
      "epoch:53,loss:1.0110\n",
      "epoch:53,loss:1.3929\n",
      "epoch:53,loss:1.7880\n",
      "epoch:53,loss:2.8122\n",
      "epoch:53,loss:1.9019\n",
      "epoch:53,loss:1.0777\n",
      "epoch:53,loss:1.7154\n",
      "epoch:53,loss:0.7351\n",
      "epoch:53,loss:0.6971\n",
      "epoch:53,loss:1.4797\n",
      "epoch:53,loss:1.4419\n",
      "epoch:53,loss:1.7679\n",
      "epoch:53,loss:1.3760\n",
      "epoch:53,loss:2.3085\n",
      "epoch:53,loss:1.9094\n",
      "epoch:53,loss:1.9534\n",
      "epoch:53,loss:1.7057\n",
      "epoch:53,loss:1.9057\n",
      "epoch:53,loss:1.1700\n",
      "epoch:53,loss:2.1178\n",
      "epoch:53,loss:1.7507\n",
      "epoch:53,loss:1.4392\n",
      "epoch:53,loss:2.0989\n",
      "epoch:53,loss:1.8704\n",
      "epoch:53,loss:1.2441\n",
      "epoch:53,loss:1.8538\n",
      "epoch:53,loss:1.5552\n",
      "epoch:53,loss:2.4218\n",
      "epoch:53,loss:2.1935\n",
      "epoch:53,loss:2.1139\n",
      "epoch:53,loss:0.6892\n",
      "epoch:53,loss:0.8458\n",
      "epoch:53,loss:2.8087\n",
      "epoch:53,loss:1.8073\n",
      "epoch:53,loss:0.9226\n",
      "epoch:53,loss:1.3118\n",
      "epoch:53,loss:1.7653\n",
      "epoch:53,loss:1.1314\n",
      "epoch:53,loss:1.3725\n",
      "epoch:53,loss:0.9657\n",
      "epoch:53,loss:1.2387\n",
      "epoch:53,loss:1.0761\n",
      "epoch:53,loss:0.8967\n",
      "epoch:53,loss:1.4946\n",
      "epoch:53,loss:1.1543\n",
      "epoch:53,loss:0.9828\n",
      "epoch:53,loss:1.6493\n",
      "epoch:53,loss:2.5279\n",
      "epoch:53,loss:2.0339\n",
      "epoch:53,loss:1.1412\n",
      "epoch:53,loss:1.5181\n",
      "epoch:53,loss:1.3900\n",
      "epoch:53,loss:2.3774\n",
      "epoch:53,loss:2.8147\n",
      "epoch:53,loss:1.8909\n",
      "epoch:53,loss:1.3736\n",
      "epoch:53,loss:1.9224\n",
      "epoch:53,loss:1.6136\n",
      "epoch:53,loss:1.9977\n",
      "epoch:53,loss:1.9658\n",
      "============================================\n",
      "第53个epoch的识别准确率为：42%\n",
      "epoch:54,loss:1.3518\n",
      "epoch:54,loss:1.6638\n",
      "epoch:54,loss:1.9000\n",
      "epoch:54,loss:1.6242\n",
      "epoch:54,loss:1.6432\n",
      "epoch:54,loss:1.8102\n",
      "epoch:54,loss:1.0660\n",
      "epoch:54,loss:2.6713\n",
      "epoch:54,loss:1.7818\n",
      "epoch:54,loss:1.3846\n",
      "epoch:54,loss:1.3181\n",
      "epoch:54,loss:1.4272\n",
      "epoch:54,loss:1.1907\n",
      "epoch:54,loss:1.4279\n",
      "epoch:54,loss:1.9318\n",
      "epoch:54,loss:0.7828\n",
      "epoch:54,loss:3.1157\n",
      "epoch:54,loss:2.6828\n",
      "epoch:54,loss:2.1811\n",
      "epoch:54,loss:1.7239\n",
      "epoch:54,loss:1.5562\n",
      "epoch:54,loss:1.4972\n",
      "epoch:54,loss:3.3631\n",
      "epoch:54,loss:1.8707\n",
      "epoch:54,loss:0.9952\n",
      "epoch:54,loss:2.5615\n",
      "epoch:54,loss:2.2190\n",
      "epoch:54,loss:2.5752\n",
      "epoch:54,loss:1.3664\n",
      "epoch:54,loss:1.2513\n",
      "epoch:54,loss:1.0813\n",
      "epoch:54,loss:1.7502\n",
      "epoch:54,loss:1.6222\n",
      "epoch:54,loss:1.9156\n",
      "epoch:54,loss:0.8276\n",
      "epoch:54,loss:2.0981\n",
      "epoch:54,loss:1.3806\n",
      "epoch:54,loss:2.5644\n",
      "epoch:54,loss:2.9317\n",
      "epoch:54,loss:2.0706\n",
      "epoch:54,loss:2.0010\n",
      "epoch:54,loss:1.2917\n",
      "epoch:54,loss:1.3719\n",
      "epoch:54,loss:1.0420\n",
      "epoch:54,loss:1.1405\n",
      "epoch:54,loss:1.0286\n",
      "epoch:54,loss:2.0517\n",
      "epoch:54,loss:2.0163\n",
      "epoch:54,loss:1.2882\n",
      "epoch:54,loss:1.4465\n",
      "epoch:54,loss:1.1177\n",
      "epoch:54,loss:0.5109\n",
      "epoch:54,loss:1.4069\n",
      "epoch:54,loss:1.2903\n",
      "epoch:54,loss:0.9881\n",
      "epoch:54,loss:1.2206\n",
      "epoch:54,loss:1.6763\n",
      "epoch:54,loss:1.4751\n",
      "epoch:54,loss:1.4760\n",
      "epoch:54,loss:3.5622\n",
      "============================================\n",
      "准确率由： tensor(0.4320) 上升至： tensor(0.4559) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第54个epoch的识别准确率为：45%\n",
      "epoch:55,loss:2.0656\n",
      "epoch:55,loss:1.9439\n",
      "epoch:55,loss:0.5085\n",
      "epoch:55,loss:1.7582\n",
      "epoch:55,loss:1.7112\n",
      "epoch:55,loss:0.6570\n",
      "epoch:55,loss:0.8152\n",
      "epoch:55,loss:2.4291\n",
      "epoch:55,loss:2.7446\n",
      "epoch:55,loss:2.3308\n",
      "epoch:55,loss:1.9781\n",
      "epoch:55,loss:1.7902\n",
      "epoch:55,loss:1.8020\n",
      "epoch:55,loss:1.8666\n",
      "epoch:55,loss:0.7477\n",
      "epoch:55,loss:2.9709\n",
      "epoch:55,loss:1.1232\n",
      "epoch:55,loss:2.0343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:55,loss:1.6035\n",
      "epoch:55,loss:1.6560\n",
      "epoch:55,loss:1.2354\n",
      "epoch:55,loss:2.2746\n",
      "epoch:55,loss:1.5497\n",
      "epoch:55,loss:1.9707\n",
      "epoch:55,loss:0.8009\n",
      "epoch:55,loss:2.0882\n",
      "epoch:55,loss:1.4874\n",
      "epoch:55,loss:1.8662\n",
      "epoch:55,loss:0.9790\n",
      "epoch:55,loss:2.2686\n",
      "epoch:55,loss:1.8403\n",
      "epoch:55,loss:1.9124\n",
      "epoch:55,loss:0.9608\n",
      "epoch:55,loss:2.0849\n",
      "epoch:55,loss:1.3266\n",
      "epoch:55,loss:1.5076\n",
      "epoch:55,loss:2.0794\n",
      "epoch:55,loss:2.4389\n",
      "epoch:55,loss:2.1859\n",
      "epoch:55,loss:1.5874\n",
      "epoch:55,loss:2.1557\n",
      "epoch:55,loss:1.7485\n",
      "epoch:55,loss:1.2373\n",
      "epoch:55,loss:1.5639\n",
      "epoch:55,loss:1.7085\n",
      "epoch:55,loss:1.4765\n",
      "epoch:55,loss:1.7360\n",
      "epoch:55,loss:1.4950\n",
      "epoch:55,loss:0.9083\n",
      "epoch:55,loss:1.8957\n",
      "epoch:55,loss:0.7292\n",
      "epoch:55,loss:1.5959\n",
      "epoch:55,loss:1.2317\n",
      "epoch:55,loss:1.5950\n",
      "epoch:55,loss:2.2426\n",
      "epoch:55,loss:1.8177\n",
      "epoch:55,loss:1.5301\n",
      "epoch:55,loss:1.5508\n",
      "epoch:55,loss:1.2247\n",
      "epoch:55,loss:2.6248\n",
      "============================================\n",
      "第55个epoch的识别准确率为：45%\n",
      "epoch:56,loss:1.9444\n",
      "epoch:56,loss:1.1372\n",
      "epoch:56,loss:1.9189\n",
      "epoch:56,loss:1.2039\n",
      "epoch:56,loss:1.1830\n",
      "epoch:56,loss:1.5302\n",
      "epoch:56,loss:1.8131\n",
      "epoch:56,loss:0.8524\n",
      "epoch:56,loss:1.5535\n",
      "epoch:56,loss:2.0873\n",
      "epoch:56,loss:1.3076\n",
      "epoch:56,loss:1.2226\n",
      "epoch:56,loss:1.1922\n",
      "epoch:56,loss:1.6904\n",
      "epoch:56,loss:1.8679\n",
      "epoch:56,loss:2.4591\n",
      "epoch:56,loss:3.0858\n",
      "epoch:56,loss:1.0947\n",
      "epoch:56,loss:1.4799\n",
      "epoch:56,loss:0.4356\n",
      "epoch:56,loss:1.4177\n",
      "epoch:56,loss:2.6959\n",
      "epoch:56,loss:1.1326\n",
      "epoch:56,loss:1.0903\n",
      "epoch:56,loss:0.9095\n",
      "epoch:56,loss:0.7633\n",
      "epoch:56,loss:1.7687\n",
      "epoch:56,loss:2.3126\n",
      "epoch:56,loss:2.7529\n",
      "epoch:56,loss:1.1476\n",
      "epoch:56,loss:1.9122\n",
      "epoch:56,loss:1.7461\n",
      "epoch:56,loss:1.0907\n",
      "epoch:56,loss:2.6048\n",
      "epoch:56,loss:1.0006\n",
      "epoch:56,loss:2.2238\n",
      "epoch:56,loss:1.3426\n",
      "epoch:56,loss:1.7343\n",
      "epoch:56,loss:1.3808\n",
      "epoch:56,loss:1.5934\n",
      "epoch:56,loss:2.6370\n",
      "epoch:56,loss:0.8411\n",
      "epoch:56,loss:2.9971\n",
      "epoch:56,loss:1.9152\n",
      "epoch:56,loss:2.1560\n",
      "epoch:56,loss:1.5893\n",
      "epoch:56,loss:1.2645\n",
      "epoch:56,loss:0.9058\n",
      "epoch:56,loss:2.7719\n",
      "epoch:56,loss:2.2976\n",
      "epoch:56,loss:1.1636\n",
      "epoch:56,loss:1.7770\n",
      "epoch:56,loss:2.4337\n",
      "epoch:56,loss:1.5459\n",
      "epoch:56,loss:1.7409\n",
      "epoch:56,loss:0.7899\n",
      "epoch:56,loss:1.5095\n",
      "epoch:56,loss:1.4786\n",
      "epoch:56,loss:1.5427\n",
      "epoch:56,loss:1.6409\n",
      "============================================\n",
      "第56个epoch的识别准确率为：45%\n",
      "epoch:57,loss:2.6051\n",
      "epoch:57,loss:2.1281\n",
      "epoch:57,loss:1.1839\n",
      "epoch:57,loss:1.6125\n",
      "epoch:57,loss:1.0382\n",
      "epoch:57,loss:1.8933\n",
      "epoch:57,loss:1.7200\n",
      "epoch:57,loss:1.6990\n",
      "epoch:57,loss:1.7082\n",
      "epoch:57,loss:1.3337\n",
      "epoch:57,loss:1.0178\n",
      "epoch:57,loss:0.8497\n",
      "epoch:57,loss:1.2554\n",
      "epoch:57,loss:1.5197\n",
      "epoch:57,loss:1.5715\n",
      "epoch:57,loss:1.6322\n",
      "epoch:57,loss:1.1410\n",
      "epoch:57,loss:1.6979\n",
      "epoch:57,loss:1.1596\n",
      "epoch:57,loss:1.3700\n",
      "epoch:57,loss:1.7215\n",
      "epoch:57,loss:0.6821\n",
      "epoch:57,loss:1.6883\n",
      "epoch:57,loss:1.3466\n",
      "epoch:57,loss:2.4916\n",
      "epoch:57,loss:1.3289\n",
      "epoch:57,loss:2.4253\n",
      "epoch:57,loss:2.9407\n",
      "epoch:57,loss:1.5118\n",
      "epoch:57,loss:2.1242\n",
      "epoch:57,loss:1.2232\n",
      "epoch:57,loss:1.8295\n",
      "epoch:57,loss:1.0763\n",
      "epoch:57,loss:1.3357\n",
      "epoch:57,loss:1.9309\n",
      "epoch:57,loss:2.5667\n",
      "epoch:57,loss:0.9126\n",
      "epoch:57,loss:0.4733\n",
      "epoch:57,loss:1.5410\n",
      "epoch:57,loss:1.5233\n",
      "epoch:57,loss:1.0548\n",
      "epoch:57,loss:1.6586\n",
      "epoch:57,loss:0.7429\n",
      "epoch:57,loss:1.8535\n",
      "epoch:57,loss:0.9828\n",
      "epoch:57,loss:0.7155\n",
      "epoch:57,loss:1.8160\n",
      "epoch:57,loss:2.3327\n",
      "epoch:57,loss:0.6685\n",
      "epoch:57,loss:0.9626\n",
      "epoch:57,loss:2.3059\n",
      "epoch:57,loss:0.8514\n",
      "epoch:57,loss:1.0097\n",
      "epoch:57,loss:1.4256\n",
      "epoch:57,loss:1.5301\n",
      "epoch:57,loss:1.7688\n",
      "epoch:57,loss:1.0051\n",
      "epoch:57,loss:2.1812\n",
      "epoch:57,loss:2.0063\n",
      "epoch:57,loss:0.7983\n",
      "============================================\n",
      "准确率由： tensor(0.4559) 上升至： tensor(0.4715) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第57个epoch的识别准确率为：47%\n",
      "epoch:58,loss:1.4481\n",
      "epoch:58,loss:1.1287\n",
      "epoch:58,loss:1.2725\n",
      "epoch:58,loss:1.0101\n",
      "epoch:58,loss:1.9699\n",
      "epoch:58,loss:1.3386\n",
      "epoch:58,loss:1.8772\n",
      "epoch:58,loss:2.1464\n",
      "epoch:58,loss:1.2439\n",
      "epoch:58,loss:2.5537\n",
      "epoch:58,loss:1.9360\n",
      "epoch:58,loss:0.9034\n",
      "epoch:58,loss:0.8525\n",
      "epoch:58,loss:1.8651\n",
      "epoch:58,loss:2.0781\n",
      "epoch:58,loss:2.1874\n",
      "epoch:58,loss:1.1011\n",
      "epoch:58,loss:1.3092\n",
      "epoch:58,loss:0.7188\n",
      "epoch:58,loss:1.7442\n",
      "epoch:58,loss:1.2281\n",
      "epoch:58,loss:2.0219\n",
      "epoch:58,loss:3.0963\n",
      "epoch:58,loss:1.5903\n",
      "epoch:58,loss:1.0586\n",
      "epoch:58,loss:1.7080\n",
      "epoch:58,loss:0.9091\n",
      "epoch:58,loss:1.2195\n",
      "epoch:58,loss:0.7413\n",
      "epoch:58,loss:1.2216\n",
      "epoch:58,loss:1.5113\n",
      "epoch:58,loss:2.7394\n",
      "epoch:58,loss:2.6680\n",
      "epoch:58,loss:1.9266\n",
      "epoch:58,loss:0.7920\n",
      "epoch:58,loss:1.3693\n",
      "epoch:58,loss:0.9617\n",
      "epoch:58,loss:1.3895\n",
      "epoch:58,loss:1.1906\n",
      "epoch:58,loss:1.8645\n",
      "epoch:58,loss:1.1585\n",
      "epoch:58,loss:2.3399\n",
      "epoch:58,loss:1.7082\n",
      "epoch:58,loss:1.1151\n",
      "epoch:58,loss:1.3103\n",
      "epoch:58,loss:1.3214\n",
      "epoch:58,loss:1.4891\n",
      "epoch:58,loss:1.8159\n",
      "epoch:58,loss:0.8948\n",
      "epoch:58,loss:1.2869\n",
      "epoch:58,loss:1.2250\n",
      "epoch:58,loss:1.9812\n",
      "epoch:58,loss:1.0694\n",
      "epoch:58,loss:1.2062\n",
      "epoch:58,loss:1.0839\n",
      "epoch:58,loss:2.6895\n",
      "epoch:58,loss:1.5610\n",
      "epoch:58,loss:1.4900\n",
      "epoch:58,loss:1.6559\n",
      "epoch:58,loss:1.8870\n",
      "============================================\n",
      "第58个epoch的识别准确率为：46%\n",
      "epoch:59,loss:0.8634\n",
      "epoch:59,loss:1.2144\n",
      "epoch:59,loss:1.7404\n",
      "epoch:59,loss:1.3680\n",
      "epoch:59,loss:0.7501\n",
      "epoch:59,loss:1.9447\n",
      "epoch:59,loss:1.3173\n",
      "epoch:59,loss:1.6448\n",
      "epoch:59,loss:2.3823\n",
      "epoch:59,loss:2.2665\n",
      "epoch:59,loss:0.6441\n",
      "epoch:59,loss:0.8910\n",
      "epoch:59,loss:2.0550\n",
      "epoch:59,loss:1.0448\n",
      "epoch:59,loss:0.7694\n",
      "epoch:59,loss:0.9963\n",
      "epoch:59,loss:1.3938\n",
      "epoch:59,loss:1.4362\n",
      "epoch:59,loss:2.1882\n",
      "epoch:59,loss:1.6991\n",
      "epoch:59,loss:1.2279\n",
      "epoch:59,loss:0.5769\n",
      "epoch:59,loss:2.5533\n",
      "epoch:59,loss:2.0901\n",
      "epoch:59,loss:2.0175\n",
      "epoch:59,loss:0.7917\n",
      "epoch:59,loss:0.6611\n",
      "epoch:59,loss:1.4924\n",
      "epoch:59,loss:2.2040\n",
      "epoch:59,loss:1.9731\n",
      "epoch:59,loss:1.8122\n",
      "epoch:59,loss:1.4596\n",
      "epoch:59,loss:0.5261\n",
      "epoch:59,loss:1.8528\n",
      "epoch:59,loss:1.6510\n",
      "epoch:59,loss:0.7466\n",
      "epoch:59,loss:2.0175\n",
      "epoch:59,loss:0.4691\n",
      "epoch:59,loss:0.7782\n",
      "epoch:59,loss:0.4216\n",
      "epoch:59,loss:1.7896\n",
      "epoch:59,loss:1.0638\n",
      "epoch:59,loss:0.4938\n",
      "epoch:59,loss:1.2385\n",
      "epoch:59,loss:1.5204\n",
      "epoch:59,loss:2.7072\n",
      "epoch:59,loss:1.7049\n",
      "epoch:59,loss:1.9775\n",
      "epoch:59,loss:1.1370\n",
      "epoch:59,loss:1.9522\n",
      "epoch:59,loss:1.0851\n",
      "epoch:59,loss:2.7298\n",
      "epoch:59,loss:1.4514\n",
      "epoch:59,loss:1.4574\n",
      "epoch:59,loss:2.3582\n",
      "epoch:59,loss:1.2750\n",
      "epoch:59,loss:1.5453\n",
      "epoch:59,loss:1.7069\n",
      "epoch:59,loss:1.4158\n",
      "epoch:59,loss:1.6722\n",
      "============================================\n",
      "准确率由： tensor(0.4715) 上升至： tensor(0.4789) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第59个epoch的识别准确率为：47%\n",
      "epoch:60,loss:2.3929\n",
      "epoch:60,loss:1.1513\n",
      "epoch:60,loss:1.8667\n",
      "epoch:60,loss:1.3399\n",
      "epoch:60,loss:1.1094\n",
      "epoch:60,loss:1.0990\n",
      "epoch:60,loss:1.4163\n",
      "epoch:60,loss:0.9894\n",
      "epoch:60,loss:1.0428\n",
      "epoch:60,loss:2.1123\n",
      "epoch:60,loss:1.5495\n",
      "epoch:60,loss:0.5161\n",
      "epoch:60,loss:1.8237\n",
      "epoch:60,loss:0.6750\n",
      "epoch:60,loss:2.3869\n",
      "epoch:60,loss:1.2178\n",
      "epoch:60,loss:0.8974\n",
      "epoch:60,loss:1.1563\n",
      "epoch:60,loss:0.7443\n",
      "epoch:60,loss:1.4341\n",
      "epoch:60,loss:2.0130\n",
      "epoch:60,loss:0.5573\n",
      "epoch:60,loss:1.4036\n",
      "epoch:60,loss:2.9376\n",
      "epoch:60,loss:1.6414\n",
      "epoch:60,loss:1.0799\n",
      "epoch:60,loss:1.2526\n",
      "epoch:60,loss:2.3092\n",
      "epoch:60,loss:1.8852\n",
      "epoch:60,loss:1.3264\n",
      "epoch:60,loss:1.4666\n",
      "epoch:60,loss:0.5607\n",
      "epoch:60,loss:1.5372\n",
      "epoch:60,loss:0.3019\n",
      "epoch:60,loss:0.5859\n",
      "epoch:60,loss:1.4779\n",
      "epoch:60,loss:1.2444\n",
      "epoch:60,loss:1.1483\n",
      "epoch:60,loss:2.2268\n",
      "epoch:60,loss:1.7998\n",
      "epoch:60,loss:0.3970\n",
      "epoch:60,loss:1.1885\n",
      "epoch:60,loss:1.6457\n",
      "epoch:60,loss:1.4872\n",
      "epoch:60,loss:2.8620\n",
      "epoch:60,loss:1.1861\n",
      "epoch:60,loss:1.1196\n",
      "epoch:60,loss:1.6407\n",
      "epoch:60,loss:0.9167\n",
      "epoch:60,loss:1.8375\n",
      "epoch:60,loss:1.3886\n",
      "epoch:60,loss:1.9386\n",
      "epoch:60,loss:1.3165\n",
      "epoch:60,loss:0.9479\n",
      "epoch:60,loss:1.3094\n",
      "epoch:60,loss:1.3903\n",
      "epoch:60,loss:1.3816\n",
      "epoch:60,loss:2.6066\n",
      "epoch:60,loss:1.6483\n",
      "epoch:60,loss:1.0538\n",
      "============================================\n",
      "准确率由： tensor(0.4789) 上升至： tensor(0.4853) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第60个epoch的识别准确率为：48%\n",
      "epoch:61,loss:1.3518\n",
      "epoch:61,loss:1.1834\n",
      "epoch:61,loss:1.2675\n",
      "epoch:61,loss:0.7781\n",
      "epoch:61,loss:0.8521\n",
      "epoch:61,loss:1.1527\n",
      "epoch:61,loss:1.0402\n",
      "epoch:61,loss:1.7357\n",
      "epoch:61,loss:1.9773\n",
      "epoch:61,loss:1.5530\n",
      "epoch:61,loss:1.5987\n",
      "epoch:61,loss:2.5800\n",
      "epoch:61,loss:0.9234\n",
      "epoch:61,loss:1.5890\n",
      "epoch:61,loss:1.5450\n",
      "epoch:61,loss:1.1310\n",
      "epoch:61,loss:1.3872\n",
      "epoch:61,loss:0.7509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:61,loss:1.5822\n",
      "epoch:61,loss:0.7685\n",
      "epoch:61,loss:3.0823\n",
      "epoch:61,loss:0.9108\n",
      "epoch:61,loss:1.2295\n",
      "epoch:61,loss:0.6121\n",
      "epoch:61,loss:0.8957\n",
      "epoch:61,loss:1.3006\n",
      "epoch:61,loss:0.4771\n",
      "epoch:61,loss:1.2144\n",
      "epoch:61,loss:2.6548\n",
      "epoch:61,loss:1.4745\n",
      "epoch:61,loss:0.5508\n",
      "epoch:61,loss:1.9306\n",
      "epoch:61,loss:1.7072\n",
      "epoch:61,loss:1.3525\n",
      "epoch:61,loss:2.4942\n",
      "epoch:61,loss:0.8447\n",
      "epoch:61,loss:1.6608\n",
      "epoch:61,loss:1.1405\n",
      "epoch:61,loss:1.2848\n",
      "epoch:61,loss:0.5751\n",
      "epoch:61,loss:1.1196\n",
      "epoch:61,loss:1.5934\n",
      "epoch:61,loss:1.3895\n",
      "epoch:61,loss:1.4159\n",
      "epoch:61,loss:1.0010\n",
      "epoch:61,loss:0.9077\n",
      "epoch:61,loss:1.9801\n",
      "epoch:61,loss:2.3311\n",
      "epoch:61,loss:1.6347\n",
      "epoch:61,loss:0.9379\n",
      "epoch:61,loss:1.0015\n",
      "epoch:61,loss:0.7156\n",
      "epoch:61,loss:0.9168\n",
      "epoch:61,loss:1.0140\n",
      "epoch:61,loss:1.2898\n",
      "epoch:61,loss:2.1542\n",
      "epoch:61,loss:1.3819\n",
      "epoch:61,loss:1.5245\n",
      "epoch:61,loss:2.7551\n",
      "epoch:61,loss:1.3073\n",
      "============================================\n",
      "准确率由： tensor(0.4853) 上升至： tensor(0.4881) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第61个epoch的识别准确率为：48%\n",
      "epoch:62,loss:0.7131\n",
      "epoch:62,loss:2.2570\n",
      "epoch:62,loss:1.7118\n",
      "epoch:62,loss:1.4877\n",
      "epoch:62,loss:1.2711\n",
      "epoch:62,loss:0.8349\n",
      "epoch:62,loss:1.9434\n",
      "epoch:62,loss:2.0589\n",
      "epoch:62,loss:1.2599\n",
      "epoch:62,loss:1.3257\n",
      "epoch:62,loss:1.8622\n",
      "epoch:62,loss:2.2364\n",
      "epoch:62,loss:0.8397\n",
      "epoch:62,loss:1.3036\n",
      "epoch:62,loss:0.9418\n",
      "epoch:62,loss:1.8373\n",
      "epoch:62,loss:1.4697\n",
      "epoch:62,loss:1.7492\n",
      "epoch:62,loss:0.7805\n",
      "epoch:62,loss:0.7855\n",
      "epoch:62,loss:1.4591\n",
      "epoch:62,loss:1.2198\n",
      "epoch:62,loss:0.9366\n",
      "epoch:62,loss:2.0990\n",
      "epoch:62,loss:2.0747\n",
      "epoch:62,loss:0.7358\n",
      "epoch:62,loss:1.2842\n",
      "epoch:62,loss:1.1246\n",
      "epoch:62,loss:1.4908\n",
      "epoch:62,loss:1.5693\n",
      "epoch:62,loss:0.7961\n",
      "epoch:62,loss:1.7488\n",
      "epoch:62,loss:0.9108\n",
      "epoch:62,loss:2.4117\n",
      "epoch:62,loss:1.2178\n",
      "epoch:62,loss:1.8593\n",
      "epoch:62,loss:2.4029\n",
      "epoch:62,loss:2.2971\n",
      "epoch:62,loss:2.4487\n",
      "epoch:62,loss:0.7927\n",
      "epoch:62,loss:1.5955\n",
      "epoch:62,loss:1.4933\n",
      "epoch:62,loss:1.7505\n",
      "epoch:62,loss:1.3995\n",
      "epoch:62,loss:2.5903\n",
      "epoch:62,loss:1.4954\n",
      "epoch:62,loss:2.6100\n",
      "epoch:62,loss:1.0716\n",
      "epoch:62,loss:2.4429\n",
      "epoch:62,loss:1.0645\n",
      "epoch:62,loss:1.1300\n",
      "epoch:62,loss:2.4858\n",
      "epoch:62,loss:0.4425\n",
      "epoch:62,loss:1.5034\n",
      "epoch:62,loss:1.9127\n",
      "epoch:62,loss:1.2600\n",
      "epoch:62,loss:2.0916\n",
      "epoch:62,loss:1.4842\n",
      "epoch:62,loss:0.9826\n",
      "epoch:62,loss:0.8026\n",
      "============================================\n",
      "第62个epoch的识别准确率为：48%\n",
      "epoch:63,loss:1.7242\n",
      "epoch:63,loss:1.1462\n",
      "epoch:63,loss:0.3638\n",
      "epoch:63,loss:1.0310\n",
      "epoch:63,loss:0.3852\n",
      "epoch:63,loss:0.9007\n",
      "epoch:63,loss:1.7012\n",
      "epoch:63,loss:0.3464\n",
      "epoch:63,loss:1.4026\n",
      "epoch:63,loss:2.2293\n",
      "epoch:63,loss:1.6183\n",
      "epoch:63,loss:1.6043\n",
      "epoch:63,loss:1.4342\n",
      "epoch:63,loss:1.2808\n",
      "epoch:63,loss:1.8009\n",
      "epoch:63,loss:2.0636\n",
      "epoch:63,loss:1.2222\n",
      "epoch:63,loss:0.9175\n",
      "epoch:63,loss:0.9996\n",
      "epoch:63,loss:1.2777\n",
      "epoch:63,loss:0.6961\n",
      "epoch:63,loss:1.8461\n",
      "epoch:63,loss:1.4121\n",
      "epoch:63,loss:1.1571\n",
      "epoch:63,loss:1.6159\n",
      "epoch:63,loss:1.8153\n",
      "epoch:63,loss:1.8432\n",
      "epoch:63,loss:1.0098\n",
      "epoch:63,loss:1.3249\n",
      "epoch:63,loss:0.8634\n",
      "epoch:63,loss:1.3695\n",
      "epoch:63,loss:1.2400\n",
      "epoch:63,loss:1.0326\n",
      "epoch:63,loss:1.5610\n",
      "epoch:63,loss:1.1473\n",
      "epoch:63,loss:2.3578\n",
      "epoch:63,loss:1.2116\n",
      "epoch:63,loss:1.7696\n",
      "epoch:63,loss:1.9065\n",
      "epoch:63,loss:2.2266\n",
      "epoch:63,loss:1.0917\n",
      "epoch:63,loss:2.4432\n",
      "epoch:63,loss:2.0542\n",
      "epoch:63,loss:2.1596\n",
      "epoch:63,loss:1.6649\n",
      "epoch:63,loss:1.6536\n",
      "epoch:63,loss:0.6731\n",
      "epoch:63,loss:2.2634\n",
      "epoch:63,loss:1.8079\n",
      "epoch:63,loss:1.5491\n",
      "epoch:63,loss:2.0608\n",
      "epoch:63,loss:0.8919\n",
      "epoch:63,loss:1.3081\n",
      "epoch:63,loss:1.2862\n",
      "epoch:63,loss:1.2460\n",
      "epoch:63,loss:1.3426\n",
      "epoch:63,loss:1.3311\n",
      "epoch:63,loss:1.3663\n",
      "epoch:63,loss:1.0919\n",
      "epoch:63,loss:0.9142\n",
      "============================================\n",
      "准确率由： tensor(0.4881) 上升至： tensor(0.5165) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第63个epoch的识别准确率为：51%\n",
      "epoch:64,loss:1.1720\n",
      "epoch:64,loss:1.4165\n",
      "epoch:64,loss:1.0307\n",
      "epoch:64,loss:1.2028\n",
      "epoch:64,loss:1.6079\n",
      "epoch:64,loss:0.9968\n",
      "epoch:64,loss:0.9222\n",
      "epoch:64,loss:1.4341\n",
      "epoch:64,loss:1.2717\n",
      "epoch:64,loss:1.2614\n",
      "epoch:64,loss:1.6682\n",
      "epoch:64,loss:0.6460\n",
      "epoch:64,loss:2.0306\n",
      "epoch:64,loss:2.4046\n",
      "epoch:64,loss:0.9943\n",
      "epoch:64,loss:2.5895\n",
      "epoch:64,loss:2.3909\n",
      "epoch:64,loss:1.0748\n",
      "epoch:64,loss:0.5584\n",
      "epoch:64,loss:2.4858\n",
      "epoch:64,loss:2.1828\n",
      "epoch:64,loss:1.2652\n",
      "epoch:64,loss:1.2251\n",
      "epoch:64,loss:1.2465\n",
      "epoch:64,loss:1.4734\n",
      "epoch:64,loss:0.8321\n",
      "epoch:64,loss:1.2843\n",
      "epoch:64,loss:1.6575\n",
      "epoch:64,loss:1.8770\n",
      "epoch:64,loss:0.9767\n",
      "epoch:64,loss:0.8419\n",
      "epoch:64,loss:0.7022\n",
      "epoch:64,loss:1.1293\n",
      "epoch:64,loss:1.9294\n",
      "epoch:64,loss:1.7062\n",
      "epoch:64,loss:1.8446\n",
      "epoch:64,loss:1.3169\n",
      "epoch:64,loss:0.8348\n",
      "epoch:64,loss:1.1137\n",
      "epoch:64,loss:1.7593\n",
      "epoch:64,loss:0.8635\n",
      "epoch:64,loss:1.7417\n",
      "epoch:64,loss:0.9825\n",
      "epoch:64,loss:1.3015\n",
      "epoch:64,loss:1.2057\n",
      "epoch:64,loss:0.9164\n",
      "epoch:64,loss:2.2036\n",
      "epoch:64,loss:1.5582\n",
      "epoch:64,loss:0.7071\n",
      "epoch:64,loss:2.5528\n",
      "epoch:64,loss:1.6364\n",
      "epoch:64,loss:0.6153\n",
      "epoch:64,loss:0.6611\n",
      "epoch:64,loss:1.1428\n",
      "epoch:64,loss:1.7280\n",
      "epoch:64,loss:2.6283\n",
      "epoch:64,loss:2.6313\n",
      "epoch:64,loss:0.9517\n",
      "epoch:64,loss:0.5769\n",
      "epoch:64,loss:1.2860\n",
      "============================================\n",
      "第64个epoch的识别准确率为：48%\n",
      "epoch:65,loss:1.3795\n",
      "epoch:65,loss:1.3008\n",
      "epoch:65,loss:2.2319\n",
      "epoch:65,loss:1.2913\n",
      "epoch:65,loss:1.1009\n",
      "epoch:65,loss:1.9266\n",
      "epoch:65,loss:1.5344\n",
      "epoch:65,loss:1.7287\n",
      "epoch:65,loss:0.3617\n",
      "epoch:65,loss:1.5030\n",
      "epoch:65,loss:0.3913\n",
      "epoch:65,loss:1.5445\n",
      "epoch:65,loss:1.4191\n",
      "epoch:65,loss:3.3786\n",
      "epoch:65,loss:1.2352\n",
      "epoch:65,loss:0.8898\n",
      "epoch:65,loss:2.1736\n",
      "epoch:65,loss:1.7501\n",
      "epoch:65,loss:0.8999\n",
      "epoch:65,loss:2.0410\n",
      "epoch:65,loss:1.8608\n",
      "epoch:65,loss:1.1353\n",
      "epoch:65,loss:1.0758\n",
      "epoch:65,loss:1.4877\n",
      "epoch:65,loss:1.0221\n",
      "epoch:65,loss:0.6933\n",
      "epoch:65,loss:1.9391\n",
      "epoch:65,loss:2.6525\n",
      "epoch:65,loss:2.4525\n",
      "epoch:65,loss:2.4196\n",
      "epoch:65,loss:0.7961\n",
      "epoch:65,loss:1.1521\n",
      "epoch:65,loss:1.7398\n",
      "epoch:65,loss:0.8167\n",
      "epoch:65,loss:1.3630\n",
      "epoch:65,loss:1.6845\n",
      "epoch:65,loss:1.3505\n",
      "epoch:65,loss:2.3680\n",
      "epoch:65,loss:1.6054\n",
      "epoch:65,loss:2.0033\n",
      "epoch:65,loss:1.7720\n",
      "epoch:65,loss:1.5069\n",
      "epoch:65,loss:1.6653\n",
      "epoch:65,loss:1.3663\n",
      "epoch:65,loss:0.8554\n",
      "epoch:65,loss:1.8518\n",
      "epoch:65,loss:0.5753\n",
      "epoch:65,loss:1.6972\n",
      "epoch:65,loss:1.2282\n",
      "epoch:65,loss:2.2549\n",
      "epoch:65,loss:1.6334\n",
      "epoch:65,loss:0.9318\n",
      "epoch:65,loss:0.6946\n",
      "epoch:65,loss:2.0281\n",
      "epoch:65,loss:2.0232\n",
      "epoch:65,loss:0.8085\n",
      "epoch:65,loss:1.1890\n",
      "epoch:65,loss:0.2902\n",
      "epoch:65,loss:2.5585\n",
      "epoch:65,loss:1.6571\n",
      "============================================\n",
      "第65个epoch的识别准确率为：49%\n",
      "epoch:66,loss:0.8587\n",
      "epoch:66,loss:0.4768\n",
      "epoch:66,loss:0.9830\n",
      "epoch:66,loss:0.9102\n",
      "epoch:66,loss:0.5481\n",
      "epoch:66,loss:1.3158\n",
      "epoch:66,loss:2.2336\n",
      "epoch:66,loss:1.0470\n",
      "epoch:66,loss:1.3236\n",
      "epoch:66,loss:0.9358\n",
      "epoch:66,loss:2.0470\n",
      "epoch:66,loss:2.1343\n",
      "epoch:66,loss:1.5362\n",
      "epoch:66,loss:1.4998\n",
      "epoch:66,loss:2.1448\n",
      "epoch:66,loss:1.0029\n",
      "epoch:66,loss:1.5300\n",
      "epoch:66,loss:0.9730\n",
      "epoch:66,loss:1.2998\n",
      "epoch:66,loss:0.9533\n",
      "epoch:66,loss:1.5762\n",
      "epoch:66,loss:1.9176\n",
      "epoch:66,loss:1.8303\n",
      "epoch:66,loss:2.1059\n",
      "epoch:66,loss:1.7372\n",
      "epoch:66,loss:1.0882\n",
      "epoch:66,loss:1.5196\n",
      "epoch:66,loss:2.2951\n",
      "epoch:66,loss:0.6411\n",
      "epoch:66,loss:1.2237\n",
      "epoch:66,loss:1.1438\n",
      "epoch:66,loss:0.8301\n",
      "epoch:66,loss:2.1376\n",
      "epoch:66,loss:2.6520\n",
      "epoch:66,loss:1.4740\n",
      "epoch:66,loss:0.7894\n",
      "epoch:66,loss:1.8092\n",
      "epoch:66,loss:0.9019\n",
      "epoch:66,loss:1.1122\n",
      "epoch:66,loss:0.9421\n",
      "epoch:66,loss:1.5577\n",
      "epoch:66,loss:1.5159\n",
      "epoch:66,loss:0.9321\n",
      "epoch:66,loss:1.5647\n",
      "epoch:66,loss:1.8842\n",
      "epoch:66,loss:0.9325\n",
      "epoch:66,loss:0.5678\n",
      "epoch:66,loss:1.2463\n",
      "epoch:66,loss:1.1608\n",
      "epoch:66,loss:1.7904\n",
      "epoch:66,loss:0.8096\n",
      "epoch:66,loss:1.4302\n",
      "epoch:66,loss:0.7728\n",
      "epoch:66,loss:1.2403\n",
      "epoch:66,loss:2.3105\n",
      "epoch:66,loss:1.3450\n",
      "epoch:66,loss:2.6245\n",
      "epoch:66,loss:2.8272\n",
      "epoch:66,loss:0.9762\n",
      "epoch:66,loss:1.5745\n",
      "============================================\n",
      "准确率由： tensor(0.5165) 上升至： tensor(0.5175) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第66个epoch的识别准确率为：51%\n",
      "epoch:67,loss:2.0612\n",
      "epoch:67,loss:1.5040\n",
      "epoch:67,loss:1.4908\n",
      "epoch:67,loss:1.1994\n",
      "epoch:67,loss:0.7492\n",
      "epoch:67,loss:2.1729\n",
      "epoch:67,loss:1.3076\n",
      "epoch:67,loss:1.1230\n",
      "epoch:67,loss:1.2243\n",
      "epoch:67,loss:1.0725\n",
      "epoch:67,loss:1.4660\n",
      "epoch:67,loss:1.0092\n",
      "epoch:67,loss:1.4901\n",
      "epoch:67,loss:1.4950\n",
      "epoch:67,loss:0.4228\n",
      "epoch:67,loss:0.6181\n",
      "epoch:67,loss:1.7430\n",
      "epoch:67,loss:3.5798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:67,loss:1.0087\n",
      "epoch:67,loss:1.3339\n",
      "epoch:67,loss:0.8290\n",
      "epoch:67,loss:1.1680\n",
      "epoch:67,loss:1.2306\n",
      "epoch:67,loss:1.7597\n",
      "epoch:67,loss:0.3547\n",
      "epoch:67,loss:1.7935\n",
      "epoch:67,loss:1.7678\n",
      "epoch:67,loss:1.7478\n",
      "epoch:67,loss:2.0096\n",
      "epoch:67,loss:1.3059\n",
      "epoch:67,loss:1.8230\n",
      "epoch:67,loss:1.3338\n",
      "epoch:67,loss:0.7723\n",
      "epoch:67,loss:1.9369\n",
      "epoch:67,loss:1.7423\n",
      "epoch:67,loss:0.8694\n",
      "epoch:67,loss:0.8623\n",
      "epoch:67,loss:2.7143\n",
      "epoch:67,loss:1.7071\n",
      "epoch:67,loss:2.6742\n",
      "epoch:67,loss:1.7414\n",
      "epoch:67,loss:1.2082\n",
      "epoch:67,loss:0.9477\n",
      "epoch:67,loss:1.6515\n",
      "epoch:67,loss:2.1666\n",
      "epoch:67,loss:1.1682\n",
      "epoch:67,loss:0.9632\n",
      "epoch:67,loss:0.9101\n",
      "epoch:67,loss:1.8264\n",
      "epoch:67,loss:1.7881\n",
      "epoch:67,loss:0.6849\n",
      "epoch:67,loss:1.2938\n",
      "epoch:67,loss:1.9704\n",
      "epoch:67,loss:0.9137\n",
      "epoch:67,loss:2.3361\n",
      "epoch:67,loss:1.1349\n",
      "epoch:67,loss:0.9982\n",
      "epoch:67,loss:1.0205\n",
      "epoch:67,loss:1.6480\n",
      "epoch:67,loss:1.3760\n",
      "============================================\n",
      "准确率由： tensor(0.5175) 上升至： tensor(0.5230) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第67个epoch的识别准确率为：52%\n",
      "epoch:68,loss:1.1541\n",
      "epoch:68,loss:1.8237\n",
      "epoch:68,loss:0.9028\n",
      "epoch:68,loss:2.3137\n",
      "epoch:68,loss:0.9113\n",
      "epoch:68,loss:1.4145\n",
      "epoch:68,loss:0.3292\n",
      "epoch:68,loss:1.7186\n",
      "epoch:68,loss:1.8261\n",
      "epoch:68,loss:0.6609\n",
      "epoch:68,loss:0.1827\n",
      "epoch:68,loss:1.4936\n",
      "epoch:68,loss:1.6531\n",
      "epoch:68,loss:0.9530\n",
      "epoch:68,loss:0.9526\n",
      "epoch:68,loss:1.9460\n",
      "epoch:68,loss:1.8716\n",
      "epoch:68,loss:1.0976\n",
      "epoch:68,loss:0.8928\n",
      "epoch:68,loss:1.5373\n",
      "epoch:68,loss:0.8004\n",
      "epoch:68,loss:1.2568\n",
      "epoch:68,loss:1.3585\n",
      "epoch:68,loss:1.4253\n",
      "epoch:68,loss:1.6063\n",
      "epoch:68,loss:1.3780\n",
      "epoch:68,loss:1.4732\n",
      "epoch:68,loss:1.1098\n",
      "epoch:68,loss:1.0687\n",
      "epoch:68,loss:1.4363\n",
      "epoch:68,loss:1.0862\n",
      "epoch:68,loss:1.8848\n",
      "epoch:68,loss:1.4163\n",
      "epoch:68,loss:1.3684\n",
      "epoch:68,loss:2.6207\n",
      "epoch:68,loss:1.4076\n",
      "epoch:68,loss:1.6152\n",
      "epoch:68,loss:1.0349\n",
      "epoch:68,loss:0.3146\n",
      "epoch:68,loss:0.8293\n",
      "epoch:68,loss:1.1891\n",
      "epoch:68,loss:1.1707\n",
      "epoch:68,loss:0.9286\n",
      "epoch:68,loss:1.4504\n",
      "epoch:68,loss:1.4677\n",
      "epoch:68,loss:0.7714\n",
      "epoch:68,loss:0.8388\n",
      "epoch:68,loss:0.9980\n",
      "epoch:68,loss:2.4184\n",
      "epoch:68,loss:1.3112\n",
      "epoch:68,loss:1.9836\n",
      "epoch:68,loss:2.0249\n",
      "epoch:68,loss:1.5428\n",
      "epoch:68,loss:1.9021\n",
      "epoch:68,loss:1.8387\n",
      "epoch:68,loss:1.8377\n",
      "epoch:68,loss:0.7726\n",
      "epoch:68,loss:0.7276\n",
      "epoch:68,loss:0.8727\n",
      "epoch:68,loss:2.0534\n",
      "============================================\n",
      "准确率由： tensor(0.5230) 上升至： tensor(0.5478) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第68个epoch的识别准确率为：54%\n",
      "epoch:69,loss:0.7118\n",
      "epoch:69,loss:1.7851\n",
      "epoch:69,loss:1.0586\n",
      "epoch:69,loss:2.3762\n",
      "epoch:69,loss:2.2916\n",
      "epoch:69,loss:1.5237\n",
      "epoch:69,loss:1.4963\n",
      "epoch:69,loss:0.6213\n",
      "epoch:69,loss:1.2152\n",
      "epoch:69,loss:1.0644\n",
      "epoch:69,loss:0.8178\n",
      "epoch:69,loss:1.1210\n",
      "epoch:69,loss:1.2900\n",
      "epoch:69,loss:0.7586\n",
      "epoch:69,loss:1.2813\n",
      "epoch:69,loss:2.1783\n",
      "epoch:69,loss:1.9392\n",
      "epoch:69,loss:1.9565\n",
      "epoch:69,loss:0.6375\n",
      "epoch:69,loss:2.0117\n",
      "epoch:69,loss:1.1535\n",
      "epoch:69,loss:1.8459\n",
      "epoch:69,loss:1.6412\n",
      "epoch:69,loss:1.0789\n",
      "epoch:69,loss:1.8314\n",
      "epoch:69,loss:2.0480\n",
      "epoch:69,loss:2.4341\n",
      "epoch:69,loss:2.2656\n",
      "epoch:69,loss:1.3217\n",
      "epoch:69,loss:0.7620\n",
      "epoch:69,loss:1.9781\n",
      "epoch:69,loss:1.3523\n",
      "epoch:69,loss:2.6140\n",
      "epoch:69,loss:1.0986\n",
      "epoch:69,loss:1.5909\n",
      "epoch:69,loss:2.5939\n",
      "epoch:69,loss:0.9272\n",
      "epoch:69,loss:0.8056\n",
      "epoch:69,loss:1.0134\n",
      "epoch:69,loss:2.4103\n",
      "epoch:69,loss:0.8574\n",
      "epoch:69,loss:1.4023\n",
      "epoch:69,loss:1.7560\n",
      "epoch:69,loss:1.7117\n",
      "epoch:69,loss:1.1394\n",
      "epoch:69,loss:1.3385\n",
      "epoch:69,loss:2.0686\n",
      "epoch:69,loss:2.0492\n",
      "epoch:69,loss:1.4480\n",
      "epoch:69,loss:1.5512\n",
      "epoch:69,loss:0.9609\n",
      "epoch:69,loss:0.9735\n",
      "epoch:69,loss:1.5241\n",
      "epoch:69,loss:2.3872\n",
      "epoch:69,loss:2.1249\n",
      "epoch:69,loss:2.1334\n",
      "epoch:69,loss:1.0520\n",
      "epoch:69,loss:1.9382\n",
      "epoch:69,loss:1.9327\n",
      "epoch:69,loss:1.1524\n",
      "============================================\n",
      "第69个epoch的识别准确率为：52%\n",
      "epoch:70,loss:0.7912\n",
      "epoch:70,loss:1.3372\n",
      "epoch:70,loss:0.9387\n",
      "epoch:70,loss:1.3629\n",
      "epoch:70,loss:1.1567\n",
      "epoch:70,loss:1.3557\n",
      "epoch:70,loss:0.7930\n",
      "epoch:70,loss:0.4188\n",
      "epoch:70,loss:0.9691\n",
      "epoch:70,loss:1.0284\n",
      "epoch:70,loss:1.0037\n",
      "epoch:70,loss:0.4302\n",
      "epoch:70,loss:0.7653\n",
      "epoch:70,loss:1.6680\n",
      "epoch:70,loss:1.4786\n",
      "epoch:70,loss:1.6298\n",
      "epoch:70,loss:1.3057\n",
      "epoch:70,loss:1.1624\n",
      "epoch:70,loss:1.9177\n",
      "epoch:70,loss:3.2220\n",
      "epoch:70,loss:0.9801\n",
      "epoch:70,loss:1.0626\n",
      "epoch:70,loss:1.2345\n",
      "epoch:70,loss:3.0041\n",
      "epoch:70,loss:1.6776\n",
      "epoch:70,loss:2.3903\n",
      "epoch:70,loss:1.0852\n",
      "epoch:70,loss:1.4126\n",
      "epoch:70,loss:0.9118\n",
      "epoch:70,loss:1.6250\n",
      "epoch:70,loss:1.3007\n",
      "epoch:70,loss:0.4067\n",
      "epoch:70,loss:2.3785\n",
      "epoch:70,loss:2.3496\n",
      "epoch:70,loss:2.9591\n",
      "epoch:70,loss:1.3076\n",
      "epoch:70,loss:2.3315\n",
      "epoch:70,loss:1.3355\n",
      "epoch:70,loss:1.5623\n",
      "epoch:70,loss:2.0670\n",
      "epoch:70,loss:1.5375\n",
      "epoch:70,loss:1.7790\n",
      "epoch:70,loss:1.8895\n",
      "epoch:70,loss:2.5173\n",
      "epoch:70,loss:1.8707\n",
      "epoch:70,loss:0.8853\n",
      "epoch:70,loss:0.7414\n",
      "epoch:70,loss:0.8681\n",
      "epoch:70,loss:1.4001\n",
      "epoch:70,loss:1.3943\n",
      "epoch:70,loss:2.3310\n",
      "epoch:70,loss:1.5414\n",
      "epoch:70,loss:0.4124\n",
      "epoch:70,loss:1.0870\n",
      "epoch:70,loss:0.5525\n",
      "epoch:70,loss:1.3246\n",
      "epoch:70,loss:1.9115\n",
      "epoch:70,loss:0.8512\n",
      "epoch:70,loss:0.9997\n",
      "epoch:70,loss:1.7073\n",
      "============================================\n",
      "第70个epoch的识别准确率为：54%\n",
      "epoch:71,loss:0.3894\n",
      "epoch:71,loss:1.3720\n",
      "epoch:71,loss:1.2646\n",
      "epoch:71,loss:1.1035\n",
      "epoch:71,loss:0.4340\n",
      "epoch:71,loss:1.1684\n",
      "epoch:71,loss:0.4459\n",
      "epoch:71,loss:1.9250\n",
      "epoch:71,loss:1.4143\n",
      "epoch:71,loss:0.4248\n",
      "epoch:71,loss:1.1008\n",
      "epoch:71,loss:2.5204\n",
      "epoch:71,loss:1.5258\n",
      "epoch:71,loss:2.5590\n",
      "epoch:71,loss:2.5139\n",
      "epoch:71,loss:0.8847\n",
      "epoch:71,loss:1.9102\n",
      "epoch:71,loss:0.5287\n",
      "epoch:71,loss:0.9764\n",
      "epoch:71,loss:0.9559\n",
      "epoch:71,loss:1.7093\n",
      "epoch:71,loss:1.4769\n",
      "epoch:71,loss:2.6747\n",
      "epoch:71,loss:2.7179\n",
      "epoch:71,loss:1.7597\n",
      "epoch:71,loss:0.4996\n",
      "epoch:71,loss:1.5490\n",
      "epoch:71,loss:0.8123\n",
      "epoch:71,loss:2.0004\n",
      "epoch:71,loss:3.9088\n",
      "epoch:71,loss:1.3910\n",
      "epoch:71,loss:2.0572\n",
      "epoch:71,loss:0.7430\n",
      "epoch:71,loss:0.6024\n",
      "epoch:71,loss:1.9893\n",
      "epoch:71,loss:1.4419\n",
      "epoch:71,loss:0.7598\n",
      "epoch:71,loss:1.4329\n",
      "epoch:71,loss:1.1845\n",
      "epoch:71,loss:1.5990\n",
      "epoch:71,loss:1.0802\n",
      "epoch:71,loss:1.4259\n",
      "epoch:71,loss:1.1267\n",
      "epoch:71,loss:1.2614\n",
      "epoch:71,loss:0.2480\n",
      "epoch:71,loss:0.7280\n",
      "epoch:71,loss:0.7142\n",
      "epoch:71,loss:1.1558\n",
      "epoch:71,loss:1.1009\n",
      "epoch:71,loss:1.4330\n",
      "epoch:71,loss:3.4725\n",
      "epoch:71,loss:1.3133\n",
      "epoch:71,loss:0.9214\n",
      "epoch:71,loss:1.4652\n",
      "epoch:71,loss:0.9168\n",
      "epoch:71,loss:1.8185\n",
      "epoch:71,loss:1.4492\n",
      "epoch:71,loss:0.6972\n",
      "epoch:71,loss:1.0177\n",
      "epoch:71,loss:1.4197\n",
      "============================================\n",
      "准确率由： tensor(0.5478) 上升至： tensor(0.5671) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第71个epoch的识别准确率为：56%\n",
      "epoch:72,loss:1.1207\n",
      "epoch:72,loss:1.7799\n",
      "epoch:72,loss:1.8385\n",
      "epoch:72,loss:1.3845\n",
      "epoch:72,loss:1.2308\n",
      "epoch:72,loss:0.9223\n",
      "epoch:72,loss:0.4436\n",
      "epoch:72,loss:0.9488\n",
      "epoch:72,loss:1.1921\n",
      "epoch:72,loss:1.0211\n",
      "epoch:72,loss:1.5660\n",
      "epoch:72,loss:0.4042\n",
      "epoch:72,loss:1.6315\n",
      "epoch:72,loss:0.4493\n",
      "epoch:72,loss:0.7781\n",
      "epoch:72,loss:1.5167\n",
      "epoch:72,loss:1.7428\n",
      "epoch:72,loss:0.6072\n",
      "epoch:72,loss:0.3654\n",
      "epoch:72,loss:2.1875\n",
      "epoch:72,loss:0.8522\n",
      "epoch:72,loss:1.1532\n",
      "epoch:72,loss:1.3166\n",
      "epoch:72,loss:1.4479\n",
      "epoch:72,loss:1.7363\n",
      "epoch:72,loss:2.2555\n",
      "epoch:72,loss:0.9312\n",
      "epoch:72,loss:0.4739\n",
      "epoch:72,loss:1.2429\n",
      "epoch:72,loss:0.9891\n",
      "epoch:72,loss:1.5287\n",
      "epoch:72,loss:1.3542\n",
      "epoch:72,loss:1.6789\n",
      "epoch:72,loss:1.5324\n",
      "epoch:72,loss:0.6764\n",
      "epoch:72,loss:1.1639\n",
      "epoch:72,loss:1.3864\n",
      "epoch:72,loss:1.1068\n",
      "epoch:72,loss:0.6887\n",
      "epoch:72,loss:0.8258\n",
      "epoch:72,loss:0.7513\n",
      "epoch:72,loss:1.6623\n",
      "epoch:72,loss:1.2499\n",
      "epoch:72,loss:1.0984\n",
      "epoch:72,loss:1.7151\n",
      "epoch:72,loss:0.7427\n",
      "epoch:72,loss:1.0716\n",
      "epoch:72,loss:1.6658\n",
      "epoch:72,loss:1.1771\n",
      "epoch:72,loss:1.5128\n",
      "epoch:72,loss:1.2788\n",
      "epoch:72,loss:1.7918\n",
      "epoch:72,loss:0.7595\n",
      "epoch:72,loss:0.8194\n",
      "epoch:72,loss:1.1244\n",
      "epoch:72,loss:0.8186\n",
      "epoch:72,loss:0.6806\n",
      "epoch:72,loss:0.9775\n",
      "epoch:72,loss:1.6541\n",
      "epoch:72,loss:1.2016\n",
      "============================================\n",
      "第72个epoch的识别准确率为：54%\n",
      "epoch:73,loss:1.9319\n",
      "epoch:73,loss:0.6916\n",
      "epoch:73,loss:2.3048\n",
      "epoch:73,loss:0.7725\n",
      "epoch:73,loss:1.0543\n",
      "epoch:73,loss:1.4086\n",
      "epoch:73,loss:1.4014\n",
      "epoch:73,loss:1.3287\n",
      "epoch:73,loss:1.9351\n",
      "epoch:73,loss:1.4286\n",
      "epoch:73,loss:0.9482\n",
      "epoch:73,loss:0.6943\n",
      "epoch:73,loss:1.1925\n",
      "epoch:73,loss:1.4637\n",
      "epoch:73,loss:0.5223\n",
      "epoch:73,loss:1.2648\n",
      "epoch:73,loss:1.5798\n",
      "epoch:73,loss:1.9822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:73,loss:1.2374\n",
      "epoch:73,loss:1.7649\n",
      "epoch:73,loss:1.1341\n",
      "epoch:73,loss:1.2825\n",
      "epoch:73,loss:1.9297\n",
      "epoch:73,loss:1.0720\n",
      "epoch:73,loss:0.9276\n",
      "epoch:73,loss:1.0368\n",
      "epoch:73,loss:0.8802\n",
      "epoch:73,loss:1.5099\n",
      "epoch:73,loss:2.1384\n",
      "epoch:73,loss:1.0732\n",
      "epoch:73,loss:0.9180\n",
      "epoch:73,loss:2.2982\n",
      "epoch:73,loss:1.1706\n",
      "epoch:73,loss:0.9158\n",
      "epoch:73,loss:1.4570\n",
      "epoch:73,loss:1.4515\n",
      "epoch:73,loss:1.4064\n",
      "epoch:73,loss:0.9182\n",
      "epoch:73,loss:1.0286\n",
      "epoch:73,loss:2.6599\n",
      "epoch:73,loss:2.7570\n",
      "epoch:73,loss:1.1049\n",
      "epoch:73,loss:1.6855\n",
      "epoch:73,loss:2.2286\n",
      "epoch:73,loss:0.9083\n",
      "epoch:73,loss:1.4978\n",
      "epoch:73,loss:0.6035\n",
      "epoch:73,loss:0.8504\n",
      "epoch:73,loss:1.8356\n",
      "epoch:73,loss:1.5658\n",
      "epoch:73,loss:1.6384\n",
      "epoch:73,loss:1.2434\n",
      "epoch:73,loss:1.9069\n",
      "epoch:73,loss:2.6592\n",
      "epoch:73,loss:1.1990\n",
      "epoch:73,loss:1.3743\n",
      "epoch:73,loss:1.2646\n",
      "epoch:73,loss:0.7376\n",
      "epoch:73,loss:0.9045\n",
      "epoch:73,loss:1.2268\n",
      "============================================\n",
      "第73个epoch的识别准确率为：55%\n",
      "epoch:74,loss:1.8830\n",
      "epoch:74,loss:1.1595\n",
      "epoch:74,loss:2.7406\n",
      "epoch:74,loss:1.6395\n",
      "epoch:74,loss:1.7087\n",
      "epoch:74,loss:1.4912\n",
      "epoch:74,loss:0.8742\n",
      "epoch:74,loss:0.9839\n",
      "epoch:74,loss:2.2641\n",
      "epoch:74,loss:1.0327\n",
      "epoch:74,loss:1.0731\n",
      "epoch:74,loss:1.8111\n",
      "epoch:74,loss:1.5817\n",
      "epoch:74,loss:1.8472\n",
      "epoch:74,loss:1.2067\n",
      "epoch:74,loss:1.2300\n",
      "epoch:74,loss:1.4710\n",
      "epoch:74,loss:0.9936\n",
      "epoch:74,loss:0.7475\n",
      "epoch:74,loss:2.2465\n",
      "epoch:74,loss:1.2750\n",
      "epoch:74,loss:1.2121\n",
      "epoch:74,loss:1.5647\n",
      "epoch:74,loss:1.2517\n",
      "epoch:74,loss:1.8430\n",
      "epoch:74,loss:0.6412\n",
      "epoch:74,loss:1.1225\n",
      "epoch:74,loss:1.6607\n",
      "epoch:74,loss:2.5134\n",
      "epoch:74,loss:1.8396\n",
      "epoch:74,loss:1.4278\n",
      "epoch:74,loss:1.2905\n",
      "epoch:74,loss:1.0141\n",
      "epoch:74,loss:0.8648\n",
      "epoch:74,loss:1.0301\n",
      "epoch:74,loss:1.3516\n",
      "epoch:74,loss:1.4639\n",
      "epoch:74,loss:2.5783\n",
      "epoch:74,loss:0.7927\n",
      "epoch:74,loss:1.2852\n",
      "epoch:74,loss:2.7119\n",
      "epoch:74,loss:1.0074\n",
      "epoch:74,loss:2.8555\n",
      "epoch:74,loss:1.3516\n",
      "epoch:74,loss:1.7750\n",
      "epoch:74,loss:1.5959\n",
      "epoch:74,loss:0.6846\n",
      "epoch:74,loss:2.3969\n",
      "epoch:74,loss:1.6146\n",
      "epoch:74,loss:1.4293\n",
      "epoch:74,loss:1.5056\n",
      "epoch:74,loss:0.7545\n",
      "epoch:74,loss:1.5307\n",
      "epoch:74,loss:0.5731\n",
      "epoch:74,loss:0.2910\n",
      "epoch:74,loss:1.0327\n",
      "epoch:74,loss:0.9460\n",
      "epoch:74,loss:0.8436\n",
      "epoch:74,loss:1.1793\n",
      "epoch:74,loss:1.9254\n",
      "============================================\n",
      "准确率由： tensor(0.5671) 上升至： tensor(0.5680) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第74个epoch的识别准确率为：56%\n",
      "epoch:75,loss:1.1580\n",
      "epoch:75,loss:1.5673\n",
      "epoch:75,loss:1.6907\n",
      "epoch:75,loss:1.3335\n",
      "epoch:75,loss:1.7860\n",
      "epoch:75,loss:1.0950\n",
      "epoch:75,loss:0.8094\n",
      "epoch:75,loss:1.6623\n",
      "epoch:75,loss:1.0302\n",
      "epoch:75,loss:1.1998\n",
      "epoch:75,loss:0.8885\n",
      "epoch:75,loss:1.9922\n",
      "epoch:75,loss:0.5617\n",
      "epoch:75,loss:1.7207\n",
      "epoch:75,loss:1.5076\n",
      "epoch:75,loss:0.6713\n",
      "epoch:75,loss:0.7633\n",
      "epoch:75,loss:1.5900\n",
      "epoch:75,loss:1.2846\n",
      "epoch:75,loss:0.3798\n",
      "epoch:75,loss:0.8640\n",
      "epoch:75,loss:0.7940\n",
      "epoch:75,loss:0.6545\n",
      "epoch:75,loss:0.8940\n",
      "epoch:75,loss:1.4399\n",
      "epoch:75,loss:2.4070\n",
      "epoch:75,loss:0.8662\n",
      "epoch:75,loss:1.7170\n",
      "epoch:75,loss:1.1577\n",
      "epoch:75,loss:0.5593\n",
      "epoch:75,loss:0.8012\n",
      "epoch:75,loss:1.3988\n",
      "epoch:75,loss:1.1832\n",
      "epoch:75,loss:1.3514\n",
      "epoch:75,loss:1.5316\n",
      "epoch:75,loss:1.7491\n",
      "epoch:75,loss:2.5233\n",
      "epoch:75,loss:2.1788\n",
      "epoch:75,loss:0.7935\n",
      "epoch:75,loss:2.1224\n",
      "epoch:75,loss:1.9056\n",
      "epoch:75,loss:1.5233\n",
      "epoch:75,loss:1.0202\n",
      "epoch:75,loss:1.6742\n",
      "epoch:75,loss:1.4899\n",
      "epoch:75,loss:0.5790\n",
      "epoch:75,loss:0.6940\n",
      "epoch:75,loss:1.7003\n",
      "epoch:75,loss:0.9764\n",
      "epoch:75,loss:1.2176\n",
      "epoch:75,loss:0.6429\n",
      "epoch:75,loss:1.7083\n",
      "epoch:75,loss:1.7747\n",
      "epoch:75,loss:0.8657\n",
      "epoch:75,loss:1.3356\n",
      "epoch:75,loss:1.0985\n",
      "epoch:75,loss:1.0902\n",
      "epoch:75,loss:1.7025\n",
      "epoch:75,loss:1.0521\n",
      "epoch:75,loss:0.9359\n",
      "============================================\n",
      "第75个epoch的识别准确率为：55%\n",
      "epoch:76,loss:1.6889\n",
      "epoch:76,loss:0.4664\n",
      "epoch:76,loss:0.9286\n",
      "epoch:76,loss:1.1330\n",
      "epoch:76,loss:1.3907\n",
      "epoch:76,loss:2.4259\n",
      "epoch:76,loss:1.0269\n",
      "epoch:76,loss:1.7445\n",
      "epoch:76,loss:1.8016\n",
      "epoch:76,loss:2.2067\n",
      "epoch:76,loss:1.2746\n",
      "epoch:76,loss:1.8557\n",
      "epoch:76,loss:1.5270\n",
      "epoch:76,loss:2.0695\n",
      "epoch:76,loss:1.4444\n",
      "epoch:76,loss:1.5225\n",
      "epoch:76,loss:2.4159\n",
      "epoch:76,loss:0.9632\n",
      "epoch:76,loss:1.1104\n",
      "epoch:76,loss:0.4044\n",
      "epoch:76,loss:1.2521\n",
      "epoch:76,loss:0.9217\n",
      "epoch:76,loss:0.5086\n",
      "epoch:76,loss:1.8091\n",
      "epoch:76,loss:1.0935\n",
      "epoch:76,loss:1.2064\n",
      "epoch:76,loss:1.0452\n",
      "epoch:76,loss:0.9653\n",
      "epoch:76,loss:0.8054\n",
      "epoch:76,loss:0.8930\n",
      "epoch:76,loss:0.4432\n",
      "epoch:76,loss:0.6009\n",
      "epoch:76,loss:0.9862\n",
      "epoch:76,loss:2.3358\n",
      "epoch:76,loss:1.3352\n",
      "epoch:76,loss:1.6148\n",
      "epoch:76,loss:0.5980\n",
      "epoch:76,loss:0.9985\n",
      "epoch:76,loss:1.8966\n",
      "epoch:76,loss:0.9046\n",
      "epoch:76,loss:1.1942\n",
      "epoch:76,loss:1.1469\n",
      "epoch:76,loss:0.7896\n",
      "epoch:76,loss:0.7251\n",
      "epoch:76,loss:1.7119\n",
      "epoch:76,loss:1.0214\n",
      "epoch:76,loss:0.9263\n",
      "epoch:76,loss:1.4531\n",
      "epoch:76,loss:1.6760\n",
      "epoch:76,loss:0.9901\n",
      "epoch:76,loss:1.4327\n",
      "epoch:76,loss:1.0890\n",
      "epoch:76,loss:0.9389\n",
      "epoch:76,loss:2.0597\n",
      "epoch:76,loss:0.8857\n",
      "epoch:76,loss:1.0306\n",
      "epoch:76,loss:0.7371\n",
      "epoch:76,loss:1.6583\n",
      "epoch:76,loss:0.9787\n",
      "epoch:76,loss:1.7153\n",
      "============================================\n",
      "第76个epoch的识别准确率为：54%\n",
      "epoch:77,loss:2.5201\n",
      "epoch:77,loss:0.6313\n",
      "epoch:77,loss:0.6156\n",
      "epoch:77,loss:1.5264\n",
      "epoch:77,loss:1.4174\n",
      "epoch:77,loss:1.1713\n",
      "epoch:77,loss:1.6170\n",
      "epoch:77,loss:0.3025\n",
      "epoch:77,loss:0.7262\n",
      "epoch:77,loss:1.0160\n",
      "epoch:77,loss:1.0513\n",
      "epoch:77,loss:1.4301\n",
      "epoch:77,loss:1.0153\n",
      "epoch:77,loss:0.8624\n",
      "epoch:77,loss:1.4435\n",
      "epoch:77,loss:1.6403\n",
      "epoch:77,loss:1.2086\n",
      "epoch:77,loss:2.0837\n",
      "epoch:77,loss:1.9380\n",
      "epoch:77,loss:2.1977\n",
      "epoch:77,loss:2.2065\n",
      "epoch:77,loss:2.7580\n",
      "epoch:77,loss:2.6357\n",
      "epoch:77,loss:1.0152\n",
      "epoch:77,loss:0.8104\n",
      "epoch:77,loss:0.6828\n",
      "epoch:77,loss:0.7103\n",
      "epoch:77,loss:1.5885\n",
      "epoch:77,loss:0.8225\n",
      "epoch:77,loss:1.3858\n",
      "epoch:77,loss:1.2867\n",
      "epoch:77,loss:1.8958\n",
      "epoch:77,loss:0.8897\n",
      "epoch:77,loss:2.2801\n",
      "epoch:77,loss:0.3990\n",
      "epoch:77,loss:1.9074\n",
      "epoch:77,loss:1.1483\n",
      "epoch:77,loss:0.7010\n",
      "epoch:77,loss:0.5067\n",
      "epoch:77,loss:0.5894\n",
      "epoch:77,loss:1.7609\n",
      "epoch:77,loss:1.2501\n",
      "epoch:77,loss:2.0254\n",
      "epoch:77,loss:1.2045\n",
      "epoch:77,loss:0.9492\n",
      "epoch:77,loss:0.8816\n",
      "epoch:77,loss:0.7707\n",
      "epoch:77,loss:0.7511\n",
      "epoch:77,loss:1.0482\n",
      "epoch:77,loss:0.4609\n",
      "epoch:77,loss:1.8799\n",
      "epoch:77,loss:0.9449\n",
      "epoch:77,loss:1.0434\n",
      "epoch:77,loss:0.6110\n",
      "epoch:77,loss:1.1949\n",
      "epoch:77,loss:2.3643\n",
      "epoch:77,loss:1.2632\n",
      "epoch:77,loss:1.5484\n",
      "epoch:77,loss:0.6448\n",
      "epoch:77,loss:0.9355\n",
      "============================================\n",
      "第77个epoch的识别准确率为：56%\n",
      "epoch:78,loss:1.0988\n",
      "epoch:78,loss:0.5293\n",
      "epoch:78,loss:0.8290\n",
      "epoch:78,loss:1.1691\n",
      "epoch:78,loss:1.0585\n",
      "epoch:78,loss:0.3658\n",
      "epoch:78,loss:1.5459\n",
      "epoch:78,loss:1.2172\n",
      "epoch:78,loss:1.2721\n",
      "epoch:78,loss:1.2916\n",
      "epoch:78,loss:1.5442\n",
      "epoch:78,loss:0.6130\n",
      "epoch:78,loss:1.3328\n",
      "epoch:78,loss:0.8723\n",
      "epoch:78,loss:1.2261\n",
      "epoch:78,loss:1.2719\n",
      "epoch:78,loss:0.8076\n",
      "epoch:78,loss:1.3300\n",
      "epoch:78,loss:0.6737\n",
      "epoch:78,loss:1.3866\n",
      "epoch:78,loss:0.7390\n",
      "epoch:78,loss:1.4539\n",
      "epoch:78,loss:0.4512\n",
      "epoch:78,loss:1.9716\n",
      "epoch:78,loss:0.8557\n",
      "epoch:78,loss:1.3581\n",
      "epoch:78,loss:1.0127\n",
      "epoch:78,loss:1.6822\n",
      "epoch:78,loss:1.2481\n",
      "epoch:78,loss:0.2302\n",
      "epoch:78,loss:0.9016\n",
      "epoch:78,loss:0.5427\n",
      "epoch:78,loss:1.2710\n",
      "epoch:78,loss:1.3086\n",
      "epoch:78,loss:1.2596\n",
      "epoch:78,loss:1.2600\n",
      "epoch:78,loss:1.9181\n",
      "epoch:78,loss:1.1669\n",
      "epoch:78,loss:2.2253\n",
      "epoch:78,loss:0.7797\n",
      "epoch:78,loss:0.8025\n",
      "epoch:78,loss:1.0442\n",
      "epoch:78,loss:1.9605\n",
      "epoch:78,loss:1.6197\n",
      "epoch:78,loss:1.4956\n",
      "epoch:78,loss:1.0933\n",
      "epoch:78,loss:2.1107\n",
      "epoch:78,loss:1.2630\n",
      "epoch:78,loss:1.3003\n",
      "epoch:78,loss:0.7896\n",
      "epoch:78,loss:1.1976\n",
      "epoch:78,loss:1.3303\n",
      "epoch:78,loss:1.3646\n",
      "epoch:78,loss:1.5038\n",
      "epoch:78,loss:0.7959\n",
      "epoch:78,loss:1.8943\n",
      "epoch:78,loss:1.8645\n",
      "epoch:78,loss:2.2523\n",
      "epoch:78,loss:1.0965\n",
      "epoch:78,loss:1.2397\n",
      "============================================\n",
      "第78个epoch的识别准确率为：54%\n",
      "epoch:79,loss:1.5910\n",
      "epoch:79,loss:0.8891\n",
      "epoch:79,loss:0.4643\n",
      "epoch:79,loss:1.4025\n",
      "epoch:79,loss:0.9131\n",
      "epoch:79,loss:1.2112\n",
      "epoch:79,loss:0.9213\n",
      "epoch:79,loss:1.4687\n",
      "epoch:79,loss:1.9774\n",
      "epoch:79,loss:1.4574\n",
      "epoch:79,loss:1.0521\n",
      "epoch:79,loss:0.8252\n",
      "epoch:79,loss:0.6888\n",
      "epoch:79,loss:1.3785\n",
      "epoch:79,loss:0.6923\n",
      "epoch:79,loss:0.7459\n",
      "epoch:79,loss:0.8261\n",
      "epoch:79,loss:2.0202\n",
      "epoch:79,loss:2.4741\n",
      "epoch:79,loss:1.6422\n",
      "epoch:79,loss:1.3416\n",
      "epoch:79,loss:1.0512\n",
      "epoch:79,loss:1.0495\n",
      "epoch:79,loss:1.8807\n",
      "epoch:79,loss:1.7053\n",
      "epoch:79,loss:2.9707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:79,loss:1.3414\n",
      "epoch:79,loss:1.8089\n",
      "epoch:79,loss:0.7787\n",
      "epoch:79,loss:2.7108\n",
      "epoch:79,loss:0.3530\n",
      "epoch:79,loss:1.4074\n",
      "epoch:79,loss:0.4985\n",
      "epoch:79,loss:1.7576\n",
      "epoch:79,loss:2.2801\n",
      "epoch:79,loss:1.0461\n",
      "epoch:79,loss:1.9656\n",
      "epoch:79,loss:1.2947\n",
      "epoch:79,loss:1.4354\n",
      "epoch:79,loss:0.7975\n",
      "epoch:79,loss:1.2340\n",
      "epoch:79,loss:2.4691\n",
      "epoch:79,loss:1.1187\n",
      "epoch:79,loss:1.2426\n",
      "epoch:79,loss:1.1943\n",
      "epoch:79,loss:1.2928\n",
      "epoch:79,loss:1.0739\n",
      "epoch:79,loss:0.9254\n",
      "epoch:79,loss:2.3717\n",
      "epoch:79,loss:4.8740\n",
      "epoch:79,loss:0.9509\n",
      "epoch:79,loss:0.9706\n",
      "epoch:79,loss:0.3247\n",
      "epoch:79,loss:1.1474\n",
      "epoch:79,loss:1.9792\n",
      "epoch:79,loss:1.0729\n",
      "epoch:79,loss:1.0755\n",
      "epoch:79,loss:0.8450\n",
      "epoch:79,loss:1.5415\n",
      "epoch:79,loss:0.9118\n",
      "============================================\n",
      "第79个epoch的识别准确率为：56%\n",
      "epoch:80,loss:2.0729\n",
      "epoch:80,loss:1.5920\n",
      "epoch:80,loss:0.9232\n",
      "epoch:80,loss:1.0646\n",
      "epoch:80,loss:1.1522\n",
      "epoch:80,loss:1.9013\n",
      "epoch:80,loss:0.5316\n",
      "epoch:80,loss:0.8475\n",
      "epoch:80,loss:0.6604\n",
      "epoch:80,loss:0.2217\n",
      "epoch:80,loss:0.9964\n",
      "epoch:80,loss:1.4617\n",
      "epoch:80,loss:1.4083\n",
      "epoch:80,loss:1.1195\n",
      "epoch:80,loss:1.3326\n",
      "epoch:80,loss:0.7052\n",
      "epoch:80,loss:0.8710\n",
      "epoch:80,loss:1.1010\n",
      "epoch:80,loss:1.5491\n",
      "epoch:80,loss:1.7021\n",
      "epoch:80,loss:1.6189\n",
      "epoch:80,loss:1.2941\n",
      "epoch:80,loss:1.7832\n",
      "epoch:80,loss:0.5021\n",
      "epoch:80,loss:1.2925\n",
      "epoch:80,loss:0.4550\n",
      "epoch:80,loss:0.9822\n",
      "epoch:80,loss:1.2748\n",
      "epoch:80,loss:0.9861\n",
      "epoch:80,loss:1.1072\n",
      "epoch:80,loss:0.6074\n",
      "epoch:80,loss:1.0482\n",
      "epoch:80,loss:0.5974\n",
      "epoch:80,loss:0.8342\n",
      "epoch:80,loss:1.3140\n",
      "epoch:80,loss:0.6517\n",
      "epoch:80,loss:1.3404\n",
      "epoch:80,loss:1.9242\n",
      "epoch:80,loss:1.1089\n",
      "epoch:80,loss:2.1056\n",
      "epoch:80,loss:1.3813\n",
      "epoch:80,loss:1.3059\n",
      "epoch:80,loss:1.7171\n",
      "epoch:80,loss:0.9711\n",
      "epoch:80,loss:2.4054\n",
      "epoch:80,loss:0.4951\n",
      "epoch:80,loss:0.7405\n",
      "epoch:80,loss:2.5615\n",
      "epoch:80,loss:2.3610\n",
      "epoch:80,loss:1.1456\n",
      "epoch:80,loss:1.1557\n",
      "epoch:80,loss:1.2128\n",
      "epoch:80,loss:0.7741\n",
      "epoch:80,loss:1.6061\n",
      "epoch:80,loss:2.3461\n",
      "epoch:80,loss:0.6534\n",
      "epoch:80,loss:1.9277\n",
      "epoch:80,loss:1.7612\n",
      "epoch:80,loss:0.9502\n",
      "epoch:80,loss:1.3509\n",
      "============================================\n",
      "第80个epoch的识别准确率为：55%\n",
      "epoch:81,loss:1.5648\n",
      "epoch:81,loss:1.3812\n",
      "epoch:81,loss:0.3507\n",
      "epoch:81,loss:3.0458\n",
      "epoch:81,loss:0.7077\n",
      "epoch:81,loss:0.9750\n",
      "epoch:81,loss:0.3401\n",
      "epoch:81,loss:1.2662\n",
      "epoch:81,loss:1.7603\n",
      "epoch:81,loss:1.3375\n",
      "epoch:81,loss:1.2858\n",
      "epoch:81,loss:0.6646\n",
      "epoch:81,loss:0.9527\n",
      "epoch:81,loss:1.7101\n",
      "epoch:81,loss:1.1332\n",
      "epoch:81,loss:0.7301\n",
      "epoch:81,loss:1.9280\n",
      "epoch:81,loss:2.4587\n",
      "epoch:81,loss:1.4607\n",
      "epoch:81,loss:1.2921\n",
      "epoch:81,loss:0.7076\n",
      "epoch:81,loss:1.7960\n",
      "epoch:81,loss:1.1290\n",
      "epoch:81,loss:1.6584\n",
      "epoch:81,loss:0.7578\n",
      "epoch:81,loss:1.1709\n",
      "epoch:81,loss:1.3591\n",
      "epoch:81,loss:0.5204\n",
      "epoch:81,loss:1.4222\n",
      "epoch:81,loss:1.1412\n",
      "epoch:81,loss:1.2236\n",
      "epoch:81,loss:0.9273\n",
      "epoch:81,loss:1.0824\n",
      "epoch:81,loss:1.8188\n",
      "epoch:81,loss:0.9764\n",
      "epoch:81,loss:0.9610\n",
      "epoch:81,loss:2.3054\n",
      "epoch:81,loss:1.4859\n",
      "epoch:81,loss:1.8908\n",
      "epoch:81,loss:1.9134\n",
      "epoch:81,loss:0.3540\n",
      "epoch:81,loss:1.8662\n",
      "epoch:81,loss:1.0781\n",
      "epoch:81,loss:0.7359\n",
      "epoch:81,loss:1.4279\n",
      "epoch:81,loss:0.7521\n",
      "epoch:81,loss:1.1095\n",
      "epoch:81,loss:0.9529\n",
      "epoch:81,loss:1.5034\n",
      "epoch:81,loss:0.6987\n",
      "epoch:81,loss:1.0170\n",
      "epoch:81,loss:0.5554\n",
      "epoch:81,loss:1.0716\n",
      "epoch:81,loss:1.5888\n",
      "epoch:81,loss:1.6650\n",
      "epoch:81,loss:1.2820\n",
      "epoch:81,loss:1.4594\n",
      "epoch:81,loss:0.7527\n",
      "epoch:81,loss:1.3376\n",
      "epoch:81,loss:1.1808\n",
      "============================================\n",
      "第81个epoch的识别准确率为：56%\n",
      "epoch:82,loss:1.1250\n",
      "epoch:82,loss:1.7028\n",
      "epoch:82,loss:1.5905\n",
      "epoch:82,loss:1.0415\n",
      "epoch:82,loss:0.7814\n",
      "epoch:82,loss:1.6319\n",
      "epoch:82,loss:1.6210\n",
      "epoch:82,loss:0.4918\n",
      "epoch:82,loss:1.2948\n",
      "epoch:82,loss:1.1715\n",
      "epoch:82,loss:2.0743\n",
      "epoch:82,loss:0.3629\n",
      "epoch:82,loss:0.9970\n",
      "epoch:82,loss:1.7938\n",
      "epoch:82,loss:1.0697\n",
      "epoch:82,loss:1.4311\n",
      "epoch:82,loss:1.1270\n",
      "epoch:82,loss:0.4715\n",
      "epoch:82,loss:0.9096\n",
      "epoch:82,loss:0.7009\n",
      "epoch:82,loss:1.9789\n",
      "epoch:82,loss:0.8738\n",
      "epoch:82,loss:1.1037\n",
      "epoch:82,loss:0.9057\n",
      "epoch:82,loss:0.6272\n",
      "epoch:82,loss:0.7600\n",
      "epoch:82,loss:0.6301\n",
      "epoch:82,loss:0.9420\n",
      "epoch:82,loss:1.4237\n",
      "epoch:82,loss:0.4519\n",
      "epoch:82,loss:1.6209\n",
      "epoch:82,loss:1.1071\n",
      "epoch:82,loss:1.4130\n",
      "epoch:82,loss:1.8831\n",
      "epoch:82,loss:1.0471\n",
      "epoch:82,loss:1.0222\n",
      "epoch:82,loss:1.0641\n",
      "epoch:82,loss:1.6563\n",
      "epoch:82,loss:1.1702\n",
      "epoch:82,loss:1.0416\n",
      "epoch:82,loss:0.8518\n",
      "epoch:82,loss:0.7426\n",
      "epoch:82,loss:1.9926\n",
      "epoch:82,loss:0.7310\n",
      "epoch:82,loss:1.8759\n",
      "epoch:82,loss:1.5274\n",
      "epoch:82,loss:1.0582\n",
      "epoch:82,loss:2.0087\n",
      "epoch:82,loss:0.7438\n",
      "epoch:82,loss:1.1959\n",
      "epoch:82,loss:1.1379\n",
      "epoch:82,loss:1.8414\n",
      "epoch:82,loss:1.8661\n",
      "epoch:82,loss:0.5809\n",
      "epoch:82,loss:0.2935\n",
      "epoch:82,loss:1.0690\n",
      "epoch:82,loss:0.7579\n",
      "epoch:82,loss:1.0410\n",
      "epoch:82,loss:1.0445\n",
      "epoch:82,loss:1.0513\n",
      "============================================\n",
      "准确率由： tensor(0.5680) 上升至： tensor(0.5735) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第82个epoch的识别准确率为：57%\n",
      "epoch:83,loss:0.7759\n",
      "epoch:83,loss:2.3756\n",
      "epoch:83,loss:0.9463\n",
      "epoch:83,loss:1.6650\n",
      "epoch:83,loss:1.4829\n",
      "epoch:83,loss:2.0724\n",
      "epoch:83,loss:0.8082\n",
      "epoch:83,loss:2.0644\n",
      "epoch:83,loss:1.1525\n",
      "epoch:83,loss:0.8046\n",
      "epoch:83,loss:0.6867\n",
      "epoch:83,loss:1.2275\n",
      "epoch:83,loss:2.3551\n",
      "epoch:83,loss:1.2936\n",
      "epoch:83,loss:0.7391\n",
      "epoch:83,loss:1.2470\n",
      "epoch:83,loss:1.2554\n",
      "epoch:83,loss:1.5328\n",
      "epoch:83,loss:1.0934\n",
      "epoch:83,loss:1.5568\n",
      "epoch:83,loss:1.2017\n",
      "epoch:83,loss:3.0405\n",
      "epoch:83,loss:1.0039\n",
      "epoch:83,loss:0.7872\n",
      "epoch:83,loss:0.8110\n",
      "epoch:83,loss:2.5428\n",
      "epoch:83,loss:1.9629\n",
      "epoch:83,loss:1.0536\n",
      "epoch:83,loss:1.6513\n",
      "epoch:83,loss:1.5734\n",
      "epoch:83,loss:0.3315\n",
      "epoch:83,loss:2.5348\n",
      "epoch:83,loss:0.5694\n",
      "epoch:83,loss:1.3871\n",
      "epoch:83,loss:1.1509\n",
      "epoch:83,loss:1.4449\n",
      "epoch:83,loss:0.6300\n",
      "epoch:83,loss:0.5033\n",
      "epoch:83,loss:1.7352\n",
      "epoch:83,loss:1.4798\n",
      "epoch:83,loss:1.6573\n",
      "epoch:83,loss:1.7095\n",
      "epoch:83,loss:0.4987\n",
      "epoch:83,loss:1.8540\n",
      "epoch:83,loss:1.5452\n",
      "epoch:83,loss:1.0547\n",
      "epoch:83,loss:1.5967\n",
      "epoch:83,loss:1.9785\n",
      "epoch:83,loss:1.1937\n",
      "epoch:83,loss:1.1563\n",
      "epoch:83,loss:0.9876\n",
      "epoch:83,loss:0.7098\n",
      "epoch:83,loss:1.6923\n",
      "epoch:83,loss:1.3120\n",
      "epoch:83,loss:1.3058\n",
      "epoch:83,loss:1.9951\n",
      "epoch:83,loss:0.3217\n",
      "epoch:83,loss:0.5399\n",
      "epoch:83,loss:0.4834\n",
      "epoch:83,loss:0.2128\n",
      "============================================\n",
      "准确率由： tensor(0.5735) 上升至： tensor(0.5781) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第83个epoch的识别准确率为：57%\n",
      "epoch:84,loss:2.6202\n",
      "epoch:84,loss:1.9367\n",
      "epoch:84,loss:1.0281\n",
      "epoch:84,loss:0.9647\n",
      "epoch:84,loss:0.5204\n",
      "epoch:84,loss:1.1220\n",
      "epoch:84,loss:1.4159\n",
      "epoch:84,loss:0.5342\n",
      "epoch:84,loss:1.9528\n",
      "epoch:84,loss:0.8075\n",
      "epoch:84,loss:1.5381\n",
      "epoch:84,loss:1.0761\n",
      "epoch:84,loss:0.5685\n",
      "epoch:84,loss:0.8759\n",
      "epoch:84,loss:0.8002\n",
      "epoch:84,loss:1.2569\n",
      "epoch:84,loss:1.3405\n",
      "epoch:84,loss:1.8952\n",
      "epoch:84,loss:0.8337\n",
      "epoch:84,loss:0.4050\n",
      "epoch:84,loss:0.7624\n",
      "epoch:84,loss:0.8447\n",
      "epoch:84,loss:1.8023\n",
      "epoch:84,loss:1.2176\n",
      "epoch:84,loss:1.4985\n",
      "epoch:84,loss:0.9851\n",
      "epoch:84,loss:1.1069\n",
      "epoch:84,loss:2.0002\n",
      "epoch:84,loss:1.6641\n",
      "epoch:84,loss:0.8719\n",
      "epoch:84,loss:0.7518\n",
      "epoch:84,loss:1.0129\n",
      "epoch:84,loss:0.9665\n",
      "epoch:84,loss:0.6568\n",
      "epoch:84,loss:2.0237\n",
      "epoch:84,loss:0.9809\n",
      "epoch:84,loss:2.0971\n",
      "epoch:84,loss:0.3237\n",
      "epoch:84,loss:1.5158\n",
      "epoch:84,loss:0.7071\n",
      "epoch:84,loss:0.7600\n",
      "epoch:84,loss:1.6445\n",
      "epoch:84,loss:1.7105\n",
      "epoch:84,loss:1.2225\n",
      "epoch:84,loss:0.8263\n",
      "epoch:84,loss:1.1589\n",
      "epoch:84,loss:0.9229\n",
      "epoch:84,loss:0.7783\n",
      "epoch:84,loss:2.1212\n",
      "epoch:84,loss:0.5116\n",
      "epoch:84,loss:0.5818\n",
      "epoch:84,loss:1.5541\n",
      "epoch:84,loss:3.7649\n",
      "epoch:84,loss:1.3942\n",
      "epoch:84,loss:1.7073\n",
      "epoch:84,loss:0.9405\n",
      "epoch:84,loss:1.2314\n",
      "epoch:84,loss:1.5477\n",
      "epoch:84,loss:1.0226\n",
      "epoch:84,loss:1.9288\n",
      "============================================\n",
      "准确率由： tensor(0.5781) 上升至： tensor(0.5910) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第84个epoch的识别准确率为：59%\n",
      "epoch:85,loss:1.2381\n",
      "epoch:85,loss:1.0916\n",
      "epoch:85,loss:0.4565\n",
      "epoch:85,loss:1.0523\n",
      "epoch:85,loss:1.0444\n",
      "epoch:85,loss:1.2139\n",
      "epoch:85,loss:1.2965\n",
      "epoch:85,loss:0.5758\n",
      "epoch:85,loss:1.2654\n",
      "epoch:85,loss:1.1795\n",
      "epoch:85,loss:0.8229\n",
      "epoch:85,loss:1.1190\n",
      "epoch:85,loss:1.4307\n",
      "epoch:85,loss:1.7371\n",
      "epoch:85,loss:0.7197\n",
      "epoch:85,loss:1.7919\n",
      "epoch:85,loss:0.5668\n",
      "epoch:85,loss:1.9116\n",
      "epoch:85,loss:1.7756\n",
      "epoch:85,loss:2.0596\n",
      "epoch:85,loss:1.6910\n",
      "epoch:85,loss:1.0225\n",
      "epoch:85,loss:0.6080\n",
      "epoch:85,loss:0.6039\n",
      "epoch:85,loss:1.1225\n",
      "epoch:85,loss:1.4808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:85,loss:1.8359\n",
      "epoch:85,loss:0.5569\n",
      "epoch:85,loss:0.6782\n",
      "epoch:85,loss:1.8070\n",
      "epoch:85,loss:0.7963\n",
      "epoch:85,loss:1.4072\n",
      "epoch:85,loss:1.4128\n",
      "epoch:85,loss:1.5077\n",
      "epoch:85,loss:1.5506\n",
      "epoch:85,loss:1.2388\n",
      "epoch:85,loss:0.7540\n",
      "epoch:85,loss:1.0196\n",
      "epoch:85,loss:0.6828\n",
      "epoch:85,loss:0.7881\n",
      "epoch:85,loss:1.6085\n",
      "epoch:85,loss:1.1595\n",
      "epoch:85,loss:1.5562\n",
      "epoch:85,loss:0.5019\n",
      "epoch:85,loss:1.4559\n",
      "epoch:85,loss:1.4653\n",
      "epoch:85,loss:1.8943\n",
      "epoch:85,loss:2.0716\n",
      "epoch:85,loss:0.7672\n",
      "epoch:85,loss:0.3340\n",
      "epoch:85,loss:1.3875\n",
      "epoch:85,loss:2.0966\n",
      "epoch:85,loss:2.3348\n",
      "epoch:85,loss:0.9984\n",
      "epoch:85,loss:0.7606\n",
      "epoch:85,loss:1.6235\n",
      "epoch:85,loss:0.5939\n",
      "epoch:85,loss:1.4789\n",
      "epoch:85,loss:4.1240\n",
      "epoch:85,loss:0.7327\n",
      "============================================\n",
      "第85个epoch的识别准确率为：58%\n",
      "epoch:86,loss:1.6093\n",
      "epoch:86,loss:1.7024\n",
      "epoch:86,loss:0.9987\n",
      "epoch:86,loss:1.3061\n",
      "epoch:86,loss:0.9838\n",
      "epoch:86,loss:0.7816\n",
      "epoch:86,loss:0.8485\n",
      "epoch:86,loss:1.0155\n",
      "epoch:86,loss:0.9435\n",
      "epoch:86,loss:1.6551\n",
      "epoch:86,loss:1.3958\n",
      "epoch:86,loss:1.2800\n",
      "epoch:86,loss:0.8814\n",
      "epoch:86,loss:1.3294\n",
      "epoch:86,loss:1.6014\n",
      "epoch:86,loss:1.4548\n",
      "epoch:86,loss:2.9410\n",
      "epoch:86,loss:0.7280\n",
      "epoch:86,loss:0.7343\n",
      "epoch:86,loss:0.6990\n",
      "epoch:86,loss:1.1126\n",
      "epoch:86,loss:1.4234\n",
      "epoch:86,loss:1.1500\n",
      "epoch:86,loss:0.9965\n",
      "epoch:86,loss:1.4702\n",
      "epoch:86,loss:0.9212\n",
      "epoch:86,loss:0.3459\n",
      "epoch:86,loss:1.8572\n",
      "epoch:86,loss:0.8512\n",
      "epoch:86,loss:0.8780\n",
      "epoch:86,loss:0.8219\n",
      "epoch:86,loss:0.2720\n",
      "epoch:86,loss:2.1449\n",
      "epoch:86,loss:0.8338\n",
      "epoch:86,loss:0.6457\n",
      "epoch:86,loss:0.7067\n",
      "epoch:86,loss:1.8555\n",
      "epoch:86,loss:0.5738\n",
      "epoch:86,loss:0.5249\n",
      "epoch:86,loss:1.1022\n",
      "epoch:86,loss:5.3309\n",
      "epoch:86,loss:1.9862\n",
      "epoch:86,loss:0.5538\n",
      "epoch:86,loss:1.6955\n",
      "epoch:86,loss:1.0552\n",
      "epoch:86,loss:1.9229\n",
      "epoch:86,loss:1.6449\n",
      "epoch:86,loss:1.0416\n",
      "epoch:86,loss:1.3033\n",
      "epoch:86,loss:1.9813\n",
      "epoch:86,loss:0.4251\n",
      "epoch:86,loss:0.8411\n",
      "epoch:86,loss:1.4571\n",
      "epoch:86,loss:0.9929\n",
      "epoch:86,loss:1.4816\n",
      "epoch:86,loss:1.5374\n",
      "epoch:86,loss:0.8224\n",
      "epoch:86,loss:1.6929\n",
      "epoch:86,loss:0.5112\n",
      "epoch:86,loss:0.6461\n",
      "============================================\n",
      "准确率由： tensor(0.5910) 上升至： tensor(0.6186) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第86个epoch的识别准确率为：61%\n",
      "epoch:87,loss:1.3456\n",
      "epoch:87,loss:1.0963\n",
      "epoch:87,loss:1.3471\n",
      "epoch:87,loss:0.6020\n",
      "epoch:87,loss:0.6663\n",
      "epoch:87,loss:0.4027\n",
      "epoch:87,loss:2.3363\n",
      "epoch:87,loss:2.4622\n",
      "epoch:87,loss:1.5910\n",
      "epoch:87,loss:0.9847\n",
      "epoch:87,loss:0.5995\n",
      "epoch:87,loss:1.0542\n",
      "epoch:87,loss:0.5374\n",
      "epoch:87,loss:0.4200\n",
      "epoch:87,loss:1.6403\n",
      "epoch:87,loss:0.5707\n",
      "epoch:87,loss:1.0693\n",
      "epoch:87,loss:2.1497\n",
      "epoch:87,loss:1.0179\n",
      "epoch:87,loss:0.8710\n",
      "epoch:87,loss:0.7702\n",
      "epoch:87,loss:1.0881\n",
      "epoch:87,loss:0.6740\n",
      "epoch:87,loss:0.5490\n",
      "epoch:87,loss:0.8608\n",
      "epoch:87,loss:1.6523\n",
      "epoch:87,loss:1.2618\n",
      "epoch:87,loss:0.3970\n",
      "epoch:87,loss:1.4122\n",
      "epoch:87,loss:1.5799\n",
      "epoch:87,loss:0.3835\n",
      "epoch:87,loss:0.5459\n",
      "epoch:87,loss:1.1148\n",
      "epoch:87,loss:1.0782\n",
      "epoch:87,loss:0.4606\n",
      "epoch:87,loss:1.6089\n",
      "epoch:87,loss:1.5921\n",
      "epoch:87,loss:0.9731\n",
      "epoch:87,loss:0.8282\n",
      "epoch:87,loss:1.3746\n",
      "epoch:87,loss:0.9138\n",
      "epoch:87,loss:1.6956\n",
      "epoch:87,loss:0.7091\n",
      "epoch:87,loss:1.2957\n",
      "epoch:87,loss:0.9667\n",
      "epoch:87,loss:1.4787\n",
      "epoch:87,loss:0.4985\n",
      "epoch:87,loss:1.8690\n",
      "epoch:87,loss:1.4786\n",
      "epoch:87,loss:1.4817\n",
      "epoch:87,loss:1.2756\n",
      "epoch:87,loss:0.2506\n",
      "epoch:87,loss:1.2625\n",
      "epoch:87,loss:0.8423\n",
      "epoch:87,loss:1.5164\n",
      "epoch:87,loss:0.6777\n",
      "epoch:87,loss:0.4961\n",
      "epoch:87,loss:1.9454\n",
      "epoch:87,loss:1.6246\n",
      "epoch:87,loss:0.3927\n",
      "============================================\n",
      "准确率由： tensor(0.6186) 上升至： tensor(0.6232) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第87个epoch的识别准确率为：62%\n",
      "epoch:88,loss:1.3147\n",
      "epoch:88,loss:1.7294\n",
      "epoch:88,loss:0.8508\n",
      "epoch:88,loss:1.0446\n",
      "epoch:88,loss:0.6716\n",
      "epoch:88,loss:1.2125\n",
      "epoch:88,loss:0.9361\n",
      "epoch:88,loss:1.5063\n",
      "epoch:88,loss:1.6974\n",
      "epoch:88,loss:1.6076\n",
      "epoch:88,loss:0.7803\n",
      "epoch:88,loss:1.2751\n",
      "epoch:88,loss:1.7116\n",
      "epoch:88,loss:0.9695\n",
      "epoch:88,loss:0.7046\n",
      "epoch:88,loss:0.9610\n",
      "epoch:88,loss:1.7527\n",
      "epoch:88,loss:0.7457\n",
      "epoch:88,loss:1.2125\n",
      "epoch:88,loss:0.9008\n",
      "epoch:88,loss:1.7523\n",
      "epoch:88,loss:2.1377\n",
      "epoch:88,loss:2.1619\n",
      "epoch:88,loss:0.1960\n",
      "epoch:88,loss:1.1730\n",
      "epoch:88,loss:2.2915\n",
      "epoch:88,loss:0.7159\n",
      "epoch:88,loss:1.1242\n",
      "epoch:88,loss:0.7622\n",
      "epoch:88,loss:1.0409\n",
      "epoch:88,loss:1.5404\n",
      "epoch:88,loss:0.9509\n",
      "epoch:88,loss:2.1910\n",
      "epoch:88,loss:0.4255\n",
      "epoch:88,loss:1.2950\n",
      "epoch:88,loss:1.2850\n",
      "epoch:88,loss:1.2752\n",
      "epoch:88,loss:0.6725\n",
      "epoch:88,loss:1.2005\n",
      "epoch:88,loss:0.9368\n",
      "epoch:88,loss:1.6586\n",
      "epoch:88,loss:1.8128\n",
      "epoch:88,loss:0.6796\n",
      "epoch:88,loss:1.0372\n",
      "epoch:88,loss:1.7367\n",
      "epoch:88,loss:1.0025\n",
      "epoch:88,loss:1.6903\n",
      "epoch:88,loss:1.1441\n",
      "epoch:88,loss:1.2135\n",
      "epoch:88,loss:2.0165\n",
      "epoch:88,loss:0.7979\n",
      "epoch:88,loss:0.7067\n",
      "epoch:88,loss:1.0218\n",
      "epoch:88,loss:0.3167\n",
      "epoch:88,loss:1.3298\n",
      "epoch:88,loss:2.0217\n",
      "epoch:88,loss:1.1984\n",
      "epoch:88,loss:1.7969\n",
      "epoch:88,loss:2.2390\n",
      "epoch:88,loss:1.7922\n",
      "============================================\n",
      "第88个epoch的识别准确率为：60%\n",
      "epoch:89,loss:0.3748\n",
      "epoch:89,loss:2.2440\n",
      "epoch:89,loss:0.5425\n",
      "epoch:89,loss:0.7736\n",
      "epoch:89,loss:0.5525\n",
      "epoch:89,loss:0.9432\n",
      "epoch:89,loss:0.4320\n",
      "epoch:89,loss:0.5247\n",
      "epoch:89,loss:1.1312\n",
      "epoch:89,loss:0.5417\n",
      "epoch:89,loss:3.7975\n",
      "epoch:89,loss:0.3575\n",
      "epoch:89,loss:1.3685\n",
      "epoch:89,loss:1.0956\n",
      "epoch:89,loss:1.2837\n",
      "epoch:89,loss:0.4960\n",
      "epoch:89,loss:0.7706\n",
      "epoch:89,loss:1.2504\n",
      "epoch:89,loss:1.2995\n",
      "epoch:89,loss:1.3513\n",
      "epoch:89,loss:0.5672\n",
      "epoch:89,loss:0.9881\n",
      "epoch:89,loss:1.1972\n",
      "epoch:89,loss:1.4268\n",
      "epoch:89,loss:1.6090\n",
      "epoch:89,loss:1.8585\n",
      "epoch:89,loss:1.3200\n",
      "epoch:89,loss:2.2227\n",
      "epoch:89,loss:0.6196\n",
      "epoch:89,loss:0.7186\n",
      "epoch:89,loss:0.8702\n",
      "epoch:89,loss:0.7832\n",
      "epoch:89,loss:1.2530\n",
      "epoch:89,loss:1.2443\n",
      "epoch:89,loss:0.8355\n",
      "epoch:89,loss:1.0754\n",
      "epoch:89,loss:1.0130\n",
      "epoch:89,loss:1.2761\n",
      "epoch:89,loss:1.6512\n",
      "epoch:89,loss:1.0604\n",
      "epoch:89,loss:1.3044\n",
      "epoch:89,loss:1.3532\n",
      "epoch:89,loss:0.8006\n",
      "epoch:89,loss:1.0434\n",
      "epoch:89,loss:1.0694\n",
      "epoch:89,loss:1.4822\n",
      "epoch:89,loss:2.3530\n",
      "epoch:89,loss:0.5416\n",
      "epoch:89,loss:0.9540\n",
      "epoch:89,loss:1.7381\n",
      "epoch:89,loss:2.3165\n",
      "epoch:89,loss:1.0018\n",
      "epoch:89,loss:1.0118\n",
      "epoch:89,loss:0.5595\n",
      "epoch:89,loss:0.8910\n",
      "epoch:89,loss:2.0870\n",
      "epoch:89,loss:1.9014\n",
      "epoch:89,loss:2.8299\n",
      "epoch:89,loss:1.1843\n",
      "epoch:89,loss:0.6865\n",
      "============================================\n",
      "第89个epoch的识别准确率为：59%\n",
      "epoch:90,loss:0.4585\n",
      "epoch:90,loss:2.1580\n",
      "epoch:90,loss:1.0727\n",
      "epoch:90,loss:1.2028\n",
      "epoch:90,loss:1.6433\n",
      "epoch:90,loss:0.3498\n",
      "epoch:90,loss:2.5626\n",
      "epoch:90,loss:0.8773\n",
      "epoch:90,loss:1.4623\n",
      "epoch:90,loss:1.2309\n",
      "epoch:90,loss:1.3659\n",
      "epoch:90,loss:1.8748\n",
      "epoch:90,loss:1.5333\n",
      "epoch:90,loss:2.1033\n",
      "epoch:90,loss:1.4041\n",
      "epoch:90,loss:0.5047\n",
      "epoch:90,loss:1.9286\n",
      "epoch:90,loss:2.2635\n",
      "epoch:90,loss:1.7428\n",
      "epoch:90,loss:1.8738\n",
      "epoch:90,loss:1.5882\n",
      "epoch:90,loss:2.1515\n",
      "epoch:90,loss:0.9845\n",
      "epoch:90,loss:1.2864\n",
      "epoch:90,loss:1.7164\n",
      "epoch:90,loss:0.9155\n",
      "epoch:90,loss:1.4101\n",
      "epoch:90,loss:0.8252\n",
      "epoch:90,loss:0.6591\n",
      "epoch:90,loss:1.6807\n",
      "epoch:90,loss:0.5369\n",
      "epoch:90,loss:0.3241\n",
      "epoch:90,loss:0.7510\n",
      "epoch:90,loss:1.3307\n",
      "epoch:90,loss:0.5700\n",
      "epoch:90,loss:2.3906\n",
      "epoch:90,loss:1.1768\n",
      "epoch:90,loss:0.7530\n",
      "epoch:90,loss:0.5184\n",
      "epoch:90,loss:0.9452\n",
      "epoch:90,loss:1.8537\n",
      "epoch:90,loss:1.6671\n",
      "epoch:90,loss:1.7369\n",
      "epoch:90,loss:1.1486\n",
      "epoch:90,loss:0.4309\n",
      "epoch:90,loss:0.6507\n",
      "epoch:90,loss:1.2076\n",
      "epoch:90,loss:0.3524\n",
      "epoch:90,loss:2.3913\n",
      "epoch:90,loss:1.0214\n",
      "epoch:90,loss:1.4372\n",
      "epoch:90,loss:1.4311\n",
      "epoch:90,loss:0.4623\n",
      "epoch:90,loss:1.6303\n",
      "epoch:90,loss:0.5828\n",
      "epoch:90,loss:1.4453\n",
      "epoch:90,loss:2.2410\n",
      "epoch:90,loss:2.0957\n",
      "epoch:90,loss:0.9789\n",
      "epoch:90,loss:1.0260\n",
      "============================================\n",
      "第90个epoch的识别准确率为：60%\n",
      "epoch:91,loss:0.2859\n",
      "epoch:91,loss:2.0634\n",
      "epoch:91,loss:1.2574\n",
      "epoch:91,loss:2.1022\n",
      "epoch:91,loss:1.8354\n",
      "epoch:91,loss:0.9413\n",
      "epoch:91,loss:1.9066\n",
      "epoch:91,loss:1.1187\n",
      "epoch:91,loss:1.5023\n",
      "epoch:91,loss:0.8326\n",
      "epoch:91,loss:1.0165\n",
      "epoch:91,loss:0.8994\n",
      "epoch:91,loss:1.0279\n",
      "epoch:91,loss:1.6253\n",
      "epoch:91,loss:2.4687\n",
      "epoch:91,loss:0.7988\n",
      "epoch:91,loss:0.8979\n",
      "epoch:91,loss:0.9633\n",
      "epoch:91,loss:1.4773\n",
      "epoch:91,loss:0.9659\n",
      "epoch:91,loss:1.1256\n",
      "epoch:91,loss:1.1959\n",
      "epoch:91,loss:1.0856\n",
      "epoch:91,loss:1.0658\n",
      "epoch:91,loss:2.4526\n",
      "epoch:91,loss:1.0905\n",
      "epoch:91,loss:0.4073\n",
      "epoch:91,loss:2.4584\n",
      "epoch:91,loss:1.5439\n",
      "epoch:91,loss:1.2730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:91,loss:0.5794\n",
      "epoch:91,loss:0.7754\n",
      "epoch:91,loss:1.9990\n",
      "epoch:91,loss:0.6765\n",
      "epoch:91,loss:1.2116\n",
      "epoch:91,loss:1.3490\n",
      "epoch:91,loss:0.9491\n",
      "epoch:91,loss:0.7094\n",
      "epoch:91,loss:1.5609\n",
      "epoch:91,loss:0.5333\n",
      "epoch:91,loss:0.9184\n",
      "epoch:91,loss:1.4554\n",
      "epoch:91,loss:0.8272\n",
      "epoch:91,loss:0.4703\n",
      "epoch:91,loss:0.5571\n",
      "epoch:91,loss:0.5197\n",
      "epoch:91,loss:0.1436\n",
      "epoch:91,loss:0.8545\n",
      "epoch:91,loss:1.3044\n",
      "epoch:91,loss:1.4644\n",
      "epoch:91,loss:0.8584\n",
      "epoch:91,loss:1.4246\n",
      "epoch:91,loss:2.3235\n",
      "epoch:91,loss:0.4204\n",
      "epoch:91,loss:0.7106\n",
      "epoch:91,loss:1.2241\n",
      "epoch:91,loss:1.1175\n",
      "epoch:91,loss:1.1380\n",
      "epoch:91,loss:1.1427\n",
      "epoch:91,loss:0.3457\n",
      "============================================\n",
      "第91个epoch的识别准确率为：56%\n",
      "epoch:92,loss:0.6928\n",
      "epoch:92,loss:1.9982\n",
      "epoch:92,loss:0.9238\n",
      "epoch:92,loss:1.3656\n",
      "epoch:92,loss:1.9356\n",
      "epoch:92,loss:0.7782\n",
      "epoch:92,loss:1.4300\n",
      "epoch:92,loss:1.3184\n",
      "epoch:92,loss:0.7797\n",
      "epoch:92,loss:1.6952\n",
      "epoch:92,loss:1.5733\n",
      "epoch:92,loss:0.6396\n",
      "epoch:92,loss:1.0866\n",
      "epoch:92,loss:2.3836\n",
      "epoch:92,loss:1.4691\n",
      "epoch:92,loss:0.5952\n",
      "epoch:92,loss:1.1410\n",
      "epoch:92,loss:1.2543\n",
      "epoch:92,loss:0.3234\n",
      "epoch:92,loss:1.6452\n",
      "epoch:92,loss:1.7927\n",
      "epoch:92,loss:2.6825\n",
      "epoch:92,loss:2.1448\n",
      "epoch:92,loss:0.5887\n",
      "epoch:92,loss:0.3926\n",
      "epoch:92,loss:1.1809\n",
      "epoch:92,loss:1.5291\n",
      "epoch:92,loss:0.8553\n",
      "epoch:92,loss:0.4662\n",
      "epoch:92,loss:0.8522\n",
      "epoch:92,loss:1.7851\n",
      "epoch:92,loss:1.4151\n",
      "epoch:92,loss:1.5785\n",
      "epoch:92,loss:1.1215\n",
      "epoch:92,loss:1.2489\n",
      "epoch:92,loss:0.8720\n",
      "epoch:92,loss:1.7944\n",
      "epoch:92,loss:2.0335\n",
      "epoch:92,loss:1.9950\n",
      "epoch:92,loss:0.7408\n",
      "epoch:92,loss:1.5710\n",
      "epoch:92,loss:0.9071\n",
      "epoch:92,loss:1.5226\n",
      "epoch:92,loss:0.3813\n",
      "epoch:92,loss:1.7173\n",
      "epoch:92,loss:2.8613\n",
      "epoch:92,loss:1.7476\n",
      "epoch:92,loss:2.1092\n",
      "epoch:92,loss:1.1202\n",
      "epoch:92,loss:1.3901\n",
      "epoch:92,loss:1.1191\n",
      "epoch:92,loss:1.8941\n",
      "epoch:92,loss:1.6333\n",
      "epoch:92,loss:0.6808\n",
      "epoch:92,loss:2.4332\n",
      "epoch:92,loss:2.1890\n",
      "epoch:92,loss:0.8845\n",
      "epoch:92,loss:0.9052\n",
      "epoch:92,loss:0.7685\n",
      "epoch:92,loss:1.6131\n",
      "============================================\n",
      "第92个epoch的识别准确率为：57%\n",
      "epoch:93,loss:0.4679\n",
      "epoch:93,loss:1.6214\n",
      "epoch:93,loss:1.0475\n",
      "epoch:93,loss:2.5464\n",
      "epoch:93,loss:1.0673\n",
      "epoch:93,loss:0.3281\n",
      "epoch:93,loss:0.3253\n",
      "epoch:93,loss:1.1071\n",
      "epoch:93,loss:1.0630\n",
      "epoch:93,loss:0.6163\n",
      "epoch:93,loss:0.4081\n",
      "epoch:93,loss:0.6609\n",
      "epoch:93,loss:1.2084\n",
      "epoch:93,loss:0.8259\n",
      "epoch:93,loss:0.7271\n",
      "epoch:93,loss:0.5436\n",
      "epoch:93,loss:1.7830\n",
      "epoch:93,loss:1.4492\n",
      "epoch:93,loss:0.8372\n",
      "epoch:93,loss:0.6077\n",
      "epoch:93,loss:2.4132\n",
      "epoch:93,loss:1.6357\n",
      "epoch:93,loss:0.6767\n",
      "epoch:93,loss:1.5271\n",
      "epoch:93,loss:1.5279\n",
      "epoch:93,loss:0.9450\n",
      "epoch:93,loss:1.8266\n",
      "epoch:93,loss:0.3890\n",
      "epoch:93,loss:0.4618\n",
      "epoch:93,loss:1.7660\n",
      "epoch:93,loss:0.8537\n",
      "epoch:93,loss:0.7135\n",
      "epoch:93,loss:0.5530\n",
      "epoch:93,loss:1.7512\n",
      "epoch:93,loss:0.5599\n",
      "epoch:93,loss:0.6024\n",
      "epoch:93,loss:1.6243\n",
      "epoch:93,loss:0.7955\n",
      "epoch:93,loss:0.9449\n",
      "epoch:93,loss:0.8102\n",
      "epoch:93,loss:0.8003\n",
      "epoch:93,loss:2.0314\n",
      "epoch:93,loss:1.1570\n",
      "epoch:93,loss:1.0738\n",
      "epoch:93,loss:0.6082\n",
      "epoch:93,loss:0.5110\n",
      "epoch:93,loss:0.4909\n",
      "epoch:93,loss:0.3104\n",
      "epoch:93,loss:0.8692\n",
      "epoch:93,loss:1.3698\n",
      "epoch:93,loss:0.7178\n",
      "epoch:93,loss:0.6904\n",
      "epoch:93,loss:0.6548\n",
      "epoch:93,loss:0.5838\n",
      "epoch:93,loss:1.2666\n",
      "epoch:93,loss:0.3185\n",
      "epoch:93,loss:1.2275\n",
      "epoch:93,loss:0.4364\n",
      "epoch:93,loss:0.8564\n",
      "epoch:93,loss:0.8994\n",
      "============================================\n",
      "准确率由： tensor(0.6232) 上升至： tensor(0.6250) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第93个epoch的识别准确率为：62%\n",
      "epoch:94,loss:1.2779\n",
      "epoch:94,loss:2.3979\n",
      "epoch:94,loss:0.4087\n",
      "epoch:94,loss:0.7704\n",
      "epoch:94,loss:0.7151\n",
      "epoch:94,loss:1.1208\n",
      "epoch:94,loss:0.6982\n",
      "epoch:94,loss:1.2661\n",
      "epoch:94,loss:0.9564\n",
      "epoch:94,loss:0.6984\n",
      "epoch:94,loss:1.8890\n",
      "epoch:94,loss:0.8526\n",
      "epoch:94,loss:1.3646\n",
      "epoch:94,loss:0.7115\n",
      "epoch:94,loss:2.0686\n",
      "epoch:94,loss:1.8385\n",
      "epoch:94,loss:0.7143\n",
      "epoch:94,loss:2.2808\n",
      "epoch:94,loss:1.2245\n",
      "epoch:94,loss:0.8506\n",
      "epoch:94,loss:2.4934\n",
      "epoch:94,loss:2.0963\n",
      "epoch:94,loss:0.2940\n",
      "epoch:94,loss:1.4001\n",
      "epoch:94,loss:0.7979\n",
      "epoch:94,loss:2.4050\n",
      "epoch:94,loss:1.1622\n",
      "epoch:94,loss:0.7686\n",
      "epoch:94,loss:1.2616\n",
      "epoch:94,loss:1.0044\n",
      "epoch:94,loss:0.3450\n",
      "epoch:94,loss:1.8582\n",
      "epoch:94,loss:1.1390\n",
      "epoch:94,loss:1.5002\n",
      "epoch:94,loss:1.2164\n",
      "epoch:94,loss:0.7806\n",
      "epoch:94,loss:0.4409\n",
      "epoch:94,loss:0.7694\n",
      "epoch:94,loss:0.9177\n",
      "epoch:94,loss:0.7463\n",
      "epoch:94,loss:0.2896\n",
      "epoch:94,loss:1.5678\n",
      "epoch:94,loss:1.3983\n",
      "epoch:94,loss:1.5410\n",
      "epoch:94,loss:1.1223\n",
      "epoch:94,loss:1.1186\n",
      "epoch:94,loss:0.4060\n",
      "epoch:94,loss:0.8830\n",
      "epoch:94,loss:0.8492\n",
      "epoch:94,loss:1.3009\n",
      "epoch:94,loss:0.9862\n",
      "epoch:94,loss:1.1923\n",
      "epoch:94,loss:1.1209\n",
      "epoch:94,loss:1.3373\n",
      "epoch:94,loss:1.3221\n",
      "epoch:94,loss:1.3061\n",
      "epoch:94,loss:1.9239\n",
      "epoch:94,loss:0.4153\n",
      "epoch:94,loss:0.5408\n",
      "epoch:94,loss:0.1598\n",
      "============================================\n",
      "第94个epoch的识别准确率为：61%\n",
      "epoch:95,loss:0.9970\n",
      "epoch:95,loss:1.9015\n",
      "epoch:95,loss:1.2273\n",
      "epoch:95,loss:0.7654\n",
      "epoch:95,loss:2.4179\n",
      "epoch:95,loss:1.3747\n",
      "epoch:95,loss:1.4306\n",
      "epoch:95,loss:0.5456\n",
      "epoch:95,loss:0.9209\n",
      "epoch:95,loss:0.9354\n",
      "epoch:95,loss:0.9395\n",
      "epoch:95,loss:0.6747\n",
      "epoch:95,loss:0.7867\n",
      "epoch:95,loss:0.5606\n",
      "epoch:95,loss:0.5326\n",
      "epoch:95,loss:0.6925\n",
      "epoch:95,loss:1.2365\n",
      "epoch:95,loss:0.6746\n",
      "epoch:95,loss:1.9098\n",
      "epoch:95,loss:1.2982\n",
      "epoch:95,loss:0.7556\n",
      "epoch:95,loss:0.5863\n",
      "epoch:95,loss:0.5634\n",
      "epoch:95,loss:0.2972\n",
      "epoch:95,loss:0.6275\n",
      "epoch:95,loss:0.7410\n",
      "epoch:95,loss:0.5829\n",
      "epoch:95,loss:0.9488\n",
      "epoch:95,loss:1.0817\n",
      "epoch:95,loss:1.7283\n",
      "epoch:95,loss:1.1112\n",
      "epoch:95,loss:0.9064\n",
      "epoch:95,loss:0.7803\n",
      "epoch:95,loss:0.9332\n",
      "epoch:95,loss:1.6625\n",
      "epoch:95,loss:1.1906\n",
      "epoch:95,loss:0.9107\n",
      "epoch:95,loss:0.5420\n",
      "epoch:95,loss:0.6355\n",
      "epoch:95,loss:2.0361\n",
      "epoch:95,loss:0.6242\n",
      "epoch:95,loss:0.5543\n",
      "epoch:95,loss:0.7777\n",
      "epoch:95,loss:1.9931\n",
      "epoch:95,loss:1.1804\n",
      "epoch:95,loss:1.3921\n",
      "epoch:95,loss:1.9015\n",
      "epoch:95,loss:0.9560\n",
      "epoch:95,loss:1.4513\n",
      "epoch:95,loss:0.9522\n",
      "epoch:95,loss:0.7761\n",
      "epoch:95,loss:1.2357\n",
      "epoch:95,loss:0.6662\n",
      "epoch:95,loss:1.0622\n",
      "epoch:95,loss:0.8526\n",
      "epoch:95,loss:1.7356\n",
      "epoch:95,loss:2.3993\n",
      "epoch:95,loss:0.7009\n",
      "epoch:95,loss:2.1359\n",
      "epoch:95,loss:0.6359\n",
      "============================================\n",
      "第95个epoch的识别准确率为：60%\n",
      "epoch:96,loss:1.9731\n",
      "epoch:96,loss:1.7309\n",
      "epoch:96,loss:0.9252\n",
      "epoch:96,loss:0.5807\n",
      "epoch:96,loss:0.6789\n",
      "epoch:96,loss:0.8055\n",
      "epoch:96,loss:1.2477\n",
      "epoch:96,loss:0.5532\n",
      "epoch:96,loss:0.8500\n",
      "epoch:96,loss:1.3403\n",
      "epoch:96,loss:0.4341\n",
      "epoch:96,loss:1.1625\n",
      "epoch:96,loss:1.6690\n",
      "epoch:96,loss:0.8471\n",
      "epoch:96,loss:1.7688\n",
      "epoch:96,loss:1.6277\n",
      "epoch:96,loss:1.8286\n",
      "epoch:96,loss:0.8560\n",
      "epoch:96,loss:1.0775\n",
      "epoch:96,loss:0.4252\n",
      "epoch:96,loss:1.1679\n",
      "epoch:96,loss:1.4026\n",
      "epoch:96,loss:1.0259\n",
      "epoch:96,loss:2.8915\n",
      "epoch:96,loss:0.4105\n",
      "epoch:96,loss:1.0514\n",
      "epoch:96,loss:0.8767\n",
      "epoch:96,loss:0.4266\n",
      "epoch:96,loss:1.5120\n",
      "epoch:96,loss:0.7157\n",
      "epoch:96,loss:1.0933\n",
      "epoch:96,loss:1.4309\n",
      "epoch:96,loss:1.1620\n",
      "epoch:96,loss:0.5999\n",
      "epoch:96,loss:1.9371\n",
      "epoch:96,loss:0.7387\n",
      "epoch:96,loss:0.4471\n",
      "epoch:96,loss:0.9552\n",
      "epoch:96,loss:0.4852\n",
      "epoch:96,loss:2.0807\n",
      "epoch:96,loss:0.8251\n",
      "epoch:96,loss:2.0912\n",
      "epoch:96,loss:0.7893\n",
      "epoch:96,loss:0.8490\n",
      "epoch:96,loss:0.9641\n",
      "epoch:96,loss:1.6662\n",
      "epoch:96,loss:1.1285\n",
      "epoch:96,loss:2.4505\n",
      "epoch:96,loss:1.7392\n",
      "epoch:96,loss:0.9809\n",
      "epoch:96,loss:1.2538\n",
      "epoch:96,loss:0.7307\n",
      "epoch:96,loss:1.1590\n",
      "epoch:96,loss:1.5542\n",
      "epoch:96,loss:0.8860\n",
      "epoch:96,loss:1.9210\n",
      "epoch:96,loss:0.5518\n",
      "epoch:96,loss:0.4073\n",
      "epoch:96,loss:0.7129\n",
      "epoch:96,loss:1.7931\n",
      "============================================\n",
      "第96个epoch的识别准确率为：60%\n",
      "epoch:97,loss:0.5060\n",
      "epoch:97,loss:2.2723\n",
      "epoch:97,loss:1.5279\n",
      "epoch:97,loss:0.6430\n",
      "epoch:97,loss:1.4692\n",
      "epoch:97,loss:0.8922\n",
      "epoch:97,loss:1.1190\n",
      "epoch:97,loss:0.9236\n",
      "epoch:97,loss:0.3271\n",
      "epoch:97,loss:0.6756\n",
      "epoch:97,loss:1.6877\n",
      "epoch:97,loss:0.5982\n",
      "epoch:97,loss:0.6015\n",
      "epoch:97,loss:0.6691\n",
      "epoch:97,loss:1.9235\n",
      "epoch:97,loss:0.2409\n",
      "epoch:97,loss:0.7750\n",
      "epoch:97,loss:1.2996\n",
      "epoch:97,loss:1.2446\n",
      "epoch:97,loss:1.2131\n",
      "epoch:97,loss:0.7883\n",
      "epoch:97,loss:1.2424\n",
      "epoch:97,loss:1.2603\n",
      "epoch:97,loss:0.9943\n",
      "epoch:97,loss:0.6763\n",
      "epoch:97,loss:2.2307\n",
      "epoch:97,loss:0.7311\n",
      "epoch:97,loss:0.6386\n",
      "epoch:97,loss:0.9160\n",
      "epoch:97,loss:1.0971\n",
      "epoch:97,loss:0.6740\n",
      "epoch:97,loss:0.1943\n",
      "epoch:97,loss:2.0059\n",
      "epoch:97,loss:0.8277\n",
      "epoch:97,loss:0.7160\n",
      "epoch:97,loss:1.9941\n",
      "epoch:97,loss:0.2124\n",
      "epoch:97,loss:0.5634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:97,loss:0.9453\n",
      "epoch:97,loss:0.5495\n",
      "epoch:97,loss:1.8208\n",
      "epoch:97,loss:1.1512\n",
      "epoch:97,loss:1.4865\n",
      "epoch:97,loss:0.8721\n",
      "epoch:97,loss:0.6493\n",
      "epoch:97,loss:1.0384\n",
      "epoch:97,loss:0.8397\n",
      "epoch:97,loss:2.0983\n",
      "epoch:97,loss:1.5850\n",
      "epoch:97,loss:3.5905\n",
      "epoch:97,loss:0.2046\n",
      "epoch:97,loss:2.2367\n",
      "epoch:97,loss:2.1000\n",
      "epoch:97,loss:0.7283\n",
      "epoch:97,loss:0.7214\n",
      "epoch:97,loss:0.6156\n",
      "epoch:97,loss:1.4858\n",
      "epoch:97,loss:0.3867\n",
      "epoch:97,loss:1.1315\n",
      "epoch:97,loss:1.0053\n",
      "============================================\n",
      "准确率由： tensor(0.6250) 上升至： tensor(0.6489) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第97个epoch的识别准确率为：64%\n",
      "epoch:98,loss:0.9626\n",
      "epoch:98,loss:0.9711\n",
      "epoch:98,loss:0.7607\n",
      "epoch:98,loss:0.1968\n",
      "epoch:98,loss:0.7851\n",
      "epoch:98,loss:0.4284\n",
      "epoch:98,loss:0.4811\n",
      "epoch:98,loss:1.3579\n",
      "epoch:98,loss:2.3138\n",
      "epoch:98,loss:3.8509\n",
      "epoch:98,loss:0.3678\n",
      "epoch:98,loss:1.5353\n",
      "epoch:98,loss:0.5108\n",
      "epoch:98,loss:2.0059\n",
      "epoch:98,loss:0.5312\n",
      "epoch:98,loss:1.1846\n",
      "epoch:98,loss:1.0736\n",
      "epoch:98,loss:1.5083\n",
      "epoch:98,loss:1.1544\n",
      "epoch:98,loss:0.3647\n",
      "epoch:98,loss:0.9521\n",
      "epoch:98,loss:1.4763\n",
      "epoch:98,loss:1.0240\n",
      "epoch:98,loss:0.4081\n",
      "epoch:98,loss:0.7573\n",
      "epoch:98,loss:1.0977\n",
      "epoch:98,loss:0.7980\n",
      "epoch:98,loss:2.2709\n",
      "epoch:98,loss:0.8374\n",
      "epoch:98,loss:1.0524\n",
      "epoch:98,loss:1.8088\n",
      "epoch:98,loss:2.1185\n",
      "epoch:98,loss:0.5728\n",
      "epoch:98,loss:1.7738\n",
      "epoch:98,loss:1.7220\n",
      "epoch:98,loss:1.3554\n",
      "epoch:98,loss:1.1302\n",
      "epoch:98,loss:1.9453\n",
      "epoch:98,loss:1.3943\n",
      "epoch:98,loss:0.4675\n",
      "epoch:98,loss:1.7756\n",
      "epoch:98,loss:0.3741\n",
      "epoch:98,loss:0.8455\n",
      "epoch:98,loss:1.1777\n",
      "epoch:98,loss:0.3355\n",
      "epoch:98,loss:1.1487\n",
      "epoch:98,loss:1.0899\n",
      "epoch:98,loss:0.2920\n",
      "epoch:98,loss:1.7906\n",
      "epoch:98,loss:0.8227\n",
      "epoch:98,loss:1.0219\n",
      "epoch:98,loss:1.4285\n",
      "epoch:98,loss:0.2555\n",
      "epoch:98,loss:1.4536\n",
      "epoch:98,loss:1.0275\n",
      "epoch:98,loss:1.7992\n",
      "epoch:98,loss:1.6058\n",
      "epoch:98,loss:0.5407\n",
      "epoch:98,loss:1.0891\n",
      "epoch:98,loss:1.6599\n",
      "============================================\n",
      "第98个epoch的识别准确率为：62%\n",
      "epoch:99,loss:0.8056\n",
      "epoch:99,loss:0.7310\n",
      "epoch:99,loss:1.3829\n",
      "epoch:99,loss:0.6757\n",
      "epoch:99,loss:0.2517\n",
      "epoch:99,loss:2.7237\n",
      "epoch:99,loss:2.4250\n",
      "epoch:99,loss:0.6710\n",
      "epoch:99,loss:0.5665\n",
      "epoch:99,loss:1.5933\n",
      "epoch:99,loss:0.5273\n",
      "epoch:99,loss:0.6553\n",
      "epoch:99,loss:0.5788\n",
      "epoch:99,loss:1.5063\n",
      "epoch:99,loss:0.5969\n",
      "epoch:99,loss:0.9739\n",
      "epoch:99,loss:0.8158\n",
      "epoch:99,loss:0.9295\n",
      "epoch:99,loss:0.9938\n",
      "epoch:99,loss:0.8663\n",
      "epoch:99,loss:1.0810\n",
      "epoch:99,loss:1.4090\n",
      "epoch:99,loss:2.5149\n",
      "epoch:99,loss:0.2224\n",
      "epoch:99,loss:0.3436\n",
      "epoch:99,loss:2.3684\n",
      "epoch:99,loss:1.8617\n",
      "epoch:99,loss:0.1873\n",
      "epoch:99,loss:1.1277\n",
      "epoch:99,loss:0.7958\n",
      "epoch:99,loss:1.6893\n",
      "epoch:99,loss:1.0599\n",
      "epoch:99,loss:1.4334\n",
      "epoch:99,loss:0.4488\n",
      "epoch:99,loss:1.0937\n",
      "epoch:99,loss:0.7074\n",
      "epoch:99,loss:0.7370\n",
      "epoch:99,loss:1.1723\n",
      "epoch:99,loss:1.4686\n",
      "epoch:99,loss:1.2748\n",
      "epoch:99,loss:0.4375\n",
      "epoch:99,loss:1.4544\n",
      "epoch:99,loss:0.7023\n",
      "epoch:99,loss:0.7290\n",
      "epoch:99,loss:1.1548\n",
      "epoch:99,loss:1.6324\n",
      "epoch:99,loss:0.7717\n",
      "epoch:99,loss:1.3674\n",
      "epoch:99,loss:2.2961\n",
      "epoch:99,loss:1.3529\n",
      "epoch:99,loss:1.5840\n",
      "epoch:99,loss:1.0326\n",
      "epoch:99,loss:0.7653\n",
      "epoch:99,loss:0.6080\n",
      "epoch:99,loss:2.2089\n",
      "epoch:99,loss:0.6978\n",
      "epoch:99,loss:0.1919\n",
      "epoch:99,loss:1.4056\n",
      "epoch:99,loss:0.4125\n",
      "epoch:99,loss:0.1891\n",
      "============================================\n",
      "第99个epoch的识别准确率为：64%\n",
      "epoch:100,loss:1.9627\n",
      "epoch:100,loss:0.8608\n",
      "epoch:100,loss:0.5492\n",
      "epoch:100,loss:0.7693\n",
      "epoch:100,loss:1.0590\n",
      "epoch:100,loss:1.9043\n",
      "epoch:100,loss:1.1648\n",
      "epoch:100,loss:0.8879\n",
      "epoch:100,loss:0.1032\n",
      "epoch:100,loss:0.3274\n",
      "epoch:100,loss:0.5588\n",
      "epoch:100,loss:1.7492\n",
      "epoch:100,loss:1.0457\n",
      "epoch:100,loss:1.0455\n",
      "epoch:100,loss:0.5941\n",
      "epoch:100,loss:0.4960\n",
      "epoch:100,loss:0.1025\n",
      "epoch:100,loss:0.2360\n",
      "epoch:100,loss:0.9179\n",
      "epoch:100,loss:0.1347\n",
      "epoch:100,loss:0.7862\n",
      "epoch:100,loss:1.4293\n",
      "epoch:100,loss:0.8918\n",
      "epoch:100,loss:1.4104\n",
      "epoch:100,loss:0.2365\n",
      "epoch:100,loss:1.2025\n",
      "epoch:100,loss:0.8057\n",
      "epoch:100,loss:0.2104\n",
      "epoch:100,loss:0.8861\n",
      "epoch:100,loss:0.8249\n",
      "epoch:100,loss:0.4018\n",
      "epoch:100,loss:0.3387\n",
      "epoch:100,loss:0.9042\n",
      "epoch:100,loss:1.0018\n",
      "epoch:100,loss:1.8270\n",
      "epoch:100,loss:0.5292\n",
      "epoch:100,loss:1.2447\n",
      "epoch:100,loss:1.0420\n",
      "epoch:100,loss:1.0831\n",
      "epoch:100,loss:0.8298\n",
      "epoch:100,loss:0.8512\n",
      "epoch:100,loss:0.7146\n",
      "epoch:100,loss:1.7398\n",
      "epoch:100,loss:0.3340\n",
      "epoch:100,loss:2.0218\n",
      "epoch:100,loss:0.9494\n",
      "epoch:100,loss:0.8754\n",
      "epoch:100,loss:0.3195\n",
      "epoch:100,loss:1.0266\n",
      "epoch:100,loss:1.0533\n",
      "epoch:100,loss:0.4012\n",
      "epoch:100,loss:1.8493\n",
      "epoch:100,loss:1.5023\n",
      "epoch:100,loss:0.5505\n",
      "epoch:100,loss:1.3619\n",
      "epoch:100,loss:0.7712\n",
      "epoch:100,loss:1.2588\n",
      "epoch:100,loss:1.4894\n",
      "epoch:100,loss:1.8934\n",
      "epoch:100,loss:1.5343\n",
      "============================================\n",
      "准确率由： tensor(0.6489) 上升至： tensor(0.6535) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第100个epoch的识别准确率为：65%\n",
      "epoch:101,loss:1.5746\n",
      "epoch:101,loss:1.2672\n",
      "epoch:101,loss:1.1043\n",
      "epoch:101,loss:0.7402\n",
      "epoch:101,loss:0.5038\n",
      "epoch:101,loss:0.5469\n",
      "epoch:101,loss:1.0394\n",
      "epoch:101,loss:0.8456\n",
      "epoch:101,loss:2.2435\n",
      "epoch:101,loss:0.8345\n",
      "epoch:101,loss:2.8971\n",
      "epoch:101,loss:2.3069\n",
      "epoch:101,loss:0.4798\n",
      "epoch:101,loss:0.7709\n",
      "epoch:101,loss:1.3963\n",
      "epoch:101,loss:0.6262\n",
      "epoch:101,loss:0.8540\n",
      "epoch:101,loss:0.1733\n",
      "epoch:101,loss:0.8489\n",
      "epoch:101,loss:0.2013\n",
      "epoch:101,loss:2.8023\n",
      "epoch:101,loss:1.3140\n",
      "epoch:101,loss:1.6372\n",
      "epoch:101,loss:0.7172\n",
      "epoch:101,loss:1.3032\n",
      "epoch:101,loss:2.1052\n",
      "epoch:101,loss:1.0422\n",
      "epoch:101,loss:0.9703\n",
      "epoch:101,loss:0.3964\n",
      "epoch:101,loss:0.5273\n",
      "epoch:101,loss:0.2768\n",
      "epoch:101,loss:2.4828\n",
      "epoch:101,loss:0.3946\n",
      "epoch:101,loss:0.7761\n",
      "epoch:101,loss:0.5280\n",
      "epoch:101,loss:1.3850\n",
      "epoch:101,loss:0.5151\n",
      "epoch:101,loss:1.6967\n",
      "epoch:101,loss:0.9697\n",
      "epoch:101,loss:0.3196\n",
      "epoch:101,loss:1.1558\n",
      "epoch:101,loss:0.5305\n",
      "epoch:101,loss:0.7829\n",
      "epoch:101,loss:1.0925\n",
      "epoch:101,loss:0.8792\n",
      "epoch:101,loss:1.0070\n",
      "epoch:101,loss:0.5792\n",
      "epoch:101,loss:1.1543\n",
      "epoch:101,loss:1.4836\n",
      "epoch:101,loss:1.1629\n",
      "epoch:101,loss:0.9022\n",
      "epoch:101,loss:1.8989\n",
      "epoch:101,loss:1.0917\n",
      "epoch:101,loss:1.5030\n",
      "epoch:101,loss:1.2191\n",
      "epoch:101,loss:0.4522\n",
      "epoch:101,loss:1.8520\n",
      "epoch:101,loss:1.0581\n",
      "epoch:101,loss:0.3569\n",
      "epoch:101,loss:1.5026\n",
      "============================================\n",
      "第101个epoch的识别准确率为：63%\n",
      "epoch:102,loss:0.8132\n",
      "epoch:102,loss:0.4057\n",
      "epoch:102,loss:0.5613\n",
      "epoch:102,loss:1.3770\n",
      "epoch:102,loss:1.3531\n",
      "epoch:102,loss:0.9034\n",
      "epoch:102,loss:2.2456\n",
      "epoch:102,loss:1.3173\n",
      "epoch:102,loss:1.6625\n",
      "epoch:102,loss:0.6000\n",
      "epoch:102,loss:1.4975\n",
      "epoch:102,loss:0.7406\n",
      "epoch:102,loss:0.3877\n",
      "epoch:102,loss:0.7892\n",
      "epoch:102,loss:1.1917\n",
      "epoch:102,loss:0.9141\n",
      "epoch:102,loss:1.1561\n",
      "epoch:102,loss:1.0018\n",
      "epoch:102,loss:0.9482\n",
      "epoch:102,loss:1.0693\n",
      "epoch:102,loss:2.0363\n",
      "epoch:102,loss:0.5429\n",
      "epoch:102,loss:1.0379\n",
      "epoch:102,loss:0.4306\n",
      "epoch:102,loss:0.6886\n",
      "epoch:102,loss:0.1941\n",
      "epoch:102,loss:0.2785\n",
      "epoch:102,loss:0.1765\n",
      "epoch:102,loss:1.0262\n",
      "epoch:102,loss:0.5199\n",
      "epoch:102,loss:0.7407\n",
      "epoch:102,loss:0.5794\n",
      "epoch:102,loss:1.3264\n",
      "epoch:102,loss:0.8708\n",
      "epoch:102,loss:0.3329\n",
      "epoch:102,loss:1.6167\n",
      "epoch:102,loss:0.8542\n",
      "epoch:102,loss:0.8648\n",
      "epoch:102,loss:2.0177\n",
      "epoch:102,loss:1.4481\n",
      "epoch:102,loss:0.2608\n",
      "epoch:102,loss:1.2489\n",
      "epoch:102,loss:1.3366\n",
      "epoch:102,loss:0.7086\n",
      "epoch:102,loss:0.6463\n",
      "epoch:102,loss:2.0749\n",
      "epoch:102,loss:1.1907\n",
      "epoch:102,loss:0.6438\n",
      "epoch:102,loss:1.5990\n",
      "epoch:102,loss:2.4895\n",
      "epoch:102,loss:1.1960\n",
      "epoch:102,loss:1.7691\n",
      "epoch:102,loss:0.7248\n",
      "epoch:102,loss:1.3616\n",
      "epoch:102,loss:1.0576\n",
      "epoch:102,loss:1.6871\n",
      "epoch:102,loss:0.6405\n",
      "epoch:102,loss:0.6335\n",
      "epoch:102,loss:1.2138\n",
      "epoch:102,loss:0.8174\n",
      "============================================\n",
      "第102个epoch的识别准确率为：63%\n",
      "epoch:103,loss:2.0778\n",
      "epoch:103,loss:0.6160\n",
      "epoch:103,loss:0.2789\n",
      "epoch:103,loss:1.1109\n",
      "epoch:103,loss:1.6405\n",
      "epoch:103,loss:1.4973\n",
      "epoch:103,loss:1.5359\n",
      "epoch:103,loss:1.5947\n",
      "epoch:103,loss:0.5047\n",
      "epoch:103,loss:1.5227\n",
      "epoch:103,loss:0.1417\n",
      "epoch:103,loss:1.1764\n",
      "epoch:103,loss:0.4534\n",
      "epoch:103,loss:1.1075\n",
      "epoch:103,loss:0.9013\n",
      "epoch:103,loss:0.9089\n",
      "epoch:103,loss:0.1771\n",
      "epoch:103,loss:0.8931\n",
      "epoch:103,loss:0.7417\n",
      "epoch:103,loss:1.1439\n",
      "epoch:103,loss:0.3783\n",
      "epoch:103,loss:1.2347\n",
      "epoch:103,loss:0.3153\n",
      "epoch:103,loss:2.5382\n",
      "epoch:103,loss:0.5348\n",
      "epoch:103,loss:1.8169\n",
      "epoch:103,loss:1.8846\n",
      "epoch:103,loss:2.5318\n",
      "epoch:103,loss:1.0054\n",
      "epoch:103,loss:1.3097\n",
      "epoch:103,loss:0.7137\n",
      "epoch:103,loss:0.6980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:103,loss:1.0779\n",
      "epoch:103,loss:0.6828\n",
      "epoch:103,loss:0.3415\n",
      "epoch:103,loss:1.5057\n",
      "epoch:103,loss:1.5954\n",
      "epoch:103,loss:2.0712\n",
      "epoch:103,loss:0.9410\n",
      "epoch:103,loss:1.1145\n",
      "epoch:103,loss:1.6659\n",
      "epoch:103,loss:1.8424\n",
      "epoch:103,loss:0.4888\n",
      "epoch:103,loss:1.3569\n",
      "epoch:103,loss:2.0516\n",
      "epoch:103,loss:0.9983\n",
      "epoch:103,loss:1.0467\n",
      "epoch:103,loss:0.6219\n",
      "epoch:103,loss:0.1882\n",
      "epoch:103,loss:1.3507\n",
      "epoch:103,loss:0.4231\n",
      "epoch:103,loss:0.4192\n",
      "epoch:103,loss:1.0908\n",
      "epoch:103,loss:1.0930\n",
      "epoch:103,loss:1.1596\n",
      "epoch:103,loss:0.7095\n",
      "epoch:103,loss:2.7792\n",
      "epoch:103,loss:0.4146\n",
      "epoch:103,loss:1.4420\n",
      "epoch:103,loss:1.6613\n",
      "============================================\n",
      "第103个epoch的识别准确率为：65%\n",
      "epoch:104,loss:1.3133\n",
      "epoch:104,loss:0.5779\n",
      "epoch:104,loss:0.9381\n",
      "epoch:104,loss:1.2050\n",
      "epoch:104,loss:1.5913\n",
      "epoch:104,loss:0.6798\n",
      "epoch:104,loss:0.2208\n",
      "epoch:104,loss:1.2942\n",
      "epoch:104,loss:0.7547\n",
      "epoch:104,loss:0.6523\n",
      "epoch:104,loss:0.4316\n",
      "epoch:104,loss:0.7097\n",
      "epoch:104,loss:1.5195\n",
      "epoch:104,loss:0.7804\n",
      "epoch:104,loss:1.1687\n",
      "epoch:104,loss:0.6458\n",
      "epoch:104,loss:1.2387\n",
      "epoch:104,loss:0.4276\n",
      "epoch:104,loss:2.4982\n",
      "epoch:104,loss:1.3460\n",
      "epoch:104,loss:0.9486\n",
      "epoch:104,loss:0.3691\n",
      "epoch:104,loss:0.7813\n",
      "epoch:104,loss:1.2150\n",
      "epoch:104,loss:1.3702\n",
      "epoch:104,loss:0.3677\n",
      "epoch:104,loss:1.2422\n",
      "epoch:104,loss:0.7535\n",
      "epoch:104,loss:0.1495\n",
      "epoch:104,loss:0.4689\n",
      "epoch:104,loss:1.3845\n",
      "epoch:104,loss:1.5768\n",
      "epoch:104,loss:0.7494\n",
      "epoch:104,loss:0.9598\n",
      "epoch:104,loss:1.0363\n",
      "epoch:104,loss:0.6262\n",
      "epoch:104,loss:0.9886\n",
      "epoch:104,loss:1.0369\n",
      "epoch:104,loss:1.7691\n",
      "epoch:104,loss:0.7059\n",
      "epoch:104,loss:0.9609\n",
      "epoch:104,loss:3.3656\n",
      "epoch:104,loss:0.8996\n",
      "epoch:104,loss:1.2956\n",
      "epoch:104,loss:1.6204\n",
      "epoch:104,loss:0.7956\n",
      "epoch:104,loss:1.8118\n",
      "epoch:104,loss:0.6287\n",
      "epoch:104,loss:0.7487\n",
      "epoch:104,loss:0.4677\n",
      "epoch:104,loss:1.2853\n",
      "epoch:104,loss:1.3882\n",
      "epoch:104,loss:0.3518\n",
      "epoch:104,loss:0.8413\n",
      "epoch:104,loss:1.1578\n",
      "epoch:104,loss:1.5232\n",
      "epoch:104,loss:1.2019\n",
      "epoch:104,loss:0.5689\n",
      "epoch:104,loss:1.3106\n",
      "epoch:104,loss:0.8298\n",
      "============================================\n",
      "第104个epoch的识别准确率为：64%\n",
      "epoch:105,loss:1.3114\n",
      "epoch:105,loss:2.1650\n",
      "epoch:105,loss:0.3155\n",
      "epoch:105,loss:0.4713\n",
      "epoch:105,loss:0.7192\n",
      "epoch:105,loss:1.8755\n",
      "epoch:105,loss:0.7679\n",
      "epoch:105,loss:0.6652\n",
      "epoch:105,loss:0.7858\n",
      "epoch:105,loss:1.8334\n",
      "epoch:105,loss:0.1947\n",
      "epoch:105,loss:0.4518\n",
      "epoch:105,loss:2.3714\n",
      "epoch:105,loss:0.4820\n",
      "epoch:105,loss:0.5369\n",
      "epoch:105,loss:1.6922\n",
      "epoch:105,loss:0.6846\n",
      "epoch:105,loss:0.6548\n",
      "epoch:105,loss:0.6128\n",
      "epoch:105,loss:0.5436\n",
      "epoch:105,loss:0.2455\n",
      "epoch:105,loss:1.2096\n",
      "epoch:105,loss:1.9881\n",
      "epoch:105,loss:0.4942\n",
      "epoch:105,loss:0.4052\n",
      "epoch:105,loss:2.6021\n",
      "epoch:105,loss:0.7315\n",
      "epoch:105,loss:0.3882\n",
      "epoch:105,loss:0.8174\n",
      "epoch:105,loss:0.7097\n",
      "epoch:105,loss:0.8725\n",
      "epoch:105,loss:0.9388\n",
      "epoch:105,loss:1.4752\n",
      "epoch:105,loss:1.1595\n",
      "epoch:105,loss:1.2431\n",
      "epoch:105,loss:0.2244\n",
      "epoch:105,loss:0.7487\n",
      "epoch:105,loss:1.0124\n",
      "epoch:105,loss:2.1934\n",
      "epoch:105,loss:0.7521\n",
      "epoch:105,loss:2.0667\n",
      "epoch:105,loss:0.8318\n",
      "epoch:105,loss:1.3540\n",
      "epoch:105,loss:0.4393\n",
      "epoch:105,loss:1.5072\n",
      "epoch:105,loss:0.3032\n",
      "epoch:105,loss:2.2734\n",
      "epoch:105,loss:2.6525\n",
      "epoch:105,loss:0.7572\n",
      "epoch:105,loss:0.6413\n",
      "epoch:105,loss:0.5630\n",
      "epoch:105,loss:0.8101\n",
      "epoch:105,loss:1.4484\n",
      "epoch:105,loss:0.7326\n",
      "epoch:105,loss:0.5498\n",
      "epoch:105,loss:1.3093\n",
      "epoch:105,loss:1.4430\n",
      "epoch:105,loss:0.6966\n",
      "epoch:105,loss:1.5111\n",
      "epoch:105,loss:0.7986\n",
      "============================================\n",
      "准确率由： tensor(0.6535) 上升至： tensor(0.6664) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第105个epoch的识别准确率为：66%\n",
      "epoch:106,loss:0.9730\n",
      "epoch:106,loss:0.7434\n",
      "epoch:106,loss:0.4854\n",
      "epoch:106,loss:0.4309\n",
      "epoch:106,loss:0.7095\n",
      "epoch:106,loss:1.1558\n",
      "epoch:106,loss:0.5811\n",
      "epoch:106,loss:1.6063\n",
      "epoch:106,loss:0.7960\n",
      "epoch:106,loss:1.2191\n",
      "epoch:106,loss:1.1081\n",
      "epoch:106,loss:0.9306\n",
      "epoch:106,loss:0.4744\n",
      "epoch:106,loss:1.1098\n",
      "epoch:106,loss:0.4070\n",
      "epoch:106,loss:1.0841\n",
      "epoch:106,loss:1.3677\n",
      "epoch:106,loss:1.0272\n",
      "epoch:106,loss:0.5345\n",
      "epoch:106,loss:0.7115\n",
      "epoch:106,loss:0.8291\n",
      "epoch:106,loss:1.7755\n",
      "epoch:106,loss:2.4315\n",
      "epoch:106,loss:1.2488\n",
      "epoch:106,loss:0.8055\n",
      "epoch:106,loss:1.1208\n",
      "epoch:106,loss:1.9977\n",
      "epoch:106,loss:1.5569\n",
      "epoch:106,loss:1.0972\n",
      "epoch:106,loss:0.6059\n",
      "epoch:106,loss:0.8224\n",
      "epoch:106,loss:2.0460\n",
      "epoch:106,loss:1.7112\n",
      "epoch:106,loss:0.5985\n",
      "epoch:106,loss:0.3039\n",
      "epoch:106,loss:1.7397\n",
      "epoch:106,loss:0.8912\n",
      "epoch:106,loss:0.9694\n",
      "epoch:106,loss:1.7646\n",
      "epoch:106,loss:0.5280\n",
      "epoch:106,loss:0.6367\n",
      "epoch:106,loss:1.2670\n",
      "epoch:106,loss:1.4185\n",
      "epoch:106,loss:0.5377\n",
      "epoch:106,loss:0.5966\n",
      "epoch:106,loss:2.1617\n",
      "epoch:106,loss:1.2496\n",
      "epoch:106,loss:0.8338\n",
      "epoch:106,loss:1.2534\n",
      "epoch:106,loss:1.4827\n",
      "epoch:106,loss:1.5238\n",
      "epoch:106,loss:0.7209\n",
      "epoch:106,loss:0.6629\n",
      "epoch:106,loss:0.9494\n",
      "epoch:106,loss:1.1034\n",
      "epoch:106,loss:1.0039\n",
      "epoch:106,loss:0.3581\n",
      "epoch:106,loss:2.0675\n",
      "epoch:106,loss:0.2771\n",
      "epoch:106,loss:0.3173\n",
      "============================================\n",
      "准确率由： tensor(0.6664) 上升至： tensor(0.6673) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第106个epoch的识别准确率为：66%\n",
      "epoch:107,loss:0.5487\n",
      "epoch:107,loss:0.4720\n",
      "epoch:107,loss:2.4294\n",
      "epoch:107,loss:1.0056\n",
      "epoch:107,loss:1.8024\n",
      "epoch:107,loss:0.3641\n",
      "epoch:107,loss:0.5083\n",
      "epoch:107,loss:0.6677\n",
      "epoch:107,loss:1.6901\n",
      "epoch:107,loss:1.4224\n",
      "epoch:107,loss:0.7400\n",
      "epoch:107,loss:0.9303\n",
      "epoch:107,loss:0.3305\n",
      "epoch:107,loss:1.0626\n",
      "epoch:107,loss:0.1539\n",
      "epoch:107,loss:0.7216\n",
      "epoch:107,loss:1.8805\n",
      "epoch:107,loss:2.5534\n",
      "epoch:107,loss:0.5853\n",
      "epoch:107,loss:0.6444\n",
      "epoch:107,loss:1.3642\n",
      "epoch:107,loss:1.0208\n",
      "epoch:107,loss:0.5305\n",
      "epoch:107,loss:1.5884\n",
      "epoch:107,loss:0.6997\n",
      "epoch:107,loss:0.5186\n",
      "epoch:107,loss:0.5223\n",
      "epoch:107,loss:0.1319\n",
      "epoch:107,loss:0.7588\n",
      "epoch:107,loss:1.7762\n",
      "epoch:107,loss:0.7849\n",
      "epoch:107,loss:0.6503\n",
      "epoch:107,loss:0.9018\n",
      "epoch:107,loss:1.2612\n",
      "epoch:107,loss:1.0711\n",
      "epoch:107,loss:0.8905\n",
      "epoch:107,loss:0.5706\n",
      "epoch:107,loss:0.7261\n",
      "epoch:107,loss:2.2068\n",
      "epoch:107,loss:0.5210\n",
      "epoch:107,loss:2.1263\n",
      "epoch:107,loss:1.6092\n",
      "epoch:107,loss:0.9590\n",
      "epoch:107,loss:1.4280\n",
      "epoch:107,loss:1.0361\n",
      "epoch:107,loss:0.8190\n",
      "epoch:107,loss:0.2453\n",
      "epoch:107,loss:1.5469\n",
      "epoch:107,loss:0.9331\n",
      "epoch:107,loss:1.4825\n",
      "epoch:107,loss:0.7783\n",
      "epoch:107,loss:0.5333\n",
      "epoch:107,loss:0.8350\n",
      "epoch:107,loss:0.6768\n",
      "epoch:107,loss:0.1851\n",
      "epoch:107,loss:1.1429\n",
      "epoch:107,loss:1.0082\n",
      "epoch:107,loss:0.7973\n",
      "epoch:107,loss:1.6141\n",
      "epoch:107,loss:1.1780\n",
      "============================================\n",
      "准确率由： tensor(0.6673) 上升至： tensor(0.6737) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第107个epoch的识别准确率为：67%\n",
      "epoch:108,loss:0.3820\n",
      "epoch:108,loss:0.7611\n",
      "epoch:108,loss:2.3757\n",
      "epoch:108,loss:0.2222\n",
      "epoch:108,loss:1.5380\n",
      "epoch:108,loss:0.3285\n",
      "epoch:108,loss:2.8550\n",
      "epoch:108,loss:0.9364\n",
      "epoch:108,loss:1.3238\n",
      "epoch:108,loss:0.9694\n",
      "epoch:108,loss:0.1455\n",
      "epoch:108,loss:0.6220\n",
      "epoch:108,loss:0.5948\n",
      "epoch:108,loss:0.6540\n",
      "epoch:108,loss:1.8556\n",
      "epoch:108,loss:0.3474\n",
      "epoch:108,loss:0.6868\n",
      "epoch:108,loss:0.3613\n",
      "epoch:108,loss:0.9764\n",
      "epoch:108,loss:1.2481\n",
      "epoch:108,loss:1.4526\n",
      "epoch:108,loss:1.4132\n",
      "epoch:108,loss:1.0092\n",
      "epoch:108,loss:0.1403\n",
      "epoch:108,loss:0.8033\n",
      "epoch:108,loss:1.0724\n",
      "epoch:108,loss:1.5643\n",
      "epoch:108,loss:1.7297\n",
      "epoch:108,loss:0.7252\n",
      "epoch:108,loss:0.6029\n",
      "epoch:108,loss:0.8809\n",
      "epoch:108,loss:1.4249\n",
      "epoch:108,loss:0.2171\n",
      "epoch:108,loss:0.6652\n",
      "epoch:108,loss:0.8261\n",
      "epoch:108,loss:1.2032\n",
      "epoch:108,loss:1.6702\n",
      "epoch:108,loss:0.9169\n",
      "epoch:108,loss:1.5506\n",
      "epoch:108,loss:1.6264\n",
      "epoch:108,loss:0.2821\n",
      "epoch:108,loss:0.6970\n",
      "epoch:108,loss:0.6926\n",
      "epoch:108,loss:1.3725\n",
      "epoch:108,loss:1.6606\n",
      "epoch:108,loss:1.3382\n",
      "epoch:108,loss:1.4317\n",
      "epoch:108,loss:0.9318\n",
      "epoch:108,loss:0.8300\n",
      "epoch:108,loss:0.1637\n",
      "epoch:108,loss:0.6138\n",
      "epoch:108,loss:0.6456\n",
      "epoch:108,loss:0.8423\n",
      "epoch:108,loss:0.8339\n",
      "epoch:108,loss:1.7584\n",
      "epoch:108,loss:2.6113\n",
      "epoch:108,loss:1.8734\n",
      "epoch:108,loss:0.5217\n",
      "epoch:108,loss:1.1796\n",
      "epoch:108,loss:0.3215\n",
      "============================================\n",
      "准确率由： tensor(0.6737) 上升至： tensor(0.6930) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第108个epoch的识别准确率为：69%\n",
      "epoch:109,loss:0.3155\n",
      "epoch:109,loss:0.8433\n",
      "epoch:109,loss:1.0622\n",
      "epoch:109,loss:0.7508\n",
      "epoch:109,loss:0.2681\n",
      "epoch:109,loss:1.2965\n",
      "epoch:109,loss:0.2663\n",
      "epoch:109,loss:1.2034\n",
      "epoch:109,loss:0.6733\n",
      "epoch:109,loss:1.5887\n",
      "epoch:109,loss:0.3191\n",
      "epoch:109,loss:0.9814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:109,loss:1.1733\n",
      "epoch:109,loss:0.6871\n",
      "epoch:109,loss:1.5733\n",
      "epoch:109,loss:0.2714\n",
      "epoch:109,loss:0.6222\n",
      "epoch:109,loss:0.4909\n",
      "epoch:109,loss:0.8657\n",
      "epoch:109,loss:0.7610\n",
      "epoch:109,loss:0.3122\n",
      "epoch:109,loss:0.8752\n",
      "epoch:109,loss:0.6269\n",
      "epoch:109,loss:0.7510\n",
      "epoch:109,loss:0.9466\n",
      "epoch:109,loss:0.5167\n",
      "epoch:109,loss:0.6607\n",
      "epoch:109,loss:0.7238\n",
      "epoch:109,loss:1.3405\n",
      "epoch:109,loss:2.7735\n",
      "epoch:109,loss:0.8372\n",
      "epoch:109,loss:1.0144\n",
      "epoch:109,loss:0.3654\n",
      "epoch:109,loss:1.3401\n",
      "epoch:109,loss:0.7721\n",
      "epoch:109,loss:1.8691\n",
      "epoch:109,loss:0.6980\n",
      "epoch:109,loss:0.2473\n",
      "epoch:109,loss:2.1468\n",
      "epoch:109,loss:0.4764\n",
      "epoch:109,loss:0.6653\n",
      "epoch:109,loss:0.7351\n",
      "epoch:109,loss:1.4037\n",
      "epoch:109,loss:0.1688\n",
      "epoch:109,loss:0.8365\n",
      "epoch:109,loss:0.2438\n",
      "epoch:109,loss:0.2086\n",
      "epoch:109,loss:0.8330\n",
      "epoch:109,loss:1.5034\n",
      "epoch:109,loss:1.2674\n",
      "epoch:109,loss:1.9916\n",
      "epoch:109,loss:0.9165\n",
      "epoch:109,loss:0.4833\n",
      "epoch:109,loss:1.9966\n",
      "epoch:109,loss:0.6866\n",
      "epoch:109,loss:1.3479\n",
      "epoch:109,loss:0.8922\n",
      "epoch:109,loss:2.5236\n",
      "epoch:109,loss:1.0592\n",
      "epoch:109,loss:1.5203\n",
      "============================================\n",
      "第109个epoch的识别准确率为：67%\n",
      "epoch:110,loss:1.0214\n",
      "epoch:110,loss:0.3319\n",
      "epoch:110,loss:2.0189\n",
      "epoch:110,loss:1.4261\n",
      "epoch:110,loss:0.5954\n",
      "epoch:110,loss:0.4499\n",
      "epoch:110,loss:0.6817\n",
      "epoch:110,loss:0.5055\n",
      "epoch:110,loss:1.1052\n",
      "epoch:110,loss:0.3677\n",
      "epoch:110,loss:1.4135\n",
      "epoch:110,loss:1.2638\n",
      "epoch:110,loss:0.2816\n",
      "epoch:110,loss:0.2139\n",
      "epoch:110,loss:0.4059\n",
      "epoch:110,loss:1.6869\n",
      "epoch:110,loss:0.9014\n",
      "epoch:110,loss:0.6068\n",
      "epoch:110,loss:0.3722\n",
      "epoch:110,loss:0.7067\n",
      "epoch:110,loss:1.2510\n",
      "epoch:110,loss:0.8003\n",
      "epoch:110,loss:1.5842\n",
      "epoch:110,loss:0.2595\n",
      "epoch:110,loss:0.8505\n",
      "epoch:110,loss:0.9374\n",
      "epoch:110,loss:1.3308\n",
      "epoch:110,loss:0.3653\n",
      "epoch:110,loss:1.0742\n",
      "epoch:110,loss:1.0939\n",
      "epoch:110,loss:1.9493\n",
      "epoch:110,loss:1.1999\n",
      "epoch:110,loss:1.4558\n",
      "epoch:110,loss:1.4976\n",
      "epoch:110,loss:0.8661\n",
      "epoch:110,loss:1.0627\n",
      "epoch:110,loss:1.2255\n",
      "epoch:110,loss:0.6297\n",
      "epoch:110,loss:1.6771\n",
      "epoch:110,loss:0.3596\n",
      "epoch:110,loss:1.4381\n",
      "epoch:110,loss:1.2148\n",
      "epoch:110,loss:0.8276\n",
      "epoch:110,loss:0.4672\n",
      "epoch:110,loss:0.7390\n",
      "epoch:110,loss:1.5985\n",
      "epoch:110,loss:0.9158\n",
      "epoch:110,loss:1.7488\n",
      "epoch:110,loss:1.0096\n",
      "epoch:110,loss:0.7175\n",
      "epoch:110,loss:1.3228\n",
      "epoch:110,loss:1.7255\n",
      "epoch:110,loss:1.2492\n",
      "epoch:110,loss:0.7398\n",
      "epoch:110,loss:0.2521\n",
      "epoch:110,loss:0.7745\n",
      "epoch:110,loss:0.7040\n",
      "epoch:110,loss:1.3096\n",
      "epoch:110,loss:0.9238\n",
      "epoch:110,loss:0.5690\n",
      "============================================\n",
      "第110个epoch的识别准确率为：65%\n",
      "epoch:111,loss:0.3762\n",
      "epoch:111,loss:0.8612\n",
      "epoch:111,loss:1.4790\n",
      "epoch:111,loss:0.7196\n",
      "epoch:111,loss:0.6832\n",
      "epoch:111,loss:1.2234\n",
      "epoch:111,loss:0.6191\n",
      "epoch:111,loss:0.5626\n",
      "epoch:111,loss:1.2018\n",
      "epoch:111,loss:0.8011\n",
      "epoch:111,loss:1.2213\n",
      "epoch:111,loss:2.0444\n",
      "epoch:111,loss:0.9677\n",
      "epoch:111,loss:2.6348\n",
      "epoch:111,loss:1.3666\n",
      "epoch:111,loss:1.6617\n",
      "epoch:111,loss:0.9052\n",
      "epoch:111,loss:0.6674\n",
      "epoch:111,loss:0.8704\n",
      "epoch:111,loss:0.7807\n",
      "epoch:111,loss:0.7778\n",
      "epoch:111,loss:0.7609\n",
      "epoch:111,loss:0.6634\n",
      "epoch:111,loss:0.7099\n",
      "epoch:111,loss:0.6322\n",
      "epoch:111,loss:1.0615\n",
      "epoch:111,loss:0.6343\n",
      "epoch:111,loss:0.5318\n",
      "epoch:111,loss:0.7718\n",
      "epoch:111,loss:0.6885\n",
      "epoch:111,loss:1.8189\n",
      "epoch:111,loss:0.3210\n",
      "epoch:111,loss:0.3182\n",
      "epoch:111,loss:0.7534\n",
      "epoch:111,loss:1.7087\n",
      "epoch:111,loss:2.1096\n",
      "epoch:111,loss:0.7612\n",
      "epoch:111,loss:1.0654\n",
      "epoch:111,loss:0.5280\n",
      "epoch:111,loss:1.3739\n",
      "epoch:111,loss:1.3812\n",
      "epoch:111,loss:0.6590\n",
      "epoch:111,loss:0.3205\n",
      "epoch:111,loss:0.7785\n",
      "epoch:111,loss:1.5117\n",
      "epoch:111,loss:0.1635\n",
      "epoch:111,loss:0.4433\n",
      "epoch:111,loss:1.3399\n",
      "epoch:111,loss:0.3520\n",
      "epoch:111,loss:1.6296\n",
      "epoch:111,loss:0.9498\n",
      "epoch:111,loss:0.3123\n",
      "epoch:111,loss:0.2127\n",
      "epoch:111,loss:1.9069\n",
      "epoch:111,loss:1.1321\n",
      "epoch:111,loss:2.1821\n",
      "epoch:111,loss:1.2303\n",
      "epoch:111,loss:0.6270\n",
      "epoch:111,loss:1.7798\n",
      "epoch:111,loss:2.0221\n",
      "============================================\n",
      "第111个epoch的识别准确率为：67%\n",
      "epoch:112,loss:0.8608\n",
      "epoch:112,loss:0.9236\n",
      "epoch:112,loss:1.7061\n",
      "epoch:112,loss:0.5172\n",
      "epoch:112,loss:0.2795\n",
      "epoch:112,loss:1.0837\n",
      "epoch:112,loss:1.4446\n",
      "epoch:112,loss:0.8916\n",
      "epoch:112,loss:2.0625\n",
      "epoch:112,loss:0.9388\n",
      "epoch:112,loss:1.3577\n",
      "epoch:112,loss:1.3813\n",
      "epoch:112,loss:0.2611\n",
      "epoch:112,loss:1.3547\n",
      "epoch:112,loss:1.4872\n",
      "epoch:112,loss:0.7961\n",
      "epoch:112,loss:0.8292\n",
      "epoch:112,loss:1.5669\n",
      "epoch:112,loss:0.2525\n",
      "epoch:112,loss:2.0481\n",
      "epoch:112,loss:0.7224\n",
      "epoch:112,loss:0.4958\n",
      "epoch:112,loss:1.2844\n",
      "epoch:112,loss:0.6879\n",
      "epoch:112,loss:0.6119\n",
      "epoch:112,loss:1.3967\n",
      "epoch:112,loss:0.9882\n",
      "epoch:112,loss:0.6422\n",
      "epoch:112,loss:0.8245\n",
      "epoch:112,loss:0.8944\n",
      "epoch:112,loss:0.9288\n",
      "epoch:112,loss:0.7747\n",
      "epoch:112,loss:0.1275\n",
      "epoch:112,loss:1.5490\n",
      "epoch:112,loss:1.0349\n",
      "epoch:112,loss:1.7649\n",
      "epoch:112,loss:0.7280\n",
      "epoch:112,loss:1.5204\n",
      "epoch:112,loss:0.7763\n",
      "epoch:112,loss:0.6714\n",
      "epoch:112,loss:0.4999\n",
      "epoch:112,loss:0.5777\n",
      "epoch:112,loss:0.6858\n",
      "epoch:112,loss:1.0310\n",
      "epoch:112,loss:1.0836\n",
      "epoch:112,loss:1.9056\n",
      "epoch:112,loss:0.9886\n",
      "epoch:112,loss:2.6665\n",
      "epoch:112,loss:0.3695\n",
      "epoch:112,loss:1.0183\n",
      "epoch:112,loss:0.6444\n",
      "epoch:112,loss:1.3916\n",
      "epoch:112,loss:1.0131\n",
      "epoch:112,loss:1.0421\n",
      "epoch:112,loss:0.2767\n",
      "epoch:112,loss:0.5805\n",
      "epoch:112,loss:1.0678\n",
      "epoch:112,loss:1.5042\n",
      "epoch:112,loss:1.3561\n",
      "epoch:112,loss:0.8624\n",
      "============================================\n",
      "第112个epoch的识别准确率为：68%\n",
      "epoch:113,loss:0.6679\n",
      "epoch:113,loss:1.1306\n",
      "epoch:113,loss:1.1283\n",
      "epoch:113,loss:0.8664\n",
      "epoch:113,loss:1.4840\n",
      "epoch:113,loss:0.6468\n",
      "epoch:113,loss:1.4684\n",
      "epoch:113,loss:1.4826\n",
      "epoch:113,loss:1.9584\n",
      "epoch:113,loss:1.3794\n",
      "epoch:113,loss:0.9389\n",
      "epoch:113,loss:0.4009\n",
      "epoch:113,loss:0.5134\n",
      "epoch:113,loss:1.4198\n",
      "epoch:113,loss:0.8189\n",
      "epoch:113,loss:1.1749\n",
      "epoch:113,loss:0.4663\n",
      "epoch:113,loss:1.0444\n",
      "epoch:113,loss:0.3072\n",
      "epoch:113,loss:0.8962\n",
      "epoch:113,loss:0.6048\n",
      "epoch:113,loss:0.9440\n",
      "epoch:113,loss:0.3857\n",
      "epoch:113,loss:1.6968\n",
      "epoch:113,loss:0.7098\n",
      "epoch:113,loss:0.3363\n",
      "epoch:113,loss:1.6408\n",
      "epoch:113,loss:0.6443\n",
      "epoch:113,loss:0.5322\n",
      "epoch:113,loss:0.5157\n",
      "epoch:113,loss:0.1001\n",
      "epoch:113,loss:0.3535\n",
      "epoch:113,loss:0.1572\n",
      "epoch:113,loss:1.3319\n",
      "epoch:113,loss:0.6735\n",
      "epoch:113,loss:1.8775\n",
      "epoch:113,loss:0.5693\n",
      "epoch:113,loss:1.0328\n",
      "epoch:113,loss:0.7028\n",
      "epoch:113,loss:0.7607\n",
      "epoch:113,loss:0.9294\n",
      "epoch:113,loss:0.4909\n",
      "epoch:113,loss:1.2349\n",
      "epoch:113,loss:1.4828\n",
      "epoch:113,loss:1.2541\n",
      "epoch:113,loss:0.7014\n",
      "epoch:113,loss:0.8212\n",
      "epoch:113,loss:0.2576\n",
      "epoch:113,loss:0.0640\n",
      "epoch:113,loss:0.4372\n",
      "epoch:113,loss:0.8096\n",
      "epoch:113,loss:0.8566\n",
      "epoch:113,loss:0.7843\n",
      "epoch:113,loss:0.9902\n",
      "epoch:113,loss:2.2049\n",
      "epoch:113,loss:0.4342\n",
      "epoch:113,loss:0.9087\n",
      "epoch:113,loss:0.8335\n",
      "epoch:113,loss:1.7779\n",
      "epoch:113,loss:0.6382\n",
      "============================================\n",
      "第113个epoch的识别准确率为：68%\n",
      "epoch:114,loss:0.3390\n",
      "epoch:114,loss:0.6600\n",
      "epoch:114,loss:0.7671\n",
      "epoch:114,loss:0.4098\n",
      "epoch:114,loss:0.0603\n",
      "epoch:114,loss:0.4194\n",
      "epoch:114,loss:0.0833\n",
      "epoch:114,loss:1.2418\n",
      "epoch:114,loss:1.1187\n",
      "epoch:114,loss:0.5997\n",
      "epoch:114,loss:1.1494\n",
      "epoch:114,loss:0.8383\n",
      "epoch:114,loss:0.6478\n",
      "epoch:114,loss:1.2052\n",
      "epoch:114,loss:1.7679\n",
      "epoch:114,loss:1.0531\n",
      "epoch:114,loss:0.2086\n",
      "epoch:114,loss:0.8766\n",
      "epoch:114,loss:0.9024\n",
      "epoch:114,loss:0.9593\n",
      "epoch:114,loss:1.6630\n",
      "epoch:114,loss:0.5832\n",
      "epoch:114,loss:0.9176\n",
      "epoch:114,loss:0.8496\n",
      "epoch:114,loss:0.8075\n",
      "epoch:114,loss:0.9489\n",
      "epoch:114,loss:0.5821\n",
      "epoch:114,loss:0.4591\n",
      "epoch:114,loss:0.3564\n",
      "epoch:114,loss:1.1261\n",
      "epoch:114,loss:0.5616\n",
      "epoch:114,loss:1.5779\n",
      "epoch:114,loss:0.7467\n",
      "epoch:114,loss:0.1903\n",
      "epoch:114,loss:0.9007\n",
      "epoch:114,loss:1.1152\n",
      "epoch:114,loss:0.2001\n",
      "epoch:114,loss:1.0178\n",
      "epoch:114,loss:1.2358\n",
      "epoch:114,loss:1.1810\n",
      "epoch:114,loss:0.2790\n",
      "epoch:114,loss:0.7210\n",
      "epoch:114,loss:0.6074\n",
      "epoch:114,loss:0.7795\n",
      "epoch:114,loss:0.6181\n",
      "epoch:114,loss:0.5587\n",
      "epoch:114,loss:0.7519\n",
      "epoch:114,loss:0.6641\n",
      "epoch:114,loss:1.1688\n",
      "epoch:114,loss:0.2545\n",
      "epoch:114,loss:1.7621\n",
      "epoch:114,loss:1.3726\n",
      "epoch:114,loss:0.9724\n",
      "epoch:114,loss:0.6136\n",
      "epoch:114,loss:1.6814\n",
      "epoch:114,loss:0.8223\n",
      "epoch:114,loss:1.8361\n",
      "epoch:114,loss:1.8558\n",
      "epoch:114,loss:1.0063\n",
      "epoch:114,loss:0.4789\n",
      "============================================\n",
      "准确率由： tensor(0.6930) 上升至： tensor(0.7004) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第114个epoch的识别准确率为：70%\n",
      "epoch:115,loss:0.8864\n",
      "epoch:115,loss:0.1979\n",
      "epoch:115,loss:0.4045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:115,loss:2.0844\n",
      "epoch:115,loss:1.3262\n",
      "epoch:115,loss:0.1134\n",
      "epoch:115,loss:1.1105\n",
      "epoch:115,loss:1.0143\n",
      "epoch:115,loss:0.9429\n",
      "epoch:115,loss:0.3688\n",
      "epoch:115,loss:0.2538\n",
      "epoch:115,loss:0.7521\n",
      "epoch:115,loss:1.5145\n",
      "epoch:115,loss:0.2259\n",
      "epoch:115,loss:0.3512\n",
      "epoch:115,loss:1.2305\n",
      "epoch:115,loss:0.7446\n",
      "epoch:115,loss:0.5199\n",
      "epoch:115,loss:1.6506\n",
      "epoch:115,loss:1.5007\n",
      "epoch:115,loss:0.9041\n",
      "epoch:115,loss:0.6603\n",
      "epoch:115,loss:0.4398\n",
      "epoch:115,loss:1.1048\n",
      "epoch:115,loss:0.7766\n",
      "epoch:115,loss:1.7677\n",
      "epoch:115,loss:0.1942\n",
      "epoch:115,loss:0.2908\n",
      "epoch:115,loss:0.4603\n",
      "epoch:115,loss:0.7412\n",
      "epoch:115,loss:1.6298\n",
      "epoch:115,loss:0.8942\n",
      "epoch:115,loss:1.4150\n",
      "epoch:115,loss:1.1968\n",
      "epoch:115,loss:0.4273\n",
      "epoch:115,loss:1.4412\n",
      "epoch:115,loss:0.7469\n",
      "epoch:115,loss:1.1205\n",
      "epoch:115,loss:1.3852\n",
      "epoch:115,loss:1.5614\n",
      "epoch:115,loss:0.6732\n",
      "epoch:115,loss:0.1959\n",
      "epoch:115,loss:0.6996\n",
      "epoch:115,loss:1.1402\n",
      "epoch:115,loss:0.6085\n",
      "epoch:115,loss:0.8308\n",
      "epoch:115,loss:0.6541\n",
      "epoch:115,loss:1.0137\n",
      "epoch:115,loss:0.8620\n",
      "epoch:115,loss:1.7158\n",
      "epoch:115,loss:0.4925\n",
      "epoch:115,loss:0.5874\n",
      "epoch:115,loss:0.9419\n",
      "epoch:115,loss:0.9240\n",
      "epoch:115,loss:0.9018\n",
      "epoch:115,loss:0.4941\n",
      "epoch:115,loss:1.2385\n",
      "epoch:115,loss:1.0509\n",
      "epoch:115,loss:0.9582\n",
      "epoch:115,loss:1.2182\n",
      "============================================\n",
      "准确率由： tensor(0.7004) 上升至： tensor(0.7096) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第115个epoch的识别准确率为：70%\n",
      "epoch:116,loss:0.4575\n",
      "epoch:116,loss:0.8050\n",
      "epoch:116,loss:0.4744\n",
      "epoch:116,loss:0.4405\n",
      "epoch:116,loss:0.9184\n",
      "epoch:116,loss:0.3769\n",
      "epoch:116,loss:1.8026\n",
      "epoch:116,loss:0.5880\n",
      "epoch:116,loss:0.3622\n",
      "epoch:116,loss:0.6630\n",
      "epoch:116,loss:0.8975\n",
      "epoch:116,loss:2.1855\n",
      "epoch:116,loss:0.8883\n",
      "epoch:116,loss:1.2668\n",
      "epoch:116,loss:0.4265\n",
      "epoch:116,loss:1.7991\n",
      "epoch:116,loss:1.5733\n",
      "epoch:116,loss:0.7523\n",
      "epoch:116,loss:0.4676\n",
      "epoch:116,loss:0.6666\n",
      "epoch:116,loss:0.5988\n",
      "epoch:116,loss:0.3594\n",
      "epoch:116,loss:0.3901\n",
      "epoch:116,loss:0.2726\n",
      "epoch:116,loss:0.4635\n",
      "epoch:116,loss:1.4492\n",
      "epoch:116,loss:1.4825\n",
      "epoch:116,loss:1.1807\n",
      "epoch:116,loss:0.6433\n",
      "epoch:116,loss:0.4567\n",
      "epoch:116,loss:0.7805\n",
      "epoch:116,loss:0.9890\n",
      "epoch:116,loss:0.7659\n",
      "epoch:116,loss:0.2130\n",
      "epoch:116,loss:0.2905\n",
      "epoch:116,loss:0.8365\n",
      "epoch:116,loss:0.2506\n",
      "epoch:116,loss:0.3557\n",
      "epoch:116,loss:0.2487\n",
      "epoch:116,loss:1.2360\n",
      "epoch:116,loss:0.6481\n",
      "epoch:116,loss:1.3945\n",
      "epoch:116,loss:0.6876\n",
      "epoch:116,loss:0.4802\n",
      "epoch:116,loss:1.2524\n",
      "epoch:116,loss:1.0339\n",
      "epoch:116,loss:1.3025\n",
      "epoch:116,loss:1.2128\n",
      "epoch:116,loss:0.4553\n",
      "epoch:116,loss:0.8735\n",
      "epoch:116,loss:1.5247\n",
      "epoch:116,loss:0.2957\n",
      "epoch:116,loss:0.7289\n",
      "epoch:116,loss:0.2513\n",
      "epoch:116,loss:0.4609\n",
      "epoch:116,loss:1.2173\n",
      "epoch:116,loss:0.1834\n",
      "epoch:116,loss:0.9676\n",
      "epoch:116,loss:1.1865\n",
      "epoch:116,loss:1.8512\n",
      "============================================\n",
      "第116个epoch的识别准确率为：70%\n",
      "epoch:117,loss:0.8412\n",
      "epoch:117,loss:0.6318\n",
      "epoch:117,loss:1.7912\n",
      "epoch:117,loss:0.8740\n",
      "epoch:117,loss:0.8690\n",
      "epoch:117,loss:1.0445\n",
      "epoch:117,loss:0.9993\n",
      "epoch:117,loss:0.5131\n",
      "epoch:117,loss:0.9664\n",
      "epoch:117,loss:0.4856\n",
      "epoch:117,loss:0.8567\n",
      "epoch:117,loss:1.0325\n",
      "epoch:117,loss:0.7560\n",
      "epoch:117,loss:1.3162\n",
      "epoch:117,loss:0.0768\n",
      "epoch:117,loss:0.7484\n",
      "epoch:117,loss:1.7419\n",
      "epoch:117,loss:1.6739\n",
      "epoch:117,loss:1.1634\n",
      "epoch:117,loss:0.2969\n",
      "epoch:117,loss:0.5254\n",
      "epoch:117,loss:0.3724\n",
      "epoch:117,loss:0.1336\n",
      "epoch:117,loss:0.6792\n",
      "epoch:117,loss:0.4588\n",
      "epoch:117,loss:0.2239\n",
      "epoch:117,loss:2.3884\n",
      "epoch:117,loss:0.3281\n",
      "epoch:117,loss:1.5348\n",
      "epoch:117,loss:0.1601\n",
      "epoch:117,loss:0.5913\n",
      "epoch:117,loss:0.2701\n",
      "epoch:117,loss:0.1358\n",
      "epoch:117,loss:1.3371\n",
      "epoch:117,loss:0.8789\n",
      "epoch:117,loss:1.0881\n",
      "epoch:117,loss:0.3239\n",
      "epoch:117,loss:0.3022\n",
      "epoch:117,loss:0.7166\n",
      "epoch:117,loss:1.0016\n",
      "epoch:117,loss:0.4205\n",
      "epoch:117,loss:1.0361\n",
      "epoch:117,loss:0.5582\n",
      "epoch:117,loss:1.3217\n",
      "epoch:117,loss:0.6357\n",
      "epoch:117,loss:0.4797\n",
      "epoch:117,loss:0.7454\n",
      "epoch:117,loss:0.7990\n",
      "epoch:117,loss:1.2605\n",
      "epoch:117,loss:2.3841\n",
      "epoch:117,loss:0.9208\n",
      "epoch:117,loss:1.0152\n",
      "epoch:117,loss:1.3861\n",
      "epoch:117,loss:1.6517\n",
      "epoch:117,loss:0.9565\n",
      "epoch:117,loss:0.5314\n",
      "epoch:117,loss:0.7491\n",
      "epoch:117,loss:1.6182\n",
      "epoch:117,loss:0.9581\n",
      "epoch:117,loss:1.1029\n",
      "============================================\n",
      "准确率由： tensor(0.7096) 上升至： tensor(0.7188) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第117个epoch的识别准确率为：71%\n",
      "epoch:118,loss:2.8097\n",
      "epoch:118,loss:0.9758\n",
      "epoch:118,loss:1.3673\n",
      "epoch:118,loss:1.2563\n",
      "epoch:118,loss:1.2338\n",
      "epoch:118,loss:0.4877\n",
      "epoch:118,loss:1.0901\n",
      "epoch:118,loss:0.1443\n",
      "epoch:118,loss:1.0579\n",
      "epoch:118,loss:0.5764\n",
      "epoch:118,loss:1.0299\n",
      "epoch:118,loss:0.1069\n",
      "epoch:118,loss:0.4473\n",
      "epoch:118,loss:1.0810\n",
      "epoch:118,loss:0.8715\n",
      "epoch:118,loss:0.9852\n",
      "epoch:118,loss:0.9788\n",
      "epoch:118,loss:1.0086\n",
      "epoch:118,loss:0.6271\n",
      "epoch:118,loss:0.2149\n",
      "epoch:118,loss:1.2724\n",
      "epoch:118,loss:1.0824\n",
      "epoch:118,loss:0.5438\n",
      "epoch:118,loss:0.5856\n",
      "epoch:118,loss:1.3846\n",
      "epoch:118,loss:1.0917\n",
      "epoch:118,loss:0.6876\n",
      "epoch:118,loss:0.9318\n",
      "epoch:118,loss:0.5802\n",
      "epoch:118,loss:0.4372\n",
      "epoch:118,loss:0.8518\n",
      "epoch:118,loss:0.6475\n",
      "epoch:118,loss:0.9846\n",
      "epoch:118,loss:0.9703\n",
      "epoch:118,loss:0.1992\n",
      "epoch:118,loss:1.3705\n",
      "epoch:118,loss:1.3965\n",
      "epoch:118,loss:0.6389\n",
      "epoch:118,loss:0.9832\n",
      "epoch:118,loss:1.5504\n",
      "epoch:118,loss:0.6377\n",
      "epoch:118,loss:0.7464\n",
      "epoch:118,loss:0.3738\n",
      "epoch:118,loss:0.3635\n",
      "epoch:118,loss:0.1026\n",
      "epoch:118,loss:0.0762\n",
      "epoch:118,loss:0.7520\n",
      "epoch:118,loss:0.5199\n",
      "epoch:118,loss:0.6905\n",
      "epoch:118,loss:0.3983\n",
      "epoch:118,loss:1.7979\n",
      "epoch:118,loss:0.6571\n",
      "epoch:118,loss:1.0399\n",
      "epoch:118,loss:1.1041\n",
      "epoch:118,loss:0.4857\n",
      "epoch:118,loss:1.1761\n",
      "epoch:118,loss:1.3197\n",
      "epoch:118,loss:2.1201\n",
      "epoch:118,loss:1.0086\n",
      "epoch:118,loss:0.1266\n",
      "============================================\n",
      "准确率由： tensor(0.7188) 上升至： tensor(0.7252) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第118个epoch的识别准确率为：72%\n",
      "epoch:119,loss:0.6679\n",
      "epoch:119,loss:0.7317\n",
      "epoch:119,loss:0.7736\n",
      "epoch:119,loss:1.1815\n",
      "epoch:119,loss:0.3559\n",
      "epoch:119,loss:1.3108\n",
      "epoch:119,loss:1.4067\n",
      "epoch:119,loss:0.7670\n",
      "epoch:119,loss:0.5470\n",
      "epoch:119,loss:0.5019\n",
      "epoch:119,loss:0.5558\n",
      "epoch:119,loss:0.3097\n",
      "epoch:119,loss:0.6108\n",
      "epoch:119,loss:0.7919\n",
      "epoch:119,loss:0.3427\n",
      "epoch:119,loss:0.5696\n",
      "epoch:119,loss:0.3539\n",
      "epoch:119,loss:0.9212\n",
      "epoch:119,loss:0.6791\n",
      "epoch:119,loss:0.3106\n",
      "epoch:119,loss:1.7462\n",
      "epoch:119,loss:0.6542\n",
      "epoch:119,loss:0.3966\n",
      "epoch:119,loss:1.3079\n",
      "epoch:119,loss:1.0120\n",
      "epoch:119,loss:0.3348\n",
      "epoch:119,loss:0.7547\n",
      "epoch:119,loss:1.1576\n",
      "epoch:119,loss:0.6085\n",
      "epoch:119,loss:0.7525\n",
      "epoch:119,loss:0.7641\n",
      "epoch:119,loss:0.0780\n",
      "epoch:119,loss:1.2694\n",
      "epoch:119,loss:0.8994\n",
      "epoch:119,loss:1.4642\n",
      "epoch:119,loss:0.6794\n",
      "epoch:119,loss:1.4900\n",
      "epoch:119,loss:0.9366\n",
      "epoch:119,loss:1.1392\n",
      "epoch:119,loss:0.6768\n",
      "epoch:119,loss:2.9343\n",
      "epoch:119,loss:0.4301\n",
      "epoch:119,loss:0.1777\n",
      "epoch:119,loss:0.4447\n",
      "epoch:119,loss:1.0176\n",
      "epoch:119,loss:2.4343\n",
      "epoch:119,loss:1.9642\n",
      "epoch:119,loss:1.2173\n",
      "epoch:119,loss:0.8370\n",
      "epoch:119,loss:0.3788\n",
      "epoch:119,loss:0.4861\n",
      "epoch:119,loss:0.7390\n",
      "epoch:119,loss:0.8944\n",
      "epoch:119,loss:0.4850\n",
      "epoch:119,loss:0.9955\n",
      "epoch:119,loss:0.4516\n",
      "epoch:119,loss:0.8018\n",
      "epoch:119,loss:1.6897\n",
      "epoch:119,loss:1.4400\n",
      "epoch:119,loss:1.0268\n",
      "============================================\n",
      "准确率由： tensor(0.7252) 上升至： tensor(0.7289) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第119个epoch的识别准确率为：72%\n",
      "epoch:120,loss:0.6905\n",
      "epoch:120,loss:1.8385\n",
      "epoch:120,loss:1.0874\n",
      "epoch:120,loss:0.9551\n",
      "epoch:120,loss:1.5861\n",
      "epoch:120,loss:0.6639\n",
      "epoch:120,loss:1.6515\n",
      "epoch:120,loss:0.9405\n",
      "epoch:120,loss:0.5210\n",
      "epoch:120,loss:1.4051\n",
      "epoch:120,loss:1.2726\n",
      "epoch:120,loss:0.3352\n",
      "epoch:120,loss:0.3260\n",
      "epoch:120,loss:0.3091\n",
      "epoch:120,loss:0.9176\n",
      "epoch:120,loss:1.6469\n",
      "epoch:120,loss:1.1617\n",
      "epoch:120,loss:1.5324\n",
      "epoch:120,loss:0.2809\n",
      "epoch:120,loss:1.3189\n",
      "epoch:120,loss:0.7384\n",
      "epoch:120,loss:0.6614\n",
      "epoch:120,loss:0.5777\n",
      "epoch:120,loss:0.3252\n",
      "epoch:120,loss:0.9756\n",
      "epoch:120,loss:0.6463\n",
      "epoch:120,loss:0.8078\n",
      "epoch:120,loss:0.9073\n",
      "epoch:120,loss:0.5966\n",
      "epoch:120,loss:0.8093\n",
      "epoch:120,loss:0.8141\n",
      "epoch:120,loss:0.7620\n",
      "epoch:120,loss:1.2807\n",
      "epoch:120,loss:0.2977\n",
      "epoch:120,loss:0.2745\n",
      "epoch:120,loss:1.9565\n",
      "epoch:120,loss:1.2763\n",
      "epoch:120,loss:1.7391\n",
      "epoch:120,loss:0.7137\n",
      "epoch:120,loss:0.2280\n",
      "epoch:120,loss:2.1705\n",
      "epoch:120,loss:0.1913\n",
      "epoch:120,loss:1.4053\n",
      "epoch:120,loss:1.9335\n",
      "epoch:120,loss:0.6887\n",
      "epoch:120,loss:0.2079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:120,loss:0.4040\n",
      "epoch:120,loss:0.8947\n",
      "epoch:120,loss:0.4198\n",
      "epoch:120,loss:1.1602\n",
      "epoch:120,loss:0.3194\n",
      "epoch:120,loss:0.2634\n",
      "epoch:120,loss:0.2891\n",
      "epoch:120,loss:0.4241\n",
      "epoch:120,loss:1.6175\n",
      "epoch:120,loss:0.5854\n",
      "epoch:120,loss:1.6741\n",
      "epoch:120,loss:0.1306\n",
      "epoch:120,loss:0.2380\n",
      "epoch:120,loss:0.2490\n",
      "============================================\n",
      "准确率由： tensor(0.7289) 上升至： tensor(0.7454) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第120个epoch的识别准确率为：74%\n",
      "epoch:121,loss:0.5387\n",
      "epoch:121,loss:0.5192\n",
      "epoch:121,loss:0.3202\n",
      "epoch:121,loss:0.2575\n",
      "epoch:121,loss:0.8897\n",
      "epoch:121,loss:0.8490\n",
      "epoch:121,loss:0.2600\n",
      "epoch:121,loss:0.2921\n",
      "epoch:121,loss:1.9145\n",
      "epoch:121,loss:0.4763\n",
      "epoch:121,loss:0.4960\n",
      "epoch:121,loss:0.8567\n",
      "epoch:121,loss:0.4140\n",
      "epoch:121,loss:0.1753\n",
      "epoch:121,loss:1.6945\n",
      "epoch:121,loss:0.2286\n",
      "epoch:121,loss:0.1560\n",
      "epoch:121,loss:0.5433\n",
      "epoch:121,loss:0.7140\n",
      "epoch:121,loss:1.0086\n",
      "epoch:121,loss:0.7315\n",
      "epoch:121,loss:0.4965\n",
      "epoch:121,loss:1.3686\n",
      "epoch:121,loss:0.6373\n",
      "epoch:121,loss:0.7158\n",
      "epoch:121,loss:0.7593\n",
      "epoch:121,loss:0.5496\n",
      "epoch:121,loss:1.2951\n",
      "epoch:121,loss:0.7903\n",
      "epoch:121,loss:0.6242\n",
      "epoch:121,loss:0.5998\n",
      "epoch:121,loss:0.5856\n",
      "epoch:121,loss:1.6446\n",
      "epoch:121,loss:1.9090\n",
      "epoch:121,loss:0.4553\n",
      "epoch:121,loss:0.0928\n",
      "epoch:121,loss:0.2930\n",
      "epoch:121,loss:0.4458\n",
      "epoch:121,loss:0.6337\n",
      "epoch:121,loss:0.1932\n",
      "epoch:121,loss:0.7601\n",
      "epoch:121,loss:1.5980\n",
      "epoch:121,loss:0.4920\n",
      "epoch:121,loss:0.7717\n",
      "epoch:121,loss:0.7671\n",
      "epoch:121,loss:0.6315\n",
      "epoch:121,loss:0.6077\n",
      "epoch:121,loss:1.5156\n",
      "epoch:121,loss:0.8224\n",
      "epoch:121,loss:0.4072\n",
      "epoch:121,loss:2.1329\n",
      "epoch:121,loss:1.4819\n",
      "epoch:121,loss:0.1864\n",
      "epoch:121,loss:0.7963\n",
      "epoch:121,loss:0.5773\n",
      "epoch:121,loss:0.6214\n",
      "epoch:121,loss:0.3447\n",
      "epoch:121,loss:0.6106\n",
      "epoch:121,loss:0.2075\n",
      "epoch:121,loss:1.2109\n",
      "============================================\n",
      "第121个epoch的识别准确率为：72%\n",
      "epoch:122,loss:0.4571\n",
      "epoch:122,loss:0.8842\n",
      "epoch:122,loss:1.1010\n",
      "epoch:122,loss:0.5028\n",
      "epoch:122,loss:0.2842\n",
      "epoch:122,loss:0.3777\n",
      "epoch:122,loss:0.7963\n",
      "epoch:122,loss:0.6732\n",
      "epoch:122,loss:0.9193\n",
      "epoch:122,loss:0.6633\n",
      "epoch:122,loss:0.6725\n",
      "epoch:122,loss:0.5219\n",
      "epoch:122,loss:0.3651\n",
      "epoch:122,loss:1.1512\n",
      "epoch:122,loss:0.4200\n",
      "epoch:122,loss:0.2589\n",
      "epoch:122,loss:0.8401\n",
      "epoch:122,loss:0.7543\n",
      "epoch:122,loss:1.0275\n",
      "epoch:122,loss:0.8276\n",
      "epoch:122,loss:1.0369\n",
      "epoch:122,loss:1.2633\n",
      "epoch:122,loss:0.3110\n",
      "epoch:122,loss:0.5791\n",
      "epoch:122,loss:0.3818\n",
      "epoch:122,loss:0.1908\n",
      "epoch:122,loss:0.6812\n",
      "epoch:122,loss:1.2737\n",
      "epoch:122,loss:0.5055\n",
      "epoch:122,loss:0.5459\n",
      "epoch:122,loss:1.3303\n",
      "epoch:122,loss:0.4462\n",
      "epoch:122,loss:1.0935\n",
      "epoch:122,loss:0.7306\n",
      "epoch:122,loss:1.3940\n",
      "epoch:122,loss:1.4181\n",
      "epoch:122,loss:0.3680\n",
      "epoch:122,loss:0.9827\n",
      "epoch:122,loss:1.4297\n",
      "epoch:122,loss:1.1473\n",
      "epoch:122,loss:1.4851\n",
      "epoch:122,loss:0.3637\n",
      "epoch:122,loss:1.3584\n",
      "epoch:122,loss:0.6534\n",
      "epoch:122,loss:1.2079\n",
      "epoch:122,loss:0.4728\n",
      "epoch:122,loss:2.2661\n",
      "epoch:122,loss:0.2351\n",
      "epoch:122,loss:0.9911\n",
      "epoch:122,loss:0.1209\n",
      "epoch:122,loss:0.8463\n",
      "epoch:122,loss:1.1872\n",
      "epoch:122,loss:0.7499\n",
      "epoch:122,loss:1.3055\n",
      "epoch:122,loss:0.2839\n",
      "epoch:122,loss:0.3552\n",
      "epoch:122,loss:0.7980\n",
      "epoch:122,loss:0.2260\n",
      "epoch:122,loss:0.3324\n",
      "epoch:122,loss:0.7360\n",
      "============================================\n",
      "第122个epoch的识别准确率为：73%\n",
      "epoch:123,loss:0.8195\n",
      "epoch:123,loss:0.1796\n",
      "epoch:123,loss:0.5007\n",
      "epoch:123,loss:0.5564\n",
      "epoch:123,loss:0.5475\n",
      "epoch:123,loss:0.9120\n",
      "epoch:123,loss:0.2101\n",
      "epoch:123,loss:1.1402\n",
      "epoch:123,loss:0.9457\n",
      "epoch:123,loss:0.1230\n",
      "epoch:123,loss:0.3702\n",
      "epoch:123,loss:0.4982\n",
      "epoch:123,loss:0.3587\n",
      "epoch:123,loss:0.9015\n",
      "epoch:123,loss:0.4507\n",
      "epoch:123,loss:0.8320\n",
      "epoch:123,loss:0.3206\n",
      "epoch:123,loss:0.9636\n",
      "epoch:123,loss:0.8038\n",
      "epoch:123,loss:0.4612\n",
      "epoch:123,loss:1.5020\n",
      "epoch:123,loss:0.9517\n",
      "epoch:123,loss:1.9723\n",
      "epoch:123,loss:0.7679\n",
      "epoch:123,loss:1.1381\n",
      "epoch:123,loss:0.4386\n",
      "epoch:123,loss:0.4997\n",
      "epoch:123,loss:0.6403\n",
      "epoch:123,loss:0.9416\n",
      "epoch:123,loss:0.6026\n",
      "epoch:123,loss:0.6268\n",
      "epoch:123,loss:0.2640\n",
      "epoch:123,loss:0.6316\n",
      "epoch:123,loss:0.8816\n",
      "epoch:123,loss:1.0338\n",
      "epoch:123,loss:0.3071\n",
      "epoch:123,loss:0.9232\n",
      "epoch:123,loss:1.2107\n",
      "epoch:123,loss:0.2407\n",
      "epoch:123,loss:1.6098\n",
      "epoch:123,loss:0.9488\n",
      "epoch:123,loss:1.0437\n",
      "epoch:123,loss:1.0079\n",
      "epoch:123,loss:0.2835\n",
      "epoch:123,loss:1.1112\n",
      "epoch:123,loss:1.2453\n",
      "epoch:123,loss:0.6433\n",
      "epoch:123,loss:1.8044\n",
      "epoch:123,loss:1.7323\n",
      "epoch:123,loss:0.9786\n",
      "epoch:123,loss:0.8870\n",
      "epoch:123,loss:0.9289\n",
      "epoch:123,loss:1.2377\n",
      "epoch:123,loss:0.2741\n",
      "epoch:123,loss:1.3338\n",
      "epoch:123,loss:1.2784\n",
      "epoch:123,loss:1.4155\n",
      "epoch:123,loss:1.0693\n",
      "epoch:123,loss:1.3995\n",
      "epoch:123,loss:0.8303\n",
      "============================================\n",
      "第123个epoch的识别准确率为：72%\n",
      "epoch:124,loss:1.2675\n",
      "epoch:124,loss:1.7726\n",
      "epoch:124,loss:1.1507\n",
      "epoch:124,loss:0.3315\n",
      "epoch:124,loss:0.5255\n",
      "epoch:124,loss:0.2533\n",
      "epoch:124,loss:0.5990\n",
      "epoch:124,loss:0.7166\n",
      "epoch:124,loss:0.6016\n",
      "epoch:124,loss:0.2187\n",
      "epoch:124,loss:2.3437\n",
      "epoch:124,loss:0.4039\n",
      "epoch:124,loss:0.9920\n",
      "epoch:124,loss:0.3675\n",
      "epoch:124,loss:1.3215\n",
      "epoch:124,loss:0.7368\n",
      "epoch:124,loss:0.5059\n",
      "epoch:124,loss:0.2995\n",
      "epoch:124,loss:0.6751\n",
      "epoch:124,loss:0.2240\n",
      "epoch:124,loss:0.1173\n",
      "epoch:124,loss:1.6821\n",
      "epoch:124,loss:2.3242\n",
      "epoch:124,loss:0.2306\n",
      "epoch:124,loss:0.9333\n",
      "epoch:124,loss:0.7591\n",
      "epoch:124,loss:1.1345\n",
      "epoch:124,loss:0.8920\n",
      "epoch:124,loss:0.4753\n",
      "epoch:124,loss:1.4508\n",
      "epoch:124,loss:0.2137\n",
      "epoch:124,loss:1.6220\n",
      "epoch:124,loss:0.4173\n",
      "epoch:124,loss:0.4277\n",
      "epoch:124,loss:0.4826\n",
      "epoch:124,loss:0.6951\n",
      "epoch:124,loss:0.5910\n",
      "epoch:124,loss:0.7499\n",
      "epoch:124,loss:0.7180\n",
      "epoch:124,loss:0.7621\n",
      "epoch:124,loss:0.8973\n",
      "epoch:124,loss:1.2437\n",
      "epoch:124,loss:1.2772\n",
      "epoch:124,loss:0.1131\n",
      "epoch:124,loss:1.6098\n",
      "epoch:124,loss:1.1353\n",
      "epoch:124,loss:0.4848\n",
      "epoch:124,loss:1.2107\n",
      "epoch:124,loss:0.2877\n",
      "epoch:124,loss:0.6200\n",
      "epoch:124,loss:0.3345\n",
      "epoch:124,loss:0.3003\n",
      "epoch:124,loss:0.4222\n",
      "epoch:124,loss:0.2199\n",
      "epoch:124,loss:1.2935\n",
      "epoch:124,loss:1.0403\n",
      "epoch:124,loss:0.6642\n",
      "epoch:124,loss:0.7053\n",
      "epoch:124,loss:0.5795\n",
      "epoch:124,loss:1.8662\n",
      "============================================\n",
      "第124个epoch的识别准确率为：73%\n",
      "epoch:125,loss:0.4929\n",
      "epoch:125,loss:0.3821\n",
      "epoch:125,loss:0.4865\n",
      "epoch:125,loss:0.6379\n",
      "epoch:125,loss:0.2476\n",
      "epoch:125,loss:0.5758\n",
      "epoch:125,loss:1.1794\n",
      "epoch:125,loss:0.2611\n",
      "epoch:125,loss:0.7863\n",
      "epoch:125,loss:0.9947\n",
      "epoch:125,loss:1.2094\n",
      "epoch:125,loss:0.6443\n",
      "epoch:125,loss:0.7785\n",
      "epoch:125,loss:0.6738\n",
      "epoch:125,loss:0.4235\n",
      "epoch:125,loss:0.0541\n",
      "epoch:125,loss:0.1557\n",
      "epoch:125,loss:0.1855\n",
      "epoch:125,loss:1.9268\n",
      "epoch:125,loss:0.2656\n",
      "epoch:125,loss:1.2090\n",
      "epoch:125,loss:0.3523\n",
      "epoch:125,loss:0.7604\n",
      "epoch:125,loss:1.0847\n",
      "epoch:125,loss:0.4591\n",
      "epoch:125,loss:1.0587\n",
      "epoch:125,loss:1.6025\n",
      "epoch:125,loss:0.5825\n",
      "epoch:125,loss:0.8610\n",
      "epoch:125,loss:1.4892\n",
      "epoch:125,loss:0.4391\n",
      "epoch:125,loss:0.6026\n",
      "epoch:125,loss:0.6276\n",
      "epoch:125,loss:0.1407\n",
      "epoch:125,loss:1.0100\n",
      "epoch:125,loss:0.8486\n",
      "epoch:125,loss:1.4361\n",
      "epoch:125,loss:0.3641\n",
      "epoch:125,loss:1.1182\n",
      "epoch:125,loss:0.0701\n",
      "epoch:125,loss:1.6132\n",
      "epoch:125,loss:0.2594\n",
      "epoch:125,loss:0.5911\n",
      "epoch:125,loss:0.9908\n",
      "epoch:125,loss:0.8219\n",
      "epoch:125,loss:0.3266\n",
      "epoch:125,loss:1.1686\n",
      "epoch:125,loss:0.9333\n",
      "epoch:125,loss:0.9320\n",
      "epoch:125,loss:0.3478\n",
      "epoch:125,loss:1.3509\n",
      "epoch:125,loss:1.3674\n",
      "epoch:125,loss:0.2068\n",
      "epoch:125,loss:0.5640\n",
      "epoch:125,loss:0.0631\n",
      "epoch:125,loss:0.7042\n",
      "epoch:125,loss:0.8268\n",
      "epoch:125,loss:1.0770\n",
      "epoch:125,loss:1.6826\n",
      "epoch:125,loss:1.9981\n",
      "============================================\n",
      "第125个epoch的识别准确率为：74%\n",
      "epoch:126,loss:0.1929\n",
      "epoch:126,loss:0.2448\n",
      "epoch:126,loss:0.2700\n",
      "epoch:126,loss:0.3630\n",
      "epoch:126,loss:0.3894\n",
      "epoch:126,loss:0.8105\n",
      "epoch:126,loss:0.6662\n",
      "epoch:126,loss:1.9257\n",
      "epoch:126,loss:0.6195\n",
      "epoch:126,loss:1.1351\n",
      "epoch:126,loss:1.2470\n",
      "epoch:126,loss:1.0239\n",
      "epoch:126,loss:1.4122\n",
      "epoch:126,loss:0.1919\n",
      "epoch:126,loss:1.1397\n",
      "epoch:126,loss:1.4783\n",
      "epoch:126,loss:0.1527\n",
      "epoch:126,loss:0.8733\n",
      "epoch:126,loss:0.4242\n",
      "epoch:126,loss:0.5190\n",
      "epoch:126,loss:0.0904\n",
      "epoch:126,loss:0.7938\n",
      "epoch:126,loss:0.3519\n",
      "epoch:126,loss:0.8086\n",
      "epoch:126,loss:0.1561\n",
      "epoch:126,loss:0.5662\n",
      "epoch:126,loss:0.8754\n",
      "epoch:126,loss:0.4324\n",
      "epoch:126,loss:1.8008\n",
      "epoch:126,loss:0.5572\n",
      "epoch:126,loss:1.2114\n",
      "epoch:126,loss:0.4881\n",
      "epoch:126,loss:0.1980\n",
      "epoch:126,loss:1.3716\n",
      "epoch:126,loss:0.9204\n",
      "epoch:126,loss:0.4439\n",
      "epoch:126,loss:1.3717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:126,loss:0.9185\n",
      "epoch:126,loss:0.3749\n",
      "epoch:126,loss:1.8533\n",
      "epoch:126,loss:1.5399\n",
      "epoch:126,loss:0.8251\n",
      "epoch:126,loss:0.7129\n",
      "epoch:126,loss:1.6202\n",
      "epoch:126,loss:2.6825\n",
      "epoch:126,loss:1.2916\n",
      "epoch:126,loss:0.3789\n",
      "epoch:126,loss:1.7393\n",
      "epoch:126,loss:0.3409\n",
      "epoch:126,loss:0.2881\n",
      "epoch:126,loss:0.5145\n",
      "epoch:126,loss:0.1325\n",
      "epoch:126,loss:1.3012\n",
      "epoch:126,loss:2.3742\n",
      "epoch:126,loss:0.2039\n",
      "epoch:126,loss:0.3447\n",
      "epoch:126,loss:2.6622\n",
      "epoch:126,loss:1.1106\n",
      "epoch:126,loss:0.5124\n",
      "epoch:126,loss:1.4434\n",
      "============================================\n",
      "第126个epoch的识别准确率为：74%\n",
      "epoch:127,loss:1.2288\n",
      "epoch:127,loss:0.1131\n",
      "epoch:127,loss:0.3733\n",
      "epoch:127,loss:0.6007\n",
      "epoch:127,loss:1.0476\n",
      "epoch:127,loss:0.9578\n",
      "epoch:127,loss:0.6813\n",
      "epoch:127,loss:0.0841\n",
      "epoch:127,loss:0.6578\n",
      "epoch:127,loss:0.1477\n",
      "epoch:127,loss:0.4044\n",
      "epoch:127,loss:0.1279\n",
      "epoch:127,loss:1.1980\n",
      "epoch:127,loss:1.0465\n",
      "epoch:127,loss:0.7070\n",
      "epoch:127,loss:0.3816\n",
      "epoch:127,loss:1.1318\n",
      "epoch:127,loss:0.3059\n",
      "epoch:127,loss:0.2704\n",
      "epoch:127,loss:1.7121\n",
      "epoch:127,loss:0.6215\n",
      "epoch:127,loss:0.2601\n",
      "epoch:127,loss:0.8672\n",
      "epoch:127,loss:0.8010\n",
      "epoch:127,loss:1.0296\n",
      "epoch:127,loss:0.7060\n",
      "epoch:127,loss:1.6345\n",
      "epoch:127,loss:0.8401\n",
      "epoch:127,loss:3.0276\n",
      "epoch:127,loss:0.1771\n",
      "epoch:127,loss:1.6607\n",
      "epoch:127,loss:0.6457\n",
      "epoch:127,loss:0.4227\n",
      "epoch:127,loss:1.3618\n",
      "epoch:127,loss:0.7623\n",
      "epoch:127,loss:0.5265\n",
      "epoch:127,loss:0.4178\n",
      "epoch:127,loss:1.3904\n",
      "epoch:127,loss:0.4411\n",
      "epoch:127,loss:1.5360\n",
      "epoch:127,loss:0.6235\n",
      "epoch:127,loss:0.2001\n",
      "epoch:127,loss:0.7925\n",
      "epoch:127,loss:1.5018\n",
      "epoch:127,loss:0.3682\n",
      "epoch:127,loss:0.4558\n",
      "epoch:127,loss:0.8870\n",
      "epoch:127,loss:0.0210\n",
      "epoch:127,loss:1.1416\n",
      "epoch:127,loss:1.4454\n",
      "epoch:127,loss:1.5694\n",
      "epoch:127,loss:0.9071\n",
      "epoch:127,loss:0.8852\n",
      "epoch:127,loss:1.3265\n",
      "epoch:127,loss:0.6683\n",
      "epoch:127,loss:1.7529\n",
      "epoch:127,loss:0.5540\n",
      "epoch:127,loss:2.1471\n",
      "epoch:127,loss:1.0210\n",
      "epoch:127,loss:0.7052\n",
      "============================================\n",
      "第127个epoch的识别准确率为：73%\n",
      "epoch:128,loss:0.6574\n",
      "epoch:128,loss:0.9259\n",
      "epoch:128,loss:1.3661\n",
      "epoch:128,loss:0.5780\n",
      "epoch:128,loss:0.8043\n",
      "epoch:128,loss:2.9359\n",
      "epoch:128,loss:0.2809\n",
      "epoch:128,loss:0.7675\n",
      "epoch:128,loss:0.4243\n",
      "epoch:128,loss:0.4299\n",
      "epoch:128,loss:1.0099\n",
      "epoch:128,loss:0.1273\n",
      "epoch:128,loss:2.8278\n",
      "epoch:128,loss:0.2138\n",
      "epoch:128,loss:0.7303\n",
      "epoch:128,loss:0.7361\n",
      "epoch:128,loss:0.2695\n",
      "epoch:128,loss:0.2931\n",
      "epoch:128,loss:0.5689\n",
      "epoch:128,loss:2.1477\n",
      "epoch:128,loss:0.5747\n",
      "epoch:128,loss:1.2655\n",
      "epoch:128,loss:0.2450\n",
      "epoch:128,loss:1.2016\n",
      "epoch:128,loss:0.6888\n",
      "epoch:128,loss:0.2617\n",
      "epoch:128,loss:0.1614\n",
      "epoch:128,loss:0.6992\n",
      "epoch:128,loss:0.2781\n",
      "epoch:128,loss:1.5824\n",
      "epoch:128,loss:0.2851\n",
      "epoch:128,loss:0.5033\n",
      "epoch:128,loss:0.1286\n",
      "epoch:128,loss:0.8183\n",
      "epoch:128,loss:2.1852\n",
      "epoch:128,loss:0.7927\n",
      "epoch:128,loss:0.7311\n",
      "epoch:128,loss:0.1786\n",
      "epoch:128,loss:0.3432\n",
      "epoch:128,loss:0.6227\n",
      "epoch:128,loss:1.5754\n",
      "epoch:128,loss:2.0014\n",
      "epoch:128,loss:0.3578\n",
      "epoch:128,loss:0.7924\n",
      "epoch:128,loss:1.9341\n",
      "epoch:128,loss:0.4894\n",
      "epoch:128,loss:0.6860\n",
      "epoch:128,loss:0.8078\n",
      "epoch:128,loss:0.5035\n",
      "epoch:128,loss:1.2137\n",
      "epoch:128,loss:0.6622\n",
      "epoch:128,loss:0.8975\n",
      "epoch:128,loss:0.9648\n",
      "epoch:128,loss:0.2794\n",
      "epoch:128,loss:0.4668\n",
      "epoch:128,loss:0.3702\n",
      "epoch:128,loss:0.8295\n",
      "epoch:128,loss:0.2442\n",
      "epoch:128,loss:0.7382\n",
      "epoch:128,loss:0.5162\n",
      "============================================\n",
      "第128个epoch的识别准确率为：73%\n",
      "epoch:129,loss:0.2905\n",
      "epoch:129,loss:0.1574\n",
      "epoch:129,loss:0.7366\n",
      "epoch:129,loss:0.9380\n",
      "epoch:129,loss:1.0838\n",
      "epoch:129,loss:0.4126\n",
      "epoch:129,loss:0.6744\n",
      "epoch:129,loss:0.5216\n",
      "epoch:129,loss:0.0522\n",
      "epoch:129,loss:1.3807\n",
      "epoch:129,loss:1.3460\n",
      "epoch:129,loss:0.2545\n",
      "epoch:129,loss:1.9702\n",
      "epoch:129,loss:0.9713\n",
      "epoch:129,loss:0.7124\n",
      "epoch:129,loss:0.7927\n",
      "epoch:129,loss:1.5440\n",
      "epoch:129,loss:0.2746\n",
      "epoch:129,loss:0.5457\n",
      "epoch:129,loss:0.2206\n",
      "epoch:129,loss:0.1533\n",
      "epoch:129,loss:0.3154\n",
      "epoch:129,loss:0.2560\n",
      "epoch:129,loss:0.3695\n",
      "epoch:129,loss:0.9070\n",
      "epoch:129,loss:1.7135\n",
      "epoch:129,loss:1.5868\n",
      "epoch:129,loss:1.7638\n",
      "epoch:129,loss:0.7253\n",
      "epoch:129,loss:1.1717\n",
      "epoch:129,loss:1.1450\n",
      "epoch:129,loss:0.1895\n",
      "epoch:129,loss:0.1984\n",
      "epoch:129,loss:0.7478\n",
      "epoch:129,loss:0.2821\n",
      "epoch:129,loss:0.7941\n",
      "epoch:129,loss:0.5151\n",
      "epoch:129,loss:0.2614\n",
      "epoch:129,loss:0.4236\n",
      "epoch:129,loss:1.3073\n",
      "epoch:129,loss:0.4613\n",
      "epoch:129,loss:0.2010\n",
      "epoch:129,loss:1.7084\n",
      "epoch:129,loss:1.1336\n",
      "epoch:129,loss:0.4097\n",
      "epoch:129,loss:0.2742\n",
      "epoch:129,loss:1.4881\n",
      "epoch:129,loss:0.3523\n",
      "epoch:129,loss:0.6163\n",
      "epoch:129,loss:1.3873\n",
      "epoch:129,loss:0.6654\n",
      "epoch:129,loss:1.1433\n",
      "epoch:129,loss:1.7348\n",
      "epoch:129,loss:1.4144\n",
      "epoch:129,loss:0.9940\n",
      "epoch:129,loss:0.2747\n",
      "epoch:129,loss:1.0781\n",
      "epoch:129,loss:0.6477\n",
      "epoch:129,loss:0.2608\n",
      "epoch:129,loss:0.1651\n",
      "============================================\n",
      "第129个epoch的识别准确率为：73%\n",
      "epoch:130,loss:1.0777\n",
      "epoch:130,loss:0.1841\n",
      "epoch:130,loss:0.4813\n",
      "epoch:130,loss:0.3279\n",
      "epoch:130,loss:1.3217\n",
      "epoch:130,loss:0.3100\n",
      "epoch:130,loss:1.5387\n",
      "epoch:130,loss:0.8802\n",
      "epoch:130,loss:0.6696\n",
      "epoch:130,loss:0.8235\n",
      "epoch:130,loss:0.5087\n",
      "epoch:130,loss:1.4229\n",
      "epoch:130,loss:0.7697\n",
      "epoch:130,loss:0.3317\n",
      "epoch:130,loss:0.1609\n",
      "epoch:130,loss:1.5370\n",
      "epoch:130,loss:0.3529\n",
      "epoch:130,loss:0.9335\n",
      "epoch:130,loss:0.7568\n",
      "epoch:130,loss:0.3507\n",
      "epoch:130,loss:0.2958\n",
      "epoch:130,loss:0.5489\n",
      "epoch:130,loss:0.4865\n",
      "epoch:130,loss:0.9413\n",
      "epoch:130,loss:3.3188\n",
      "epoch:130,loss:0.8088\n",
      "epoch:130,loss:0.5155\n",
      "epoch:130,loss:1.5444\n",
      "epoch:130,loss:0.3470\n",
      "epoch:130,loss:0.2789\n",
      "epoch:130,loss:0.9672\n",
      "epoch:130,loss:0.6354\n",
      "epoch:130,loss:1.1097\n",
      "epoch:130,loss:1.5596\n",
      "epoch:130,loss:0.4306\n",
      "epoch:130,loss:0.2384\n",
      "epoch:130,loss:1.8902\n",
      "epoch:130,loss:0.4387\n",
      "epoch:130,loss:0.7154\n",
      "epoch:130,loss:1.1579\n",
      "epoch:130,loss:1.1912\n",
      "epoch:130,loss:0.6073\n",
      "epoch:130,loss:0.5924\n",
      "epoch:130,loss:0.2023\n",
      "epoch:130,loss:0.6781\n",
      "epoch:130,loss:0.3504\n",
      "epoch:130,loss:0.2481\n",
      "epoch:130,loss:0.9352\n",
      "epoch:130,loss:0.6921\n",
      "epoch:130,loss:0.5517\n",
      "epoch:130,loss:0.2985\n",
      "epoch:130,loss:1.1180\n",
      "epoch:130,loss:0.6762\n",
      "epoch:130,loss:0.6670\n",
      "epoch:130,loss:0.5424\n",
      "epoch:130,loss:2.4558\n",
      "epoch:130,loss:0.7458\n",
      "epoch:130,loss:1.6079\n",
      "epoch:130,loss:0.2770\n",
      "epoch:130,loss:0.2567\n",
      "============================================\n",
      "第130个epoch的识别准确率为：73%\n",
      "epoch:131,loss:1.5397\n",
      "epoch:131,loss:0.7985\n",
      "epoch:131,loss:1.6541\n",
      "epoch:131,loss:1.4267\n",
      "epoch:131,loss:0.1647\n",
      "epoch:131,loss:0.5889\n",
      "epoch:131,loss:1.1991\n",
      "epoch:131,loss:0.6976\n",
      "epoch:131,loss:0.3520\n",
      "epoch:131,loss:0.6669\n",
      "epoch:131,loss:0.1339\n",
      "epoch:131,loss:0.4748\n",
      "epoch:131,loss:0.7665\n",
      "epoch:131,loss:0.0483\n",
      "epoch:131,loss:0.7566\n",
      "epoch:131,loss:2.2327\n",
      "epoch:131,loss:0.0784\n",
      "epoch:131,loss:2.1780\n",
      "epoch:131,loss:0.8853\n",
      "epoch:131,loss:0.6934\n",
      "epoch:131,loss:0.3184\n",
      "epoch:131,loss:0.7979\n",
      "epoch:131,loss:2.6553\n",
      "epoch:131,loss:1.0261\n",
      "epoch:131,loss:0.5102\n",
      "epoch:131,loss:0.2197\n",
      "epoch:131,loss:1.1806\n",
      "epoch:131,loss:1.5596\n",
      "epoch:131,loss:0.3576\n",
      "epoch:131,loss:1.4487\n",
      "epoch:131,loss:0.3439\n",
      "epoch:131,loss:1.0529\n",
      "epoch:131,loss:0.4771\n",
      "epoch:131,loss:1.4279\n",
      "epoch:131,loss:0.7817\n",
      "epoch:131,loss:1.4902\n",
      "epoch:131,loss:0.3205\n",
      "epoch:131,loss:0.3130\n",
      "epoch:131,loss:0.9784\n",
      "epoch:131,loss:0.9726\n",
      "epoch:131,loss:0.6168\n",
      "epoch:131,loss:0.3459\n",
      "epoch:131,loss:0.3117\n",
      "epoch:131,loss:0.9602\n",
      "epoch:131,loss:1.1516\n",
      "epoch:131,loss:0.2379\n",
      "epoch:131,loss:1.0996\n",
      "epoch:131,loss:0.3783\n",
      "epoch:131,loss:0.6978\n",
      "epoch:131,loss:0.1485\n",
      "epoch:131,loss:0.7313\n",
      "epoch:131,loss:1.4940\n",
      "epoch:131,loss:1.0912\n",
      "epoch:131,loss:0.5589\n",
      "epoch:131,loss:0.5502\n",
      "epoch:131,loss:0.9931\n",
      "epoch:131,loss:1.7621\n",
      "epoch:131,loss:1.5223\n",
      "epoch:131,loss:0.9477\n",
      "epoch:131,loss:0.3092\n",
      "============================================\n",
      "第131个epoch的识别准确率为：74%\n",
      "epoch:132,loss:0.0757\n",
      "epoch:132,loss:0.1026\n",
      "epoch:132,loss:0.2166\n",
      "epoch:132,loss:0.7459\n",
      "epoch:132,loss:0.9912\n",
      "epoch:132,loss:0.3614\n",
      "epoch:132,loss:1.3669\n",
      "epoch:132,loss:1.1763\n",
      "epoch:132,loss:0.0367\n",
      "epoch:132,loss:0.9760\n",
      "epoch:132,loss:0.9549\n",
      "epoch:132,loss:0.8741\n",
      "epoch:132,loss:0.0745\n",
      "epoch:132,loss:0.5524\n",
      "epoch:132,loss:0.4942\n",
      "epoch:132,loss:0.8244\n",
      "epoch:132,loss:1.2724\n",
      "epoch:132,loss:0.2643\n",
      "epoch:132,loss:0.5652\n",
      "epoch:132,loss:0.9761\n",
      "epoch:132,loss:0.0315\n",
      "epoch:132,loss:0.8724\n",
      "epoch:132,loss:0.2718\n",
      "epoch:132,loss:0.4847\n",
      "epoch:132,loss:1.2112\n",
      "epoch:132,loss:1.9575\n",
      "epoch:132,loss:1.3841\n",
      "epoch:132,loss:0.5338\n",
      "epoch:132,loss:0.4934\n",
      "epoch:132,loss:1.6313\n",
      "epoch:132,loss:0.6923\n",
      "epoch:132,loss:0.7527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:132,loss:1.0994\n",
      "epoch:132,loss:1.0759\n",
      "epoch:132,loss:0.5123\n",
      "epoch:132,loss:0.1403\n",
      "epoch:132,loss:0.4988\n",
      "epoch:132,loss:1.1629\n",
      "epoch:132,loss:1.2907\n",
      "epoch:132,loss:0.6405\n",
      "epoch:132,loss:0.4611\n",
      "epoch:132,loss:0.7450\n",
      "epoch:132,loss:0.3504\n",
      "epoch:132,loss:1.2368\n",
      "epoch:132,loss:1.1888\n",
      "epoch:132,loss:0.2334\n",
      "epoch:132,loss:0.5644\n",
      "epoch:132,loss:0.7640\n",
      "epoch:132,loss:0.5462\n",
      "epoch:132,loss:0.2981\n",
      "epoch:132,loss:0.8284\n",
      "epoch:132,loss:1.1221\n",
      "epoch:132,loss:1.0384\n",
      "epoch:132,loss:1.0008\n",
      "epoch:132,loss:1.1034\n",
      "epoch:132,loss:0.9587\n",
      "epoch:132,loss:0.6445\n",
      "epoch:132,loss:0.6137\n",
      "epoch:132,loss:0.5627\n",
      "epoch:132,loss:0.9749\n",
      "============================================\n",
      "第132个epoch的识别准确率为：74%\n",
      "epoch:133,loss:0.3287\n",
      "epoch:133,loss:1.0708\n",
      "epoch:133,loss:0.2665\n",
      "epoch:133,loss:0.8588\n",
      "epoch:133,loss:1.2167\n",
      "epoch:133,loss:0.5161\n",
      "epoch:133,loss:0.2499\n",
      "epoch:133,loss:0.4318\n",
      "epoch:133,loss:0.9903\n",
      "epoch:133,loss:1.4718\n",
      "epoch:133,loss:0.4633\n",
      "epoch:133,loss:0.4546\n",
      "epoch:133,loss:0.2261\n",
      "epoch:133,loss:0.4483\n",
      "epoch:133,loss:0.2807\n",
      "epoch:133,loss:0.8743\n",
      "epoch:133,loss:0.3505\n",
      "epoch:133,loss:0.5894\n",
      "epoch:133,loss:0.6150\n",
      "epoch:133,loss:1.1091\n",
      "epoch:133,loss:0.5150\n",
      "epoch:133,loss:1.1315\n",
      "epoch:133,loss:1.8794\n",
      "epoch:133,loss:0.1966\n",
      "epoch:133,loss:0.5114\n",
      "epoch:133,loss:1.2951\n",
      "epoch:133,loss:0.2885\n",
      "epoch:133,loss:0.4587\n",
      "epoch:133,loss:0.3708\n",
      "epoch:133,loss:0.2150\n",
      "epoch:133,loss:0.9617\n",
      "epoch:133,loss:1.5168\n",
      "epoch:133,loss:0.3178\n",
      "epoch:133,loss:0.2407\n",
      "epoch:133,loss:0.1806\n",
      "epoch:133,loss:1.1840\n",
      "epoch:133,loss:0.8462\n",
      "epoch:133,loss:1.2883\n",
      "epoch:133,loss:1.8429\n",
      "epoch:133,loss:0.8742\n",
      "epoch:133,loss:0.9610\n",
      "epoch:133,loss:0.5204\n",
      "epoch:133,loss:0.4869\n",
      "epoch:133,loss:1.0901\n",
      "epoch:133,loss:0.8623\n",
      "epoch:133,loss:0.7730\n",
      "epoch:133,loss:0.3989\n",
      "epoch:133,loss:1.3929\n",
      "epoch:133,loss:0.8351\n",
      "epoch:133,loss:0.9171\n",
      "epoch:133,loss:0.3556\n",
      "epoch:133,loss:0.1031\n",
      "epoch:133,loss:0.4796\n",
      "epoch:133,loss:0.3942\n",
      "epoch:133,loss:0.8845\n",
      "epoch:133,loss:0.1874\n",
      "epoch:133,loss:0.4073\n",
      "epoch:133,loss:0.4077\n",
      "epoch:133,loss:1.4244\n",
      "epoch:133,loss:1.2864\n",
      "============================================\n",
      "准确率由： tensor(0.7454) 上升至： tensor(0.7528) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第133个epoch的识别准确率为：75%\n",
      "epoch:134,loss:1.2657\n",
      "epoch:134,loss:0.3588\n",
      "epoch:134,loss:0.2458\n",
      "epoch:134,loss:0.3950\n",
      "epoch:134,loss:0.2947\n",
      "epoch:134,loss:2.0681\n",
      "epoch:134,loss:0.0419\n",
      "epoch:134,loss:0.4966\n",
      "epoch:134,loss:0.2255\n",
      "epoch:134,loss:0.5356\n",
      "epoch:134,loss:0.6085\n",
      "epoch:134,loss:0.3329\n",
      "epoch:134,loss:0.5139\n",
      "epoch:134,loss:0.4855\n",
      "epoch:134,loss:0.7693\n",
      "epoch:134,loss:0.5811\n",
      "epoch:134,loss:0.0895\n",
      "epoch:134,loss:0.7808\n",
      "epoch:134,loss:0.4705\n",
      "epoch:134,loss:0.4139\n",
      "epoch:134,loss:0.2347\n",
      "epoch:134,loss:1.0402\n",
      "epoch:134,loss:1.3150\n",
      "epoch:134,loss:0.9094\n",
      "epoch:134,loss:1.1810\n",
      "epoch:134,loss:1.0763\n",
      "epoch:134,loss:0.5900\n",
      "epoch:134,loss:0.4167\n",
      "epoch:134,loss:0.1263\n",
      "epoch:134,loss:0.8150\n",
      "epoch:134,loss:1.2860\n",
      "epoch:134,loss:1.6928\n",
      "epoch:134,loss:0.5947\n",
      "epoch:134,loss:1.1000\n",
      "epoch:134,loss:0.3493\n",
      "epoch:134,loss:0.0638\n",
      "epoch:134,loss:0.5173\n",
      "epoch:134,loss:1.2284\n",
      "epoch:134,loss:0.6889\n",
      "epoch:134,loss:1.1336\n",
      "epoch:134,loss:0.2153\n",
      "epoch:134,loss:1.0889\n",
      "epoch:134,loss:0.5748\n",
      "epoch:134,loss:0.1813\n",
      "epoch:134,loss:1.6243\n",
      "epoch:134,loss:0.7887\n",
      "epoch:134,loss:0.2618\n",
      "epoch:134,loss:0.1315\n",
      "epoch:134,loss:0.8619\n",
      "epoch:134,loss:1.4416\n",
      "epoch:134,loss:1.1069\n",
      "epoch:134,loss:0.8885\n",
      "epoch:134,loss:1.3208\n",
      "epoch:134,loss:0.3140\n",
      "epoch:134,loss:0.9228\n",
      "epoch:134,loss:1.3666\n",
      "epoch:134,loss:0.4800\n",
      "epoch:134,loss:0.6994\n",
      "epoch:134,loss:0.3576\n",
      "epoch:134,loss:0.5611\n",
      "============================================\n",
      "第134个epoch的识别准确率为：74%\n",
      "epoch:135,loss:0.3905\n",
      "epoch:135,loss:0.1800\n",
      "epoch:135,loss:0.7977\n",
      "epoch:135,loss:0.4142\n",
      "epoch:135,loss:0.4941\n",
      "epoch:135,loss:1.7910\n",
      "epoch:135,loss:1.2528\n",
      "epoch:135,loss:0.1587\n",
      "epoch:135,loss:0.2813\n",
      "epoch:135,loss:0.0845\n",
      "epoch:135,loss:1.4899\n",
      "epoch:135,loss:1.3968\n",
      "epoch:135,loss:0.2199\n",
      "epoch:135,loss:1.0751\n",
      "epoch:135,loss:0.5598\n",
      "epoch:135,loss:0.5373\n",
      "epoch:135,loss:0.5200\n",
      "epoch:135,loss:0.8567\n",
      "epoch:135,loss:1.0350\n",
      "epoch:135,loss:0.9057\n",
      "epoch:135,loss:0.6824\n",
      "epoch:135,loss:0.4360\n",
      "epoch:135,loss:0.6155\n",
      "epoch:135,loss:0.5956\n",
      "epoch:135,loss:0.1901\n",
      "epoch:135,loss:0.2086\n",
      "epoch:135,loss:0.6319\n",
      "epoch:135,loss:0.5525\n",
      "epoch:135,loss:0.0875\n",
      "epoch:135,loss:0.9691\n",
      "epoch:135,loss:1.8440\n",
      "epoch:135,loss:1.1131\n",
      "epoch:135,loss:0.9361\n",
      "epoch:135,loss:0.5988\n",
      "epoch:135,loss:0.1594\n",
      "epoch:135,loss:0.2645\n",
      "epoch:135,loss:0.8072\n",
      "epoch:135,loss:0.3889\n",
      "epoch:135,loss:1.8571\n",
      "epoch:135,loss:1.3699\n",
      "epoch:135,loss:0.5458\n",
      "epoch:135,loss:0.7084\n",
      "epoch:135,loss:0.8065\n",
      "epoch:135,loss:0.8379\n",
      "epoch:135,loss:0.8401\n",
      "epoch:135,loss:1.2966\n",
      "epoch:135,loss:1.0194\n",
      "epoch:135,loss:0.4713\n",
      "epoch:135,loss:0.8545\n",
      "epoch:135,loss:0.8401\n",
      "epoch:135,loss:0.9787\n",
      "epoch:135,loss:1.1042\n",
      "epoch:135,loss:0.2610\n",
      "epoch:135,loss:1.2551\n",
      "epoch:135,loss:0.4222\n",
      "epoch:135,loss:0.3029\n",
      "epoch:135,loss:0.7108\n",
      "epoch:135,loss:0.7255\n",
      "epoch:135,loss:1.2623\n",
      "epoch:135,loss:0.4232\n",
      "============================================\n",
      "第135个epoch的识别准确率为：72%\n",
      "epoch:136,loss:0.2289\n",
      "epoch:136,loss:0.7959\n",
      "epoch:136,loss:0.4913\n",
      "epoch:136,loss:0.4516\n",
      "epoch:136,loss:0.5744\n",
      "epoch:136,loss:0.9034\n",
      "epoch:136,loss:1.3636\n",
      "epoch:136,loss:1.0731\n",
      "epoch:136,loss:0.1743\n",
      "epoch:136,loss:1.6997\n",
      "epoch:136,loss:0.1283\n",
      "epoch:136,loss:0.1197\n",
      "epoch:136,loss:1.0808\n",
      "epoch:136,loss:0.5124\n",
      "epoch:136,loss:0.6692\n",
      "epoch:136,loss:2.0449\n",
      "epoch:136,loss:0.6339\n",
      "epoch:136,loss:0.1326\n",
      "epoch:136,loss:0.3112\n",
      "epoch:136,loss:0.1489\n",
      "epoch:136,loss:0.1874\n",
      "epoch:136,loss:1.0748\n",
      "epoch:136,loss:0.2605\n",
      "epoch:136,loss:0.5320\n",
      "epoch:136,loss:2.6090\n",
      "epoch:136,loss:0.8447\n",
      "epoch:136,loss:0.6732\n",
      "epoch:136,loss:1.1210\n",
      "epoch:136,loss:0.5373\n",
      "epoch:136,loss:0.8121\n",
      "epoch:136,loss:0.6899\n",
      "epoch:136,loss:1.0331\n",
      "epoch:136,loss:0.4569\n",
      "epoch:136,loss:1.0480\n",
      "epoch:136,loss:0.2628\n",
      "epoch:136,loss:0.3037\n",
      "epoch:136,loss:0.6091\n",
      "epoch:136,loss:2.7295\n",
      "epoch:136,loss:0.7322\n",
      "epoch:136,loss:0.7898\n",
      "epoch:136,loss:1.3972\n",
      "epoch:136,loss:0.6809\n",
      "epoch:136,loss:1.4416\n",
      "epoch:136,loss:0.6635\n",
      "epoch:136,loss:1.7988\n",
      "epoch:136,loss:0.1087\n",
      "epoch:136,loss:0.3602\n",
      "epoch:136,loss:0.0800\n",
      "epoch:136,loss:0.2930\n",
      "epoch:136,loss:0.9076\n",
      "epoch:136,loss:0.0948\n",
      "epoch:136,loss:0.0893\n",
      "epoch:136,loss:0.4969\n",
      "epoch:136,loss:0.4702\n",
      "epoch:136,loss:0.4238\n",
      "epoch:136,loss:1.2239\n",
      "epoch:136,loss:0.5201\n",
      "epoch:136,loss:0.5880\n",
      "epoch:136,loss:0.5446\n",
      "epoch:136,loss:0.4512\n",
      "============================================\n",
      "第136个epoch的识别准确率为：74%\n",
      "epoch:137,loss:0.4052\n",
      "epoch:137,loss:0.1218\n",
      "epoch:137,loss:1.8651\n",
      "epoch:137,loss:1.1494\n",
      "epoch:137,loss:1.6475\n",
      "epoch:137,loss:0.9176\n",
      "epoch:137,loss:1.0726\n",
      "epoch:137,loss:1.0890\n",
      "epoch:137,loss:0.9584\n",
      "epoch:137,loss:0.5324\n",
      "epoch:137,loss:0.2537\n",
      "epoch:137,loss:1.1503\n",
      "epoch:137,loss:0.5031\n",
      "epoch:137,loss:0.4447\n",
      "epoch:137,loss:0.2951\n",
      "epoch:137,loss:0.5788\n",
      "epoch:137,loss:0.1107\n",
      "epoch:137,loss:0.8479\n",
      "epoch:137,loss:0.4134\n",
      "epoch:137,loss:0.3887\n",
      "epoch:137,loss:0.6430\n",
      "epoch:137,loss:0.9796\n",
      "epoch:137,loss:0.6074\n",
      "epoch:137,loss:1.8424\n",
      "epoch:137,loss:0.7304\n",
      "epoch:137,loss:2.3597\n",
      "epoch:137,loss:1.1527\n",
      "epoch:137,loss:0.3334\n",
      "epoch:137,loss:0.9641\n",
      "epoch:137,loss:1.0431\n",
      "epoch:137,loss:0.5853\n",
      "epoch:137,loss:0.5444\n",
      "epoch:137,loss:0.5998\n",
      "epoch:137,loss:0.4978\n",
      "epoch:137,loss:0.1690\n",
      "epoch:137,loss:0.7937\n",
      "epoch:137,loss:1.8889\n",
      "epoch:137,loss:0.3743\n",
      "epoch:137,loss:0.6829\n",
      "epoch:137,loss:0.5333\n",
      "epoch:137,loss:0.8386\n",
      "epoch:137,loss:0.3363\n",
      "epoch:137,loss:0.0987\n",
      "epoch:137,loss:0.2502\n",
      "epoch:137,loss:0.7454\n",
      "epoch:137,loss:0.4372\n",
      "epoch:137,loss:0.3397\n",
      "epoch:137,loss:1.8606\n",
      "epoch:137,loss:1.1972\n",
      "epoch:137,loss:0.1977\n",
      "epoch:137,loss:1.0265\n",
      "epoch:137,loss:0.4040\n",
      "epoch:137,loss:0.4338\n",
      "epoch:137,loss:0.6314\n",
      "epoch:137,loss:0.7779\n",
      "epoch:137,loss:0.4337\n",
      "epoch:137,loss:0.9492\n",
      "epoch:137,loss:0.6428\n",
      "epoch:137,loss:1.1096\n",
      "epoch:137,loss:0.6685\n",
      "============================================\n",
      "第137个epoch的识别准确率为：72%\n",
      "epoch:138,loss:0.9859\n",
      "epoch:138,loss:0.1732\n",
      "epoch:138,loss:0.2363\n",
      "epoch:138,loss:0.8281\n",
      "epoch:138,loss:0.1670\n",
      "epoch:138,loss:0.4789\n",
      "epoch:138,loss:2.0490\n",
      "epoch:138,loss:0.2211\n",
      "epoch:138,loss:0.6632\n",
      "epoch:138,loss:0.9014\n",
      "epoch:138,loss:0.5972\n",
      "epoch:138,loss:0.0348\n",
      "epoch:138,loss:1.2921\n",
      "epoch:138,loss:0.8670\n",
      "epoch:138,loss:0.2528\n",
      "epoch:138,loss:0.4031\n",
      "epoch:138,loss:1.5502\n",
      "epoch:138,loss:0.1664\n",
      "epoch:138,loss:0.2479\n",
      "epoch:138,loss:0.3178\n",
      "epoch:138,loss:2.1695\n",
      "epoch:138,loss:0.6293\n",
      "epoch:138,loss:0.9949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:138,loss:0.6041\n",
      "epoch:138,loss:0.2960\n",
      "epoch:138,loss:0.2860\n",
      "epoch:138,loss:1.4056\n",
      "epoch:138,loss:0.1370\n",
      "epoch:138,loss:1.4805\n",
      "epoch:138,loss:0.5363\n",
      "epoch:138,loss:1.5955\n",
      "epoch:138,loss:1.7541\n",
      "epoch:138,loss:0.1770\n",
      "epoch:138,loss:0.5103\n",
      "epoch:138,loss:1.3866\n",
      "epoch:138,loss:0.7215\n",
      "epoch:138,loss:0.8007\n",
      "epoch:138,loss:0.3397\n",
      "epoch:138,loss:0.4059\n",
      "epoch:138,loss:0.5154\n",
      "epoch:138,loss:0.3582\n",
      "epoch:138,loss:0.8776\n",
      "epoch:138,loss:0.1540\n",
      "epoch:138,loss:1.8589\n",
      "epoch:138,loss:0.5633\n",
      "epoch:138,loss:1.3111\n",
      "epoch:138,loss:0.7042\n",
      "epoch:138,loss:0.1167\n",
      "epoch:138,loss:1.3106\n",
      "epoch:138,loss:0.3897\n",
      "epoch:138,loss:0.8669\n",
      "epoch:138,loss:1.2181\n",
      "epoch:138,loss:1.9058\n",
      "epoch:138,loss:1.2587\n",
      "epoch:138,loss:0.8177\n",
      "epoch:138,loss:0.1771\n",
      "epoch:138,loss:1.2695\n",
      "epoch:138,loss:1.4600\n",
      "epoch:138,loss:0.2673\n",
      "epoch:138,loss:0.9692\n",
      "============================================\n",
      "准确率由： tensor(0.7528) 上升至： tensor(0.7610) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第138个epoch的识别准确率为：76%\n",
      "epoch:139,loss:0.3810\n",
      "epoch:139,loss:0.1994\n",
      "epoch:139,loss:2.0554\n",
      "epoch:139,loss:0.3149\n",
      "epoch:139,loss:0.2155\n",
      "epoch:139,loss:0.9302\n",
      "epoch:139,loss:0.1759\n",
      "epoch:139,loss:0.7733\n",
      "epoch:139,loss:0.8085\n",
      "epoch:139,loss:2.0520\n",
      "epoch:139,loss:0.0677\n",
      "epoch:139,loss:0.6359\n",
      "epoch:139,loss:0.7678\n",
      "epoch:139,loss:0.4174\n",
      "epoch:139,loss:0.1128\n",
      "epoch:139,loss:0.2829\n",
      "epoch:139,loss:0.4826\n",
      "epoch:139,loss:1.6906\n",
      "epoch:139,loss:0.6287\n",
      "epoch:139,loss:1.0741\n",
      "epoch:139,loss:1.5747\n",
      "epoch:139,loss:1.2483\n",
      "epoch:139,loss:1.1425\n",
      "epoch:139,loss:0.6111\n",
      "epoch:139,loss:0.5047\n",
      "epoch:139,loss:0.2785\n",
      "epoch:139,loss:0.6070\n",
      "epoch:139,loss:0.4581\n",
      "epoch:139,loss:0.6014\n",
      "epoch:139,loss:1.4133\n",
      "epoch:139,loss:1.8698\n",
      "epoch:139,loss:0.6115\n",
      "epoch:139,loss:0.5876\n",
      "epoch:139,loss:0.4420\n",
      "epoch:139,loss:0.9855\n",
      "epoch:139,loss:0.0121\n",
      "epoch:139,loss:0.2892\n",
      "epoch:139,loss:0.4761\n",
      "epoch:139,loss:1.1040\n",
      "epoch:139,loss:0.4479\n",
      "epoch:139,loss:0.8900\n",
      "epoch:139,loss:0.7046\n",
      "epoch:139,loss:0.2966\n",
      "epoch:139,loss:0.4512\n",
      "epoch:139,loss:0.5275\n",
      "epoch:139,loss:0.9161\n",
      "epoch:139,loss:0.3677\n",
      "epoch:139,loss:0.2430\n",
      "epoch:139,loss:0.9204\n",
      "epoch:139,loss:0.4289\n",
      "epoch:139,loss:0.8320\n",
      "epoch:139,loss:1.7595\n",
      "epoch:139,loss:0.1683\n",
      "epoch:139,loss:0.5284\n",
      "epoch:139,loss:1.4604\n",
      "epoch:139,loss:0.3107\n",
      "epoch:139,loss:0.7202\n",
      "epoch:139,loss:1.0819\n",
      "epoch:139,loss:0.5463\n",
      "epoch:139,loss:1.1220\n",
      "============================================\n",
      "准确率由： tensor(0.7610) 上升至： tensor(0.7794) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第139个epoch的识别准确率为：77%\n",
      "epoch:140,loss:0.0849\n",
      "epoch:140,loss:0.1888\n",
      "epoch:140,loss:1.0261\n",
      "epoch:140,loss:0.2388\n",
      "epoch:140,loss:1.3120\n",
      "epoch:140,loss:0.9310\n",
      "epoch:140,loss:0.2930\n",
      "epoch:140,loss:0.2055\n",
      "epoch:140,loss:0.7281\n",
      "epoch:140,loss:0.5365\n",
      "epoch:140,loss:0.1826\n",
      "epoch:140,loss:0.3097\n",
      "epoch:140,loss:0.5348\n",
      "epoch:140,loss:0.3283\n",
      "epoch:140,loss:0.2225\n",
      "epoch:140,loss:0.3929\n",
      "epoch:140,loss:1.4401\n",
      "epoch:140,loss:0.9393\n",
      "epoch:140,loss:1.2329\n",
      "epoch:140,loss:0.1556\n",
      "epoch:140,loss:0.4455\n",
      "epoch:140,loss:0.0661\n",
      "epoch:140,loss:1.0997\n",
      "epoch:140,loss:0.5910\n",
      "epoch:140,loss:0.8925\n",
      "epoch:140,loss:0.4844\n",
      "epoch:140,loss:0.8678\n",
      "epoch:140,loss:0.1417\n",
      "epoch:140,loss:0.2595\n",
      "epoch:140,loss:1.0299\n",
      "epoch:140,loss:0.1552\n",
      "epoch:140,loss:0.1849\n",
      "epoch:140,loss:1.2340\n",
      "epoch:140,loss:2.1007\n",
      "epoch:140,loss:0.6510\n",
      "epoch:140,loss:0.5895\n",
      "epoch:140,loss:0.7051\n",
      "epoch:140,loss:0.2841\n",
      "epoch:140,loss:0.4559\n",
      "epoch:140,loss:0.8831\n",
      "epoch:140,loss:0.4251\n",
      "epoch:140,loss:0.4895\n",
      "epoch:140,loss:0.4701\n",
      "epoch:140,loss:0.9142\n",
      "epoch:140,loss:0.4336\n",
      "epoch:140,loss:0.5634\n",
      "epoch:140,loss:1.0738\n",
      "epoch:140,loss:0.4249\n",
      "epoch:140,loss:0.4542\n",
      "epoch:140,loss:1.5300\n",
      "epoch:140,loss:0.3261\n",
      "epoch:140,loss:0.5248\n",
      "epoch:140,loss:1.4034\n",
      "epoch:140,loss:1.3126\n",
      "epoch:140,loss:0.9745\n",
      "epoch:140,loss:0.6841\n",
      "epoch:140,loss:0.8275\n",
      "epoch:140,loss:0.2715\n",
      "epoch:140,loss:0.1672\n",
      "epoch:140,loss:0.5661\n",
      "============================================\n",
      "准确率由： tensor(0.7794) 上升至： tensor(0.7904) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第140个epoch的识别准确率为：79%\n",
      "epoch:141,loss:1.0593\n",
      "epoch:141,loss:0.5915\n",
      "epoch:141,loss:0.2123\n",
      "epoch:141,loss:0.1452\n",
      "epoch:141,loss:0.0383\n",
      "epoch:141,loss:2.2563\n",
      "epoch:141,loss:0.8572\n",
      "epoch:141,loss:2.8612\n",
      "epoch:141,loss:0.7067\n",
      "epoch:141,loss:0.2741\n",
      "epoch:141,loss:0.4475\n",
      "epoch:141,loss:0.3636\n",
      "epoch:141,loss:0.7206\n",
      "epoch:141,loss:0.6679\n",
      "epoch:141,loss:0.7115\n",
      "epoch:141,loss:0.2777\n",
      "epoch:141,loss:0.8129\n",
      "epoch:141,loss:1.1025\n",
      "epoch:141,loss:1.5362\n",
      "epoch:141,loss:0.7777\n",
      "epoch:141,loss:0.6368\n",
      "epoch:141,loss:0.6276\n",
      "epoch:141,loss:1.1985\n",
      "epoch:141,loss:1.3901\n",
      "epoch:141,loss:0.9518\n",
      "epoch:141,loss:1.8963\n",
      "epoch:141,loss:0.4619\n",
      "epoch:141,loss:0.2757\n",
      "epoch:141,loss:1.0587\n",
      "epoch:141,loss:0.5301\n",
      "epoch:141,loss:0.0615\n",
      "epoch:141,loss:1.5519\n",
      "epoch:141,loss:0.9281\n",
      "epoch:141,loss:0.7307\n",
      "epoch:141,loss:0.8904\n",
      "epoch:141,loss:1.0968\n",
      "epoch:141,loss:0.7726\n",
      "epoch:141,loss:1.6948\n",
      "epoch:141,loss:0.2886\n",
      "epoch:141,loss:2.1260\n",
      "epoch:141,loss:0.7938\n",
      "epoch:141,loss:0.1389\n",
      "epoch:141,loss:1.0051\n",
      "epoch:141,loss:0.8034\n",
      "epoch:141,loss:0.4965\n",
      "epoch:141,loss:0.3183\n",
      "epoch:141,loss:0.4454\n",
      "epoch:141,loss:0.2806\n",
      "epoch:141,loss:0.2647\n",
      "epoch:141,loss:0.9147\n",
      "epoch:141,loss:0.1543\n",
      "epoch:141,loss:0.4988\n",
      "epoch:141,loss:0.1590\n",
      "epoch:141,loss:1.1229\n",
      "epoch:141,loss:0.7337\n",
      "epoch:141,loss:0.2065\n",
      "epoch:141,loss:0.4058\n",
      "epoch:141,loss:1.5980\n",
      "epoch:141,loss:1.2442\n",
      "epoch:141,loss:0.5544\n",
      "============================================\n",
      "第141个epoch的识别准确率为：77%\n",
      "epoch:142,loss:0.3474\n",
      "epoch:142,loss:0.4218\n",
      "epoch:142,loss:0.0927\n",
      "epoch:142,loss:0.3696\n",
      "epoch:142,loss:0.3101\n",
      "epoch:142,loss:0.3143\n",
      "epoch:142,loss:0.5662\n",
      "epoch:142,loss:0.7348\n",
      "epoch:142,loss:0.4098\n",
      "epoch:142,loss:0.8169\n",
      "epoch:142,loss:0.5317\n",
      "epoch:142,loss:0.7588\n",
      "epoch:142,loss:0.1129\n",
      "epoch:142,loss:0.6975\n",
      "epoch:142,loss:0.6301\n",
      "epoch:142,loss:0.5641\n",
      "epoch:142,loss:3.0391\n",
      "epoch:142,loss:1.1818\n",
      "epoch:142,loss:0.8422\n",
      "epoch:142,loss:0.9378\n",
      "epoch:142,loss:1.3645\n",
      "epoch:142,loss:0.3879\n",
      "epoch:142,loss:0.1328\n",
      "epoch:142,loss:0.6319\n",
      "epoch:142,loss:0.7730\n",
      "epoch:142,loss:0.4719\n",
      "epoch:142,loss:0.5610\n",
      "epoch:142,loss:0.5940\n",
      "epoch:142,loss:0.6153\n",
      "epoch:142,loss:0.2811\n",
      "epoch:142,loss:0.4756\n",
      "epoch:142,loss:1.0973\n",
      "epoch:142,loss:0.9747\n",
      "epoch:142,loss:0.5851\n",
      "epoch:142,loss:0.0712\n",
      "epoch:142,loss:0.1782\n",
      "epoch:142,loss:1.4770\n",
      "epoch:142,loss:0.7894\n",
      "epoch:142,loss:0.3803\n",
      "epoch:142,loss:0.1186\n",
      "epoch:142,loss:0.5036\n",
      "epoch:142,loss:0.9594\n",
      "epoch:142,loss:0.1810\n",
      "epoch:142,loss:0.1194\n",
      "epoch:142,loss:0.7910\n",
      "epoch:142,loss:0.6192\n",
      "epoch:142,loss:0.4021\n",
      "epoch:142,loss:0.2814\n",
      "epoch:142,loss:1.8147\n",
      "epoch:142,loss:0.7221\n",
      "epoch:142,loss:0.8907\n",
      "epoch:142,loss:1.1000\n",
      "epoch:142,loss:0.6515\n",
      "epoch:142,loss:0.9024\n",
      "epoch:142,loss:0.1215\n",
      "epoch:142,loss:0.8450\n",
      "epoch:142,loss:0.1490\n",
      "epoch:142,loss:1.2240\n",
      "epoch:142,loss:0.0775\n",
      "epoch:142,loss:0.0609\n",
      "============================================\n",
      "第142个epoch的识别准确率为：75%\n",
      "epoch:143,loss:1.3286\n",
      "epoch:143,loss:0.9664\n",
      "epoch:143,loss:0.7630\n",
      "epoch:143,loss:0.4078\n",
      "epoch:143,loss:1.6621\n",
      "epoch:143,loss:1.0043\n",
      "epoch:143,loss:0.3412\n",
      "epoch:143,loss:1.0182\n",
      "epoch:143,loss:0.2949\n",
      "epoch:143,loss:0.3428\n",
      "epoch:143,loss:0.7943\n",
      "epoch:143,loss:0.0754\n",
      "epoch:143,loss:0.6241\n",
      "epoch:143,loss:1.0611\n",
      "epoch:143,loss:0.8477\n",
      "epoch:143,loss:0.0140\n",
      "epoch:143,loss:0.1737\n",
      "epoch:143,loss:0.4735\n",
      "epoch:143,loss:0.2885\n",
      "epoch:143,loss:0.1969\n",
      "epoch:143,loss:0.3491\n",
      "epoch:143,loss:0.2115\n",
      "epoch:143,loss:0.7462\n",
      "epoch:143,loss:0.8145\n",
      "epoch:143,loss:1.8922\n",
      "epoch:143,loss:0.9412\n",
      "epoch:143,loss:0.1291\n",
      "epoch:143,loss:0.1338\n",
      "epoch:143,loss:0.7382\n",
      "epoch:143,loss:0.7906\n",
      "epoch:143,loss:0.3436\n",
      "epoch:143,loss:0.6990\n",
      "epoch:143,loss:0.1366\n",
      "epoch:143,loss:0.3401\n",
      "epoch:143,loss:0.3958\n",
      "epoch:143,loss:0.5864\n",
      "epoch:143,loss:0.1104\n",
      "epoch:143,loss:1.3249\n",
      "epoch:143,loss:0.4776\n",
      "epoch:143,loss:0.3473\n",
      "epoch:143,loss:1.7454\n",
      "epoch:143,loss:1.8596\n",
      "epoch:143,loss:0.5862\n",
      "epoch:143,loss:1.1683\n",
      "epoch:143,loss:1.5472\n",
      "epoch:143,loss:0.3687\n",
      "epoch:143,loss:1.1583\n",
      "epoch:143,loss:0.8697\n",
      "epoch:143,loss:0.3690\n",
      "epoch:143,loss:0.8630\n",
      "epoch:143,loss:0.3643\n",
      "epoch:143,loss:0.1489\n",
      "epoch:143,loss:3.4979\n",
      "epoch:143,loss:0.5111\n",
      "epoch:143,loss:0.5653\n",
      "epoch:143,loss:1.0077\n",
      "epoch:143,loss:2.3841\n",
      "epoch:143,loss:0.2341\n",
      "epoch:143,loss:0.2738\n",
      "epoch:143,loss:0.9077\n",
      "============================================\n",
      "第143个epoch的识别准确率为：78%\n",
      "epoch:144,loss:0.4301\n",
      "epoch:144,loss:1.2695\n",
      "epoch:144,loss:1.4225\n",
      "epoch:144,loss:1.3689\n",
      "epoch:144,loss:0.1302\n",
      "epoch:144,loss:0.6242\n",
      "epoch:144,loss:0.7660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:144,loss:0.3704\n",
      "epoch:144,loss:0.4827\n",
      "epoch:144,loss:0.5203\n",
      "epoch:144,loss:0.2094\n",
      "epoch:144,loss:0.3471\n",
      "epoch:144,loss:0.4575\n",
      "epoch:144,loss:2.0171\n",
      "epoch:144,loss:0.0617\n",
      "epoch:144,loss:0.3085\n",
      "epoch:144,loss:2.9820\n",
      "epoch:144,loss:0.0841\n",
      "epoch:144,loss:0.1166\n",
      "epoch:144,loss:0.5432\n",
      "epoch:144,loss:0.0887\n",
      "epoch:144,loss:0.4667\n",
      "epoch:144,loss:0.0791\n",
      "epoch:144,loss:0.6989\n",
      "epoch:144,loss:0.3896\n",
      "epoch:144,loss:1.4022\n",
      "epoch:144,loss:0.8874\n",
      "epoch:144,loss:0.7307\n",
      "epoch:144,loss:0.2730\n",
      "epoch:144,loss:0.6355\n",
      "epoch:144,loss:0.3245\n",
      "epoch:144,loss:0.3951\n",
      "epoch:144,loss:1.6027\n",
      "epoch:144,loss:2.2795\n",
      "epoch:144,loss:0.8222\n",
      "epoch:144,loss:1.6155\n",
      "epoch:144,loss:0.2019\n",
      "epoch:144,loss:0.2587\n",
      "epoch:144,loss:1.9966\n",
      "epoch:144,loss:1.5683\n",
      "epoch:144,loss:1.3201\n",
      "epoch:144,loss:1.0169\n",
      "epoch:144,loss:0.4349\n",
      "epoch:144,loss:1.6936\n",
      "epoch:144,loss:1.7658\n",
      "epoch:144,loss:1.2513\n",
      "epoch:144,loss:0.3029\n",
      "epoch:144,loss:1.6695\n",
      "epoch:144,loss:0.6386\n",
      "epoch:144,loss:0.4234\n",
      "epoch:144,loss:1.6144\n",
      "epoch:144,loss:0.2675\n",
      "epoch:144,loss:0.3884\n",
      "epoch:144,loss:0.3326\n",
      "epoch:144,loss:0.2432\n",
      "epoch:144,loss:0.1605\n",
      "epoch:144,loss:0.3770\n",
      "epoch:144,loss:2.0279\n",
      "epoch:144,loss:0.0496\n",
      "epoch:144,loss:0.0145\n",
      "============================================\n",
      "第144个epoch的识别准确率为：78%\n",
      "epoch:145,loss:0.3867\n",
      "epoch:145,loss:0.6295\n",
      "epoch:145,loss:0.2034\n",
      "epoch:145,loss:2.4188\n",
      "epoch:145,loss:0.1048\n",
      "epoch:145,loss:0.2689\n",
      "epoch:145,loss:0.4614\n",
      "epoch:145,loss:0.7987\n",
      "epoch:145,loss:0.4695\n",
      "epoch:145,loss:0.1464\n",
      "epoch:145,loss:0.6238\n",
      "epoch:145,loss:1.0450\n",
      "epoch:145,loss:0.6157\n",
      "epoch:145,loss:0.0946\n",
      "epoch:145,loss:0.4333\n",
      "epoch:145,loss:0.0774\n",
      "epoch:145,loss:0.3453\n",
      "epoch:145,loss:1.0533\n",
      "epoch:145,loss:0.2962\n",
      "epoch:145,loss:2.9214\n",
      "epoch:145,loss:0.4412\n",
      "epoch:145,loss:0.8398\n",
      "epoch:145,loss:0.2387\n",
      "epoch:145,loss:0.1201\n",
      "epoch:145,loss:1.8067\n",
      "epoch:145,loss:0.2980\n",
      "epoch:145,loss:0.6440\n",
      "epoch:145,loss:3.8976\n",
      "epoch:145,loss:0.5886\n",
      "epoch:145,loss:0.9358\n",
      "epoch:145,loss:1.6694\n",
      "epoch:145,loss:0.5281\n",
      "epoch:145,loss:0.9591\n",
      "epoch:145,loss:0.8398\n",
      "epoch:145,loss:0.0442\n",
      "epoch:145,loss:0.4502\n",
      "epoch:145,loss:0.1868\n",
      "epoch:145,loss:2.2046\n",
      "epoch:145,loss:0.3888\n",
      "epoch:145,loss:0.4161\n",
      "epoch:145,loss:0.4212\n",
      "epoch:145,loss:0.1556\n",
      "epoch:145,loss:0.3521\n",
      "epoch:145,loss:0.2158\n",
      "epoch:145,loss:0.0416\n",
      "epoch:145,loss:0.4890\n",
      "epoch:145,loss:1.4592\n",
      "epoch:145,loss:0.1368\n",
      "epoch:145,loss:0.8091\n",
      "epoch:145,loss:0.6285\n",
      "epoch:145,loss:0.1021\n",
      "epoch:145,loss:0.7074\n",
      "epoch:145,loss:0.3966\n",
      "epoch:145,loss:0.6485\n",
      "epoch:145,loss:1.0578\n",
      "epoch:145,loss:1.4482\n",
      "epoch:145,loss:0.6815\n",
      "epoch:145,loss:0.2649\n",
      "epoch:145,loss:0.3188\n",
      "epoch:145,loss:0.3331\n",
      "============================================\n",
      "准确率由： tensor(0.7904) 上升至： tensor(0.7941) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第145个epoch的识别准确率为：79%\n",
      "epoch:146,loss:0.8009\n",
      "epoch:146,loss:0.6160\n",
      "epoch:146,loss:0.0334\n",
      "epoch:146,loss:1.5559\n",
      "epoch:146,loss:0.1421\n",
      "epoch:146,loss:0.9505\n",
      "epoch:146,loss:0.3065\n",
      "epoch:146,loss:0.1795\n",
      "epoch:146,loss:0.2657\n",
      "epoch:146,loss:0.8826\n",
      "epoch:146,loss:0.4064\n",
      "epoch:146,loss:0.2901\n",
      "epoch:146,loss:0.4793\n",
      "epoch:146,loss:0.2207\n",
      "epoch:146,loss:0.5001\n",
      "epoch:146,loss:0.2335\n",
      "epoch:146,loss:0.6012\n",
      "epoch:146,loss:0.2604\n",
      "epoch:146,loss:0.3315\n",
      "epoch:146,loss:0.0781\n",
      "epoch:146,loss:1.6103\n",
      "epoch:146,loss:2.7245\n",
      "epoch:146,loss:1.4313\n",
      "epoch:146,loss:1.5260\n",
      "epoch:146,loss:0.4754\n",
      "epoch:146,loss:0.5241\n",
      "epoch:146,loss:1.0618\n",
      "epoch:146,loss:0.2554\n",
      "epoch:146,loss:0.3635\n",
      "epoch:146,loss:0.3772\n",
      "epoch:146,loss:0.1595\n",
      "epoch:146,loss:0.4020\n",
      "epoch:146,loss:1.5537\n",
      "epoch:146,loss:0.0460\n",
      "epoch:146,loss:0.3929\n",
      "epoch:146,loss:0.7666\n",
      "epoch:146,loss:0.5524\n",
      "epoch:146,loss:0.5273\n",
      "epoch:146,loss:1.8429\n",
      "epoch:146,loss:0.9218\n",
      "epoch:146,loss:0.1977\n",
      "epoch:146,loss:0.2527\n",
      "epoch:146,loss:0.1958\n",
      "epoch:146,loss:0.5408\n",
      "epoch:146,loss:0.7618\n",
      "epoch:146,loss:0.8339\n",
      "epoch:146,loss:1.0444\n",
      "epoch:146,loss:0.8855\n",
      "epoch:146,loss:1.3073\n",
      "epoch:146,loss:0.6173\n",
      "epoch:146,loss:1.8315\n",
      "epoch:146,loss:0.7352\n",
      "epoch:146,loss:0.6307\n",
      "epoch:146,loss:0.8879\n",
      "epoch:146,loss:0.8485\n",
      "epoch:146,loss:0.4676\n",
      "epoch:146,loss:1.8185\n",
      "epoch:146,loss:1.3175\n",
      "epoch:146,loss:0.3611\n",
      "epoch:146,loss:0.1401\n",
      "============================================\n",
      "第146个epoch的识别准确率为：78%\n",
      "epoch:147,loss:0.6059\n",
      "epoch:147,loss:0.7931\n",
      "epoch:147,loss:0.5524\n",
      "epoch:147,loss:0.4592\n",
      "epoch:147,loss:0.6137\n",
      "epoch:147,loss:0.2365\n",
      "epoch:147,loss:0.9020\n",
      "epoch:147,loss:0.1353\n",
      "epoch:147,loss:0.1685\n",
      "epoch:147,loss:1.0625\n",
      "epoch:147,loss:0.0775\n",
      "epoch:147,loss:0.5220\n",
      "epoch:147,loss:0.4347\n",
      "epoch:147,loss:0.4385\n",
      "epoch:147,loss:0.3031\n",
      "epoch:147,loss:0.1580\n",
      "epoch:147,loss:0.7347\n",
      "epoch:147,loss:0.3111\n",
      "epoch:147,loss:1.3532\n",
      "epoch:147,loss:0.6344\n",
      "epoch:147,loss:2.5122\n",
      "epoch:147,loss:0.7629\n",
      "epoch:147,loss:0.7243\n",
      "epoch:147,loss:0.2818\n",
      "epoch:147,loss:0.7190\n",
      "epoch:147,loss:0.2771\n",
      "epoch:147,loss:0.1992\n",
      "epoch:147,loss:0.3070\n",
      "epoch:147,loss:0.1782\n",
      "epoch:147,loss:0.9499\n",
      "epoch:147,loss:0.1697\n",
      "epoch:147,loss:1.0873\n",
      "epoch:147,loss:0.2803\n",
      "epoch:147,loss:0.1953\n",
      "epoch:147,loss:0.1563\n",
      "epoch:147,loss:0.8033\n",
      "epoch:147,loss:0.7393\n",
      "epoch:147,loss:0.3772\n",
      "epoch:147,loss:0.3032\n",
      "epoch:147,loss:0.2219\n",
      "epoch:147,loss:0.1042\n",
      "epoch:147,loss:0.2175\n",
      "epoch:147,loss:0.7418\n",
      "epoch:147,loss:0.8419\n",
      "epoch:147,loss:0.2227\n",
      "epoch:147,loss:0.5361\n",
      "epoch:147,loss:0.3261\n",
      "epoch:147,loss:0.2844\n",
      "epoch:147,loss:0.1428\n",
      "epoch:147,loss:0.3615\n",
      "epoch:147,loss:0.5208\n",
      "epoch:147,loss:0.3457\n",
      "epoch:147,loss:0.9104\n",
      "epoch:147,loss:0.6773\n",
      "epoch:147,loss:1.3140\n",
      "epoch:147,loss:0.5808\n",
      "epoch:147,loss:0.2698\n",
      "epoch:147,loss:0.2961\n",
      "epoch:147,loss:0.3054\n",
      "epoch:147,loss:0.5427\n",
      "============================================\n",
      "准确率由： tensor(0.7941) 上升至： tensor(0.8107) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第147个epoch的识别准确率为：81%\n",
      "epoch:148,loss:0.2191\n",
      "epoch:148,loss:1.1192\n",
      "epoch:148,loss:0.6587\n",
      "epoch:148,loss:0.9185\n",
      "epoch:148,loss:0.6347\n",
      "epoch:148,loss:0.9136\n",
      "epoch:148,loss:0.0579\n",
      "epoch:148,loss:0.3238\n",
      "epoch:148,loss:0.6734\n",
      "epoch:148,loss:1.9846\n",
      "epoch:148,loss:0.5714\n",
      "epoch:148,loss:0.8801\n",
      "epoch:148,loss:0.8221\n",
      "epoch:148,loss:0.6065\n",
      "epoch:148,loss:0.0774\n",
      "epoch:148,loss:0.5553\n",
      "epoch:148,loss:0.2356\n",
      "epoch:148,loss:0.1207\n",
      "epoch:148,loss:0.7381\n",
      "epoch:148,loss:0.0937\n",
      "epoch:148,loss:0.0355\n",
      "epoch:148,loss:0.3981\n",
      "epoch:148,loss:1.4337\n",
      "epoch:148,loss:0.9954\n",
      "epoch:148,loss:0.6060\n",
      "epoch:148,loss:0.9289\n",
      "epoch:148,loss:0.0591\n",
      "epoch:148,loss:0.3027\n",
      "epoch:148,loss:1.4530\n",
      "epoch:148,loss:0.2901\n",
      "epoch:148,loss:0.5720\n",
      "epoch:148,loss:0.9553\n",
      "epoch:148,loss:0.1784\n",
      "epoch:148,loss:0.2473\n",
      "epoch:148,loss:0.2375\n",
      "epoch:148,loss:1.1608\n",
      "epoch:148,loss:0.5647\n",
      "epoch:148,loss:0.4960\n",
      "epoch:148,loss:0.8302\n",
      "epoch:148,loss:0.4644\n",
      "epoch:148,loss:0.6409\n",
      "epoch:148,loss:2.6505\n",
      "epoch:148,loss:1.0101\n",
      "epoch:148,loss:0.9294\n",
      "epoch:148,loss:0.5027\n",
      "epoch:148,loss:0.7332\n",
      "epoch:148,loss:0.8363\n",
      "epoch:148,loss:3.2593\n",
      "epoch:148,loss:1.1391\n",
      "epoch:148,loss:0.6928\n",
      "epoch:148,loss:2.1902\n",
      "epoch:148,loss:0.4286\n",
      "epoch:148,loss:0.5306\n",
      "epoch:148,loss:1.0646\n",
      "epoch:148,loss:0.3814\n",
      "epoch:148,loss:0.8156\n",
      "epoch:148,loss:0.3797\n",
      "epoch:148,loss:1.3736\n",
      "epoch:148,loss:0.6543\n",
      "epoch:148,loss:0.7496\n",
      "============================================\n",
      "第148个epoch的识别准确率为：77%\n",
      "epoch:149,loss:0.9092\n",
      "epoch:149,loss:0.4484\n",
      "epoch:149,loss:0.1843\n",
      "epoch:149,loss:1.4767\n",
      "epoch:149,loss:0.8853\n",
      "epoch:149,loss:0.1077\n",
      "epoch:149,loss:0.6475\n",
      "epoch:149,loss:0.8096\n",
      "epoch:149,loss:0.8170\n",
      "epoch:149,loss:0.3939\n",
      "epoch:149,loss:0.1271\n",
      "epoch:149,loss:0.2753\n",
      "epoch:149,loss:0.3434\n",
      "epoch:149,loss:0.1571\n",
      "epoch:149,loss:0.1418\n",
      "epoch:149,loss:0.3054\n",
      "epoch:149,loss:0.2186\n",
      "epoch:149,loss:0.5630\n",
      "epoch:149,loss:0.4509\n",
      "epoch:149,loss:1.3303\n",
      "epoch:149,loss:0.2677\n",
      "epoch:149,loss:0.2771\n",
      "epoch:149,loss:0.4363\n",
      "epoch:149,loss:0.3348\n",
      "epoch:149,loss:0.3852\n",
      "epoch:149,loss:0.3136\n",
      "epoch:149,loss:1.6538\n",
      "epoch:149,loss:0.5329\n",
      "epoch:149,loss:1.3391\n",
      "epoch:149,loss:0.7233\n",
      "epoch:149,loss:0.3156\n",
      "epoch:149,loss:0.1072\n",
      "epoch:149,loss:0.9101\n",
      "epoch:149,loss:0.2748\n",
      "epoch:149,loss:0.8556\n",
      "epoch:149,loss:0.1860\n",
      "epoch:149,loss:0.3546\n",
      "epoch:149,loss:1.5617\n",
      "epoch:149,loss:0.8843\n",
      "epoch:149,loss:0.1891\n",
      "epoch:149,loss:0.2723\n",
      "epoch:149,loss:0.6275\n",
      "epoch:149,loss:0.8247\n",
      "epoch:149,loss:0.2268\n",
      "epoch:149,loss:0.7289\n",
      "epoch:149,loss:0.3434\n",
      "epoch:149,loss:0.1157\n",
      "epoch:149,loss:0.7818\n",
      "epoch:149,loss:0.7952\n",
      "epoch:149,loss:0.6050\n",
      "epoch:149,loss:0.1623\n",
      "epoch:149,loss:0.9227\n",
      "epoch:149,loss:0.3179\n",
      "epoch:149,loss:1.0023\n",
      "epoch:149,loss:0.2850\n",
      "epoch:149,loss:0.6529\n",
      "epoch:149,loss:2.1217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:149,loss:0.4030\n",
      "epoch:149,loss:0.3970\n",
      "epoch:149,loss:0.9639\n",
      "============================================\n",
      "第149个epoch的识别准确率为：78%\n",
      "epoch:150,loss:0.0880\n",
      "epoch:150,loss:0.6450\n",
      "epoch:150,loss:0.2946\n",
      "epoch:150,loss:0.8467\n",
      "epoch:150,loss:0.9849\n",
      "epoch:150,loss:1.1569\n",
      "epoch:150,loss:0.6773\n",
      "epoch:150,loss:0.2538\n",
      "epoch:150,loss:0.1737\n",
      "epoch:150,loss:0.3216\n",
      "epoch:150,loss:0.1419\n",
      "epoch:150,loss:0.1708\n",
      "epoch:150,loss:0.7561\n",
      "epoch:150,loss:1.3795\n",
      "epoch:150,loss:0.6965\n",
      "epoch:150,loss:0.3359\n",
      "epoch:150,loss:1.1291\n",
      "epoch:150,loss:0.2678\n",
      "epoch:150,loss:0.1855\n",
      "epoch:150,loss:0.1955\n",
      "epoch:150,loss:0.6293\n",
      "epoch:150,loss:1.3400\n",
      "epoch:150,loss:0.1438\n",
      "epoch:150,loss:0.7321\n",
      "epoch:150,loss:0.0625\n",
      "epoch:150,loss:0.5968\n",
      "epoch:150,loss:0.2997\n",
      "epoch:150,loss:0.6999\n",
      "epoch:150,loss:0.1974\n",
      "epoch:150,loss:0.5765\n",
      "epoch:150,loss:0.5271\n",
      "epoch:150,loss:0.8155\n",
      "epoch:150,loss:1.4311\n",
      "epoch:150,loss:1.5049\n",
      "epoch:150,loss:1.0571\n",
      "epoch:150,loss:0.5035\n",
      "epoch:150,loss:0.2389\n",
      "epoch:150,loss:0.8118\n",
      "epoch:150,loss:0.0323\n",
      "epoch:150,loss:0.4009\n",
      "epoch:150,loss:0.3780\n",
      "epoch:150,loss:0.1782\n",
      "epoch:150,loss:0.1569\n",
      "epoch:150,loss:0.0858\n",
      "epoch:150,loss:0.6825\n",
      "epoch:150,loss:0.5137\n",
      "epoch:150,loss:0.7003\n",
      "epoch:150,loss:0.5219\n",
      "epoch:150,loss:0.1993\n",
      "epoch:150,loss:0.3551\n",
      "epoch:150,loss:1.0621\n",
      "epoch:150,loss:0.2947\n",
      "epoch:150,loss:0.5053\n",
      "epoch:150,loss:0.7727\n",
      "epoch:150,loss:0.4291\n",
      "epoch:150,loss:0.6068\n",
      "epoch:150,loss:0.4928\n",
      "epoch:150,loss:0.1132\n",
      "epoch:150,loss:0.3140\n",
      "epoch:150,loss:0.1850\n",
      "============================================\n",
      "第150个epoch的识别准确率为：79%\n",
      "epoch:151,loss:0.4594\n",
      "epoch:151,loss:0.1419\n",
      "epoch:151,loss:1.4570\n",
      "epoch:151,loss:0.2115\n",
      "epoch:151,loss:0.7864\n",
      "epoch:151,loss:0.3775\n",
      "epoch:151,loss:0.3245\n",
      "epoch:151,loss:0.6731\n",
      "epoch:151,loss:0.2671\n",
      "epoch:151,loss:1.4231\n",
      "epoch:151,loss:0.3105\n",
      "epoch:151,loss:0.7427\n",
      "epoch:151,loss:1.0622\n",
      "epoch:151,loss:0.0655\n",
      "epoch:151,loss:0.1032\n",
      "epoch:151,loss:0.2294\n",
      "epoch:151,loss:0.4045\n",
      "epoch:151,loss:0.2617\n",
      "epoch:151,loss:0.2328\n",
      "epoch:151,loss:0.7351\n",
      "epoch:151,loss:2.0375\n",
      "epoch:151,loss:0.8117\n",
      "epoch:151,loss:1.2818\n",
      "epoch:151,loss:0.1942\n",
      "epoch:151,loss:1.1802\n",
      "epoch:151,loss:0.1193\n",
      "epoch:151,loss:0.1230\n",
      "epoch:151,loss:0.7260\n",
      "epoch:151,loss:2.2392\n",
      "epoch:151,loss:0.2243\n",
      "epoch:151,loss:0.1472\n",
      "epoch:151,loss:0.3998\n",
      "epoch:151,loss:0.0744\n",
      "epoch:151,loss:0.3952\n",
      "epoch:151,loss:0.5750\n",
      "epoch:151,loss:1.3505\n",
      "epoch:151,loss:1.0620\n",
      "epoch:151,loss:0.7723\n",
      "epoch:151,loss:0.1930\n",
      "epoch:151,loss:0.0989\n",
      "epoch:151,loss:0.1545\n",
      "epoch:151,loss:0.0956\n",
      "epoch:151,loss:0.8878\n",
      "epoch:151,loss:0.6132\n",
      "epoch:151,loss:0.2707\n",
      "epoch:151,loss:0.3661\n",
      "epoch:151,loss:0.2138\n",
      "epoch:151,loss:0.4788\n",
      "epoch:151,loss:0.5123\n",
      "epoch:151,loss:1.8710\n",
      "epoch:151,loss:0.2337\n",
      "epoch:151,loss:0.9411\n",
      "epoch:151,loss:0.8915\n",
      "epoch:151,loss:0.5959\n",
      "epoch:151,loss:0.9293\n",
      "epoch:151,loss:0.1110\n",
      "epoch:151,loss:0.3713\n",
      "epoch:151,loss:0.1668\n",
      "epoch:151,loss:0.3651\n",
      "epoch:151,loss:0.0298\n",
      "============================================\n",
      "准确率由： tensor(0.8107) 上升至： tensor(0.8189) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第151个epoch的识别准确率为：81%\n",
      "epoch:152,loss:0.0447\n",
      "epoch:152,loss:0.4502\n",
      "epoch:152,loss:0.2222\n",
      "epoch:152,loss:0.3094\n",
      "epoch:152,loss:2.2198\n",
      "epoch:152,loss:0.6300\n",
      "epoch:152,loss:0.7706\n",
      "epoch:152,loss:0.8613\n",
      "epoch:152,loss:0.5606\n",
      "epoch:152,loss:0.1029\n",
      "epoch:152,loss:0.1183\n",
      "epoch:152,loss:1.0946\n",
      "epoch:152,loss:0.2026\n",
      "epoch:152,loss:0.5062\n",
      "epoch:152,loss:0.2173\n",
      "epoch:152,loss:0.5905\n",
      "epoch:152,loss:0.2573\n",
      "epoch:152,loss:0.1935\n",
      "epoch:152,loss:0.4222\n",
      "epoch:152,loss:0.3589\n",
      "epoch:152,loss:0.1741\n",
      "epoch:152,loss:0.5126\n",
      "epoch:152,loss:0.9249\n",
      "epoch:152,loss:0.1556\n",
      "epoch:152,loss:0.0611\n",
      "epoch:152,loss:0.5578\n",
      "epoch:152,loss:0.8441\n",
      "epoch:152,loss:0.1941\n",
      "epoch:152,loss:0.8189\n",
      "epoch:152,loss:0.7592\n",
      "epoch:152,loss:0.7698\n",
      "epoch:152,loss:1.0675\n",
      "epoch:152,loss:2.3617\n",
      "epoch:152,loss:0.1947\n",
      "epoch:152,loss:0.7320\n",
      "epoch:152,loss:0.0594\n",
      "epoch:152,loss:0.7252\n",
      "epoch:152,loss:0.1488\n",
      "epoch:152,loss:0.5332\n",
      "epoch:152,loss:1.1793\n",
      "epoch:152,loss:0.4258\n",
      "epoch:152,loss:0.7848\n",
      "epoch:152,loss:0.9090\n",
      "epoch:152,loss:0.8185\n",
      "epoch:152,loss:0.7103\n",
      "epoch:152,loss:1.3054\n",
      "epoch:152,loss:0.7599\n",
      "epoch:152,loss:0.7971\n",
      "epoch:152,loss:0.1957\n",
      "epoch:152,loss:0.5472\n",
      "epoch:152,loss:0.3557\n",
      "epoch:152,loss:0.3691\n",
      "epoch:152,loss:0.2595\n",
      "epoch:152,loss:0.4445\n",
      "epoch:152,loss:0.8078\n",
      "epoch:152,loss:0.1730\n",
      "epoch:152,loss:0.5125\n",
      "epoch:152,loss:0.4017\n",
      "epoch:152,loss:0.7113\n",
      "epoch:152,loss:0.7765\n",
      "============================================\n",
      "第152个epoch的识别准确率为：80%\n",
      "epoch:153,loss:0.7100\n",
      "epoch:153,loss:0.9270\n",
      "epoch:153,loss:1.0385\n",
      "epoch:153,loss:0.0334\n",
      "epoch:153,loss:0.3222\n",
      "epoch:153,loss:0.4480\n",
      "epoch:153,loss:1.5543\n",
      "epoch:153,loss:0.0961\n",
      "epoch:153,loss:0.4727\n",
      "epoch:153,loss:0.7465\n",
      "epoch:153,loss:0.3273\n",
      "epoch:153,loss:0.7512\n",
      "epoch:153,loss:0.2223\n",
      "epoch:153,loss:0.6414\n",
      "epoch:153,loss:0.5592\n",
      "epoch:153,loss:1.1575\n",
      "epoch:153,loss:0.2321\n",
      "epoch:153,loss:0.8791\n",
      "epoch:153,loss:0.6680\n",
      "epoch:153,loss:0.1441\n",
      "epoch:153,loss:1.0758\n",
      "epoch:153,loss:0.9423\n",
      "epoch:153,loss:0.9240\n",
      "epoch:153,loss:0.2409\n",
      "epoch:153,loss:2.4093\n",
      "epoch:153,loss:0.6858\n",
      "epoch:153,loss:2.7559\n",
      "epoch:153,loss:0.2650\n",
      "epoch:153,loss:1.0525\n",
      "epoch:153,loss:1.0598\n",
      "epoch:153,loss:0.1045\n",
      "epoch:153,loss:0.1964\n",
      "epoch:153,loss:2.3877\n",
      "epoch:153,loss:0.1675\n",
      "epoch:153,loss:0.1823\n",
      "epoch:153,loss:1.6018\n",
      "epoch:153,loss:1.6452\n",
      "epoch:153,loss:1.3375\n",
      "epoch:153,loss:0.2362\n",
      "epoch:153,loss:0.8092\n",
      "epoch:153,loss:0.6477\n",
      "epoch:153,loss:0.9165\n",
      "epoch:153,loss:0.3569\n",
      "epoch:153,loss:0.2888\n",
      "epoch:153,loss:0.8612\n",
      "epoch:153,loss:0.7933\n",
      "epoch:153,loss:0.7914\n",
      "epoch:153,loss:0.1530\n",
      "epoch:153,loss:0.2611\n",
      "epoch:153,loss:0.1758\n",
      "epoch:153,loss:0.3395\n",
      "epoch:153,loss:0.3763\n",
      "epoch:153,loss:0.6924\n",
      "epoch:153,loss:0.6083\n",
      "epoch:153,loss:0.4214\n",
      "epoch:153,loss:0.7761\n",
      "epoch:153,loss:0.1236\n",
      "epoch:153,loss:0.3481\n",
      "epoch:153,loss:1.7217\n",
      "epoch:153,loss:1.1563\n",
      "============================================\n",
      "第153个epoch的识别准确率为：81%\n",
      "epoch:154,loss:1.2928\n",
      "epoch:154,loss:0.6418\n",
      "epoch:154,loss:0.0539\n",
      "epoch:154,loss:0.4680\n",
      "epoch:154,loss:0.2009\n",
      "epoch:154,loss:0.0668\n",
      "epoch:154,loss:0.1719\n",
      "epoch:154,loss:0.2335\n",
      "epoch:154,loss:0.5888\n",
      "epoch:154,loss:2.0514\n",
      "epoch:154,loss:0.4168\n",
      "epoch:154,loss:0.0184\n",
      "epoch:154,loss:0.3733\n",
      "epoch:154,loss:1.0763\n",
      "epoch:154,loss:0.2643\n",
      "epoch:154,loss:0.1992\n",
      "epoch:154,loss:0.7539\n",
      "epoch:154,loss:0.3283\n",
      "epoch:154,loss:0.7357\n",
      "epoch:154,loss:0.2923\n",
      "epoch:154,loss:0.8783\n",
      "epoch:154,loss:0.0759\n",
      "epoch:154,loss:0.1573\n",
      "epoch:154,loss:0.8403\n",
      "epoch:154,loss:1.4469\n",
      "epoch:154,loss:0.3898\n",
      "epoch:154,loss:0.1895\n",
      "epoch:154,loss:0.2358\n",
      "epoch:154,loss:0.1811\n",
      "epoch:154,loss:0.7476\n",
      "epoch:154,loss:0.2367\n",
      "epoch:154,loss:0.4264\n",
      "epoch:154,loss:1.2561\n",
      "epoch:154,loss:0.3569\n",
      "epoch:154,loss:0.3333\n",
      "epoch:154,loss:0.0209\n",
      "epoch:154,loss:1.9781\n",
      "epoch:154,loss:0.4125\n",
      "epoch:154,loss:0.5685\n",
      "epoch:154,loss:0.2351\n",
      "epoch:154,loss:0.3491\n",
      "epoch:154,loss:1.5637\n",
      "epoch:154,loss:0.1636\n",
      "epoch:154,loss:0.4649\n",
      "epoch:154,loss:0.2641\n",
      "epoch:154,loss:0.2442\n",
      "epoch:154,loss:1.0857\n",
      "epoch:154,loss:0.1230\n",
      "epoch:154,loss:0.6440\n",
      "epoch:154,loss:0.8359\n",
      "epoch:154,loss:0.6004\n",
      "epoch:154,loss:0.3462\n",
      "epoch:154,loss:0.3592\n",
      "epoch:154,loss:0.2739\n",
      "epoch:154,loss:0.0791\n",
      "epoch:154,loss:0.2421\n",
      "epoch:154,loss:1.2599\n",
      "epoch:154,loss:0.4621\n",
      "epoch:154,loss:0.5621\n",
      "epoch:154,loss:0.7816\n",
      "============================================\n",
      "准确率由： tensor(0.8189) 上升至： tensor(0.8382) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第154个epoch的识别准确率为：83%\n",
      "epoch:155,loss:0.3766\n",
      "epoch:155,loss:1.1150\n",
      "epoch:155,loss:0.4647\n",
      "epoch:155,loss:0.5630\n",
      "epoch:155,loss:0.3045\n",
      "epoch:155,loss:0.3612\n",
      "epoch:155,loss:0.2813\n",
      "epoch:155,loss:0.3963\n",
      "epoch:155,loss:0.7005\n",
      "epoch:155,loss:0.8848\n",
      "epoch:155,loss:0.5061\n",
      "epoch:155,loss:1.0626\n",
      "epoch:155,loss:1.1417\n",
      "epoch:155,loss:0.9213\n",
      "epoch:155,loss:0.1223\n",
      "epoch:155,loss:1.9577\n",
      "epoch:155,loss:0.0863\n",
      "epoch:155,loss:0.3783\n",
      "epoch:155,loss:0.5261\n",
      "epoch:155,loss:1.1361\n",
      "epoch:155,loss:0.3329\n",
      "epoch:155,loss:0.1499\n",
      "epoch:155,loss:0.3871\n",
      "epoch:155,loss:0.7257\n",
      "epoch:155,loss:0.7032\n",
      "epoch:155,loss:0.4245\n",
      "epoch:155,loss:0.4432\n",
      "epoch:155,loss:1.4329\n",
      "epoch:155,loss:0.8235\n",
      "epoch:155,loss:0.0548\n",
      "epoch:155,loss:0.3533\n",
      "epoch:155,loss:0.0331\n",
      "epoch:155,loss:0.1454\n",
      "epoch:155,loss:0.2374\n",
      "epoch:155,loss:0.6287\n",
      "epoch:155,loss:0.1695\n",
      "epoch:155,loss:0.4945\n",
      "epoch:155,loss:0.8693\n",
      "epoch:155,loss:0.5549\n",
      "epoch:155,loss:0.1307\n",
      "epoch:155,loss:1.0358\n",
      "epoch:155,loss:0.7247\n",
      "epoch:155,loss:1.3511\n",
      "epoch:155,loss:0.3091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:155,loss:0.4860\n",
      "epoch:155,loss:1.1660\n",
      "epoch:155,loss:0.6518\n",
      "epoch:155,loss:1.9344\n",
      "epoch:155,loss:1.2730\n",
      "epoch:155,loss:0.1403\n",
      "epoch:155,loss:1.6068\n",
      "epoch:155,loss:0.1312\n",
      "epoch:155,loss:0.2113\n",
      "epoch:155,loss:0.4899\n",
      "epoch:155,loss:0.1808\n",
      "epoch:155,loss:0.5955\n",
      "epoch:155,loss:0.4833\n",
      "epoch:155,loss:0.0874\n",
      "epoch:155,loss:0.6099\n",
      "epoch:155,loss:0.3692\n",
      "============================================\n",
      "第155个epoch的识别准确率为：81%\n",
      "epoch:156,loss:0.5833\n",
      "epoch:156,loss:0.3623\n",
      "epoch:156,loss:0.6178\n",
      "epoch:156,loss:0.7046\n",
      "epoch:156,loss:0.1860\n",
      "epoch:156,loss:0.2499\n",
      "epoch:156,loss:0.2833\n",
      "epoch:156,loss:0.5763\n",
      "epoch:156,loss:0.2790\n",
      "epoch:156,loss:1.1008\n",
      "epoch:156,loss:0.7472\n",
      "epoch:156,loss:0.5969\n",
      "epoch:156,loss:0.8775\n",
      "epoch:156,loss:0.6146\n",
      "epoch:156,loss:1.0686\n",
      "epoch:156,loss:0.2798\n",
      "epoch:156,loss:0.2771\n",
      "epoch:156,loss:0.8637\n",
      "epoch:156,loss:0.6806\n",
      "epoch:156,loss:0.0425\n",
      "epoch:156,loss:0.6105\n",
      "epoch:156,loss:0.3876\n",
      "epoch:156,loss:0.2068\n",
      "epoch:156,loss:0.1264\n",
      "epoch:156,loss:0.2957\n",
      "epoch:156,loss:0.9729\n",
      "epoch:156,loss:0.1327\n",
      "epoch:156,loss:1.1607\n",
      "epoch:156,loss:0.2974\n",
      "epoch:156,loss:0.4352\n",
      "epoch:156,loss:0.3097\n",
      "epoch:156,loss:0.4260\n",
      "epoch:156,loss:0.1832\n",
      "epoch:156,loss:0.5885\n",
      "epoch:156,loss:0.2187\n",
      "epoch:156,loss:0.4663\n",
      "epoch:156,loss:0.0228\n",
      "epoch:156,loss:0.4649\n",
      "epoch:156,loss:0.8722\n",
      "epoch:156,loss:0.3340\n",
      "epoch:156,loss:0.2740\n",
      "epoch:156,loss:0.7526\n",
      "epoch:156,loss:0.2349\n",
      "epoch:156,loss:0.3889\n",
      "epoch:156,loss:0.3072\n",
      "epoch:156,loss:1.5819\n",
      "epoch:156,loss:0.1212\n",
      "epoch:156,loss:0.1671\n",
      "epoch:156,loss:0.0141\n",
      "epoch:156,loss:0.2112\n",
      "epoch:156,loss:0.3363\n",
      "epoch:156,loss:0.6266\n",
      "epoch:156,loss:0.7310\n",
      "epoch:156,loss:0.5623\n",
      "epoch:156,loss:0.2099\n",
      "epoch:156,loss:1.6102\n",
      "epoch:156,loss:0.1330\n",
      "epoch:156,loss:0.9868\n",
      "epoch:156,loss:0.9902\n",
      "epoch:156,loss:0.2225\n",
      "============================================\n",
      "第156个epoch的识别准确率为：83%\n",
      "epoch:157,loss:0.7655\n",
      "epoch:157,loss:0.5197\n",
      "epoch:157,loss:0.5779\n",
      "epoch:157,loss:0.1821\n",
      "epoch:157,loss:0.0564\n",
      "epoch:157,loss:0.8350\n",
      "epoch:157,loss:1.3478\n",
      "epoch:157,loss:0.1690\n",
      "epoch:157,loss:0.5513\n",
      "epoch:157,loss:1.8914\n",
      "epoch:157,loss:0.4067\n",
      "epoch:157,loss:1.1208\n",
      "epoch:157,loss:1.2899\n",
      "epoch:157,loss:0.1283\n",
      "epoch:157,loss:0.4130\n",
      "epoch:157,loss:0.5329\n",
      "epoch:157,loss:0.3313\n",
      "epoch:157,loss:0.1370\n",
      "epoch:157,loss:0.6095\n",
      "epoch:157,loss:0.2353\n",
      "epoch:157,loss:0.8742\n",
      "epoch:157,loss:0.7090\n",
      "epoch:157,loss:1.2181\n",
      "epoch:157,loss:1.6758\n",
      "epoch:157,loss:0.0621\n",
      "epoch:157,loss:0.0798\n",
      "epoch:157,loss:0.7647\n",
      "epoch:157,loss:0.5198\n",
      "epoch:157,loss:0.5904\n",
      "epoch:157,loss:0.2511\n",
      "epoch:157,loss:0.2819\n",
      "epoch:157,loss:1.2542\n",
      "epoch:157,loss:1.2185\n",
      "epoch:157,loss:0.2642\n",
      "epoch:157,loss:0.7323\n",
      "epoch:157,loss:1.1211\n",
      "epoch:157,loss:3.5697\n",
      "epoch:157,loss:2.8601\n",
      "epoch:157,loss:0.2642\n",
      "epoch:157,loss:0.4858\n",
      "epoch:157,loss:1.6095\n",
      "epoch:157,loss:0.8335\n",
      "epoch:157,loss:0.2477\n",
      "epoch:157,loss:0.1468\n",
      "epoch:157,loss:0.8708\n",
      "epoch:157,loss:0.5313\n",
      "epoch:157,loss:0.1604\n",
      "epoch:157,loss:2.1141\n",
      "epoch:157,loss:0.1208\n",
      "epoch:157,loss:0.0946\n",
      "epoch:157,loss:0.5346\n",
      "epoch:157,loss:0.2226\n",
      "epoch:157,loss:0.7404\n",
      "epoch:157,loss:0.4930\n",
      "epoch:157,loss:0.5120\n",
      "epoch:157,loss:0.6401\n",
      "epoch:157,loss:1.2527\n",
      "epoch:157,loss:0.5067\n",
      "epoch:157,loss:0.3474\n",
      "epoch:157,loss:0.3230\n",
      "============================================\n",
      "第157个epoch的识别准确率为：81%\n",
      "epoch:158,loss:0.4424\n",
      "epoch:158,loss:0.0441\n",
      "epoch:158,loss:0.8942\n",
      "epoch:158,loss:0.5283\n",
      "epoch:158,loss:0.2970\n",
      "epoch:158,loss:1.2744\n",
      "epoch:158,loss:0.3706\n",
      "epoch:158,loss:0.2067\n",
      "epoch:158,loss:0.1354\n",
      "epoch:158,loss:1.0881\n",
      "epoch:158,loss:0.2443\n",
      "epoch:158,loss:1.3506\n",
      "epoch:158,loss:0.7344\n",
      "epoch:158,loss:0.3807\n",
      "epoch:158,loss:0.1684\n",
      "epoch:158,loss:0.7650\n",
      "epoch:158,loss:0.6988\n",
      "epoch:158,loss:0.1650\n",
      "epoch:158,loss:0.2711\n",
      "epoch:158,loss:0.1850\n",
      "epoch:158,loss:0.4638\n",
      "epoch:158,loss:0.7194\n",
      "epoch:158,loss:0.1312\n",
      "epoch:158,loss:0.4467\n",
      "epoch:158,loss:0.1117\n",
      "epoch:158,loss:0.1970\n",
      "epoch:158,loss:0.4886\n",
      "epoch:158,loss:0.8250\n",
      "epoch:158,loss:0.4325\n",
      "epoch:158,loss:0.2363\n",
      "epoch:158,loss:0.1343\n",
      "epoch:158,loss:0.4699\n",
      "epoch:158,loss:0.3208\n",
      "epoch:158,loss:0.6880\n",
      "epoch:158,loss:0.1148\n",
      "epoch:158,loss:0.4480\n",
      "epoch:158,loss:0.0872\n",
      "epoch:158,loss:0.5049\n",
      "epoch:158,loss:0.2399\n",
      "epoch:158,loss:1.0646\n",
      "epoch:158,loss:1.1174\n",
      "epoch:158,loss:0.1196\n",
      "epoch:158,loss:0.0217\n",
      "epoch:158,loss:1.6261\n",
      "epoch:158,loss:0.0929\n",
      "epoch:158,loss:0.2884\n",
      "epoch:158,loss:1.5078\n",
      "epoch:158,loss:1.2134\n",
      "epoch:158,loss:0.9240\n",
      "epoch:158,loss:0.7479\n",
      "epoch:158,loss:0.0409\n",
      "epoch:158,loss:0.3267\n",
      "epoch:158,loss:0.2545\n",
      "epoch:158,loss:0.7151\n",
      "epoch:158,loss:0.4421\n",
      "epoch:158,loss:0.4534\n",
      "epoch:158,loss:0.5964\n",
      "epoch:158,loss:0.1108\n",
      "epoch:158,loss:0.7182\n",
      "epoch:158,loss:0.3790\n",
      "============================================\n",
      "准确率由： tensor(0.8382) 上升至： tensor(0.8401) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第158个epoch的识别准确率为：84%\n",
      "epoch:159,loss:0.1923\n",
      "epoch:159,loss:0.1986\n",
      "epoch:159,loss:0.2001\n",
      "epoch:159,loss:0.8907\n",
      "epoch:159,loss:0.1433\n",
      "epoch:159,loss:0.3570\n",
      "epoch:159,loss:0.2403\n",
      "epoch:159,loss:1.1538\n",
      "epoch:159,loss:0.0370\n",
      "epoch:159,loss:0.3927\n",
      "epoch:159,loss:0.3397\n",
      "epoch:159,loss:0.3274\n",
      "epoch:159,loss:1.0311\n",
      "epoch:159,loss:0.1122\n",
      "epoch:159,loss:0.2469\n",
      "epoch:159,loss:0.5624\n",
      "epoch:159,loss:0.0318\n",
      "epoch:159,loss:0.5433\n",
      "epoch:159,loss:0.7491\n",
      "epoch:159,loss:0.6549\n",
      "epoch:159,loss:0.5927\n",
      "epoch:159,loss:0.0617\n",
      "epoch:159,loss:0.1900\n",
      "epoch:159,loss:0.4678\n",
      "epoch:159,loss:0.1776\n",
      "epoch:159,loss:0.1925\n",
      "epoch:159,loss:1.2681\n",
      "epoch:159,loss:0.2741\n",
      "epoch:159,loss:0.1517\n",
      "epoch:159,loss:0.6437\n",
      "epoch:159,loss:0.3669\n",
      "epoch:159,loss:0.0811\n",
      "epoch:159,loss:0.3648\n",
      "epoch:159,loss:0.5998\n",
      "epoch:159,loss:0.8476\n",
      "epoch:159,loss:0.5257\n",
      "epoch:159,loss:1.8022\n",
      "epoch:159,loss:0.1155\n",
      "epoch:159,loss:0.2653\n",
      "epoch:159,loss:0.5546\n",
      "epoch:159,loss:0.1976\n",
      "epoch:159,loss:0.5473\n",
      "epoch:159,loss:0.1911\n",
      "epoch:159,loss:1.7414\n",
      "epoch:159,loss:0.2538\n",
      "epoch:159,loss:0.7071\n",
      "epoch:159,loss:0.2089\n",
      "epoch:159,loss:0.4675\n",
      "epoch:159,loss:0.5339\n",
      "epoch:159,loss:0.2114\n",
      "epoch:159,loss:0.2613\n",
      "epoch:159,loss:0.5928\n",
      "epoch:159,loss:1.5139\n",
      "epoch:159,loss:0.8097\n",
      "epoch:159,loss:0.5393\n",
      "epoch:159,loss:0.5758\n",
      "epoch:159,loss:0.2082\n",
      "epoch:159,loss:0.2696\n",
      "epoch:159,loss:1.1372\n",
      "epoch:159,loss:0.4284\n",
      "============================================\n",
      "准确率由： tensor(0.8401) 上升至： tensor(0.8511) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第159个epoch的识别准确率为：85%\n",
      "epoch:160,loss:1.8399\n",
      "epoch:160,loss:0.6652\n",
      "epoch:160,loss:0.4128\n",
      "epoch:160,loss:1.1987\n",
      "epoch:160,loss:0.0734\n",
      "epoch:160,loss:0.3225\n",
      "epoch:160,loss:0.9574\n",
      "epoch:160,loss:1.0917\n",
      "epoch:160,loss:0.1926\n",
      "epoch:160,loss:0.3502\n",
      "epoch:160,loss:0.2218\n",
      "epoch:160,loss:0.9160\n",
      "epoch:160,loss:0.0500\n",
      "epoch:160,loss:0.8550\n",
      "epoch:160,loss:0.6029\n",
      "epoch:160,loss:0.0981\n",
      "epoch:160,loss:0.3903\n",
      "epoch:160,loss:0.7048\n",
      "epoch:160,loss:0.5186\n",
      "epoch:160,loss:0.1865\n",
      "epoch:160,loss:0.2118\n",
      "epoch:160,loss:0.1746\n",
      "epoch:160,loss:0.1113\n",
      "epoch:160,loss:0.3392\n",
      "epoch:160,loss:1.0505\n",
      "epoch:160,loss:0.4356\n",
      "epoch:160,loss:0.0259\n",
      "epoch:160,loss:1.5349\n",
      "epoch:160,loss:0.6670\n",
      "epoch:160,loss:0.4938\n",
      "epoch:160,loss:0.4205\n",
      "epoch:160,loss:0.4503\n",
      "epoch:160,loss:1.0111\n",
      "epoch:160,loss:0.1201\n",
      "epoch:160,loss:0.2802\n",
      "epoch:160,loss:0.7199\n",
      "epoch:160,loss:0.6481\n",
      "epoch:160,loss:0.0671\n",
      "epoch:160,loss:0.0993\n",
      "epoch:160,loss:0.8535\n",
      "epoch:160,loss:0.3476\n",
      "epoch:160,loss:0.3075\n",
      "epoch:160,loss:0.1349\n",
      "epoch:160,loss:0.1414\n",
      "epoch:160,loss:0.8191\n",
      "epoch:160,loss:0.0857\n",
      "epoch:160,loss:0.1544\n",
      "epoch:160,loss:1.0661\n",
      "epoch:160,loss:0.5566\n",
      "epoch:160,loss:0.1104\n",
      "epoch:160,loss:0.0180\n",
      "epoch:160,loss:0.4625\n",
      "epoch:160,loss:0.3310\n",
      "epoch:160,loss:0.7349\n",
      "epoch:160,loss:0.1817\n",
      "epoch:160,loss:0.3740\n",
      "epoch:160,loss:0.0558\n",
      "epoch:160,loss:1.0982\n",
      "epoch:160,loss:0.2858\n",
      "epoch:160,loss:0.1644\n",
      "============================================\n",
      "第160个epoch的识别准确率为：83%\n",
      "epoch:161,loss:0.6461\n",
      "epoch:161,loss:0.7053\n",
      "epoch:161,loss:0.1470\n",
      "epoch:161,loss:0.4588\n",
      "epoch:161,loss:0.7633\n",
      "epoch:161,loss:0.1469\n",
      "epoch:161,loss:0.3700\n",
      "epoch:161,loss:0.6588\n",
      "epoch:161,loss:0.1682\n",
      "epoch:161,loss:0.3575\n",
      "epoch:161,loss:0.5629\n",
      "epoch:161,loss:0.2737\n",
      "epoch:161,loss:0.2135\n",
      "epoch:161,loss:0.1422\n",
      "epoch:161,loss:0.1266\n",
      "epoch:161,loss:0.1593\n",
      "epoch:161,loss:0.1854\n",
      "epoch:161,loss:0.4167\n",
      "epoch:161,loss:0.4278\n",
      "epoch:161,loss:0.9958\n",
      "epoch:161,loss:0.1598\n",
      "epoch:161,loss:0.1113\n",
      "epoch:161,loss:0.3848\n",
      "epoch:161,loss:0.0572\n",
      "epoch:161,loss:1.8726\n",
      "epoch:161,loss:0.0892\n",
      "epoch:161,loss:0.4311\n",
      "epoch:161,loss:0.8722\n",
      "epoch:161,loss:0.1390\n",
      "epoch:161,loss:1.5599\n",
      "epoch:161,loss:0.0872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:161,loss:0.2246\n",
      "epoch:161,loss:0.1288\n",
      "epoch:161,loss:0.2502\n",
      "epoch:161,loss:0.9123\n",
      "epoch:161,loss:0.2010\n",
      "epoch:161,loss:0.3279\n",
      "epoch:161,loss:0.8329\n",
      "epoch:161,loss:0.4730\n",
      "epoch:161,loss:0.0936\n",
      "epoch:161,loss:0.0981\n",
      "epoch:161,loss:0.0505\n",
      "epoch:161,loss:0.6898\n",
      "epoch:161,loss:0.5540\n",
      "epoch:161,loss:0.4471\n",
      "epoch:161,loss:0.3514\n",
      "epoch:161,loss:0.1805\n",
      "epoch:161,loss:0.7811\n",
      "epoch:161,loss:0.0540\n",
      "epoch:161,loss:0.1411\n",
      "epoch:161,loss:1.1141\n",
      "epoch:161,loss:0.8482\n",
      "epoch:161,loss:0.5865\n",
      "epoch:161,loss:0.7609\n",
      "epoch:161,loss:0.1682\n",
      "epoch:161,loss:0.2925\n",
      "epoch:161,loss:0.5404\n",
      "epoch:161,loss:0.0272\n",
      "epoch:161,loss:0.1783\n",
      "epoch:161,loss:0.4844\n",
      "============================================\n",
      "准确率由： tensor(0.8511) 上升至： tensor(0.8575) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第161个epoch的识别准确率为：85%\n",
      "epoch:162,loss:0.0539\n",
      "epoch:162,loss:0.2343\n",
      "epoch:162,loss:0.0630\n",
      "epoch:162,loss:0.4028\n",
      "epoch:162,loss:0.1743\n",
      "epoch:162,loss:0.1017\n",
      "epoch:162,loss:0.0502\n",
      "epoch:162,loss:0.2200\n",
      "epoch:162,loss:0.2267\n",
      "epoch:162,loss:1.1916\n",
      "epoch:162,loss:0.6741\n",
      "epoch:162,loss:0.2986\n",
      "epoch:162,loss:0.1248\n",
      "epoch:162,loss:0.0495\n",
      "epoch:162,loss:0.8351\n",
      "epoch:162,loss:0.0326\n",
      "epoch:162,loss:0.2957\n",
      "epoch:162,loss:0.1731\n",
      "epoch:162,loss:0.5287\n",
      "epoch:162,loss:1.0720\n",
      "epoch:162,loss:0.1628\n",
      "epoch:162,loss:2.2348\n",
      "epoch:162,loss:0.1457\n",
      "epoch:162,loss:1.1415\n",
      "epoch:162,loss:0.7900\n",
      "epoch:162,loss:0.2812\n",
      "epoch:162,loss:0.5664\n",
      "epoch:162,loss:0.2885\n",
      "epoch:162,loss:0.1244\n",
      "epoch:162,loss:0.4682\n",
      "epoch:162,loss:1.5240\n",
      "epoch:162,loss:0.2611\n",
      "epoch:162,loss:0.0827\n",
      "epoch:162,loss:0.4397\n",
      "epoch:162,loss:0.2305\n",
      "epoch:162,loss:0.2283\n",
      "epoch:162,loss:0.1403\n",
      "epoch:162,loss:0.6860\n",
      "epoch:162,loss:0.2661\n",
      "epoch:162,loss:0.2293\n",
      "epoch:162,loss:0.8520\n",
      "epoch:162,loss:0.1831\n",
      "epoch:162,loss:0.3475\n",
      "epoch:162,loss:0.1796\n",
      "epoch:162,loss:0.4812\n",
      "epoch:162,loss:0.0546\n",
      "epoch:162,loss:1.9774\n",
      "epoch:162,loss:0.3376\n",
      "epoch:162,loss:0.2114\n",
      "epoch:162,loss:1.0810\n",
      "epoch:162,loss:0.1686\n",
      "epoch:162,loss:0.4992\n",
      "epoch:162,loss:0.1857\n",
      "epoch:162,loss:1.0380\n",
      "epoch:162,loss:0.1355\n",
      "epoch:162,loss:0.5963\n",
      "epoch:162,loss:1.0436\n",
      "epoch:162,loss:0.0513\n",
      "epoch:162,loss:0.4423\n",
      "epoch:162,loss:0.6342\n",
      "============================================\n",
      "第162个epoch的识别准确率为：84%\n",
      "epoch:163,loss:1.4242\n",
      "epoch:163,loss:0.1857\n",
      "epoch:163,loss:0.3075\n",
      "epoch:163,loss:0.8786\n",
      "epoch:163,loss:0.0572\n",
      "epoch:163,loss:0.7891\n",
      "epoch:163,loss:0.1820\n",
      "epoch:163,loss:0.0939\n",
      "epoch:163,loss:0.3981\n",
      "epoch:163,loss:0.2198\n",
      "epoch:163,loss:0.2557\n",
      "epoch:163,loss:1.3194\n",
      "epoch:163,loss:0.8155\n",
      "epoch:163,loss:0.1965\n",
      "epoch:163,loss:0.0758\n",
      "epoch:163,loss:1.5558\n",
      "epoch:163,loss:0.4035\n",
      "epoch:163,loss:1.0347\n",
      "epoch:163,loss:1.0526\n",
      "epoch:163,loss:1.3234\n",
      "epoch:163,loss:0.4455\n",
      "epoch:163,loss:0.8420\n",
      "epoch:163,loss:0.0861\n",
      "epoch:163,loss:0.6521\n",
      "epoch:163,loss:0.0326\n",
      "epoch:163,loss:1.1220\n",
      "epoch:163,loss:0.9605\n",
      "epoch:163,loss:0.1778\n",
      "epoch:163,loss:0.2881\n",
      "epoch:163,loss:0.5641\n",
      "epoch:163,loss:0.4585\n",
      "epoch:163,loss:0.0690\n",
      "epoch:163,loss:0.3502\n",
      "epoch:163,loss:0.8495\n",
      "epoch:163,loss:0.1190\n",
      "epoch:163,loss:0.3155\n",
      "epoch:163,loss:0.3569\n",
      "epoch:163,loss:0.0249\n",
      "epoch:163,loss:0.2908\n",
      "epoch:163,loss:0.2054\n",
      "epoch:163,loss:0.2336\n",
      "epoch:163,loss:0.5801\n",
      "epoch:163,loss:0.3998\n",
      "epoch:163,loss:0.7358\n",
      "epoch:163,loss:0.0236\n",
      "epoch:163,loss:0.8911\n",
      "epoch:163,loss:0.1299\n",
      "epoch:163,loss:0.7732\n",
      "epoch:163,loss:0.1187\n",
      "epoch:163,loss:1.0127\n",
      "epoch:163,loss:0.1187\n",
      "epoch:163,loss:0.1610\n",
      "epoch:163,loss:0.7534\n",
      "epoch:163,loss:0.2686\n",
      "epoch:163,loss:0.4769\n",
      "epoch:163,loss:0.8564\n",
      "epoch:163,loss:0.0422\n",
      "epoch:163,loss:0.0391\n",
      "epoch:163,loss:0.1416\n",
      "epoch:163,loss:0.5394\n",
      "============================================\n",
      "第163个epoch的识别准确率为：84%\n",
      "epoch:164,loss:0.4262\n",
      "epoch:164,loss:0.1517\n",
      "epoch:164,loss:0.0665\n",
      "epoch:164,loss:0.2982\n",
      "epoch:164,loss:0.2820\n",
      "epoch:164,loss:0.3044\n",
      "epoch:164,loss:0.1412\n",
      "epoch:164,loss:0.3079\n",
      "epoch:164,loss:0.5539\n",
      "epoch:164,loss:0.1383\n",
      "epoch:164,loss:0.1733\n",
      "epoch:164,loss:1.0581\n",
      "epoch:164,loss:0.1604\n",
      "epoch:164,loss:0.2909\n",
      "epoch:164,loss:0.6948\n",
      "epoch:164,loss:0.1199\n",
      "epoch:164,loss:1.3682\n",
      "epoch:164,loss:0.1556\n",
      "epoch:164,loss:0.3065\n",
      "epoch:164,loss:0.1885\n",
      "epoch:164,loss:0.2841\n",
      "epoch:164,loss:0.5261\n",
      "epoch:164,loss:0.1324\n",
      "epoch:164,loss:0.2764\n",
      "epoch:164,loss:0.2835\n",
      "epoch:164,loss:1.2742\n",
      "epoch:164,loss:0.3916\n",
      "epoch:164,loss:0.2606\n",
      "epoch:164,loss:1.1183\n",
      "epoch:164,loss:0.2050\n",
      "epoch:164,loss:0.1071\n",
      "epoch:164,loss:0.0260\n",
      "epoch:164,loss:0.8249\n",
      "epoch:164,loss:0.8773\n",
      "epoch:164,loss:0.1653\n",
      "epoch:164,loss:0.2291\n",
      "epoch:164,loss:0.0885\n",
      "epoch:164,loss:0.3298\n",
      "epoch:164,loss:0.9346\n",
      "epoch:164,loss:0.0488\n",
      "epoch:164,loss:0.2112\n",
      "epoch:164,loss:0.0585\n",
      "epoch:164,loss:0.1251\n",
      "epoch:164,loss:0.5450\n",
      "epoch:164,loss:0.1819\n",
      "epoch:164,loss:1.0871\n",
      "epoch:164,loss:1.0682\n",
      "epoch:164,loss:0.5168\n",
      "epoch:164,loss:1.1406\n",
      "epoch:164,loss:0.1141\n",
      "epoch:164,loss:0.1393\n",
      "epoch:164,loss:0.1717\n",
      "epoch:164,loss:0.5191\n",
      "epoch:164,loss:0.4758\n",
      "epoch:164,loss:0.1525\n",
      "epoch:164,loss:0.2931\n",
      "epoch:164,loss:0.2005\n",
      "epoch:164,loss:0.2096\n",
      "epoch:164,loss:0.1443\n",
      "epoch:164,loss:0.1656\n",
      "============================================\n",
      "第164个epoch的识别准确率为：85%\n",
      "epoch:165,loss:0.0565\n",
      "epoch:165,loss:0.1166\n",
      "epoch:165,loss:0.3960\n",
      "epoch:165,loss:0.4028\n",
      "epoch:165,loss:0.6344\n",
      "epoch:165,loss:0.1547\n",
      "epoch:165,loss:0.0599\n",
      "epoch:165,loss:0.1645\n",
      "epoch:165,loss:0.1031\n",
      "epoch:165,loss:0.4522\n",
      "epoch:165,loss:0.2045\n",
      "epoch:165,loss:0.2519\n",
      "epoch:165,loss:0.1547\n",
      "epoch:165,loss:0.5101\n",
      "epoch:165,loss:0.9204\n",
      "epoch:165,loss:0.4488\n",
      "epoch:165,loss:0.1423\n",
      "epoch:165,loss:0.4195\n",
      "epoch:165,loss:0.3989\n",
      "epoch:165,loss:0.2171\n",
      "epoch:165,loss:0.1042\n",
      "epoch:165,loss:0.7671\n",
      "epoch:165,loss:0.4970\n",
      "epoch:165,loss:0.0855\n",
      "epoch:165,loss:0.7131\n",
      "epoch:165,loss:0.6231\n",
      "epoch:165,loss:0.0840\n",
      "epoch:165,loss:0.2846\n",
      "epoch:165,loss:0.4644\n",
      "epoch:165,loss:0.6346\n",
      "epoch:165,loss:0.0466\n",
      "epoch:165,loss:1.6776\n",
      "epoch:165,loss:0.0787\n",
      "epoch:165,loss:0.3460\n",
      "epoch:165,loss:1.5145\n",
      "epoch:165,loss:1.1962\n",
      "epoch:165,loss:0.2529\n",
      "epoch:165,loss:0.2206\n",
      "epoch:165,loss:0.1773\n",
      "epoch:165,loss:0.1027\n",
      "epoch:165,loss:0.0930\n",
      "epoch:165,loss:0.1722\n",
      "epoch:165,loss:0.4284\n",
      "epoch:165,loss:0.6348\n",
      "epoch:165,loss:0.2200\n",
      "epoch:165,loss:0.1428\n",
      "epoch:165,loss:0.8350\n",
      "epoch:165,loss:1.0653\n",
      "epoch:165,loss:0.0418\n",
      "epoch:165,loss:0.3699\n",
      "epoch:165,loss:0.1609\n",
      "epoch:165,loss:0.1481\n",
      "epoch:165,loss:0.3546\n",
      "epoch:165,loss:0.5003\n",
      "epoch:165,loss:0.2293\n",
      "epoch:165,loss:0.2575\n",
      "epoch:165,loss:0.1846\n",
      "epoch:165,loss:0.6362\n",
      "epoch:165,loss:0.8533\n",
      "epoch:165,loss:0.1056\n",
      "============================================\n",
      "准确率由： tensor(0.8575) 上升至： tensor(0.8649) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第165个epoch的识别准确率为：86%\n",
      "epoch:166,loss:0.2569\n",
      "epoch:166,loss:1.6645\n",
      "epoch:166,loss:0.4258\n",
      "epoch:166,loss:0.5790\n",
      "epoch:166,loss:0.4539\n",
      "epoch:166,loss:0.7715\n",
      "epoch:166,loss:0.1309\n",
      "epoch:166,loss:0.7857\n",
      "epoch:166,loss:0.0660\n",
      "epoch:166,loss:0.2645\n",
      "epoch:166,loss:0.1613\n",
      "epoch:166,loss:0.3105\n",
      "epoch:166,loss:0.3345\n",
      "epoch:166,loss:0.9266\n",
      "epoch:166,loss:0.4271\n",
      "epoch:166,loss:0.7018\n",
      "epoch:166,loss:0.1871\n",
      "epoch:166,loss:0.2941\n",
      "epoch:166,loss:0.7060\n",
      "epoch:166,loss:0.7758\n",
      "epoch:166,loss:0.4188\n",
      "epoch:166,loss:0.1115\n",
      "epoch:166,loss:0.5455\n",
      "epoch:166,loss:0.1506\n",
      "epoch:166,loss:0.9215\n",
      "epoch:166,loss:0.2793\n",
      "epoch:166,loss:0.3615\n",
      "epoch:166,loss:0.3230\n",
      "epoch:166,loss:0.2441\n",
      "epoch:166,loss:0.3537\n",
      "epoch:166,loss:0.8752\n",
      "epoch:166,loss:0.5951\n",
      "epoch:166,loss:0.0221\n",
      "epoch:166,loss:0.0648\n",
      "epoch:166,loss:0.0534\n",
      "epoch:166,loss:0.3290\n",
      "epoch:166,loss:0.6051\n",
      "epoch:166,loss:0.2017\n",
      "epoch:166,loss:0.2940\n",
      "epoch:166,loss:0.9813\n",
      "epoch:166,loss:1.8330\n",
      "epoch:166,loss:0.2097\n",
      "epoch:166,loss:0.1062\n",
      "epoch:166,loss:0.2433\n",
      "epoch:166,loss:0.1413\n",
      "epoch:166,loss:1.6236\n",
      "epoch:166,loss:0.0231\n",
      "epoch:166,loss:0.1700\n",
      "epoch:166,loss:0.4992\n",
      "epoch:166,loss:0.4201\n",
      "epoch:166,loss:0.0369\n",
      "epoch:166,loss:0.3784\n",
      "epoch:166,loss:0.1722\n",
      "epoch:166,loss:0.3176\n",
      "epoch:166,loss:0.3162\n",
      "epoch:166,loss:0.0587\n",
      "epoch:166,loss:0.2381\n",
      "epoch:166,loss:1.2713\n",
      "epoch:166,loss:0.0637\n",
      "epoch:166,loss:0.5300\n",
      "============================================\n",
      "第166个epoch的识别准确率为：86%\n",
      "epoch:167,loss:0.3381\n",
      "epoch:167,loss:1.0928\n",
      "epoch:167,loss:0.1027\n",
      "epoch:167,loss:0.5990\n",
      "epoch:167,loss:0.1202\n",
      "epoch:167,loss:0.2140\n",
      "epoch:167,loss:0.1465\n",
      "epoch:167,loss:0.0280\n",
      "epoch:167,loss:0.3429\n",
      "epoch:167,loss:0.0378\n",
      "epoch:167,loss:0.3226\n",
      "epoch:167,loss:0.1967\n",
      "epoch:167,loss:0.4725\n",
      "epoch:167,loss:0.1249\n",
      "epoch:167,loss:0.3248\n",
      "epoch:167,loss:0.4254\n",
      "epoch:167,loss:0.2847\n",
      "epoch:167,loss:0.0752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:167,loss:0.3169\n",
      "epoch:167,loss:0.5405\n",
      "epoch:167,loss:0.3690\n",
      "epoch:167,loss:0.1197\n",
      "epoch:167,loss:0.1517\n",
      "epoch:167,loss:0.6344\n",
      "epoch:167,loss:0.1870\n",
      "epoch:167,loss:2.8697\n",
      "epoch:167,loss:0.3673\n",
      "epoch:167,loss:0.2265\n",
      "epoch:167,loss:0.4059\n",
      "epoch:167,loss:0.2208\n",
      "epoch:167,loss:0.3325\n",
      "epoch:167,loss:0.6349\n",
      "epoch:167,loss:0.5991\n",
      "epoch:167,loss:0.2758\n",
      "epoch:167,loss:0.1675\n",
      "epoch:167,loss:0.6580\n",
      "epoch:167,loss:0.7085\n",
      "epoch:167,loss:0.8171\n",
      "epoch:167,loss:0.2465\n",
      "epoch:167,loss:0.3479\n",
      "epoch:167,loss:0.1580\n",
      "epoch:167,loss:0.7479\n",
      "epoch:167,loss:0.4874\n",
      "epoch:167,loss:0.2907\n",
      "epoch:167,loss:0.4446\n",
      "epoch:167,loss:0.4127\n",
      "epoch:167,loss:0.2212\n",
      "epoch:167,loss:0.1689\n",
      "epoch:167,loss:0.2483\n",
      "epoch:167,loss:0.1657\n",
      "epoch:167,loss:0.0518\n",
      "epoch:167,loss:0.1772\n",
      "epoch:167,loss:1.0242\n",
      "epoch:167,loss:0.6610\n",
      "epoch:167,loss:1.2626\n",
      "epoch:167,loss:0.0321\n",
      "epoch:167,loss:0.1593\n",
      "epoch:167,loss:0.5255\n",
      "epoch:167,loss:0.0760\n",
      "epoch:167,loss:0.0303\n",
      "============================================\n",
      "第167个epoch的识别准确率为：85%\n",
      "epoch:168,loss:0.4863\n",
      "epoch:168,loss:0.2778\n",
      "epoch:168,loss:0.5176\n",
      "epoch:168,loss:0.2033\n",
      "epoch:168,loss:0.0563\n",
      "epoch:168,loss:0.3628\n",
      "epoch:168,loss:0.4076\n",
      "epoch:168,loss:0.6569\n",
      "epoch:168,loss:0.6799\n",
      "epoch:168,loss:0.2579\n",
      "epoch:168,loss:0.3731\n",
      "epoch:168,loss:0.1415\n",
      "epoch:168,loss:0.1561\n",
      "epoch:168,loss:0.4486\n",
      "epoch:168,loss:0.1876\n",
      "epoch:168,loss:0.3785\n",
      "epoch:168,loss:0.7973\n",
      "epoch:168,loss:0.4588\n",
      "epoch:168,loss:0.0781\n",
      "epoch:168,loss:0.2411\n",
      "epoch:168,loss:0.8788\n",
      "epoch:168,loss:0.1178\n",
      "epoch:168,loss:0.0949\n",
      "epoch:168,loss:0.0953\n",
      "epoch:168,loss:0.6578\n",
      "epoch:168,loss:0.2162\n",
      "epoch:168,loss:0.2025\n",
      "epoch:168,loss:0.6711\n",
      "epoch:168,loss:0.0867\n",
      "epoch:168,loss:0.6674\n",
      "epoch:168,loss:0.0300\n",
      "epoch:168,loss:0.1453\n",
      "epoch:168,loss:0.1348\n",
      "epoch:168,loss:0.4778\n",
      "epoch:168,loss:0.5270\n",
      "epoch:168,loss:0.0939\n",
      "epoch:168,loss:0.5276\n",
      "epoch:168,loss:0.1308\n",
      "epoch:168,loss:0.1392\n",
      "epoch:168,loss:0.0587\n",
      "epoch:168,loss:0.7611\n",
      "epoch:168,loss:0.1742\n",
      "epoch:168,loss:0.3084\n",
      "epoch:168,loss:1.0414\n",
      "epoch:168,loss:0.1254\n",
      "epoch:168,loss:0.1157\n",
      "epoch:168,loss:0.0863\n",
      "epoch:168,loss:0.4666\n",
      "epoch:168,loss:0.1516\n",
      "epoch:168,loss:0.2687\n",
      "epoch:168,loss:0.6136\n",
      "epoch:168,loss:0.3529\n",
      "epoch:168,loss:1.1186\n",
      "epoch:168,loss:0.4278\n",
      "epoch:168,loss:0.2060\n",
      "epoch:168,loss:0.2590\n",
      "epoch:168,loss:0.4173\n",
      "epoch:168,loss:0.1092\n",
      "epoch:168,loss:0.1312\n",
      "epoch:168,loss:0.0580\n",
      "============================================\n",
      "准确率由： tensor(0.8649) 上升至： tensor(0.8860) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第168个epoch的识别准确率为：88%\n",
      "epoch:169,loss:0.5348\n",
      "epoch:169,loss:0.0798\n",
      "epoch:169,loss:0.0880\n",
      "epoch:169,loss:0.4750\n",
      "epoch:169,loss:0.7200\n",
      "epoch:169,loss:0.3480\n",
      "epoch:169,loss:0.7825\n",
      "epoch:169,loss:1.4067\n",
      "epoch:169,loss:0.2815\n",
      "epoch:169,loss:0.5222\n",
      "epoch:169,loss:0.8984\n",
      "epoch:169,loss:0.2627\n",
      "epoch:169,loss:0.1749\n",
      "epoch:169,loss:0.7387\n",
      "epoch:169,loss:0.0287\n",
      "epoch:169,loss:0.0879\n",
      "epoch:169,loss:0.3323\n",
      "epoch:169,loss:0.1215\n",
      "epoch:169,loss:1.5249\n",
      "epoch:169,loss:0.1566\n",
      "epoch:169,loss:0.3060\n",
      "epoch:169,loss:0.1097\n",
      "epoch:169,loss:0.4156\n",
      "epoch:169,loss:0.4910\n",
      "epoch:169,loss:0.3025\n",
      "epoch:169,loss:0.1602\n",
      "epoch:169,loss:0.1474\n",
      "epoch:169,loss:0.2206\n",
      "epoch:169,loss:0.2757\n",
      "epoch:169,loss:1.0044\n",
      "epoch:169,loss:0.0635\n",
      "epoch:169,loss:0.0392\n",
      "epoch:169,loss:0.2321\n",
      "epoch:169,loss:0.3262\n",
      "epoch:169,loss:0.1865\n",
      "epoch:169,loss:0.1367\n",
      "epoch:169,loss:0.5071\n",
      "epoch:169,loss:0.3530\n",
      "epoch:169,loss:0.1176\n",
      "epoch:169,loss:0.0186\n",
      "epoch:169,loss:0.0664\n",
      "epoch:169,loss:0.1209\n",
      "epoch:169,loss:0.1507\n",
      "epoch:169,loss:0.3036\n",
      "epoch:169,loss:0.4361\n",
      "epoch:169,loss:0.1752\n",
      "epoch:169,loss:0.2657\n",
      "epoch:169,loss:0.0400\n",
      "epoch:169,loss:0.1145\n",
      "epoch:169,loss:0.7439\n",
      "epoch:169,loss:0.4845\n",
      "epoch:169,loss:0.0699\n",
      "epoch:169,loss:0.1894\n",
      "epoch:169,loss:0.3347\n",
      "epoch:169,loss:0.0493\n",
      "epoch:169,loss:0.0944\n",
      "epoch:169,loss:0.3734\n",
      "epoch:169,loss:0.5410\n",
      "epoch:169,loss:0.7178\n",
      "epoch:169,loss:0.4194\n",
      "============================================\n",
      "第169个epoch的识别准确率为：87%\n",
      "epoch:170,loss:0.0879\n",
      "epoch:170,loss:0.0998\n",
      "epoch:170,loss:0.4323\n",
      "epoch:170,loss:0.6588\n",
      "epoch:170,loss:0.5771\n",
      "epoch:170,loss:0.1629\n",
      "epoch:170,loss:0.3197\n",
      "epoch:170,loss:0.1739\n",
      "epoch:170,loss:0.1099\n",
      "epoch:170,loss:0.0962\n",
      "epoch:170,loss:0.9954\n",
      "epoch:170,loss:0.0822\n",
      "epoch:170,loss:0.6428\n",
      "epoch:170,loss:0.1139\n",
      "epoch:170,loss:0.3091\n",
      "epoch:170,loss:0.0876\n",
      "epoch:170,loss:0.8007\n",
      "epoch:170,loss:1.7529\n",
      "epoch:170,loss:0.3735\n",
      "epoch:170,loss:0.1534\n",
      "epoch:170,loss:0.0878\n",
      "epoch:170,loss:1.4692\n",
      "epoch:170,loss:0.0708\n",
      "epoch:170,loss:0.3844\n",
      "epoch:170,loss:0.3154\n",
      "epoch:170,loss:0.1328\n",
      "epoch:170,loss:0.7389\n",
      "epoch:170,loss:0.0808\n",
      "epoch:170,loss:0.0409\n",
      "epoch:170,loss:0.6354\n",
      "epoch:170,loss:0.1695\n",
      "epoch:170,loss:0.1283\n",
      "epoch:170,loss:0.5622\n",
      "epoch:170,loss:0.0597\n",
      "epoch:170,loss:0.0627\n",
      "epoch:170,loss:0.0305\n",
      "epoch:170,loss:0.5781\n",
      "epoch:170,loss:0.3437\n",
      "epoch:170,loss:0.8842\n",
      "epoch:170,loss:0.1668\n",
      "epoch:170,loss:1.3338\n",
      "epoch:170,loss:0.0654\n",
      "epoch:170,loss:0.5763\n",
      "epoch:170,loss:1.3911\n",
      "epoch:170,loss:0.4006\n",
      "epoch:170,loss:0.1304\n",
      "epoch:170,loss:0.1259\n",
      "epoch:170,loss:0.2181\n",
      "epoch:170,loss:0.1646\n",
      "epoch:170,loss:0.7994\n",
      "epoch:170,loss:0.1168\n",
      "epoch:170,loss:0.1909\n",
      "epoch:170,loss:0.1553\n",
      "epoch:170,loss:0.1049\n",
      "epoch:170,loss:1.0941\n",
      "epoch:170,loss:0.9195\n",
      "epoch:170,loss:0.0725\n",
      "epoch:170,loss:0.5974\n",
      "epoch:170,loss:0.8228\n",
      "epoch:170,loss:0.1851\n",
      "============================================\n",
      "第170个epoch的识别准确率为：88%\n",
      "epoch:171,loss:0.6718\n",
      "epoch:171,loss:0.0696\n",
      "epoch:171,loss:0.4543\n",
      "epoch:171,loss:0.4770\n",
      "epoch:171,loss:0.5653\n",
      "epoch:171,loss:1.2048\n",
      "epoch:171,loss:1.2786\n",
      "epoch:171,loss:0.1959\n",
      "epoch:171,loss:0.0503\n",
      "epoch:171,loss:0.0703\n",
      "epoch:171,loss:0.5485\n",
      "epoch:171,loss:1.9898\n",
      "epoch:171,loss:1.3840\n",
      "epoch:171,loss:0.0596\n",
      "epoch:171,loss:0.2208\n",
      "epoch:171,loss:0.4735\n",
      "epoch:171,loss:0.1106\n",
      "epoch:171,loss:0.5292\n",
      "epoch:171,loss:2.2058\n",
      "epoch:171,loss:0.1862\n",
      "epoch:171,loss:0.5389\n",
      "epoch:171,loss:0.6533\n",
      "epoch:171,loss:0.2332\n",
      "epoch:171,loss:1.3734\n",
      "epoch:171,loss:0.9798\n",
      "epoch:171,loss:0.0694\n",
      "epoch:171,loss:0.0978\n",
      "epoch:171,loss:0.0990\n",
      "epoch:171,loss:0.0231\n",
      "epoch:171,loss:0.0536\n",
      "epoch:171,loss:0.1346\n",
      "epoch:171,loss:0.1264\n",
      "epoch:171,loss:0.4452\n",
      "epoch:171,loss:0.0606\n",
      "epoch:171,loss:0.0491\n",
      "epoch:171,loss:0.3429\n",
      "epoch:171,loss:0.0683\n",
      "epoch:171,loss:0.2141\n",
      "epoch:171,loss:0.1350\n",
      "epoch:171,loss:0.3994\n",
      "epoch:171,loss:0.0387\n",
      "epoch:171,loss:0.2162\n",
      "epoch:171,loss:0.2423\n",
      "epoch:171,loss:1.4132\n",
      "epoch:171,loss:0.4227\n",
      "epoch:171,loss:0.0274\n",
      "epoch:171,loss:1.0160\n",
      "epoch:171,loss:0.0222\n",
      "epoch:171,loss:0.5158\n",
      "epoch:171,loss:0.4595\n",
      "epoch:171,loss:0.6854\n",
      "epoch:171,loss:0.3929\n",
      "epoch:171,loss:0.5777\n",
      "epoch:171,loss:0.1442\n",
      "epoch:171,loss:0.5206\n",
      "epoch:171,loss:1.2082\n",
      "epoch:171,loss:0.1830\n",
      "epoch:171,loss:0.7927\n",
      "epoch:171,loss:0.1139\n",
      "epoch:171,loss:0.0914\n",
      "============================================\n",
      "第171个epoch的识别准确率为：85%\n",
      "epoch:172,loss:0.0599\n",
      "epoch:172,loss:0.4697\n",
      "epoch:172,loss:0.3089\n",
      "epoch:172,loss:0.2922\n",
      "epoch:172,loss:0.1514\n",
      "epoch:172,loss:0.2989\n",
      "epoch:172,loss:0.6510\n",
      "epoch:172,loss:0.2966\n",
      "epoch:172,loss:0.2759\n",
      "epoch:172,loss:2.5645\n",
      "epoch:172,loss:0.1269\n",
      "epoch:172,loss:1.5663\n",
      "epoch:172,loss:0.4688\n",
      "epoch:172,loss:1.0337\n",
      "epoch:172,loss:0.2722\n",
      "epoch:172,loss:0.3273\n",
      "epoch:172,loss:0.1827\n",
      "epoch:172,loss:0.2389\n",
      "epoch:172,loss:0.3028\n",
      "epoch:172,loss:0.1428\n",
      "epoch:172,loss:0.0696\n",
      "epoch:172,loss:0.7189\n",
      "epoch:172,loss:1.2013\n",
      "epoch:172,loss:0.7721\n",
      "epoch:172,loss:0.2348\n",
      "epoch:172,loss:0.1160\n",
      "epoch:172,loss:1.5690\n",
      "epoch:172,loss:0.7477\n",
      "epoch:172,loss:0.1326\n",
      "epoch:172,loss:0.9580\n",
      "epoch:172,loss:1.0099\n",
      "epoch:172,loss:0.6457\n",
      "epoch:172,loss:0.1144\n",
      "epoch:172,loss:2.0962\n",
      "epoch:172,loss:1.2226\n",
      "epoch:172,loss:0.5073\n",
      "epoch:172,loss:0.3606\n",
      "epoch:172,loss:0.0309\n",
      "epoch:172,loss:0.8899\n",
      "epoch:172,loss:0.8498\n",
      "epoch:172,loss:0.4544\n",
      "epoch:172,loss:0.0180\n",
      "epoch:172,loss:0.2420\n",
      "epoch:172,loss:0.4753\n",
      "epoch:172,loss:0.1122\n",
      "epoch:172,loss:0.3526\n",
      "epoch:172,loss:0.1005\n",
      "epoch:172,loss:0.4397\n",
      "epoch:172,loss:0.1612\n",
      "epoch:172,loss:0.5050\n",
      "epoch:172,loss:0.8799\n",
      "epoch:172,loss:0.0672\n",
      "epoch:172,loss:0.8282\n",
      "epoch:172,loss:0.3077\n",
      "epoch:172,loss:0.4345\n",
      "epoch:172,loss:0.8105\n",
      "epoch:172,loss:0.0460\n",
      "epoch:172,loss:0.0793\n",
      "epoch:172,loss:0.2260\n",
      "epoch:172,loss:0.3427\n",
      "============================================\n",
      "第172个epoch的识别准确率为：85%\n",
      "epoch:173,loss:0.5076\n",
      "epoch:173,loss:0.1816\n",
      "epoch:173,loss:0.3682\n",
      "epoch:173,loss:0.5309\n",
      "epoch:173,loss:0.1145\n",
      "epoch:173,loss:0.8932\n",
      "epoch:173,loss:0.4971\n",
      "epoch:173,loss:0.1124\n",
      "epoch:173,loss:1.4919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:173,loss:0.6321\n",
      "epoch:173,loss:0.0921\n",
      "epoch:173,loss:0.8765\n",
      "epoch:173,loss:0.2020\n",
      "epoch:173,loss:0.4713\n",
      "epoch:173,loss:0.2852\n",
      "epoch:173,loss:0.1362\n",
      "epoch:173,loss:0.3758\n",
      "epoch:173,loss:0.8368\n",
      "epoch:173,loss:0.1732\n",
      "epoch:173,loss:0.2643\n",
      "epoch:173,loss:0.6325\n",
      "epoch:173,loss:0.9138\n",
      "epoch:173,loss:0.1178\n",
      "epoch:173,loss:0.0998\n",
      "epoch:173,loss:0.6776\n",
      "epoch:173,loss:0.1150\n",
      "epoch:173,loss:0.5382\n",
      "epoch:173,loss:0.0897\n",
      "epoch:173,loss:0.1359\n",
      "epoch:173,loss:0.2665\n",
      "epoch:173,loss:0.3344\n",
      "epoch:173,loss:0.6253\n",
      "epoch:173,loss:0.3105\n",
      "epoch:173,loss:0.3690\n",
      "epoch:173,loss:0.9824\n",
      "epoch:173,loss:0.3164\n",
      "epoch:173,loss:0.0541\n",
      "epoch:173,loss:0.9003\n",
      "epoch:173,loss:0.0285\n",
      "epoch:173,loss:0.0732\n",
      "epoch:173,loss:0.3380\n",
      "epoch:173,loss:0.0959\n",
      "epoch:173,loss:0.3642\n",
      "epoch:173,loss:1.0349\n",
      "epoch:173,loss:0.2089\n",
      "epoch:173,loss:0.2456\n",
      "epoch:173,loss:0.8795\n",
      "epoch:173,loss:0.4817\n",
      "epoch:173,loss:0.0819\n",
      "epoch:173,loss:0.2713\n",
      "epoch:173,loss:1.0960\n",
      "epoch:173,loss:0.3967\n",
      "epoch:173,loss:0.1775\n",
      "epoch:173,loss:0.2390\n",
      "epoch:173,loss:0.3760\n",
      "epoch:173,loss:0.1030\n",
      "epoch:173,loss:0.4826\n",
      "epoch:173,loss:0.2208\n",
      "epoch:173,loss:0.4536\n",
      "epoch:173,loss:1.2594\n",
      "============================================\n",
      "第173个epoch的识别准确率为：87%\n",
      "epoch:174,loss:1.4014\n",
      "epoch:174,loss:0.2158\n",
      "epoch:174,loss:0.0925\n",
      "epoch:174,loss:1.5083\n",
      "epoch:174,loss:0.0637\n",
      "epoch:174,loss:0.1200\n",
      "epoch:174,loss:0.0204\n",
      "epoch:174,loss:0.4820\n",
      "epoch:174,loss:0.8816\n",
      "epoch:174,loss:0.5758\n",
      "epoch:174,loss:0.0536\n",
      "epoch:174,loss:0.1076\n",
      "epoch:174,loss:0.9233\n",
      "epoch:174,loss:0.6407\n",
      "epoch:174,loss:0.0332\n",
      "epoch:174,loss:0.5015\n",
      "epoch:174,loss:0.3804\n",
      "epoch:174,loss:0.3198\n",
      "epoch:174,loss:0.0300\n",
      "epoch:174,loss:0.2770\n",
      "epoch:174,loss:0.4984\n",
      "epoch:174,loss:0.1020\n",
      "epoch:174,loss:0.0415\n",
      "epoch:174,loss:0.1487\n",
      "epoch:174,loss:0.6466\n",
      "epoch:174,loss:0.3465\n",
      "epoch:174,loss:1.8073\n",
      "epoch:174,loss:0.6541\n",
      "epoch:174,loss:0.3689\n",
      "epoch:174,loss:0.1531\n",
      "epoch:174,loss:0.1879\n",
      "epoch:174,loss:0.1625\n",
      "epoch:174,loss:0.0110\n",
      "epoch:174,loss:0.0956\n",
      "epoch:174,loss:0.1811\n",
      "epoch:174,loss:0.1654\n",
      "epoch:174,loss:1.0197\n",
      "epoch:174,loss:0.4497\n",
      "epoch:174,loss:0.3528\n",
      "epoch:174,loss:0.2504\n",
      "epoch:174,loss:0.0513\n",
      "epoch:174,loss:0.1259\n",
      "epoch:174,loss:0.1364\n",
      "epoch:174,loss:0.5330\n",
      "epoch:174,loss:0.1167\n",
      "epoch:174,loss:0.2694\n",
      "epoch:174,loss:0.3798\n",
      "epoch:174,loss:0.0850\n",
      "epoch:174,loss:0.1429\n",
      "epoch:174,loss:0.3541\n",
      "epoch:174,loss:0.7718\n",
      "epoch:174,loss:0.5436\n",
      "epoch:174,loss:0.1398\n",
      "epoch:174,loss:0.1704\n",
      "epoch:174,loss:0.2830\n",
      "epoch:174,loss:0.0309\n",
      "epoch:174,loss:0.8487\n",
      "epoch:174,loss:0.2786\n",
      "epoch:174,loss:0.4102\n",
      "epoch:174,loss:0.2089\n",
      "============================================\n",
      "第174个epoch的识别准确率为：87%\n",
      "epoch:175,loss:0.5309\n",
      "epoch:175,loss:0.5879\n",
      "epoch:175,loss:0.1090\n",
      "epoch:175,loss:0.1426\n",
      "epoch:175,loss:0.1842\n",
      "epoch:175,loss:0.1889\n",
      "epoch:175,loss:0.2019\n",
      "epoch:175,loss:0.5957\n",
      "epoch:175,loss:0.0611\n",
      "epoch:175,loss:0.8298\n",
      "epoch:175,loss:0.7676\n",
      "epoch:175,loss:0.0616\n",
      "epoch:175,loss:0.7489\n",
      "epoch:175,loss:0.0215\n",
      "epoch:175,loss:0.0704\n",
      "epoch:175,loss:0.8749\n",
      "epoch:175,loss:0.3290\n",
      "epoch:175,loss:0.5172\n",
      "epoch:175,loss:1.5456\n",
      "epoch:175,loss:0.0424\n",
      "epoch:175,loss:0.0582\n",
      "epoch:175,loss:0.2204\n",
      "epoch:175,loss:0.0976\n",
      "epoch:175,loss:1.2309\n",
      "epoch:175,loss:0.6645\n",
      "epoch:175,loss:0.0818\n",
      "epoch:175,loss:0.0766\n",
      "epoch:175,loss:0.1440\n",
      "epoch:175,loss:0.1720\n",
      "epoch:175,loss:0.1126\n",
      "epoch:175,loss:0.2232\n",
      "epoch:175,loss:0.0873\n",
      "epoch:175,loss:0.1002\n",
      "epoch:175,loss:0.0516\n",
      "epoch:175,loss:0.9157\n",
      "epoch:175,loss:0.0227\n",
      "epoch:175,loss:0.1533\n",
      "epoch:175,loss:0.2539\n",
      "epoch:175,loss:0.3673\n",
      "epoch:175,loss:1.0808\n",
      "epoch:175,loss:0.1975\n",
      "epoch:175,loss:0.2093\n",
      "epoch:175,loss:0.1541\n",
      "epoch:175,loss:0.1569\n",
      "epoch:175,loss:0.0971\n",
      "epoch:175,loss:0.2223\n",
      "epoch:175,loss:0.6197\n",
      "epoch:175,loss:0.2212\n",
      "epoch:175,loss:0.5045\n",
      "epoch:175,loss:0.2895\n",
      "epoch:175,loss:0.2323\n",
      "epoch:175,loss:0.1481\n",
      "epoch:175,loss:0.2954\n",
      "epoch:175,loss:0.1560\n",
      "epoch:175,loss:0.4780\n",
      "epoch:175,loss:2.6168\n",
      "epoch:175,loss:0.3633\n",
      "epoch:175,loss:0.5247\n",
      "epoch:175,loss:0.3120\n",
      "epoch:175,loss:0.4566\n",
      "============================================\n",
      "第175个epoch的识别准确率为：88%\n",
      "epoch:176,loss:1.0311\n",
      "epoch:176,loss:0.1945\n",
      "epoch:176,loss:0.2337\n",
      "epoch:176,loss:0.5990\n",
      "epoch:176,loss:0.2124\n",
      "epoch:176,loss:0.1141\n",
      "epoch:176,loss:0.1897\n",
      "epoch:176,loss:0.9811\n",
      "epoch:176,loss:0.5057\n",
      "epoch:176,loss:0.0738\n",
      "epoch:176,loss:1.0645\n",
      "epoch:176,loss:0.7125\n",
      "epoch:176,loss:0.1156\n",
      "epoch:176,loss:0.0249\n",
      "epoch:176,loss:0.4257\n",
      "epoch:176,loss:0.0494\n",
      "epoch:176,loss:0.2207\n",
      "epoch:176,loss:0.0859\n",
      "epoch:176,loss:0.6941\n",
      "epoch:176,loss:0.0524\n",
      "epoch:176,loss:0.1788\n",
      "epoch:176,loss:1.2790\n",
      "epoch:176,loss:0.6217\n",
      "epoch:176,loss:0.1373\n",
      "epoch:176,loss:0.3152\n",
      "epoch:176,loss:0.0805\n",
      "epoch:176,loss:0.8132\n",
      "epoch:176,loss:0.2429\n",
      "epoch:176,loss:0.1022\n",
      "epoch:176,loss:0.0981\n",
      "epoch:176,loss:0.3034\n",
      "epoch:176,loss:0.3093\n",
      "epoch:176,loss:0.2239\n",
      "epoch:176,loss:0.2891\n",
      "epoch:176,loss:0.6877\n",
      "epoch:176,loss:0.4053\n",
      "epoch:176,loss:0.1669\n",
      "epoch:176,loss:0.1443\n",
      "epoch:176,loss:0.7156\n",
      "epoch:176,loss:1.7458\n",
      "epoch:176,loss:0.3403\n",
      "epoch:176,loss:0.0928\n",
      "epoch:176,loss:0.1145\n",
      "epoch:176,loss:0.0555\n",
      "epoch:176,loss:0.0237\n",
      "epoch:176,loss:0.0272\n",
      "epoch:176,loss:0.2271\n",
      "epoch:176,loss:0.5537\n",
      "epoch:176,loss:0.2941\n",
      "epoch:176,loss:0.0198\n",
      "epoch:176,loss:0.5082\n",
      "epoch:176,loss:1.2746\n",
      "epoch:176,loss:0.0997\n",
      "epoch:176,loss:0.0683\n",
      "epoch:176,loss:0.2253\n",
      "epoch:176,loss:0.1049\n",
      "epoch:176,loss:0.2927\n",
      "epoch:176,loss:0.1720\n",
      "epoch:176,loss:0.4425\n",
      "epoch:176,loss:0.0358\n",
      "============================================\n",
      "第176个epoch的识别准确率为：87%\n",
      "epoch:177,loss:0.5094\n",
      "epoch:177,loss:0.2750\n",
      "epoch:177,loss:1.1392\n",
      "epoch:177,loss:0.2890\n",
      "epoch:177,loss:0.1737\n",
      "epoch:177,loss:0.9446\n",
      "epoch:177,loss:0.2622\n",
      "epoch:177,loss:0.3453\n",
      "epoch:177,loss:0.0668\n",
      "epoch:177,loss:1.3711\n",
      "epoch:177,loss:0.3201\n",
      "epoch:177,loss:0.0566\n",
      "epoch:177,loss:0.4496\n",
      "epoch:177,loss:0.1422\n",
      "epoch:177,loss:0.5120\n",
      "epoch:177,loss:1.8397\n",
      "epoch:177,loss:0.2874\n",
      "epoch:177,loss:0.4458\n",
      "epoch:177,loss:0.7153\n",
      "epoch:177,loss:0.2537\n",
      "epoch:177,loss:0.3074\n",
      "epoch:177,loss:0.1091\n",
      "epoch:177,loss:0.1561\n",
      "epoch:177,loss:0.1864\n",
      "epoch:177,loss:1.7215\n",
      "epoch:177,loss:0.0087\n",
      "epoch:177,loss:0.2471\n",
      "epoch:177,loss:0.1399\n",
      "epoch:177,loss:0.3703\n",
      "epoch:177,loss:0.3344\n",
      "epoch:177,loss:0.2535\n",
      "epoch:177,loss:0.0499\n",
      "epoch:177,loss:0.0806\n",
      "epoch:177,loss:0.0920\n",
      "epoch:177,loss:0.9593\n",
      "epoch:177,loss:0.2300\n",
      "epoch:177,loss:1.0495\n",
      "epoch:177,loss:0.5724\n",
      "epoch:177,loss:0.5936\n",
      "epoch:177,loss:0.8758\n",
      "epoch:177,loss:1.2302\n",
      "epoch:177,loss:0.3926\n",
      "epoch:177,loss:0.1238\n",
      "epoch:177,loss:0.5460\n",
      "epoch:177,loss:1.6082\n",
      "epoch:177,loss:0.1704\n",
      "epoch:177,loss:0.0955\n",
      "epoch:177,loss:0.1904\n",
      "epoch:177,loss:0.2105\n",
      "epoch:177,loss:0.0712\n",
      "epoch:177,loss:0.0116\n",
      "epoch:177,loss:0.3802\n",
      "epoch:177,loss:0.4973\n",
      "epoch:177,loss:0.8161\n",
      "epoch:177,loss:1.8921\n",
      "epoch:177,loss:0.7342\n",
      "epoch:177,loss:0.1964\n",
      "epoch:177,loss:0.0362\n",
      "epoch:177,loss:0.3745\n",
      "epoch:177,loss:0.1026\n",
      "============================================\n",
      "第177个epoch的识别准确率为：87%\n",
      "epoch:178,loss:0.5452\n",
      "epoch:178,loss:0.3934\n",
      "epoch:178,loss:0.2401\n",
      "epoch:178,loss:0.1687\n",
      "epoch:178,loss:0.0998\n",
      "epoch:178,loss:0.1585\n",
      "epoch:178,loss:0.2778\n",
      "epoch:178,loss:0.0460\n",
      "epoch:178,loss:0.0550\n",
      "epoch:178,loss:0.3071\n",
      "epoch:178,loss:0.0476\n",
      "epoch:178,loss:0.2897\n",
      "epoch:178,loss:2.1634\n",
      "epoch:178,loss:0.0497\n",
      "epoch:178,loss:0.0310\n",
      "epoch:178,loss:0.6408\n",
      "epoch:178,loss:0.6228\n",
      "epoch:178,loss:0.0174\n",
      "epoch:178,loss:0.6888\n",
      "epoch:178,loss:0.4122\n",
      "epoch:178,loss:0.7194\n",
      "epoch:178,loss:1.1904\n",
      "epoch:178,loss:1.1288\n",
      "epoch:178,loss:0.2992\n",
      "epoch:178,loss:0.5419\n",
      "epoch:178,loss:0.5657\n",
      "epoch:178,loss:0.3730\n",
      "epoch:178,loss:0.3372\n",
      "epoch:178,loss:0.2189\n",
      "epoch:178,loss:0.6868\n",
      "epoch:178,loss:0.7759\n",
      "epoch:178,loss:0.2066\n",
      "epoch:178,loss:0.3844\n",
      "epoch:178,loss:0.2157\n",
      "epoch:178,loss:0.3932\n",
      "epoch:178,loss:0.0659\n",
      "epoch:178,loss:0.0390\n",
      "epoch:178,loss:0.1882\n",
      "epoch:178,loss:0.2362\n",
      "epoch:178,loss:1.5748\n",
      "epoch:178,loss:0.0452\n",
      "epoch:178,loss:0.1352\n",
      "epoch:178,loss:0.3631\n",
      "epoch:178,loss:0.2498\n",
      "epoch:178,loss:0.0812\n",
      "epoch:178,loss:0.2356\n",
      "epoch:178,loss:0.2179\n",
      "epoch:178,loss:0.0391\n",
      "epoch:178,loss:0.6571\n",
      "epoch:178,loss:0.1531\n",
      "epoch:178,loss:0.1887\n",
      "epoch:178,loss:0.4711\n",
      "epoch:178,loss:0.1045\n",
      "epoch:178,loss:1.0009\n",
      "epoch:178,loss:0.2713\n",
      "epoch:178,loss:1.1071\n",
      "epoch:178,loss:0.1242\n",
      "epoch:178,loss:0.3996\n",
      "epoch:178,loss:0.0998\n",
      "epoch:178,loss:1.1657\n",
      "============================================\n",
      "第178个epoch的识别准确率为：86%\n",
      "epoch:179,loss:0.4200\n",
      "epoch:179,loss:0.4038\n",
      "epoch:179,loss:0.1636\n",
      "epoch:179,loss:0.0390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:179,loss:0.6446\n",
      "epoch:179,loss:0.3494\n",
      "epoch:179,loss:0.0695\n",
      "epoch:179,loss:0.0678\n",
      "epoch:179,loss:0.4103\n",
      "epoch:179,loss:0.2641\n",
      "epoch:179,loss:0.0838\n",
      "epoch:179,loss:0.0335\n",
      "epoch:179,loss:0.9638\n",
      "epoch:179,loss:0.1803\n",
      "epoch:179,loss:0.0279\n",
      "epoch:179,loss:0.3131\n",
      "epoch:179,loss:0.0849\n",
      "epoch:179,loss:0.5746\n",
      "epoch:179,loss:0.3570\n",
      "epoch:179,loss:1.7115\n",
      "epoch:179,loss:0.4850\n",
      "epoch:179,loss:0.4744\n",
      "epoch:179,loss:0.4561\n",
      "epoch:179,loss:0.8901\n",
      "epoch:179,loss:0.0440\n",
      "epoch:179,loss:0.1052\n",
      "epoch:179,loss:0.0769\n",
      "epoch:179,loss:1.1357\n",
      "epoch:179,loss:0.0352\n",
      "epoch:179,loss:0.3247\n",
      "epoch:179,loss:0.3395\n",
      "epoch:179,loss:0.0333\n",
      "epoch:179,loss:0.2111\n",
      "epoch:179,loss:0.0492\n",
      "epoch:179,loss:0.1502\n",
      "epoch:179,loss:1.0887\n",
      "epoch:179,loss:1.7330\n",
      "epoch:179,loss:0.0833\n",
      "epoch:179,loss:0.2924\n",
      "epoch:179,loss:0.8235\n",
      "epoch:179,loss:0.0599\n",
      "epoch:179,loss:0.2586\n",
      "epoch:179,loss:1.3902\n",
      "epoch:179,loss:0.0362\n",
      "epoch:179,loss:0.1190\n",
      "epoch:179,loss:0.0505\n",
      "epoch:179,loss:0.5747\n",
      "epoch:179,loss:0.1581\n",
      "epoch:179,loss:0.2197\n",
      "epoch:179,loss:0.4546\n",
      "epoch:179,loss:1.5315\n",
      "epoch:179,loss:0.0846\n",
      "epoch:179,loss:0.0604\n",
      "epoch:179,loss:0.8192\n",
      "epoch:179,loss:0.7003\n",
      "epoch:179,loss:0.5367\n",
      "epoch:179,loss:0.1479\n",
      "epoch:179,loss:0.0144\n",
      "epoch:179,loss:0.0503\n",
      "epoch:179,loss:0.4139\n",
      "============================================\n",
      "第179个epoch的识别准确率为：87%\n",
      "epoch:180,loss:1.0979\n",
      "epoch:180,loss:0.1643\n",
      "epoch:180,loss:0.2427\n",
      "epoch:180,loss:1.1702\n",
      "epoch:180,loss:0.1615\n",
      "epoch:180,loss:1.1563\n",
      "epoch:180,loss:0.5942\n",
      "epoch:180,loss:0.0932\n",
      "epoch:180,loss:0.0100\n",
      "epoch:180,loss:0.4033\n",
      "epoch:180,loss:0.0258\n",
      "epoch:180,loss:0.1275\n",
      "epoch:180,loss:1.0207\n",
      "epoch:180,loss:1.3176\n",
      "epoch:180,loss:0.6066\n",
      "epoch:180,loss:0.2019\n",
      "epoch:180,loss:0.2602\n",
      "epoch:180,loss:0.3390\n",
      "epoch:180,loss:0.4522\n",
      "epoch:180,loss:0.0789\n",
      "epoch:180,loss:0.0470\n",
      "epoch:180,loss:0.1987\n",
      "epoch:180,loss:0.4884\n",
      "epoch:180,loss:0.1646\n",
      "epoch:180,loss:0.3910\n",
      "epoch:180,loss:0.3599\n",
      "epoch:180,loss:0.1306\n",
      "epoch:180,loss:0.0628\n",
      "epoch:180,loss:0.4912\n",
      "epoch:180,loss:0.8937\n",
      "epoch:180,loss:0.8788\n",
      "epoch:180,loss:0.0597\n",
      "epoch:180,loss:0.2733\n",
      "epoch:180,loss:0.0252\n",
      "epoch:180,loss:0.1601\n",
      "epoch:180,loss:1.1339\n",
      "epoch:180,loss:0.2607\n",
      "epoch:180,loss:0.0212\n",
      "epoch:180,loss:0.4784\n",
      "epoch:180,loss:0.5612\n",
      "epoch:180,loss:0.0246\n",
      "epoch:180,loss:0.2362\n",
      "epoch:180,loss:1.0134\n",
      "epoch:180,loss:0.0333\n",
      "epoch:180,loss:0.4998\n",
      "epoch:180,loss:0.1835\n",
      "epoch:180,loss:0.9155\n",
      "epoch:180,loss:0.1086\n",
      "epoch:180,loss:0.5270\n",
      "epoch:180,loss:0.2180\n",
      "epoch:180,loss:0.1246\n",
      "epoch:180,loss:0.0606\n",
      "epoch:180,loss:0.0623\n",
      "epoch:180,loss:0.1933\n",
      "epoch:180,loss:0.1303\n",
      "epoch:180,loss:0.5478\n",
      "epoch:180,loss:0.0646\n",
      "epoch:180,loss:0.2169\n",
      "epoch:180,loss:0.6479\n",
      "epoch:180,loss:0.1828\n",
      "============================================\n",
      "准确率由： tensor(0.8860) 上升至： tensor(0.8888) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第180个epoch的识别准确率为：88%\n",
      "epoch:181,loss:0.3722\n",
      "epoch:181,loss:0.3530\n",
      "epoch:181,loss:0.1933\n",
      "epoch:181,loss:0.0394\n",
      "epoch:181,loss:0.1400\n",
      "epoch:181,loss:0.2715\n",
      "epoch:181,loss:0.3043\n",
      "epoch:181,loss:0.0165\n",
      "epoch:181,loss:0.1049\n",
      "epoch:181,loss:0.6407\n",
      "epoch:181,loss:0.9663\n",
      "epoch:181,loss:0.1892\n",
      "epoch:181,loss:0.2025\n",
      "epoch:181,loss:0.0828\n",
      "epoch:181,loss:1.0001\n",
      "epoch:181,loss:0.5485\n",
      "epoch:181,loss:0.2814\n",
      "epoch:181,loss:1.7306\n",
      "epoch:181,loss:0.0214\n",
      "epoch:181,loss:0.4413\n",
      "epoch:181,loss:0.9375\n",
      "epoch:181,loss:1.5828\n",
      "epoch:181,loss:0.0126\n",
      "epoch:181,loss:0.1794\n",
      "epoch:181,loss:0.2933\n",
      "epoch:181,loss:0.0388\n",
      "epoch:181,loss:0.2767\n",
      "epoch:181,loss:0.2619\n",
      "epoch:181,loss:0.1808\n",
      "epoch:181,loss:0.0866\n",
      "epoch:181,loss:0.6571\n",
      "epoch:181,loss:0.4916\n",
      "epoch:181,loss:0.1015\n",
      "epoch:181,loss:0.0052\n",
      "epoch:181,loss:0.4115\n",
      "epoch:181,loss:0.4626\n",
      "epoch:181,loss:0.0758\n",
      "epoch:181,loss:0.9684\n",
      "epoch:181,loss:0.1335\n",
      "epoch:181,loss:0.7895\n",
      "epoch:181,loss:0.2254\n",
      "epoch:181,loss:1.1438\n",
      "epoch:181,loss:0.6227\n",
      "epoch:181,loss:0.4374\n",
      "epoch:181,loss:0.4953\n",
      "epoch:181,loss:0.1053\n",
      "epoch:181,loss:0.2962\n",
      "epoch:181,loss:0.6208\n",
      "epoch:181,loss:1.8032\n",
      "epoch:181,loss:0.0370\n",
      "epoch:181,loss:0.4970\n",
      "epoch:181,loss:0.6155\n",
      "epoch:181,loss:0.0405\n",
      "epoch:181,loss:0.1870\n",
      "epoch:181,loss:0.0302\n",
      "epoch:181,loss:0.9172\n",
      "epoch:181,loss:0.5788\n",
      "epoch:181,loss:0.1677\n",
      "epoch:181,loss:0.3885\n",
      "epoch:181,loss:1.5001\n",
      "============================================\n",
      "第181个epoch的识别准确率为：86%\n",
      "epoch:182,loss:0.0426\n",
      "epoch:182,loss:0.1908\n",
      "epoch:182,loss:0.0548\n",
      "epoch:182,loss:0.3613\n",
      "epoch:182,loss:0.2756\n",
      "epoch:182,loss:0.7759\n",
      "epoch:182,loss:0.9194\n",
      "epoch:182,loss:0.8257\n",
      "epoch:182,loss:0.6569\n",
      "epoch:182,loss:0.2868\n",
      "epoch:182,loss:0.2916\n",
      "epoch:182,loss:0.2047\n",
      "epoch:182,loss:0.1128\n",
      "epoch:182,loss:1.2032\n",
      "epoch:182,loss:0.2753\n",
      "epoch:182,loss:0.0517\n",
      "epoch:182,loss:0.7003\n",
      "epoch:182,loss:0.2432\n",
      "epoch:182,loss:0.4879\n",
      "epoch:182,loss:0.0658\n",
      "epoch:182,loss:1.0013\n",
      "epoch:182,loss:0.1944\n",
      "epoch:182,loss:0.0582\n",
      "epoch:182,loss:0.1548\n",
      "epoch:182,loss:0.0561\n",
      "epoch:182,loss:0.4107\n",
      "epoch:182,loss:0.1678\n",
      "epoch:182,loss:0.1143\n",
      "epoch:182,loss:0.6200\n",
      "epoch:182,loss:0.2115\n",
      "epoch:182,loss:0.0590\n",
      "epoch:182,loss:0.1522\n",
      "epoch:182,loss:0.2259\n",
      "epoch:182,loss:0.1590\n",
      "epoch:182,loss:0.3394\n",
      "epoch:182,loss:0.1517\n",
      "epoch:182,loss:0.0098\n",
      "epoch:182,loss:0.0833\n",
      "epoch:182,loss:0.7219\n",
      "epoch:182,loss:0.7163\n",
      "epoch:182,loss:0.1138\n",
      "epoch:182,loss:0.6117\n",
      "epoch:182,loss:0.0458\n",
      "epoch:182,loss:0.2395\n",
      "epoch:182,loss:0.2728\n",
      "epoch:182,loss:0.3538\n",
      "epoch:182,loss:0.0152\n",
      "epoch:182,loss:0.1455\n",
      "epoch:182,loss:0.1721\n",
      "epoch:182,loss:0.1725\n",
      "epoch:182,loss:0.1915\n",
      "epoch:182,loss:1.8840\n",
      "epoch:182,loss:0.0690\n",
      "epoch:182,loss:0.4748\n",
      "epoch:182,loss:0.1827\n",
      "epoch:182,loss:1.9067\n",
      "epoch:182,loss:0.0297\n",
      "epoch:182,loss:0.8580\n",
      "epoch:182,loss:0.0832\n",
      "epoch:182,loss:0.0213\n",
      "============================================\n",
      "准确率由： tensor(0.8888) 上升至： tensor(0.8943) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第182个epoch的识别准确率为：89%\n",
      "epoch:183,loss:0.2326\n",
      "epoch:183,loss:0.3355\n",
      "epoch:183,loss:0.1312\n",
      "epoch:183,loss:0.2192\n",
      "epoch:183,loss:0.0424\n",
      "epoch:183,loss:0.0183\n",
      "epoch:183,loss:0.0249\n",
      "epoch:183,loss:0.1819\n",
      "epoch:183,loss:0.2806\n",
      "epoch:183,loss:0.2402\n",
      "epoch:183,loss:0.1376\n",
      "epoch:183,loss:0.2214\n",
      "epoch:183,loss:0.0907\n",
      "epoch:183,loss:0.3711\n",
      "epoch:183,loss:0.3509\n",
      "epoch:183,loss:0.0341\n",
      "epoch:183,loss:0.1445\n",
      "epoch:183,loss:0.0613\n",
      "epoch:183,loss:0.6096\n",
      "epoch:183,loss:0.1355\n",
      "epoch:183,loss:0.2849\n",
      "epoch:183,loss:0.0518\n",
      "epoch:183,loss:0.3471\n",
      "epoch:183,loss:0.9375\n",
      "epoch:183,loss:0.0211\n",
      "epoch:183,loss:0.2382\n",
      "epoch:183,loss:0.7166\n",
      "epoch:183,loss:0.8929\n",
      "epoch:183,loss:0.5969\n",
      "epoch:183,loss:0.2482\n",
      "epoch:183,loss:0.5497\n",
      "epoch:183,loss:1.9193\n",
      "epoch:183,loss:0.0532\n",
      "epoch:183,loss:0.3026\n",
      "epoch:183,loss:0.1089\n",
      "epoch:183,loss:0.5627\n",
      "epoch:183,loss:0.9533\n",
      "epoch:183,loss:0.1123\n",
      "epoch:183,loss:0.0886\n",
      "epoch:183,loss:1.1076\n",
      "epoch:183,loss:0.2089\n",
      "epoch:183,loss:0.2349\n",
      "epoch:183,loss:0.2319\n",
      "epoch:183,loss:0.5576\n",
      "epoch:183,loss:0.3325\n",
      "epoch:183,loss:1.0260\n",
      "epoch:183,loss:0.2602\n",
      "epoch:183,loss:1.0048\n",
      "epoch:183,loss:0.1829\n",
      "epoch:183,loss:0.1303\n",
      "epoch:183,loss:1.2908\n",
      "epoch:183,loss:0.2827\n",
      "epoch:183,loss:1.1548\n",
      "epoch:183,loss:0.1318\n",
      "epoch:183,loss:0.3625\n",
      "epoch:183,loss:0.1966\n",
      "epoch:183,loss:0.4931\n",
      "epoch:183,loss:0.8244\n",
      "epoch:183,loss:0.7803\n",
      "epoch:183,loss:0.7375\n",
      "============================================\n",
      "第183个epoch的识别准确率为：85%\n",
      "epoch:184,loss:0.1478\n",
      "epoch:184,loss:0.0137\n",
      "epoch:184,loss:0.3273\n",
      "epoch:184,loss:0.0138\n",
      "epoch:184,loss:0.1257\n",
      "epoch:184,loss:0.4847\n",
      "epoch:184,loss:0.8285\n",
      "epoch:184,loss:0.0980\n",
      "epoch:184,loss:0.0163\n",
      "epoch:184,loss:0.9865\n",
      "epoch:184,loss:0.8796\n",
      "epoch:184,loss:0.1631\n",
      "epoch:184,loss:0.2262\n",
      "epoch:184,loss:0.5424\n",
      "epoch:184,loss:0.6665\n",
      "epoch:184,loss:0.2590\n",
      "epoch:184,loss:0.2373\n",
      "epoch:184,loss:0.0600\n",
      "epoch:184,loss:1.3951\n",
      "epoch:184,loss:0.5163\n",
      "epoch:184,loss:0.4608\n",
      "epoch:184,loss:0.3369\n",
      "epoch:184,loss:0.0494\n",
      "epoch:184,loss:1.1436\n",
      "epoch:184,loss:0.2030\n",
      "epoch:184,loss:0.3602\n",
      "epoch:184,loss:0.1769\n",
      "epoch:184,loss:0.2763\n",
      "epoch:184,loss:0.0807\n",
      "epoch:184,loss:0.9877\n",
      "epoch:184,loss:0.3892\n",
      "epoch:184,loss:0.0915\n",
      "epoch:184,loss:0.4038\n",
      "epoch:184,loss:0.3177\n",
      "epoch:184,loss:0.5291\n",
      "epoch:184,loss:0.2459\n",
      "epoch:184,loss:0.7796\n",
      "epoch:184,loss:0.4937\n",
      "epoch:184,loss:0.5160\n",
      "epoch:184,loss:0.0566\n",
      "epoch:184,loss:0.0609\n",
      "epoch:184,loss:0.1872\n",
      "epoch:184,loss:0.2159\n",
      "epoch:184,loss:0.0832\n",
      "epoch:184,loss:0.2389\n",
      "epoch:184,loss:1.9417\n",
      "epoch:184,loss:0.4264\n",
      "epoch:184,loss:0.4499\n",
      "epoch:184,loss:0.3101\n",
      "epoch:184,loss:0.5571\n",
      "epoch:184,loss:0.1638\n",
      "epoch:184,loss:0.6723\n",
      "epoch:184,loss:0.0835\n",
      "epoch:184,loss:0.2514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:184,loss:0.7862\n",
      "epoch:184,loss:0.3831\n",
      "epoch:184,loss:0.5639\n",
      "epoch:184,loss:0.1763\n",
      "epoch:184,loss:0.1215\n",
      "epoch:184,loss:0.7523\n",
      "============================================\n",
      "第184个epoch的识别准确率为：87%\n",
      "epoch:185,loss:0.0466\n",
      "epoch:185,loss:0.0902\n",
      "epoch:185,loss:0.0515\n",
      "epoch:185,loss:0.0395\n",
      "epoch:185,loss:0.0509\n",
      "epoch:185,loss:0.1021\n",
      "epoch:185,loss:0.2653\n",
      "epoch:185,loss:0.1116\n",
      "epoch:185,loss:1.2846\n",
      "epoch:185,loss:4.5494\n",
      "epoch:185,loss:0.2037\n",
      "epoch:185,loss:0.5586\n",
      "epoch:185,loss:0.1132\n",
      "epoch:185,loss:0.7877\n",
      "epoch:185,loss:0.5173\n",
      "epoch:185,loss:0.2769\n",
      "epoch:185,loss:0.2842\n",
      "epoch:185,loss:0.1389\n",
      "epoch:185,loss:0.1013\n",
      "epoch:185,loss:0.4481\n",
      "epoch:185,loss:1.1454\n",
      "epoch:185,loss:0.3668\n",
      "epoch:185,loss:0.3020\n",
      "epoch:185,loss:2.0612\n",
      "epoch:185,loss:0.5521\n",
      "epoch:185,loss:0.5817\n",
      "epoch:185,loss:0.1490\n",
      "epoch:185,loss:0.1658\n",
      "epoch:185,loss:0.0044\n",
      "epoch:185,loss:1.0311\n",
      "epoch:185,loss:0.4356\n",
      "epoch:185,loss:0.3020\n",
      "epoch:185,loss:0.0555\n",
      "epoch:185,loss:1.0263\n",
      "epoch:185,loss:0.3387\n",
      "epoch:185,loss:0.0507\n",
      "epoch:185,loss:0.1730\n",
      "epoch:185,loss:0.2046\n",
      "epoch:185,loss:1.1706\n",
      "epoch:185,loss:0.1409\n",
      "epoch:185,loss:0.0416\n",
      "epoch:185,loss:0.7399\n",
      "epoch:185,loss:0.3347\n",
      "epoch:185,loss:1.1495\n",
      "epoch:185,loss:0.1615\n",
      "epoch:185,loss:0.1196\n",
      "epoch:185,loss:0.5591\n",
      "epoch:185,loss:0.1342\n",
      "epoch:185,loss:0.2038\n",
      "epoch:185,loss:0.2865\n",
      "epoch:185,loss:0.1398\n",
      "epoch:185,loss:0.1686\n",
      "epoch:185,loss:0.7127\n",
      "epoch:185,loss:0.7688\n",
      "epoch:185,loss:0.2642\n",
      "epoch:185,loss:0.1329\n",
      "epoch:185,loss:0.5055\n",
      "epoch:185,loss:0.5612\n",
      "epoch:185,loss:0.2451\n",
      "epoch:185,loss:0.3736\n",
      "============================================\n",
      "第185个epoch的识别准确率为：83%\n",
      "epoch:186,loss:0.0522\n",
      "epoch:186,loss:1.6485\n",
      "epoch:186,loss:0.1913\n",
      "epoch:186,loss:0.0395\n",
      "epoch:186,loss:0.0309\n",
      "epoch:186,loss:0.0431\n",
      "epoch:186,loss:0.1204\n",
      "epoch:186,loss:0.3105\n",
      "epoch:186,loss:0.4419\n",
      "epoch:186,loss:0.4195\n",
      "epoch:186,loss:0.0958\n",
      "epoch:186,loss:0.2478\n",
      "epoch:186,loss:0.4585\n",
      "epoch:186,loss:0.2308\n",
      "epoch:186,loss:0.0483\n",
      "epoch:186,loss:0.0483\n",
      "epoch:186,loss:0.5306\n",
      "epoch:186,loss:1.1015\n",
      "epoch:186,loss:0.0909\n",
      "epoch:186,loss:0.0992\n",
      "epoch:186,loss:1.0510\n",
      "epoch:186,loss:0.0585\n",
      "epoch:186,loss:0.5556\n",
      "epoch:186,loss:0.7922\n",
      "epoch:186,loss:0.5214\n",
      "epoch:186,loss:0.2391\n",
      "epoch:186,loss:0.0806\n",
      "epoch:186,loss:0.0352\n",
      "epoch:186,loss:0.2223\n",
      "epoch:186,loss:0.1234\n",
      "epoch:186,loss:0.0730\n",
      "epoch:186,loss:0.0411\n",
      "epoch:186,loss:0.1206\n",
      "epoch:186,loss:0.0316\n",
      "epoch:186,loss:0.0729\n",
      "epoch:186,loss:0.0773\n",
      "epoch:186,loss:0.0966\n",
      "epoch:186,loss:0.1897\n",
      "epoch:186,loss:0.4502\n",
      "epoch:186,loss:1.0547\n",
      "epoch:186,loss:0.1363\n",
      "epoch:186,loss:0.7846\n",
      "epoch:186,loss:0.0856\n",
      "epoch:186,loss:0.3583\n",
      "epoch:186,loss:0.0757\n",
      "epoch:186,loss:1.6118\n",
      "epoch:186,loss:0.2447\n",
      "epoch:186,loss:0.7645\n",
      "epoch:186,loss:0.4012\n",
      "epoch:186,loss:0.6586\n",
      "epoch:186,loss:1.9114\n",
      "epoch:186,loss:0.4643\n",
      "epoch:186,loss:0.0885\n",
      "epoch:186,loss:0.1702\n",
      "epoch:186,loss:0.3374\n",
      "epoch:186,loss:0.1736\n",
      "epoch:186,loss:0.2271\n",
      "epoch:186,loss:1.2495\n",
      "epoch:186,loss:0.0757\n",
      "epoch:186,loss:0.9243\n",
      "============================================\n",
      "第186个epoch的识别准确率为：85%\n",
      "epoch:187,loss:0.5123\n",
      "epoch:187,loss:0.0794\n",
      "epoch:187,loss:0.0438\n",
      "epoch:187,loss:0.3759\n",
      "epoch:187,loss:0.0891\n",
      "epoch:187,loss:0.0902\n",
      "epoch:187,loss:0.3882\n",
      "epoch:187,loss:0.3165\n",
      "epoch:187,loss:0.2409\n",
      "epoch:187,loss:0.5591\n",
      "epoch:187,loss:0.1890\n",
      "epoch:187,loss:0.1684\n",
      "epoch:187,loss:0.0212\n",
      "epoch:187,loss:0.7552\n",
      "epoch:187,loss:0.0309\n",
      "epoch:187,loss:0.1075\n",
      "epoch:187,loss:0.0948\n",
      "epoch:187,loss:0.0942\n",
      "epoch:187,loss:0.0495\n",
      "epoch:187,loss:0.6522\n",
      "epoch:187,loss:0.2368\n",
      "epoch:187,loss:0.3508\n",
      "epoch:187,loss:0.0540\n",
      "epoch:187,loss:0.0423\n",
      "epoch:187,loss:0.4979\n",
      "epoch:187,loss:0.6582\n",
      "epoch:187,loss:0.1091\n",
      "epoch:187,loss:0.0748\n",
      "epoch:187,loss:0.4457\n",
      "epoch:187,loss:0.1533\n",
      "epoch:187,loss:0.8449\n",
      "epoch:187,loss:0.1088\n",
      "epoch:187,loss:0.0883\n",
      "epoch:187,loss:0.2227\n",
      "epoch:187,loss:0.1996\n",
      "epoch:187,loss:0.0559\n",
      "epoch:187,loss:0.0181\n",
      "epoch:187,loss:0.0627\n",
      "epoch:187,loss:0.0701\n",
      "epoch:187,loss:0.0488\n",
      "epoch:187,loss:0.1258\n",
      "epoch:187,loss:0.0912\n",
      "epoch:187,loss:0.4095\n",
      "epoch:187,loss:0.2307\n",
      "epoch:187,loss:0.5084\n",
      "epoch:187,loss:0.2142\n",
      "epoch:187,loss:0.5570\n",
      "epoch:187,loss:0.3438\n",
      "epoch:187,loss:0.6881\n",
      "epoch:187,loss:0.1470\n",
      "epoch:187,loss:0.3775\n",
      "epoch:187,loss:0.1537\n",
      "epoch:187,loss:1.1948\n",
      "epoch:187,loss:2.0351\n",
      "epoch:187,loss:0.0195\n",
      "epoch:187,loss:0.4569\n",
      "epoch:187,loss:0.0832\n",
      "epoch:187,loss:0.4682\n",
      "epoch:187,loss:2.0462\n",
      "epoch:187,loss:0.0256\n",
      "============================================\n",
      "第187个epoch的识别准确率为：89%\n",
      "epoch:188,loss:0.7101\n",
      "epoch:188,loss:0.0560\n",
      "epoch:188,loss:0.1492\n",
      "epoch:188,loss:0.2874\n",
      "epoch:188,loss:0.2124\n",
      "epoch:188,loss:1.1116\n",
      "epoch:188,loss:0.2478\n",
      "epoch:188,loss:0.1113\n",
      "epoch:188,loss:0.2110\n",
      "epoch:188,loss:1.1368\n",
      "epoch:188,loss:0.4066\n",
      "epoch:188,loss:0.1870\n",
      "epoch:188,loss:0.0198\n",
      "epoch:188,loss:0.0495\n",
      "epoch:188,loss:0.4270\n",
      "epoch:188,loss:1.1299\n",
      "epoch:188,loss:0.5550\n",
      "epoch:188,loss:0.0478\n",
      "epoch:188,loss:0.1679\n",
      "epoch:188,loss:0.0341\n",
      "epoch:188,loss:0.9452\n",
      "epoch:188,loss:0.4137\n",
      "epoch:188,loss:0.0267\n",
      "epoch:188,loss:0.4558\n",
      "epoch:188,loss:0.6843\n",
      "epoch:188,loss:1.5245\n",
      "epoch:188,loss:0.0174\n",
      "epoch:188,loss:0.5783\n",
      "epoch:188,loss:0.1779\n",
      "epoch:188,loss:0.2483\n",
      "epoch:188,loss:0.2362\n",
      "epoch:188,loss:0.0596\n",
      "epoch:188,loss:0.0717\n",
      "epoch:188,loss:0.3774\n",
      "epoch:188,loss:0.2147\n",
      "epoch:188,loss:0.2745\n",
      "epoch:188,loss:0.3345\n",
      "epoch:188,loss:0.9380\n",
      "epoch:188,loss:0.0073\n",
      "epoch:188,loss:0.4073\n",
      "epoch:188,loss:0.0923\n",
      "epoch:188,loss:0.0406\n",
      "epoch:188,loss:0.2898\n",
      "epoch:188,loss:0.0074\n",
      "epoch:188,loss:0.2019\n",
      "epoch:188,loss:0.4170\n",
      "epoch:188,loss:0.4572\n",
      "epoch:188,loss:0.6985\n",
      "epoch:188,loss:0.0990\n",
      "epoch:188,loss:0.2409\n",
      "epoch:188,loss:0.0588\n",
      "epoch:188,loss:0.1344\n",
      "epoch:188,loss:0.3575\n",
      "epoch:188,loss:0.0516\n",
      "epoch:188,loss:0.2610\n",
      "epoch:188,loss:0.3506\n",
      "epoch:188,loss:0.6065\n",
      "epoch:188,loss:0.4989\n",
      "epoch:188,loss:0.0515\n",
      "epoch:188,loss:0.7221\n",
      "============================================\n",
      "准确率由： tensor(0.8943) 上升至： tensor(0.9062) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第188个epoch的识别准确率为：90%\n",
      "epoch:189,loss:0.0268\n",
      "epoch:189,loss:0.1381\n",
      "epoch:189,loss:0.0226\n",
      "epoch:189,loss:0.6007\n",
      "epoch:189,loss:0.1929\n",
      "epoch:189,loss:0.0282\n",
      "epoch:189,loss:0.3506\n",
      "epoch:189,loss:0.1673\n",
      "epoch:189,loss:0.0711\n",
      "epoch:189,loss:0.7955\n",
      "epoch:189,loss:0.3585\n",
      "epoch:189,loss:0.0259\n",
      "epoch:189,loss:1.0056\n",
      "epoch:189,loss:0.0660\n",
      "epoch:189,loss:0.1716\n",
      "epoch:189,loss:0.0751\n",
      "epoch:189,loss:0.1115\n",
      "epoch:189,loss:0.2206\n",
      "epoch:189,loss:0.2505\n",
      "epoch:189,loss:0.0454\n",
      "epoch:189,loss:0.2002\n",
      "epoch:189,loss:0.2136\n",
      "epoch:189,loss:0.0856\n",
      "epoch:189,loss:0.0276\n",
      "epoch:189,loss:0.1950\n",
      "epoch:189,loss:0.0166\n",
      "epoch:189,loss:0.1104\n",
      "epoch:189,loss:1.3147\n",
      "epoch:189,loss:1.1510\n",
      "epoch:189,loss:0.5631\n",
      "epoch:189,loss:0.7410\n",
      "epoch:189,loss:0.0858\n",
      "epoch:189,loss:0.5898\n",
      "epoch:189,loss:1.7361\n",
      "epoch:189,loss:0.5147\n",
      "epoch:189,loss:0.1571\n",
      "epoch:189,loss:0.1679\n",
      "epoch:189,loss:0.1450\n",
      "epoch:189,loss:0.0571\n",
      "epoch:189,loss:0.6239\n",
      "epoch:189,loss:0.2161\n",
      "epoch:189,loss:0.5767\n",
      "epoch:189,loss:0.3941\n",
      "epoch:189,loss:1.4976\n",
      "epoch:189,loss:0.0468\n",
      "epoch:189,loss:0.1761\n",
      "epoch:189,loss:0.1895\n",
      "epoch:189,loss:0.3652\n",
      "epoch:189,loss:2.0872\n",
      "epoch:189,loss:0.1507\n",
      "epoch:189,loss:0.2980\n",
      "epoch:189,loss:0.0318\n",
      "epoch:189,loss:0.0185\n",
      "epoch:189,loss:0.6833\n",
      "epoch:189,loss:0.5018\n",
      "epoch:189,loss:0.1230\n",
      "epoch:189,loss:0.0168\n",
      "epoch:189,loss:1.8552\n",
      "epoch:189,loss:0.0104\n",
      "epoch:189,loss:0.2634\n",
      "============================================\n",
      "第189个epoch的识别准确率为：90%\n",
      "epoch:190,loss:0.5851\n",
      "epoch:190,loss:0.4265\n",
      "epoch:190,loss:0.2819\n",
      "epoch:190,loss:0.3659\n",
      "epoch:190,loss:0.0937\n",
      "epoch:190,loss:0.0625\n",
      "epoch:190,loss:0.1967\n",
      "epoch:190,loss:0.2796\n",
      "epoch:190,loss:0.0997\n",
      "epoch:190,loss:0.1852\n",
      "epoch:190,loss:0.0318\n",
      "epoch:190,loss:0.0560\n",
      "epoch:190,loss:0.0203\n",
      "epoch:190,loss:0.5164\n",
      "epoch:190,loss:0.4534\n",
      "epoch:190,loss:0.1719\n",
      "epoch:190,loss:0.0124\n",
      "epoch:190,loss:0.0625\n",
      "epoch:190,loss:0.6249\n",
      "epoch:190,loss:0.0547\n",
      "epoch:190,loss:0.2168\n",
      "epoch:190,loss:1.1679\n",
      "epoch:190,loss:0.2400\n",
      "epoch:190,loss:0.0154\n",
      "epoch:190,loss:0.1721\n",
      "epoch:190,loss:0.4635\n",
      "epoch:190,loss:0.0395\n",
      "epoch:190,loss:0.2213\n",
      "epoch:190,loss:0.1101\n",
      "epoch:190,loss:0.0240\n",
      "epoch:190,loss:0.1870\n",
      "epoch:190,loss:0.6102\n",
      "epoch:190,loss:0.0595\n",
      "epoch:190,loss:1.0009\n",
      "epoch:190,loss:0.0864\n",
      "epoch:190,loss:0.2025\n",
      "epoch:190,loss:0.0740\n",
      "epoch:190,loss:0.0674\n",
      "epoch:190,loss:0.0359\n",
      "epoch:190,loss:0.0451\n",
      "epoch:190,loss:0.0884\n",
      "epoch:190,loss:0.0496\n",
      "epoch:190,loss:0.2691\n",
      "epoch:190,loss:0.7883\n",
      "epoch:190,loss:0.2919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:190,loss:0.5283\n",
      "epoch:190,loss:0.1089\n",
      "epoch:190,loss:0.6412\n",
      "epoch:190,loss:0.0581\n",
      "epoch:190,loss:0.8461\n",
      "epoch:190,loss:0.1081\n",
      "epoch:190,loss:0.2663\n",
      "epoch:190,loss:0.1977\n",
      "epoch:190,loss:0.0991\n",
      "epoch:190,loss:0.2086\n",
      "epoch:190,loss:0.0247\n",
      "epoch:190,loss:0.0917\n",
      "epoch:190,loss:1.6684\n",
      "epoch:190,loss:0.3990\n",
      "epoch:190,loss:0.6849\n",
      "============================================\n",
      "第190个epoch的识别准确率为：89%\n",
      "epoch:191,loss:0.5415\n",
      "epoch:191,loss:0.8571\n",
      "epoch:191,loss:0.1716\n",
      "epoch:191,loss:0.0962\n",
      "epoch:191,loss:0.1278\n",
      "epoch:191,loss:0.2983\n",
      "epoch:191,loss:0.1210\n",
      "epoch:191,loss:0.5604\n",
      "epoch:191,loss:0.2832\n",
      "epoch:191,loss:0.1630\n",
      "epoch:191,loss:0.3972\n",
      "epoch:191,loss:0.1257\n",
      "epoch:191,loss:0.3489\n",
      "epoch:191,loss:0.1926\n",
      "epoch:191,loss:0.1210\n",
      "epoch:191,loss:0.2402\n",
      "epoch:191,loss:0.3226\n",
      "epoch:191,loss:0.0750\n",
      "epoch:191,loss:0.1522\n",
      "epoch:191,loss:0.0123\n",
      "epoch:191,loss:0.1714\n",
      "epoch:191,loss:0.0295\n",
      "epoch:191,loss:0.2152\n",
      "epoch:191,loss:0.0306\n",
      "epoch:191,loss:0.0377\n",
      "epoch:191,loss:0.0982\n",
      "epoch:191,loss:0.1388\n",
      "epoch:191,loss:0.2173\n",
      "epoch:191,loss:0.1520\n",
      "epoch:191,loss:0.4388\n",
      "epoch:191,loss:0.0064\n",
      "epoch:191,loss:0.4028\n",
      "epoch:191,loss:0.0590\n",
      "epoch:191,loss:0.0143\n",
      "epoch:191,loss:0.3878\n",
      "epoch:191,loss:0.1558\n",
      "epoch:191,loss:0.0356\n",
      "epoch:191,loss:0.2517\n",
      "epoch:191,loss:0.0789\n",
      "epoch:191,loss:0.5479\n",
      "epoch:191,loss:0.1479\n",
      "epoch:191,loss:0.2902\n",
      "epoch:191,loss:0.0213\n",
      "epoch:191,loss:0.1482\n",
      "epoch:191,loss:0.1107\n",
      "epoch:191,loss:0.0324\n",
      "epoch:191,loss:0.4833\n",
      "epoch:191,loss:0.1495\n",
      "epoch:191,loss:0.0911\n",
      "epoch:191,loss:0.0105\n",
      "epoch:191,loss:0.0379\n",
      "epoch:191,loss:0.0870\n",
      "epoch:191,loss:0.7177\n",
      "epoch:191,loss:0.0655\n",
      "epoch:191,loss:0.1648\n",
      "epoch:191,loss:0.4523\n",
      "epoch:191,loss:0.5250\n",
      "epoch:191,loss:0.2720\n",
      "epoch:191,loss:0.1383\n",
      "epoch:191,loss:0.0201\n",
      "============================================\n",
      "准确率由： tensor(0.9062) 上升至： tensor(0.9118) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第191个epoch的识别准确率为：91%\n",
      "epoch:192,loss:0.3117\n",
      "epoch:192,loss:0.1180\n",
      "epoch:192,loss:0.0586\n",
      "epoch:192,loss:0.0765\n",
      "epoch:192,loss:0.1504\n",
      "epoch:192,loss:0.0207\n",
      "epoch:192,loss:0.0320\n",
      "epoch:192,loss:0.0645\n",
      "epoch:192,loss:0.1687\n",
      "epoch:192,loss:0.0780\n",
      "epoch:192,loss:0.5188\n",
      "epoch:192,loss:0.0430\n",
      "epoch:192,loss:0.0543\n",
      "epoch:192,loss:0.0403\n",
      "epoch:192,loss:0.1097\n",
      "epoch:192,loss:0.1185\n",
      "epoch:192,loss:0.0957\n",
      "epoch:192,loss:0.4751\n",
      "epoch:192,loss:0.2486\n",
      "epoch:192,loss:0.0115\n",
      "epoch:192,loss:0.1268\n",
      "epoch:192,loss:0.2703\n",
      "epoch:192,loss:0.5067\n",
      "epoch:192,loss:0.3774\n",
      "epoch:192,loss:0.0128\n",
      "epoch:192,loss:0.0464\n",
      "epoch:192,loss:0.0390\n",
      "epoch:192,loss:0.3321\n",
      "epoch:192,loss:0.3291\n",
      "epoch:192,loss:0.0316\n",
      "epoch:192,loss:0.0833\n",
      "epoch:192,loss:0.5640\n",
      "epoch:192,loss:0.2260\n",
      "epoch:192,loss:0.4504\n",
      "epoch:192,loss:0.0725\n",
      "epoch:192,loss:0.3816\n",
      "epoch:192,loss:0.0681\n",
      "epoch:192,loss:0.0043\n",
      "epoch:192,loss:0.0492\n",
      "epoch:192,loss:0.0745\n",
      "epoch:192,loss:0.0690\n",
      "epoch:192,loss:0.3229\n",
      "epoch:192,loss:0.8288\n",
      "epoch:192,loss:0.6321\n",
      "epoch:192,loss:0.1768\n",
      "epoch:192,loss:0.0712\n",
      "epoch:192,loss:0.2339\n",
      "epoch:192,loss:0.0097\n",
      "epoch:192,loss:0.0893\n",
      "epoch:192,loss:0.0684\n",
      "epoch:192,loss:0.4520\n",
      "epoch:192,loss:0.3249\n",
      "epoch:192,loss:1.2229\n",
      "epoch:192,loss:0.0864\n",
      "epoch:192,loss:0.2887\n",
      "epoch:192,loss:0.0706\n",
      "epoch:192,loss:0.0862\n",
      "epoch:192,loss:0.0689\n",
      "epoch:192,loss:0.0742\n",
      "epoch:192,loss:0.2081\n",
      "============================================\n",
      "准确率由： tensor(0.9118) 上升至： tensor(0.9219) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第192个epoch的识别准确率为：92%\n",
      "epoch:193,loss:1.8026\n",
      "epoch:193,loss:0.0216\n",
      "epoch:193,loss:0.0302\n",
      "epoch:193,loss:0.2859\n",
      "epoch:193,loss:0.5676\n",
      "epoch:193,loss:0.0330\n",
      "epoch:193,loss:0.3001\n",
      "epoch:193,loss:0.0660\n",
      "epoch:193,loss:0.3608\n",
      "epoch:193,loss:0.1961\n",
      "epoch:193,loss:0.9896\n",
      "epoch:193,loss:0.0538\n",
      "epoch:193,loss:0.5944\n",
      "epoch:193,loss:0.5678\n",
      "epoch:193,loss:0.2374\n",
      "epoch:193,loss:0.0734\n",
      "epoch:193,loss:0.1792\n",
      "epoch:193,loss:0.2449\n",
      "epoch:193,loss:0.1842\n",
      "epoch:193,loss:0.2993\n",
      "epoch:193,loss:0.0998\n",
      "epoch:193,loss:0.0903\n",
      "epoch:193,loss:0.6239\n",
      "epoch:193,loss:0.3373\n",
      "epoch:193,loss:0.1203\n",
      "epoch:193,loss:0.1001\n",
      "epoch:193,loss:0.1254\n",
      "epoch:193,loss:0.8594\n",
      "epoch:193,loss:0.0131\n",
      "epoch:193,loss:0.1759\n",
      "epoch:193,loss:0.7754\n",
      "epoch:193,loss:0.0212\n",
      "epoch:193,loss:0.2631\n",
      "epoch:193,loss:0.4514\n",
      "epoch:193,loss:0.0855\n",
      "epoch:193,loss:0.6194\n",
      "epoch:193,loss:0.0530\n",
      "epoch:193,loss:0.0629\n",
      "epoch:193,loss:0.0275\n",
      "epoch:193,loss:0.3465\n",
      "epoch:193,loss:0.9075\n",
      "epoch:193,loss:0.6745\n",
      "epoch:193,loss:0.1724\n",
      "epoch:193,loss:0.8565\n",
      "epoch:193,loss:0.0092\n",
      "epoch:193,loss:0.8913\n",
      "epoch:193,loss:0.7689\n",
      "epoch:193,loss:0.3755\n",
      "epoch:193,loss:0.1511\n",
      "epoch:193,loss:0.0887\n",
      "epoch:193,loss:0.0359\n",
      "epoch:193,loss:1.2052\n",
      "epoch:193,loss:0.9808\n",
      "epoch:193,loss:0.7571\n",
      "epoch:193,loss:0.2710\n",
      "epoch:193,loss:0.0395\n",
      "epoch:193,loss:0.1352\n",
      "epoch:193,loss:0.8696\n",
      "epoch:193,loss:0.2641\n",
      "epoch:193,loss:0.3373\n",
      "============================================\n",
      "第193个epoch的识别准确率为：91%\n",
      "epoch:194,loss:0.4835\n",
      "epoch:194,loss:0.2229\n",
      "epoch:194,loss:0.0430\n",
      "epoch:194,loss:0.0511\n",
      "epoch:194,loss:0.3717\n",
      "epoch:194,loss:0.0326\n",
      "epoch:194,loss:0.3079\n",
      "epoch:194,loss:0.0561\n",
      "epoch:194,loss:0.4274\n",
      "epoch:194,loss:0.2183\n",
      "epoch:194,loss:0.0672\n",
      "epoch:194,loss:0.0596\n",
      "epoch:194,loss:0.0385\n",
      "epoch:194,loss:1.8086\n",
      "epoch:194,loss:0.2590\n",
      "epoch:194,loss:0.3797\n",
      "epoch:194,loss:0.0672\n",
      "epoch:194,loss:0.0493\n",
      "epoch:194,loss:0.2463\n",
      "epoch:194,loss:0.3299\n",
      "epoch:194,loss:0.1316\n",
      "epoch:194,loss:0.2243\n",
      "epoch:194,loss:0.0945\n",
      "epoch:194,loss:1.1880\n",
      "epoch:194,loss:0.3539\n",
      "epoch:194,loss:0.0482\n",
      "epoch:194,loss:3.6359\n",
      "epoch:194,loss:0.4400\n",
      "epoch:194,loss:0.0445\n",
      "epoch:194,loss:0.8657\n",
      "epoch:194,loss:1.1730\n",
      "epoch:194,loss:0.3928\n",
      "epoch:194,loss:0.2982\n",
      "epoch:194,loss:0.1267\n",
      "epoch:194,loss:0.2843\n",
      "epoch:194,loss:0.3612\n",
      "epoch:194,loss:0.3042\n",
      "epoch:194,loss:0.4293\n",
      "epoch:194,loss:0.0549\n",
      "epoch:194,loss:0.1562\n",
      "epoch:194,loss:0.1941\n",
      "epoch:194,loss:0.0625\n",
      "epoch:194,loss:0.0024\n",
      "epoch:194,loss:0.2087\n",
      "epoch:194,loss:0.1495\n",
      "epoch:194,loss:0.0703\n",
      "epoch:194,loss:0.0489\n",
      "epoch:194,loss:0.3781\n",
      "epoch:194,loss:0.1815\n",
      "epoch:194,loss:0.0340\n",
      "epoch:194,loss:0.0132\n",
      "epoch:194,loss:0.3891\n",
      "epoch:194,loss:0.0818\n",
      "epoch:194,loss:0.2456\n",
      "epoch:194,loss:0.3233\n",
      "epoch:194,loss:0.0106\n",
      "epoch:194,loss:0.5007\n",
      "epoch:194,loss:0.5875\n",
      "epoch:194,loss:0.0323\n",
      "epoch:194,loss:0.4421\n",
      "============================================\n",
      "第194个epoch的识别准确率为：91%\n",
      "epoch:195,loss:1.5458\n",
      "epoch:195,loss:0.2275\n",
      "epoch:195,loss:0.2840\n",
      "epoch:195,loss:0.0342\n",
      "epoch:195,loss:0.0193\n",
      "epoch:195,loss:0.0703\n",
      "epoch:195,loss:0.5546\n",
      "epoch:195,loss:0.5396\n",
      "epoch:195,loss:0.2204\n",
      "epoch:195,loss:0.7035\n",
      "epoch:195,loss:1.4416\n",
      "epoch:195,loss:0.3366\n",
      "epoch:195,loss:0.2546\n",
      "epoch:195,loss:0.3650\n",
      "epoch:195,loss:0.4432\n",
      "epoch:195,loss:0.1425\n",
      "epoch:195,loss:0.0481\n",
      "epoch:195,loss:0.0700\n",
      "epoch:195,loss:0.0255\n",
      "epoch:195,loss:0.1072\n",
      "epoch:195,loss:0.0903\n",
      "epoch:195,loss:0.1236\n",
      "epoch:195,loss:0.2128\n",
      "epoch:195,loss:0.1264\n",
      "epoch:195,loss:0.0138\n",
      "epoch:195,loss:0.4530\n",
      "epoch:195,loss:0.2186\n",
      "epoch:195,loss:0.0061\n",
      "epoch:195,loss:0.0189\n",
      "epoch:195,loss:0.5176\n",
      "epoch:195,loss:0.0798\n",
      "epoch:195,loss:0.0129\n",
      "epoch:195,loss:0.4187\n",
      "epoch:195,loss:0.0313\n",
      "epoch:195,loss:0.5496\n",
      "epoch:195,loss:0.2815\n",
      "epoch:195,loss:0.2653\n",
      "epoch:195,loss:0.5504\n",
      "epoch:195,loss:0.6950\n",
      "epoch:195,loss:0.1231\n",
      "epoch:195,loss:0.1828\n",
      "epoch:195,loss:0.3231\n",
      "epoch:195,loss:0.3519\n",
      "epoch:195,loss:0.0353\n",
      "epoch:195,loss:0.3812\n",
      "epoch:195,loss:0.0520\n",
      "epoch:195,loss:0.7144\n",
      "epoch:195,loss:0.3043\n",
      "epoch:195,loss:0.7870\n",
      "epoch:195,loss:0.0294\n",
      "epoch:195,loss:0.0540\n",
      "epoch:195,loss:1.3081\n",
      "epoch:195,loss:0.0225\n",
      "epoch:195,loss:1.0041\n",
      "epoch:195,loss:0.1102\n",
      "epoch:195,loss:0.0776\n",
      "epoch:195,loss:1.1068\n",
      "epoch:195,loss:0.1097\n",
      "epoch:195,loss:0.2440\n",
      "epoch:195,loss:0.1264\n",
      "============================================\n",
      "第195个epoch的识别准确率为：90%\n",
      "epoch:196,loss:0.3889\n",
      "epoch:196,loss:0.1547\n",
      "epoch:196,loss:0.8879\n",
      "epoch:196,loss:0.0072\n",
      "epoch:196,loss:0.0830\n",
      "epoch:196,loss:1.5426\n",
      "epoch:196,loss:0.0171\n",
      "epoch:196,loss:0.9995\n",
      "epoch:196,loss:0.2002\n",
      "epoch:196,loss:0.2179\n",
      "epoch:196,loss:0.1050\n",
      "epoch:196,loss:1.3782\n",
      "epoch:196,loss:0.2446\n",
      "epoch:196,loss:0.0648\n",
      "epoch:196,loss:0.0549\n",
      "epoch:196,loss:0.0105\n",
      "epoch:196,loss:0.7707\n",
      "epoch:196,loss:0.0818\n",
      "epoch:196,loss:0.0138\n",
      "epoch:196,loss:0.1859\n",
      "epoch:196,loss:0.3193\n",
      "epoch:196,loss:0.5594\n",
      "epoch:196,loss:0.3522\n",
      "epoch:196,loss:0.0800\n",
      "epoch:196,loss:0.6401\n",
      "epoch:196,loss:0.0282\n",
      "epoch:196,loss:0.3602\n",
      "epoch:196,loss:0.0777\n",
      "epoch:196,loss:1.7892\n",
      "epoch:196,loss:0.0344\n",
      "epoch:196,loss:0.0658\n",
      "epoch:196,loss:0.3330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:196,loss:0.0325\n",
      "epoch:196,loss:0.4793\n",
      "epoch:196,loss:0.0205\n",
      "epoch:196,loss:0.3989\n",
      "epoch:196,loss:0.6735\n",
      "epoch:196,loss:0.8109\n",
      "epoch:196,loss:0.0487\n",
      "epoch:196,loss:0.0112\n",
      "epoch:196,loss:0.8755\n",
      "epoch:196,loss:0.1850\n",
      "epoch:196,loss:0.0471\n",
      "epoch:196,loss:0.1249\n",
      "epoch:196,loss:0.0825\n",
      "epoch:196,loss:0.2274\n",
      "epoch:196,loss:0.3701\n",
      "epoch:196,loss:0.5784\n",
      "epoch:196,loss:1.6873\n",
      "epoch:196,loss:0.0558\n",
      "epoch:196,loss:0.2494\n",
      "epoch:196,loss:0.0489\n",
      "epoch:196,loss:0.8120\n",
      "epoch:196,loss:0.1718\n",
      "epoch:196,loss:0.2434\n",
      "epoch:196,loss:0.2580\n",
      "epoch:196,loss:0.1677\n",
      "epoch:196,loss:0.0237\n",
      "epoch:196,loss:0.0345\n",
      "epoch:196,loss:0.1761\n",
      "============================================\n",
      "第196个epoch的识别准确率为：90%\n",
      "epoch:197,loss:0.2665\n",
      "epoch:197,loss:0.2756\n",
      "epoch:197,loss:0.0206\n",
      "epoch:197,loss:0.5839\n",
      "epoch:197,loss:0.1337\n",
      "epoch:197,loss:0.1102\n",
      "epoch:197,loss:0.4514\n",
      "epoch:197,loss:0.4902\n",
      "epoch:197,loss:0.9793\n",
      "epoch:197,loss:1.0630\n",
      "epoch:197,loss:0.0938\n",
      "epoch:197,loss:1.4424\n",
      "epoch:197,loss:0.1742\n",
      "epoch:197,loss:0.3666\n",
      "epoch:197,loss:0.1680\n",
      "epoch:197,loss:0.0940\n",
      "epoch:197,loss:0.0145\n",
      "epoch:197,loss:0.1167\n",
      "epoch:197,loss:0.0264\n",
      "epoch:197,loss:0.0858\n",
      "epoch:197,loss:0.7500\n",
      "epoch:197,loss:2.3880\n",
      "epoch:197,loss:0.0230\n",
      "epoch:197,loss:0.2606\n",
      "epoch:197,loss:0.0333\n",
      "epoch:197,loss:0.7574\n",
      "epoch:197,loss:0.7228\n",
      "epoch:197,loss:0.7228\n",
      "epoch:197,loss:0.2160\n",
      "epoch:197,loss:0.5687\n",
      "epoch:197,loss:0.0362\n",
      "epoch:197,loss:0.1415\n",
      "epoch:197,loss:0.5354\n",
      "epoch:197,loss:0.1839\n",
      "epoch:197,loss:1.1467\n",
      "epoch:197,loss:0.1603\n",
      "epoch:197,loss:0.1098\n",
      "epoch:197,loss:0.1633\n",
      "epoch:197,loss:0.9481\n",
      "epoch:197,loss:0.0573\n",
      "epoch:197,loss:0.0776\n",
      "epoch:197,loss:0.3287\n",
      "epoch:197,loss:0.6500\n",
      "epoch:197,loss:0.0140\n",
      "epoch:197,loss:0.0081\n",
      "epoch:197,loss:0.1163\n",
      "epoch:197,loss:0.0186\n",
      "epoch:197,loss:0.2777\n",
      "epoch:197,loss:0.4237\n",
      "epoch:197,loss:0.3988\n",
      "epoch:197,loss:0.1494\n",
      "epoch:197,loss:0.7881\n",
      "epoch:197,loss:0.1708\n",
      "epoch:197,loss:0.2966\n",
      "epoch:197,loss:0.2120\n",
      "epoch:197,loss:0.0495\n",
      "epoch:197,loss:0.9273\n",
      "epoch:197,loss:0.0407\n",
      "epoch:197,loss:0.0300\n",
      "epoch:197,loss:0.1956\n",
      "============================================\n",
      "第197个epoch的识别准确率为：90%\n",
      "epoch:198,loss:0.4134\n",
      "epoch:198,loss:0.1127\n",
      "epoch:198,loss:0.4005\n",
      "epoch:198,loss:0.0475\n",
      "epoch:198,loss:1.3857\n",
      "epoch:198,loss:0.8580\n",
      "epoch:198,loss:0.0167\n",
      "epoch:198,loss:0.3385\n",
      "epoch:198,loss:0.3144\n",
      "epoch:198,loss:0.2143\n",
      "epoch:198,loss:0.1219\n",
      "epoch:198,loss:0.0364\n",
      "epoch:198,loss:0.2497\n",
      "epoch:198,loss:0.0125\n",
      "epoch:198,loss:0.7033\n",
      "epoch:198,loss:0.3297\n",
      "epoch:198,loss:0.0709\n",
      "epoch:198,loss:0.0692\n",
      "epoch:198,loss:0.9053\n",
      "epoch:198,loss:0.0734\n",
      "epoch:198,loss:0.0219\n",
      "epoch:198,loss:0.1030\n",
      "epoch:198,loss:0.1914\n",
      "epoch:198,loss:0.3468\n",
      "epoch:198,loss:0.2356\n",
      "epoch:198,loss:0.0063\n",
      "epoch:198,loss:0.1618\n",
      "epoch:198,loss:0.1435\n",
      "epoch:198,loss:0.1425\n",
      "epoch:198,loss:0.0051\n",
      "epoch:198,loss:0.7221\n",
      "epoch:198,loss:0.4684\n",
      "epoch:198,loss:0.0478\n",
      "epoch:198,loss:0.0737\n",
      "epoch:198,loss:0.3038\n",
      "epoch:198,loss:0.1386\n",
      "epoch:198,loss:0.3665\n",
      "epoch:198,loss:0.0798\n",
      "epoch:198,loss:0.0230\n",
      "epoch:198,loss:0.3684\n",
      "epoch:198,loss:0.1753\n",
      "epoch:198,loss:0.0611\n",
      "epoch:198,loss:0.8428\n",
      "epoch:198,loss:0.0255\n",
      "epoch:198,loss:1.3977\n",
      "epoch:198,loss:0.0152\n",
      "epoch:198,loss:0.0984\n",
      "epoch:198,loss:0.3073\n",
      "epoch:198,loss:0.0556\n",
      "epoch:198,loss:0.0422\n",
      "epoch:198,loss:0.8440\n",
      "epoch:198,loss:0.1455\n",
      "epoch:198,loss:0.0588\n",
      "epoch:198,loss:0.1947\n",
      "epoch:198,loss:0.0934\n",
      "epoch:198,loss:0.1588\n",
      "epoch:198,loss:0.4731\n",
      "epoch:198,loss:0.0366\n",
      "epoch:198,loss:0.1148\n",
      "epoch:198,loss:0.1892\n",
      "============================================\n",
      "准确率由： tensor(0.9219) 上升至： tensor(0.9228) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第198个epoch的识别准确率为：92%\n",
      "epoch:199,loss:0.5539\n",
      "epoch:199,loss:0.2756\n",
      "epoch:199,loss:0.1414\n",
      "epoch:199,loss:0.3033\n",
      "epoch:199,loss:0.0820\n",
      "epoch:199,loss:0.0525\n",
      "epoch:199,loss:0.5640\n",
      "epoch:199,loss:0.1082\n",
      "epoch:199,loss:0.3978\n",
      "epoch:199,loss:0.1103\n",
      "epoch:199,loss:0.3818\n",
      "epoch:199,loss:0.1057\n",
      "epoch:199,loss:0.1329\n",
      "epoch:199,loss:0.4910\n",
      "epoch:199,loss:0.4100\n",
      "epoch:199,loss:0.0318\n",
      "epoch:199,loss:0.1896\n",
      "epoch:199,loss:0.0922\n",
      "epoch:199,loss:0.0095\n",
      "epoch:199,loss:0.1097\n",
      "epoch:199,loss:0.0653\n",
      "epoch:199,loss:0.4536\n",
      "epoch:199,loss:1.0029\n",
      "epoch:199,loss:0.0054\n",
      "epoch:199,loss:0.2744\n",
      "epoch:199,loss:0.5154\n",
      "epoch:199,loss:0.6208\n",
      "epoch:199,loss:0.2621\n",
      "epoch:199,loss:0.1434\n",
      "epoch:199,loss:0.7044\n",
      "epoch:199,loss:0.2601\n",
      "epoch:199,loss:0.2445\n",
      "epoch:199,loss:0.0704\n",
      "epoch:199,loss:0.5023\n",
      "epoch:199,loss:0.0800\n",
      "epoch:199,loss:0.3238\n",
      "epoch:199,loss:0.0264\n",
      "epoch:199,loss:1.0897\n",
      "epoch:199,loss:0.1142\n",
      "epoch:199,loss:0.0265\n",
      "epoch:199,loss:0.0357\n",
      "epoch:199,loss:0.1970\n",
      "epoch:199,loss:0.0568\n",
      "epoch:199,loss:0.0368\n",
      "epoch:199,loss:0.6018\n",
      "epoch:199,loss:0.0523\n",
      "epoch:199,loss:0.0774\n",
      "epoch:199,loss:0.0471\n",
      "epoch:199,loss:0.0785\n",
      "epoch:199,loss:0.0359\n",
      "epoch:199,loss:1.0666\n",
      "epoch:199,loss:0.1815\n",
      "epoch:199,loss:0.6383\n",
      "epoch:199,loss:1.0169\n",
      "epoch:199,loss:0.2749\n",
      "epoch:199,loss:0.2930\n",
      "epoch:199,loss:0.1203\n",
      "epoch:199,loss:0.1557\n",
      "epoch:199,loss:0.0091\n",
      "epoch:199,loss:0.0914\n",
      "============================================\n",
      "第199个epoch的识别准确率为：92%\n",
      "epoch:200,loss:0.0487\n",
      "epoch:200,loss:0.1572\n",
      "epoch:200,loss:0.1281\n",
      "epoch:200,loss:0.4960\n",
      "epoch:200,loss:0.4807\n",
      "epoch:200,loss:0.0217\n",
      "epoch:200,loss:0.0179\n",
      "epoch:200,loss:0.1571\n",
      "epoch:200,loss:0.4890\n",
      "epoch:200,loss:0.0392\n",
      "epoch:200,loss:0.3356\n",
      "epoch:200,loss:0.1785\n",
      "epoch:200,loss:0.1520\n",
      "epoch:200,loss:0.1750\n",
      "epoch:200,loss:0.5891\n",
      "epoch:200,loss:0.1255\n",
      "epoch:200,loss:0.2525\n",
      "epoch:200,loss:0.5911\n",
      "epoch:200,loss:0.2473\n",
      "epoch:200,loss:0.1560\n",
      "epoch:200,loss:0.4790\n",
      "epoch:200,loss:0.3125\n",
      "epoch:200,loss:0.1980\n",
      "epoch:200,loss:0.0482\n",
      "epoch:200,loss:0.0206\n",
      "epoch:200,loss:0.0347\n",
      "epoch:200,loss:0.0206\n",
      "epoch:200,loss:0.0875\n",
      "epoch:200,loss:0.0311\n",
      "epoch:200,loss:0.3828\n",
      "epoch:200,loss:0.3949\n",
      "epoch:200,loss:0.0436\n",
      "epoch:200,loss:0.4842\n",
      "epoch:200,loss:0.0569\n",
      "epoch:200,loss:0.0964\n",
      "epoch:200,loss:0.2816\n",
      "epoch:200,loss:0.2076\n",
      "epoch:200,loss:0.0517\n",
      "epoch:200,loss:0.2100\n",
      "epoch:200,loss:0.2297\n",
      "epoch:200,loss:0.2249\n",
      "epoch:200,loss:0.0643\n",
      "epoch:200,loss:0.3908\n",
      "epoch:200,loss:0.2183\n",
      "epoch:200,loss:0.0355\n",
      "epoch:200,loss:0.1608\n",
      "epoch:200,loss:0.4123\n",
      "epoch:200,loss:0.0831\n",
      "epoch:200,loss:4.3535\n",
      "epoch:200,loss:0.0077\n",
      "epoch:200,loss:0.3066\n",
      "epoch:200,loss:0.0759\n",
      "epoch:200,loss:1.6217\n",
      "epoch:200,loss:0.8523\n",
      "epoch:200,loss:0.2300\n",
      "epoch:200,loss:0.1222\n",
      "epoch:200,loss:0.1678\n",
      "epoch:200,loss:0.1069\n",
      "epoch:200,loss:0.2061\n",
      "epoch:200,loss:0.2110\n",
      "============================================\n",
      "第200个epoch的识别准确率为：90%\n",
      "epoch:201,loss:0.1589\n",
      "epoch:201,loss:0.0864\n",
      "epoch:201,loss:0.1629\n",
      "epoch:201,loss:0.0495\n",
      "epoch:201,loss:0.0163\n",
      "epoch:201,loss:0.0490\n",
      "epoch:201,loss:0.7571\n",
      "epoch:201,loss:0.5818\n",
      "epoch:201,loss:0.0237\n",
      "epoch:201,loss:0.5917\n",
      "epoch:201,loss:0.1577\n",
      "epoch:201,loss:0.0541\n",
      "epoch:201,loss:0.2569\n",
      "epoch:201,loss:0.3409\n",
      "epoch:201,loss:0.0291\n",
      "epoch:201,loss:0.0882\n",
      "epoch:201,loss:0.0584\n",
      "epoch:201,loss:0.0587\n",
      "epoch:201,loss:0.6955\n",
      "epoch:201,loss:0.1801\n",
      "epoch:201,loss:0.1264\n",
      "epoch:201,loss:0.0825\n",
      "epoch:201,loss:0.6190\n",
      "epoch:201,loss:0.2475\n",
      "epoch:201,loss:0.0632\n",
      "epoch:201,loss:0.1189\n",
      "epoch:201,loss:0.0319\n",
      "epoch:201,loss:0.1580\n",
      "epoch:201,loss:0.0195\n",
      "epoch:201,loss:0.4850\n",
      "epoch:201,loss:0.4380\n",
      "epoch:201,loss:1.6085\n",
      "epoch:201,loss:0.1753\n",
      "epoch:201,loss:0.0780\n",
      "epoch:201,loss:0.0149\n",
      "epoch:201,loss:0.0425\n",
      "epoch:201,loss:0.7676\n",
      "epoch:201,loss:0.1341\n",
      "epoch:201,loss:0.0251\n",
      "epoch:201,loss:0.0150\n",
      "epoch:201,loss:2.3638\n",
      "epoch:201,loss:0.0792\n",
      "epoch:201,loss:0.0183\n",
      "epoch:201,loss:0.4318\n",
      "epoch:201,loss:0.0180\n",
      "epoch:201,loss:0.1517\n",
      "epoch:201,loss:0.3286\n",
      "epoch:201,loss:0.2597\n",
      "epoch:201,loss:0.4129\n",
      "epoch:201,loss:0.2854\n",
      "epoch:201,loss:0.0546\n",
      "epoch:201,loss:0.1765\n",
      "epoch:201,loss:0.0253\n",
      "epoch:201,loss:0.1221\n",
      "epoch:201,loss:0.2716\n",
      "epoch:201,loss:0.0420\n",
      "epoch:201,loss:0.0391\n",
      "epoch:201,loss:0.7169\n",
      "epoch:201,loss:0.0088\n",
      "epoch:201,loss:0.0995\n",
      "============================================\n",
      "准确率由： tensor(0.9228) 上升至： tensor(0.9283) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第201个epoch的识别准确率为：92%\n",
      "epoch:202,loss:0.1241\n",
      "epoch:202,loss:0.1055\n",
      "epoch:202,loss:0.2654\n",
      "epoch:202,loss:0.1580\n",
      "epoch:202,loss:0.0395\n",
      "epoch:202,loss:0.5279\n",
      "epoch:202,loss:0.3867\n",
      "epoch:202,loss:0.0416\n",
      "epoch:202,loss:0.0260\n",
      "epoch:202,loss:0.1802\n",
      "epoch:202,loss:0.0143\n",
      "epoch:202,loss:0.1379\n",
      "epoch:202,loss:0.3155\n",
      "epoch:202,loss:0.3562\n",
      "epoch:202,loss:1.1952\n",
      "epoch:202,loss:0.0341\n",
      "epoch:202,loss:0.9256\n",
      "epoch:202,loss:0.2877\n",
      "epoch:202,loss:0.0546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:202,loss:0.0902\n",
      "epoch:202,loss:0.1689\n",
      "epoch:202,loss:0.0917\n",
      "epoch:202,loss:0.1284\n",
      "epoch:202,loss:0.1285\n",
      "epoch:202,loss:0.7690\n",
      "epoch:202,loss:1.8010\n",
      "epoch:202,loss:0.0741\n",
      "epoch:202,loss:0.6526\n",
      "epoch:202,loss:0.1174\n",
      "epoch:202,loss:0.0340\n",
      "epoch:202,loss:0.0258\n",
      "epoch:202,loss:0.0404\n",
      "epoch:202,loss:0.0155\n",
      "epoch:202,loss:0.0228\n",
      "epoch:202,loss:0.1328\n",
      "epoch:202,loss:0.1485\n",
      "epoch:202,loss:0.2323\n",
      "epoch:202,loss:0.0277\n",
      "epoch:202,loss:0.0859\n",
      "epoch:202,loss:0.1672\n",
      "epoch:202,loss:0.6652\n",
      "epoch:202,loss:0.3976\n",
      "epoch:202,loss:0.0220\n",
      "epoch:202,loss:0.0159\n",
      "epoch:202,loss:0.3994\n",
      "epoch:202,loss:0.0723\n",
      "epoch:202,loss:0.6139\n",
      "epoch:202,loss:0.1069\n",
      "epoch:202,loss:0.2087\n",
      "epoch:202,loss:0.6951\n",
      "epoch:202,loss:0.0724\n",
      "epoch:202,loss:0.3087\n",
      "epoch:202,loss:0.1107\n",
      "epoch:202,loss:0.0617\n",
      "epoch:202,loss:0.0561\n",
      "epoch:202,loss:0.0988\n",
      "epoch:202,loss:0.0560\n",
      "epoch:202,loss:0.0676\n",
      "epoch:202,loss:0.4431\n",
      "epoch:202,loss:0.0311\n",
      "============================================\n",
      "第202个epoch的识别准确率为：92%\n",
      "epoch:203,loss:0.0183\n",
      "epoch:203,loss:0.1647\n",
      "epoch:203,loss:0.0268\n",
      "epoch:203,loss:1.1864\n",
      "epoch:203,loss:0.1386\n",
      "epoch:203,loss:0.0411\n",
      "epoch:203,loss:0.0309\n",
      "epoch:203,loss:0.0252\n",
      "epoch:203,loss:0.0430\n",
      "epoch:203,loss:0.0483\n",
      "epoch:203,loss:0.0952\n",
      "epoch:203,loss:0.3066\n",
      "epoch:203,loss:0.0642\n",
      "epoch:203,loss:0.2021\n",
      "epoch:203,loss:0.0141\n",
      "epoch:203,loss:0.0035\n",
      "epoch:203,loss:0.1107\n",
      "epoch:203,loss:0.1819\n",
      "epoch:203,loss:0.3022\n",
      "epoch:203,loss:0.4774\n",
      "epoch:203,loss:0.0664\n",
      "epoch:203,loss:0.1582\n",
      "epoch:203,loss:0.0349\n",
      "epoch:203,loss:0.0620\n",
      "epoch:203,loss:0.1655\n",
      "epoch:203,loss:0.0483\n",
      "epoch:203,loss:0.0693\n",
      "epoch:203,loss:0.2070\n",
      "epoch:203,loss:0.4787\n",
      "epoch:203,loss:0.0610\n",
      "epoch:203,loss:0.0894\n",
      "epoch:203,loss:0.3042\n",
      "epoch:203,loss:0.0405\n",
      "epoch:203,loss:0.0188\n",
      "epoch:203,loss:0.2123\n",
      "epoch:203,loss:0.1332\n",
      "epoch:203,loss:1.0268\n",
      "epoch:203,loss:0.0935\n",
      "epoch:203,loss:0.1842\n",
      "epoch:203,loss:0.0523\n",
      "epoch:203,loss:0.0744\n",
      "epoch:203,loss:0.0226\n",
      "epoch:203,loss:0.0147\n",
      "epoch:203,loss:0.1703\n",
      "epoch:203,loss:0.3081\n",
      "epoch:203,loss:0.0431\n",
      "epoch:203,loss:0.9733\n",
      "epoch:203,loss:0.0248\n",
      "epoch:203,loss:0.3993\n",
      "epoch:203,loss:0.5055\n",
      "epoch:203,loss:0.0720\n",
      "epoch:203,loss:0.2004\n",
      "epoch:203,loss:0.9390\n",
      "epoch:203,loss:0.2226\n",
      "epoch:203,loss:0.0770\n",
      "epoch:203,loss:0.0472\n",
      "epoch:203,loss:0.1834\n",
      "epoch:203,loss:0.1302\n",
      "epoch:203,loss:0.3769\n",
      "epoch:203,loss:0.5685\n",
      "============================================\n",
      "准确率由： tensor(0.9283) 上升至： tensor(0.9403) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第203个epoch的识别准确率为：94%\n",
      "epoch:204,loss:0.4024\n",
      "epoch:204,loss:0.0032\n",
      "epoch:204,loss:0.0770\n",
      "epoch:204,loss:0.1019\n",
      "epoch:204,loss:0.0359\n",
      "epoch:204,loss:0.0460\n",
      "epoch:204,loss:0.0235\n",
      "epoch:204,loss:0.2739\n",
      "epoch:204,loss:0.6209\n",
      "epoch:204,loss:0.0434\n",
      "epoch:204,loss:0.2713\n",
      "epoch:204,loss:0.2523\n",
      "epoch:204,loss:0.1468\n",
      "epoch:204,loss:0.0405\n",
      "epoch:204,loss:0.0139\n",
      "epoch:204,loss:0.7442\n",
      "epoch:204,loss:0.1082\n",
      "epoch:204,loss:0.0418\n",
      "epoch:204,loss:0.0261\n",
      "epoch:204,loss:0.2099\n",
      "epoch:204,loss:0.0582\n",
      "epoch:204,loss:0.5166\n",
      "epoch:204,loss:0.2493\n",
      "epoch:204,loss:0.1756\n",
      "epoch:204,loss:0.0832\n",
      "epoch:204,loss:0.0911\n",
      "epoch:204,loss:0.0017\n",
      "epoch:204,loss:0.0521\n",
      "epoch:204,loss:0.0677\n",
      "epoch:204,loss:0.0571\n",
      "epoch:204,loss:0.0178\n",
      "epoch:204,loss:0.0616\n",
      "epoch:204,loss:0.6286\n",
      "epoch:204,loss:0.0736\n",
      "epoch:204,loss:0.0081\n",
      "epoch:204,loss:0.7045\n",
      "epoch:204,loss:0.8828\n",
      "epoch:204,loss:0.0496\n",
      "epoch:204,loss:0.1090\n",
      "epoch:204,loss:0.0492\n",
      "epoch:204,loss:0.0176\n",
      "epoch:204,loss:0.1794\n",
      "epoch:204,loss:0.0428\n",
      "epoch:204,loss:0.0117\n",
      "epoch:204,loss:0.1869\n",
      "epoch:204,loss:0.0706\n",
      "epoch:204,loss:0.8795\n",
      "epoch:204,loss:0.0472\n",
      "epoch:204,loss:0.4489\n",
      "epoch:204,loss:0.0186\n",
      "epoch:204,loss:0.0992\n",
      "epoch:204,loss:0.9945\n",
      "epoch:204,loss:0.4987\n",
      "epoch:204,loss:0.0723\n",
      "epoch:204,loss:0.0142\n",
      "epoch:204,loss:0.1558\n",
      "epoch:204,loss:0.0621\n",
      "epoch:204,loss:0.4489\n",
      "epoch:204,loss:0.0941\n",
      "epoch:204,loss:0.0205\n",
      "============================================\n",
      "第204个epoch的识别准确率为：92%\n",
      "epoch:205,loss:0.0740\n",
      "epoch:205,loss:0.1506\n",
      "epoch:205,loss:0.2541\n",
      "epoch:205,loss:0.7387\n",
      "epoch:205,loss:0.0508\n",
      "epoch:205,loss:0.0246\n",
      "epoch:205,loss:0.0975\n",
      "epoch:205,loss:0.2030\n",
      "epoch:205,loss:0.0194\n",
      "epoch:205,loss:0.3749\n",
      "epoch:205,loss:0.0771\n",
      "epoch:205,loss:0.1119\n",
      "epoch:205,loss:0.0355\n",
      "epoch:205,loss:0.0526\n",
      "epoch:205,loss:0.5940\n",
      "epoch:205,loss:0.0325\n",
      "epoch:205,loss:0.0081\n",
      "epoch:205,loss:0.2113\n",
      "epoch:205,loss:0.4149\n",
      "epoch:205,loss:0.5316\n",
      "epoch:205,loss:0.0628\n",
      "epoch:205,loss:0.0260\n",
      "epoch:205,loss:0.0328\n",
      "epoch:205,loss:0.3607\n",
      "epoch:205,loss:0.0406\n",
      "epoch:205,loss:0.4935\n",
      "epoch:205,loss:0.2188\n",
      "epoch:205,loss:0.1525\n",
      "epoch:205,loss:0.0302\n",
      "epoch:205,loss:0.2340\n",
      "epoch:205,loss:0.0201\n",
      "epoch:205,loss:0.0558\n",
      "epoch:205,loss:0.1933\n",
      "epoch:205,loss:0.2783\n",
      "epoch:205,loss:0.0301\n",
      "epoch:205,loss:0.0667\n",
      "epoch:205,loss:0.1743\n",
      "epoch:205,loss:0.0069\n",
      "epoch:205,loss:0.1497\n",
      "epoch:205,loss:0.1754\n",
      "epoch:205,loss:0.5847\n",
      "epoch:205,loss:0.0133\n",
      "epoch:205,loss:1.3230\n",
      "epoch:205,loss:0.2241\n",
      "epoch:205,loss:0.3568\n",
      "epoch:205,loss:0.0819\n",
      "epoch:205,loss:0.0360\n",
      "epoch:205,loss:0.2328\n",
      "epoch:205,loss:0.4808\n",
      "epoch:205,loss:0.0518\n",
      "epoch:205,loss:0.1614\n",
      "epoch:205,loss:0.3206\n",
      "epoch:205,loss:0.0591\n",
      "epoch:205,loss:0.0395\n",
      "epoch:205,loss:0.0091\n",
      "epoch:205,loss:0.0820\n",
      "epoch:205,loss:0.5288\n",
      "epoch:205,loss:0.0097\n",
      "epoch:205,loss:0.1462\n",
      "epoch:205,loss:0.0673\n",
      "============================================\n",
      "准确率由： tensor(0.9403) 上升至： tensor(0.9439) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第205个epoch的识别准确率为：94%\n",
      "epoch:206,loss:0.0274\n",
      "epoch:206,loss:0.4014\n",
      "epoch:206,loss:0.1351\n",
      "epoch:206,loss:0.0125\n",
      "epoch:206,loss:0.6432\n",
      "epoch:206,loss:0.0018\n",
      "epoch:206,loss:0.0676\n",
      "epoch:206,loss:0.1178\n",
      "epoch:206,loss:0.2922\n",
      "epoch:206,loss:1.3116\n",
      "epoch:206,loss:0.0270\n",
      "epoch:206,loss:0.1331\n",
      "epoch:206,loss:0.0984\n",
      "epoch:206,loss:0.1062\n",
      "epoch:206,loss:0.1676\n",
      "epoch:206,loss:0.0164\n",
      "epoch:206,loss:1.5638\n",
      "epoch:206,loss:0.0243\n",
      "epoch:206,loss:0.2582\n",
      "epoch:206,loss:0.0509\n",
      "epoch:206,loss:0.1372\n",
      "epoch:206,loss:0.1245\n",
      "epoch:206,loss:0.1737\n",
      "epoch:206,loss:0.0387\n",
      "epoch:206,loss:0.3487\n",
      "epoch:206,loss:0.0348\n",
      "epoch:206,loss:0.0092\n",
      "epoch:206,loss:0.8867\n",
      "epoch:206,loss:0.0323\n",
      "epoch:206,loss:0.2935\n",
      "epoch:206,loss:0.1228\n",
      "epoch:206,loss:0.2868\n",
      "epoch:206,loss:0.1264\n",
      "epoch:206,loss:1.0029\n",
      "epoch:206,loss:0.0461\n",
      "epoch:206,loss:0.3684\n",
      "epoch:206,loss:0.0460\n",
      "epoch:206,loss:0.2056\n",
      "epoch:206,loss:0.7145\n",
      "epoch:206,loss:0.4441\n",
      "epoch:206,loss:1.0834\n",
      "epoch:206,loss:0.0703\n",
      "epoch:206,loss:0.0705\n",
      "epoch:206,loss:0.9950\n",
      "epoch:206,loss:0.1563\n",
      "epoch:206,loss:0.0863\n",
      "epoch:206,loss:0.7791\n",
      "epoch:206,loss:0.3422\n",
      "epoch:206,loss:0.0830\n",
      "epoch:206,loss:0.0486\n",
      "epoch:206,loss:0.5069\n",
      "epoch:206,loss:0.0531\n",
      "epoch:206,loss:0.3722\n",
      "epoch:206,loss:0.7484\n",
      "epoch:206,loss:0.7166\n",
      "epoch:206,loss:0.0566\n",
      "epoch:206,loss:0.6887\n",
      "epoch:206,loss:0.5393\n",
      "epoch:206,loss:0.1072\n",
      "epoch:206,loss:0.6027\n",
      "============================================\n",
      "第206个epoch的识别准确率为：92%\n",
      "epoch:207,loss:1.2188\n",
      "epoch:207,loss:0.0062\n",
      "epoch:207,loss:0.1937\n",
      "epoch:207,loss:0.0328\n",
      "epoch:207,loss:0.0616\n",
      "epoch:207,loss:0.0730\n",
      "epoch:207,loss:0.0729\n",
      "epoch:207,loss:0.1348\n",
      "epoch:207,loss:0.0635\n",
      "epoch:207,loss:0.0646\n",
      "epoch:207,loss:0.2330\n",
      "epoch:207,loss:0.2336\n",
      "epoch:207,loss:0.0549\n",
      "epoch:207,loss:0.0520\n",
      "epoch:207,loss:0.0555\n",
      "epoch:207,loss:0.0533\n",
      "epoch:207,loss:0.0264\n",
      "epoch:207,loss:0.0399\n",
      "epoch:207,loss:0.1829\n",
      "epoch:207,loss:0.1923\n",
      "epoch:207,loss:0.0297\n",
      "epoch:207,loss:0.4379\n",
      "epoch:207,loss:0.0492\n",
      "epoch:207,loss:0.4292\n",
      "epoch:207,loss:0.2730\n",
      "epoch:207,loss:0.4733\n",
      "epoch:207,loss:0.1050\n",
      "epoch:207,loss:0.2723\n",
      "epoch:207,loss:0.4971\n",
      "epoch:207,loss:1.0061\n",
      "epoch:207,loss:0.0908\n",
      "epoch:207,loss:1.3984\n",
      "epoch:207,loss:0.1643\n",
      "epoch:207,loss:0.8681\n",
      "epoch:207,loss:0.2527\n",
      "epoch:207,loss:0.0468\n",
      "epoch:207,loss:0.0920\n",
      "epoch:207,loss:0.0633\n",
      "epoch:207,loss:0.4436\n",
      "epoch:207,loss:1.0776\n",
      "epoch:207,loss:1.0737\n",
      "epoch:207,loss:0.4348\n",
      "epoch:207,loss:0.1602\n",
      "epoch:207,loss:0.2368\n",
      "epoch:207,loss:0.0498\n",
      "epoch:207,loss:0.2163\n",
      "epoch:207,loss:0.0247\n",
      "epoch:207,loss:0.2366\n",
      "epoch:207,loss:0.1261\n",
      "epoch:207,loss:0.0154\n",
      "epoch:207,loss:0.2224\n",
      "epoch:207,loss:0.6330\n",
      "epoch:207,loss:0.0126\n",
      "epoch:207,loss:0.0597\n",
      "epoch:207,loss:0.8715\n",
      "epoch:207,loss:0.7273\n",
      "epoch:207,loss:0.0104\n",
      "epoch:207,loss:0.2538\n",
      "epoch:207,loss:0.0105\n",
      "epoch:207,loss:1.5731\n",
      "============================================\n",
      "第207个epoch的识别准确率为：92%\n",
      "epoch:208,loss:0.0627\n",
      "epoch:208,loss:0.4940\n",
      "epoch:208,loss:0.2086\n",
      "epoch:208,loss:0.1997\n",
      "epoch:208,loss:0.0457\n",
      "epoch:208,loss:0.0028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:208,loss:0.0697\n",
      "epoch:208,loss:0.1355\n",
      "epoch:208,loss:0.0219\n",
      "epoch:208,loss:0.4626\n",
      "epoch:208,loss:0.2162\n",
      "epoch:208,loss:0.0395\n",
      "epoch:208,loss:0.7550\n",
      "epoch:208,loss:0.0138\n",
      "epoch:208,loss:0.2290\n",
      "epoch:208,loss:0.2500\n",
      "epoch:208,loss:0.0209\n",
      "epoch:208,loss:0.0503\n",
      "epoch:208,loss:1.4439\n",
      "epoch:208,loss:0.0165\n",
      "epoch:208,loss:0.2475\n",
      "epoch:208,loss:0.0316\n",
      "epoch:208,loss:0.0367\n",
      "epoch:208,loss:0.1103\n",
      "epoch:208,loss:0.0740\n",
      "epoch:208,loss:0.6190\n",
      "epoch:208,loss:0.0197\n",
      "epoch:208,loss:0.0272\n",
      "epoch:208,loss:0.6598\n",
      "epoch:208,loss:0.0272\n",
      "epoch:208,loss:0.1556\n",
      "epoch:208,loss:0.3645\n",
      "epoch:208,loss:0.3917\n",
      "epoch:208,loss:0.3663\n",
      "epoch:208,loss:1.1372\n",
      "epoch:208,loss:0.0285\n",
      "epoch:208,loss:0.0157\n",
      "epoch:208,loss:0.8501\n",
      "epoch:208,loss:0.0243\n",
      "epoch:208,loss:0.1181\n",
      "epoch:208,loss:0.0850\n",
      "epoch:208,loss:0.1297\n",
      "epoch:208,loss:0.2179\n",
      "epoch:208,loss:0.0262\n",
      "epoch:208,loss:0.0770\n",
      "epoch:208,loss:0.2066\n",
      "epoch:208,loss:0.1607\n",
      "epoch:208,loss:0.1131\n",
      "epoch:208,loss:0.0985\n",
      "epoch:208,loss:0.1074\n",
      "epoch:208,loss:0.0603\n",
      "epoch:208,loss:0.0327\n",
      "epoch:208,loss:0.0197\n",
      "epoch:208,loss:0.0190\n",
      "epoch:208,loss:0.2045\n",
      "epoch:208,loss:0.1063\n",
      "epoch:208,loss:0.0865\n",
      "epoch:208,loss:0.1999\n",
      "epoch:208,loss:0.1367\n",
      "epoch:208,loss:0.2412\n",
      "============================================\n",
      "第208个epoch的识别准确率为：93%\n",
      "epoch:209,loss:0.0762\n",
      "epoch:209,loss:0.0128\n",
      "epoch:209,loss:0.6536\n",
      "epoch:209,loss:0.3993\n",
      "epoch:209,loss:0.0872\n",
      "epoch:209,loss:0.0092\n",
      "epoch:209,loss:0.2735\n",
      "epoch:209,loss:0.5388\n",
      "epoch:209,loss:0.1757\n",
      "epoch:209,loss:0.0668\n",
      "epoch:209,loss:0.2958\n",
      "epoch:209,loss:0.0929\n",
      "epoch:209,loss:0.1806\n",
      "epoch:209,loss:0.4021\n",
      "epoch:209,loss:0.5547\n",
      "epoch:209,loss:0.1493\n",
      "epoch:209,loss:0.3003\n",
      "epoch:209,loss:0.3847\n",
      "epoch:209,loss:0.0317\n",
      "epoch:209,loss:0.1902\n",
      "epoch:209,loss:0.0574\n",
      "epoch:209,loss:0.1659\n",
      "epoch:209,loss:0.0063\n",
      "epoch:209,loss:0.0367\n",
      "epoch:209,loss:0.0244\n",
      "epoch:209,loss:0.1585\n",
      "epoch:209,loss:0.2078\n",
      "epoch:209,loss:0.2325\n",
      "epoch:209,loss:0.0505\n",
      "epoch:209,loss:0.1129\n",
      "epoch:209,loss:0.4906\n",
      "epoch:209,loss:0.0341\n",
      "epoch:209,loss:0.1386\n",
      "epoch:209,loss:0.0097\n",
      "epoch:209,loss:0.5263\n",
      "epoch:209,loss:0.0410\n",
      "epoch:209,loss:0.0692\n",
      "epoch:209,loss:0.1082\n",
      "epoch:209,loss:0.9892\n",
      "epoch:209,loss:0.2330\n",
      "epoch:209,loss:0.2238\n",
      "epoch:209,loss:0.9385\n",
      "epoch:209,loss:1.0655\n",
      "epoch:209,loss:0.0409\n",
      "epoch:209,loss:0.1276\n",
      "epoch:209,loss:0.0702\n",
      "epoch:209,loss:0.1368\n",
      "epoch:209,loss:0.0993\n",
      "epoch:209,loss:0.5051\n",
      "epoch:209,loss:0.0344\n",
      "epoch:209,loss:0.8291\n",
      "epoch:209,loss:0.4503\n",
      "epoch:209,loss:0.1354\n",
      "epoch:209,loss:0.0176\n",
      "epoch:209,loss:0.0633\n",
      "epoch:209,loss:0.1772\n",
      "epoch:209,loss:0.1026\n",
      "epoch:209,loss:0.0184\n",
      "epoch:209,loss:0.0135\n",
      "epoch:209,loss:0.1874\n",
      "============================================\n",
      "第209个epoch的识别准确率为：93%\n",
      "epoch:210,loss:0.0155\n",
      "epoch:210,loss:0.3538\n",
      "epoch:210,loss:0.0373\n",
      "epoch:210,loss:0.1857\n",
      "epoch:210,loss:0.2216\n",
      "epoch:210,loss:0.1921\n",
      "epoch:210,loss:0.0733\n",
      "epoch:210,loss:0.0260\n",
      "epoch:210,loss:0.0701\n",
      "epoch:210,loss:0.3754\n",
      "epoch:210,loss:0.0439\n",
      "epoch:210,loss:0.0715\n",
      "epoch:210,loss:0.0917\n",
      "epoch:210,loss:0.1092\n",
      "epoch:210,loss:0.0338\n",
      "epoch:210,loss:0.1898\n",
      "epoch:210,loss:0.0731\n",
      "epoch:210,loss:0.0464\n",
      "epoch:210,loss:0.0157\n",
      "epoch:210,loss:0.1038\n",
      "epoch:210,loss:0.1308\n",
      "epoch:210,loss:0.0968\n",
      "epoch:210,loss:0.1107\n",
      "epoch:210,loss:0.3935\n",
      "epoch:210,loss:0.1238\n",
      "epoch:210,loss:0.0972\n",
      "epoch:210,loss:0.4862\n",
      "epoch:210,loss:0.0434\n",
      "epoch:210,loss:1.1252\n",
      "epoch:210,loss:0.0046\n",
      "epoch:210,loss:0.0195\n",
      "epoch:210,loss:0.2272\n",
      "epoch:210,loss:0.1691\n",
      "epoch:210,loss:0.0706\n",
      "epoch:210,loss:0.1121\n",
      "epoch:210,loss:0.0441\n",
      "epoch:210,loss:0.1258\n",
      "epoch:210,loss:0.0346\n",
      "epoch:210,loss:0.5584\n",
      "epoch:210,loss:0.0771\n",
      "epoch:210,loss:0.2672\n",
      "epoch:210,loss:0.0797\n",
      "epoch:210,loss:0.2794\n",
      "epoch:210,loss:0.2226\n",
      "epoch:210,loss:0.0504\n",
      "epoch:210,loss:0.0081\n",
      "epoch:210,loss:0.0562\n",
      "epoch:210,loss:0.0927\n",
      "epoch:210,loss:0.7784\n",
      "epoch:210,loss:0.2603\n",
      "epoch:210,loss:0.2290\n",
      "epoch:210,loss:0.1815\n",
      "epoch:210,loss:0.2430\n",
      "epoch:210,loss:0.0150\n",
      "epoch:210,loss:0.8021\n",
      "epoch:210,loss:0.2011\n",
      "epoch:210,loss:0.2624\n",
      "epoch:210,loss:0.3578\n",
      "epoch:210,loss:0.0051\n",
      "epoch:210,loss:0.1476\n",
      "============================================\n",
      "第210个epoch的识别准确率为：94%\n",
      "epoch:211,loss:0.0875\n",
      "epoch:211,loss:0.0328\n",
      "epoch:211,loss:0.0712\n",
      "epoch:211,loss:0.0476\n",
      "epoch:211,loss:0.0391\n",
      "epoch:211,loss:0.0520\n",
      "epoch:211,loss:0.0674\n",
      "epoch:211,loss:0.0231\n",
      "epoch:211,loss:0.0246\n",
      "epoch:211,loss:0.1995\n",
      "epoch:211,loss:0.2534\n",
      "epoch:211,loss:0.0759\n",
      "epoch:211,loss:0.2131\n",
      "epoch:211,loss:0.2462\n",
      "epoch:211,loss:0.1680\n",
      "epoch:211,loss:0.0035\n",
      "epoch:211,loss:0.0508\n",
      "epoch:211,loss:0.1702\n",
      "epoch:211,loss:0.3548\n",
      "epoch:211,loss:0.7363\n",
      "epoch:211,loss:0.0205\n",
      "epoch:211,loss:0.8378\n",
      "epoch:211,loss:0.0547\n",
      "epoch:211,loss:0.1535\n",
      "epoch:211,loss:0.1138\n",
      "epoch:211,loss:0.0161\n",
      "epoch:211,loss:0.2830\n",
      "epoch:211,loss:0.4544\n",
      "epoch:211,loss:0.1423\n",
      "epoch:211,loss:0.0574\n",
      "epoch:211,loss:0.0663\n",
      "epoch:211,loss:0.4930\n",
      "epoch:211,loss:0.1834\n",
      "epoch:211,loss:0.0168\n",
      "epoch:211,loss:0.0563\n",
      "epoch:211,loss:0.0141\n",
      "epoch:211,loss:0.0613\n",
      "epoch:211,loss:0.0129\n",
      "epoch:211,loss:0.1811\n",
      "epoch:211,loss:0.3709\n",
      "epoch:211,loss:0.0878\n",
      "epoch:211,loss:0.0165\n",
      "epoch:211,loss:0.0029\n",
      "epoch:211,loss:0.5671\n",
      "epoch:211,loss:0.1436\n",
      "epoch:211,loss:0.1238\n",
      "epoch:211,loss:0.2143\n",
      "epoch:211,loss:0.0499\n",
      "epoch:211,loss:0.2761\n",
      "epoch:211,loss:0.1113\n",
      "epoch:211,loss:0.0102\n",
      "epoch:211,loss:0.2647\n",
      "epoch:211,loss:0.1315\n",
      "epoch:211,loss:0.0602\n",
      "epoch:211,loss:0.4861\n",
      "epoch:211,loss:0.1782\n",
      "epoch:211,loss:0.0491\n",
      "epoch:211,loss:0.1218\n",
      "epoch:211,loss:0.0042\n",
      "epoch:211,loss:0.0061\n",
      "============================================\n",
      "准确率由： tensor(0.9439) 上升至： tensor(0.9467) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第211个epoch的识别准确率为：94%\n",
      "epoch:212,loss:0.0329\n",
      "epoch:212,loss:0.0184\n",
      "epoch:212,loss:0.0283\n",
      "epoch:212,loss:0.5881\n",
      "epoch:212,loss:0.0292\n",
      "epoch:212,loss:0.4637\n",
      "epoch:212,loss:0.9222\n",
      "epoch:212,loss:0.0081\n",
      "epoch:212,loss:0.0463\n",
      "epoch:212,loss:0.0820\n",
      "epoch:212,loss:0.0447\n",
      "epoch:212,loss:0.1881\n",
      "epoch:212,loss:1.2108\n",
      "epoch:212,loss:0.0413\n",
      "epoch:212,loss:0.4596\n",
      "epoch:212,loss:0.0652\n",
      "epoch:212,loss:0.0258\n",
      "epoch:212,loss:0.0776\n",
      "epoch:212,loss:0.0119\n",
      "epoch:212,loss:0.1097\n",
      "epoch:212,loss:0.0717\n",
      "epoch:212,loss:0.0750\n",
      "epoch:212,loss:0.0109\n",
      "epoch:212,loss:0.0453\n",
      "epoch:212,loss:0.0464\n",
      "epoch:212,loss:0.0673\n",
      "epoch:212,loss:0.1477\n",
      "epoch:212,loss:0.0356\n",
      "epoch:212,loss:0.1306\n",
      "epoch:212,loss:0.0660\n",
      "epoch:212,loss:0.0115\n",
      "epoch:212,loss:0.0205\n",
      "epoch:212,loss:0.0764\n",
      "epoch:212,loss:0.0339\n",
      "epoch:212,loss:0.1925\n",
      "epoch:212,loss:0.0655\n",
      "epoch:212,loss:0.0198\n",
      "epoch:212,loss:0.0088\n",
      "epoch:212,loss:0.1830\n",
      "epoch:212,loss:0.0760\n",
      "epoch:212,loss:0.0331\n",
      "epoch:212,loss:0.3831\n",
      "epoch:212,loss:0.5258\n",
      "epoch:212,loss:0.1503\n",
      "epoch:212,loss:0.0310\n",
      "epoch:212,loss:0.0865\n",
      "epoch:212,loss:0.0211\n",
      "epoch:212,loss:0.1988\n",
      "epoch:212,loss:0.0050\n",
      "epoch:212,loss:0.3664\n",
      "epoch:212,loss:0.1340\n",
      "epoch:212,loss:0.2580\n",
      "epoch:212,loss:0.1096\n",
      "epoch:212,loss:0.0293\n",
      "epoch:212,loss:0.0677\n",
      "epoch:212,loss:0.8557\n",
      "epoch:212,loss:0.1973\n",
      "epoch:212,loss:0.2304\n",
      "epoch:212,loss:0.0088\n",
      "epoch:212,loss:0.0675\n",
      "============================================\n",
      "第212个epoch的识别准确率为：93%\n",
      "epoch:213,loss:0.0763\n",
      "epoch:213,loss:0.1137\n",
      "epoch:213,loss:0.0419\n",
      "epoch:213,loss:0.0092\n",
      "epoch:213,loss:0.0299\n",
      "epoch:213,loss:0.0280\n",
      "epoch:213,loss:0.0150\n",
      "epoch:213,loss:0.2035\n",
      "epoch:213,loss:0.0062\n",
      "epoch:213,loss:0.6630\n",
      "epoch:213,loss:0.3083\n",
      "epoch:213,loss:2.2122\n",
      "epoch:213,loss:0.0227\n",
      "epoch:213,loss:0.0104\n",
      "epoch:213,loss:0.7587\n",
      "epoch:213,loss:0.1587\n",
      "epoch:213,loss:0.0050\n",
      "epoch:213,loss:0.0052\n",
      "epoch:213,loss:0.0230\n",
      "epoch:213,loss:0.0989\n",
      "epoch:213,loss:0.0175\n",
      "epoch:213,loss:0.3811\n",
      "epoch:213,loss:0.0100\n",
      "epoch:213,loss:0.0502\n",
      "epoch:213,loss:0.2378\n",
      "epoch:213,loss:0.1812\n",
      "epoch:213,loss:0.1585\n",
      "epoch:213,loss:0.6157\n",
      "epoch:213,loss:0.0123\n",
      "epoch:213,loss:0.2072\n",
      "epoch:213,loss:0.3140\n",
      "epoch:213,loss:0.0452\n",
      "epoch:213,loss:0.0655\n",
      "epoch:213,loss:0.5819\n",
      "epoch:213,loss:0.2798\n",
      "epoch:213,loss:0.1164\n",
      "epoch:213,loss:0.0201\n",
      "epoch:213,loss:0.0209\n",
      "epoch:213,loss:0.0193\n",
      "epoch:213,loss:0.0409\n",
      "epoch:213,loss:0.0946\n",
      "epoch:213,loss:0.1607\n",
      "epoch:213,loss:0.1531\n",
      "epoch:213,loss:0.0183\n",
      "epoch:213,loss:0.6886\n",
      "epoch:213,loss:0.0598\n",
      "epoch:213,loss:0.0968\n",
      "epoch:213,loss:0.0954\n",
      "epoch:213,loss:0.6757\n",
      "epoch:213,loss:0.2066\n",
      "epoch:213,loss:0.0563\n",
      "epoch:213,loss:0.0101\n",
      "epoch:213,loss:0.1828\n",
      "epoch:213,loss:0.5359\n",
      "epoch:213,loss:0.0357\n",
      "epoch:213,loss:0.0286\n",
      "epoch:213,loss:1.0126\n",
      "epoch:213,loss:0.0116\n",
      "epoch:213,loss:0.0462\n",
      "epoch:213,loss:1.3973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "第213个epoch的识别准确率为：93%\n",
      "epoch:214,loss:0.0671\n",
      "epoch:214,loss:0.0528\n",
      "epoch:214,loss:0.0422\n",
      "epoch:214,loss:0.0040\n",
      "epoch:214,loss:0.2319\n",
      "epoch:214,loss:0.0223\n",
      "epoch:214,loss:0.0457\n",
      "epoch:214,loss:0.0683\n",
      "epoch:214,loss:0.2688\n",
      "epoch:214,loss:0.3291\n",
      "epoch:214,loss:0.5244\n",
      "epoch:214,loss:0.0413\n",
      "epoch:214,loss:0.8277\n",
      "epoch:214,loss:0.1189\n",
      "epoch:214,loss:0.1427\n",
      "epoch:214,loss:0.1047\n",
      "epoch:214,loss:0.0615\n",
      "epoch:214,loss:0.0620\n",
      "epoch:214,loss:0.1611\n",
      "epoch:214,loss:0.0117\n",
      "epoch:214,loss:0.4052\n",
      "epoch:214,loss:0.0120\n",
      "epoch:214,loss:0.1768\n",
      "epoch:214,loss:0.1761\n",
      "epoch:214,loss:0.2051\n",
      "epoch:214,loss:0.4730\n",
      "epoch:214,loss:0.0070\n",
      "epoch:214,loss:0.0272\n",
      "epoch:214,loss:0.0149\n",
      "epoch:214,loss:0.0572\n",
      "epoch:214,loss:0.2566\n",
      "epoch:214,loss:0.1685\n",
      "epoch:214,loss:0.0514\n",
      "epoch:214,loss:0.6825\n",
      "epoch:214,loss:0.9681\n",
      "epoch:214,loss:1.4488\n",
      "epoch:214,loss:0.0086\n",
      "epoch:214,loss:0.0053\n",
      "epoch:214,loss:0.0500\n",
      "epoch:214,loss:0.8249\n",
      "epoch:214,loss:0.0692\n",
      "epoch:214,loss:0.1206\n",
      "epoch:214,loss:0.1746\n",
      "epoch:214,loss:1.2855\n",
      "epoch:214,loss:0.2087\n",
      "epoch:214,loss:0.0312\n",
      "epoch:214,loss:0.0543\n",
      "epoch:214,loss:0.1448\n",
      "epoch:214,loss:0.0915\n",
      "epoch:214,loss:0.0181\n",
      "epoch:214,loss:0.0213\n",
      "epoch:214,loss:0.0481\n",
      "epoch:214,loss:0.0325\n",
      "epoch:214,loss:0.0048\n",
      "epoch:214,loss:0.4427\n",
      "epoch:214,loss:0.0959\n",
      "epoch:214,loss:0.0738\n",
      "epoch:214,loss:0.5404\n",
      "epoch:214,loss:0.0382\n",
      "epoch:214,loss:0.1290\n",
      "============================================\n",
      "第214个epoch的识别准确率为：94%\n",
      "epoch:215,loss:0.0204\n",
      "epoch:215,loss:0.0477\n",
      "epoch:215,loss:0.0039\n",
      "epoch:215,loss:0.0747\n",
      "epoch:215,loss:0.0199\n",
      "epoch:215,loss:0.2987\n",
      "epoch:215,loss:0.0739\n",
      "epoch:215,loss:0.0169\n",
      "epoch:215,loss:0.4427\n",
      "epoch:215,loss:0.1730\n",
      "epoch:215,loss:0.0125\n",
      "epoch:215,loss:0.0027\n",
      "epoch:215,loss:0.0325\n",
      "epoch:215,loss:0.9456\n",
      "epoch:215,loss:0.0554\n",
      "epoch:215,loss:0.1455\n",
      "epoch:215,loss:0.0817\n",
      "epoch:215,loss:0.0900\n",
      "epoch:215,loss:0.0702\n",
      "epoch:215,loss:0.0318\n",
      "epoch:215,loss:0.0965\n",
      "epoch:215,loss:0.0879\n",
      "epoch:215,loss:1.2045\n",
      "epoch:215,loss:0.0832\n",
      "epoch:215,loss:0.0701\n",
      "epoch:215,loss:0.0354\n",
      "epoch:215,loss:0.0064\n",
      "epoch:215,loss:0.0535\n",
      "epoch:215,loss:0.0407\n",
      "epoch:215,loss:0.0627\n",
      "epoch:215,loss:0.2974\n",
      "epoch:215,loss:0.0266\n",
      "epoch:215,loss:0.0200\n",
      "epoch:215,loss:0.2254\n",
      "epoch:215,loss:0.2165\n",
      "epoch:215,loss:1.1091\n",
      "epoch:215,loss:0.0470\n",
      "epoch:215,loss:0.0017\n",
      "epoch:215,loss:1.3216\n",
      "epoch:215,loss:0.0129\n",
      "epoch:215,loss:0.7720\n",
      "epoch:215,loss:0.3321\n",
      "epoch:215,loss:0.0515\n",
      "epoch:215,loss:0.1584\n",
      "epoch:215,loss:0.0445\n",
      "epoch:215,loss:0.0666\n",
      "epoch:215,loss:0.0218\n",
      "epoch:215,loss:0.6039\n",
      "epoch:215,loss:0.0380\n",
      "epoch:215,loss:0.2895\n",
      "epoch:215,loss:0.3141\n",
      "epoch:215,loss:0.0468\n",
      "epoch:215,loss:0.2906\n",
      "epoch:215,loss:0.6098\n",
      "epoch:215,loss:0.2235\n",
      "epoch:215,loss:0.0965\n",
      "epoch:215,loss:1.0088\n",
      "epoch:215,loss:0.0433\n",
      "epoch:215,loss:1.1080\n",
      "epoch:215,loss:0.6345\n",
      "============================================\n",
      "第215个epoch的识别准确率为：93%\n",
      "epoch:216,loss:0.1653\n",
      "epoch:216,loss:0.0088\n",
      "epoch:216,loss:0.3882\n",
      "epoch:216,loss:0.6508\n",
      "epoch:216,loss:0.0235\n",
      "epoch:216,loss:0.2217\n",
      "epoch:216,loss:0.2637\n",
      "epoch:216,loss:0.1121\n",
      "epoch:216,loss:0.2533\n",
      "epoch:216,loss:0.5295\n",
      "epoch:216,loss:0.1056\n",
      "epoch:216,loss:0.0040\n",
      "epoch:216,loss:0.2014\n",
      "epoch:216,loss:0.0477\n",
      "epoch:216,loss:0.2718\n",
      "epoch:216,loss:0.0806\n",
      "epoch:216,loss:0.0429\n",
      "epoch:216,loss:0.3247\n",
      "epoch:216,loss:0.1321\n",
      "epoch:216,loss:0.1042\n",
      "epoch:216,loss:0.0904\n",
      "epoch:216,loss:0.0476\n",
      "epoch:216,loss:0.1059\n",
      "epoch:216,loss:0.1582\n",
      "epoch:216,loss:0.2746\n",
      "epoch:216,loss:0.0227\n",
      "epoch:216,loss:0.2847\n",
      "epoch:216,loss:0.2774\n",
      "epoch:216,loss:0.2328\n",
      "epoch:216,loss:0.1553\n",
      "epoch:216,loss:0.0865\n",
      "epoch:216,loss:0.1488\n",
      "epoch:216,loss:0.6363\n",
      "epoch:216,loss:0.1508\n",
      "epoch:216,loss:0.0198\n",
      "epoch:216,loss:0.0075\n",
      "epoch:216,loss:0.1680\n",
      "epoch:216,loss:0.0399\n",
      "epoch:216,loss:0.0026\n",
      "epoch:216,loss:0.0218\n",
      "epoch:216,loss:0.3743\n",
      "epoch:216,loss:0.0037\n",
      "epoch:216,loss:0.4910\n",
      "epoch:216,loss:0.0127\n",
      "epoch:216,loss:0.2033\n",
      "epoch:216,loss:0.0907\n",
      "epoch:216,loss:0.1084\n",
      "epoch:216,loss:0.0100\n",
      "epoch:216,loss:0.0540\n",
      "epoch:216,loss:0.0102\n",
      "epoch:216,loss:0.3898\n",
      "epoch:216,loss:0.0227\n",
      "epoch:216,loss:0.1013\n",
      "epoch:216,loss:0.0100\n",
      "epoch:216,loss:0.0361\n",
      "epoch:216,loss:0.0511\n",
      "epoch:216,loss:0.0750\n",
      "epoch:216,loss:0.0354\n",
      "epoch:216,loss:0.1771\n",
      "epoch:216,loss:0.0153\n",
      "============================================\n",
      "准确率由： tensor(0.9467) 上升至： tensor(0.9642) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第216个epoch的识别准确率为：96%\n",
      "epoch:217,loss:1.1557\n",
      "epoch:217,loss:0.0100\n",
      "epoch:217,loss:0.1223\n",
      "epoch:217,loss:0.0019\n",
      "epoch:217,loss:0.0656\n",
      "epoch:217,loss:0.0119\n",
      "epoch:217,loss:0.3161\n",
      "epoch:217,loss:0.2888\n",
      "epoch:217,loss:0.0022\n",
      "epoch:217,loss:0.0291\n",
      "epoch:217,loss:0.0453\n",
      "epoch:217,loss:0.0346\n",
      "epoch:217,loss:0.0290\n",
      "epoch:217,loss:0.1452\n",
      "epoch:217,loss:0.0731\n",
      "epoch:217,loss:0.2280\n",
      "epoch:217,loss:0.0913\n",
      "epoch:217,loss:0.2004\n",
      "epoch:217,loss:0.0219\n",
      "epoch:217,loss:0.1397\n",
      "epoch:217,loss:0.0231\n",
      "epoch:217,loss:0.2022\n",
      "epoch:217,loss:0.1056\n",
      "epoch:217,loss:0.0061\n",
      "epoch:217,loss:0.1165\n",
      "epoch:217,loss:0.7418\n",
      "epoch:217,loss:0.8692\n",
      "epoch:217,loss:0.6938\n",
      "epoch:217,loss:0.0171\n",
      "epoch:217,loss:0.0050\n",
      "epoch:217,loss:0.0096\n",
      "epoch:217,loss:0.4916\n",
      "epoch:217,loss:0.0976\n",
      "epoch:217,loss:0.0949\n",
      "epoch:217,loss:0.2744\n",
      "epoch:217,loss:0.2126\n",
      "epoch:217,loss:0.4733\n",
      "epoch:217,loss:0.4966\n",
      "epoch:217,loss:0.1017\n",
      "epoch:217,loss:0.2993\n",
      "epoch:217,loss:0.1426\n",
      "epoch:217,loss:0.0169\n",
      "epoch:217,loss:0.0911\n",
      "epoch:217,loss:0.2722\n",
      "epoch:217,loss:0.1839\n",
      "epoch:217,loss:0.2914\n",
      "epoch:217,loss:0.0263\n",
      "epoch:217,loss:0.0392\n",
      "epoch:217,loss:0.3139\n",
      "epoch:217,loss:1.9118\n",
      "epoch:217,loss:0.2798\n",
      "epoch:217,loss:0.0490\n",
      "epoch:217,loss:0.0611\n",
      "epoch:217,loss:0.0199\n",
      "epoch:217,loss:0.0101\n",
      "epoch:217,loss:0.2515\n",
      "epoch:217,loss:0.0266\n",
      "epoch:217,loss:0.0166\n",
      "epoch:217,loss:0.0304\n",
      "epoch:217,loss:0.0157\n",
      "============================================\n",
      "第217个epoch的识别准确率为：94%\n",
      "epoch:218,loss:0.1600\n",
      "epoch:218,loss:0.0517\n",
      "epoch:218,loss:0.5576\n",
      "epoch:218,loss:0.0511\n",
      "epoch:218,loss:0.0776\n",
      "epoch:218,loss:0.3006\n",
      "epoch:218,loss:0.0491\n",
      "epoch:218,loss:0.2064\n",
      "epoch:218,loss:0.3887\n",
      "epoch:218,loss:0.5583\n",
      "epoch:218,loss:0.0887\n",
      "epoch:218,loss:0.5758\n",
      "epoch:218,loss:0.0070\n",
      "epoch:218,loss:0.2866\n",
      "epoch:218,loss:0.0147\n",
      "epoch:218,loss:0.1238\n",
      "epoch:218,loss:0.1253\n",
      "epoch:218,loss:0.4812\n",
      "epoch:218,loss:0.2266\n",
      "epoch:218,loss:0.0233\n",
      "epoch:218,loss:0.1055\n",
      "epoch:218,loss:0.0367\n",
      "epoch:218,loss:0.0639\n",
      "epoch:218,loss:0.0717\n",
      "epoch:218,loss:0.9231\n",
      "epoch:218,loss:0.2314\n",
      "epoch:218,loss:0.3612\n",
      "epoch:218,loss:0.0423\n",
      "epoch:218,loss:0.7585\n",
      "epoch:218,loss:0.3576\n",
      "epoch:218,loss:0.6841\n",
      "epoch:218,loss:0.0653\n",
      "epoch:218,loss:0.1488\n",
      "epoch:218,loss:0.1371\n",
      "epoch:218,loss:0.0955\n",
      "epoch:218,loss:1.8089\n",
      "epoch:218,loss:0.3129\n",
      "epoch:218,loss:0.7207\n",
      "epoch:218,loss:1.4271\n",
      "epoch:218,loss:0.0033\n",
      "epoch:218,loss:0.3983\n",
      "epoch:218,loss:0.3006\n",
      "epoch:218,loss:0.0288\n",
      "epoch:218,loss:0.0423\n",
      "epoch:218,loss:0.0689\n",
      "epoch:218,loss:0.0400\n",
      "epoch:218,loss:0.0438\n",
      "epoch:218,loss:0.0397\n",
      "epoch:218,loss:0.0416\n",
      "epoch:218,loss:0.0700\n",
      "epoch:218,loss:0.0254\n",
      "epoch:218,loss:0.2328\n",
      "epoch:218,loss:0.0978\n",
      "epoch:218,loss:0.6244\n",
      "epoch:218,loss:0.1237\n",
      "epoch:218,loss:0.0093\n",
      "epoch:218,loss:0.3659\n",
      "epoch:218,loss:0.0735\n",
      "epoch:218,loss:0.5303\n",
      "epoch:218,loss:0.1052\n",
      "============================================\n",
      "第218个epoch的识别准确率为：95%\n",
      "epoch:219,loss:0.1504\n",
      "epoch:219,loss:0.0254\n",
      "epoch:219,loss:0.0177\n",
      "epoch:219,loss:0.0921\n",
      "epoch:219,loss:1.8602\n",
      "epoch:219,loss:0.1421\n",
      "epoch:219,loss:0.0573\n",
      "epoch:219,loss:0.0694\n",
      "epoch:219,loss:0.0546\n",
      "epoch:219,loss:1.4434\n",
      "epoch:219,loss:0.0126\n",
      "epoch:219,loss:0.1248\n",
      "epoch:219,loss:0.1186\n",
      "epoch:219,loss:0.2161\n",
      "epoch:219,loss:0.0597\n",
      "epoch:219,loss:0.1184\n",
      "epoch:219,loss:0.3649\n",
      "epoch:219,loss:0.0403\n",
      "epoch:219,loss:0.0147\n",
      "epoch:219,loss:0.0328\n",
      "epoch:219,loss:0.0332\n",
      "epoch:219,loss:0.0828\n",
      "epoch:219,loss:0.0290\n",
      "epoch:219,loss:0.0153\n",
      "epoch:219,loss:0.0361\n",
      "epoch:219,loss:0.1074\n",
      "epoch:219,loss:0.1251\n",
      "epoch:219,loss:0.0134\n",
      "epoch:219,loss:0.0150\n",
      "epoch:219,loss:0.2113\n",
      "epoch:219,loss:0.0888\n",
      "epoch:219,loss:0.0104\n",
      "epoch:219,loss:0.0386\n",
      "epoch:219,loss:0.0165\n",
      "epoch:219,loss:0.0073\n",
      "epoch:219,loss:0.0092\n",
      "epoch:219,loss:0.0218\n",
      "epoch:219,loss:0.2088\n",
      "epoch:219,loss:0.6731\n",
      "epoch:219,loss:0.3600\n",
      "epoch:219,loss:0.0424\n",
      "epoch:219,loss:0.0358\n",
      "epoch:219,loss:0.0116\n",
      "epoch:219,loss:0.0089\n",
      "epoch:219,loss:0.0044\n",
      "epoch:219,loss:0.0026\n",
      "epoch:219,loss:0.0017\n",
      "epoch:219,loss:0.0317\n",
      "epoch:219,loss:0.0446\n",
      "epoch:219,loss:0.0924\n",
      "epoch:219,loss:0.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:219,loss:0.0349\n",
      "epoch:219,loss:0.7951\n",
      "epoch:219,loss:0.0026\n",
      "epoch:219,loss:0.7626\n",
      "epoch:219,loss:1.2898\n",
      "epoch:219,loss:0.1342\n",
      "epoch:219,loss:0.0321\n",
      "epoch:219,loss:0.0141\n",
      "epoch:219,loss:0.6244\n",
      "============================================\n",
      "第219个epoch的识别准确率为：94%\n",
      "epoch:220,loss:0.0098\n",
      "epoch:220,loss:0.2444\n",
      "epoch:220,loss:0.3370\n",
      "epoch:220,loss:0.0051\n",
      "epoch:220,loss:0.1636\n",
      "epoch:220,loss:0.5913\n",
      "epoch:220,loss:0.2386\n",
      "epoch:220,loss:0.2346\n",
      "epoch:220,loss:0.0887\n",
      "epoch:220,loss:0.0155\n",
      "epoch:220,loss:0.0133\n",
      "epoch:220,loss:0.1153\n",
      "epoch:220,loss:0.2692\n",
      "epoch:220,loss:0.0217\n",
      "epoch:220,loss:0.2684\n",
      "epoch:220,loss:0.0188\n",
      "epoch:220,loss:0.1197\n",
      "epoch:220,loss:0.0101\n",
      "epoch:220,loss:0.0076\n",
      "epoch:220,loss:0.1611\n",
      "epoch:220,loss:0.0291\n",
      "epoch:220,loss:0.0154\n",
      "epoch:220,loss:0.1113\n",
      "epoch:220,loss:0.8736\n",
      "epoch:220,loss:0.1621\n",
      "epoch:220,loss:0.6013\n",
      "epoch:220,loss:0.0878\n",
      "epoch:220,loss:0.0382\n",
      "epoch:220,loss:0.1181\n",
      "epoch:220,loss:0.0091\n",
      "epoch:220,loss:0.0463\n",
      "epoch:220,loss:0.1107\n",
      "epoch:220,loss:0.0641\n",
      "epoch:220,loss:0.0670\n",
      "epoch:220,loss:0.0568\n",
      "epoch:220,loss:0.0830\n",
      "epoch:220,loss:0.0019\n",
      "epoch:220,loss:0.1598\n",
      "epoch:220,loss:1.7046\n",
      "epoch:220,loss:0.1030\n",
      "epoch:220,loss:0.8097\n",
      "epoch:220,loss:0.5682\n",
      "epoch:220,loss:0.2194\n",
      "epoch:220,loss:0.4566\n",
      "epoch:220,loss:0.1176\n",
      "epoch:220,loss:0.0289\n",
      "epoch:220,loss:0.0041\n",
      "epoch:220,loss:0.1267\n",
      "epoch:220,loss:0.3869\n",
      "epoch:220,loss:0.0034\n",
      "epoch:220,loss:0.5685\n",
      "epoch:220,loss:0.0554\n",
      "epoch:220,loss:0.1427\n",
      "epoch:220,loss:0.0034\n",
      "epoch:220,loss:0.2753\n",
      "epoch:220,loss:0.1299\n",
      "epoch:220,loss:0.1767\n",
      "epoch:220,loss:0.1329\n",
      "epoch:220,loss:0.0368\n",
      "epoch:220,loss:0.0083\n",
      "============================================\n",
      "第220个epoch的识别准确率为：95%\n",
      "epoch:221,loss:0.0358\n",
      "epoch:221,loss:0.0017\n",
      "epoch:221,loss:0.3866\n",
      "epoch:221,loss:0.0140\n",
      "epoch:221,loss:0.0056\n",
      "epoch:221,loss:0.0954\n",
      "epoch:221,loss:0.8539\n",
      "epoch:221,loss:0.7172\n",
      "epoch:221,loss:0.1071\n",
      "epoch:221,loss:0.0047\n",
      "epoch:221,loss:0.0289\n",
      "epoch:221,loss:0.0085\n",
      "epoch:221,loss:0.0476\n",
      "epoch:221,loss:0.0037\n",
      "epoch:221,loss:0.0064\n",
      "epoch:221,loss:0.3873\n",
      "epoch:221,loss:0.2421\n",
      "epoch:221,loss:0.0257\n",
      "epoch:221,loss:0.0450\n",
      "epoch:221,loss:0.0693\n",
      "epoch:221,loss:0.1068\n",
      "epoch:221,loss:2.2588\n",
      "epoch:221,loss:0.3306\n",
      "epoch:221,loss:1.7084\n",
      "epoch:221,loss:0.1063\n",
      "epoch:221,loss:0.1475\n",
      "epoch:221,loss:0.3844\n",
      "epoch:221,loss:0.1301\n",
      "epoch:221,loss:0.2155\n",
      "epoch:221,loss:0.0558\n",
      "epoch:221,loss:0.0121\n",
      "epoch:221,loss:0.9611\n",
      "epoch:221,loss:0.0657\n",
      "epoch:221,loss:0.0937\n",
      "epoch:221,loss:0.0132\n",
      "epoch:221,loss:0.2592\n",
      "epoch:221,loss:0.0869\n",
      "epoch:221,loss:0.0706\n",
      "epoch:221,loss:0.0732\n",
      "epoch:221,loss:0.0064\n",
      "epoch:221,loss:0.0070\n",
      "epoch:221,loss:0.3391\n",
      "epoch:221,loss:0.0659\n",
      "epoch:221,loss:0.0099\n",
      "epoch:221,loss:0.0074\n",
      "epoch:221,loss:0.0716\n",
      "epoch:221,loss:0.0214\n",
      "epoch:221,loss:0.0091\n",
      "epoch:221,loss:0.0230\n",
      "epoch:221,loss:0.0135\n",
      "epoch:221,loss:0.0083\n",
      "epoch:221,loss:0.5842\n",
      "epoch:221,loss:0.1999\n",
      "epoch:221,loss:0.0429\n",
      "epoch:221,loss:0.0660\n",
      "epoch:221,loss:0.1202\n",
      "epoch:221,loss:0.0264\n",
      "epoch:221,loss:0.0157\n",
      "epoch:221,loss:0.4603\n",
      "epoch:221,loss:0.0065\n",
      "============================================\n",
      "第221个epoch的识别准确率为：94%\n",
      "epoch:222,loss:0.7883\n",
      "epoch:222,loss:0.0002\n",
      "epoch:222,loss:0.1536\n",
      "epoch:222,loss:0.2971\n",
      "epoch:222,loss:0.1296\n",
      "epoch:222,loss:0.0104\n",
      "epoch:222,loss:0.5580\n",
      "epoch:222,loss:0.0309\n",
      "epoch:222,loss:0.0314\n",
      "epoch:222,loss:0.1773\n",
      "epoch:222,loss:0.0316\n",
      "epoch:222,loss:0.0052\n",
      "epoch:222,loss:0.0124\n",
      "epoch:222,loss:0.3774\n",
      "epoch:222,loss:0.0090\n",
      "epoch:222,loss:0.0179\n",
      "epoch:222,loss:0.0823\n",
      "epoch:222,loss:0.0668\n",
      "epoch:222,loss:0.0019\n",
      "epoch:222,loss:0.0101\n",
      "epoch:222,loss:0.1026\n",
      "epoch:222,loss:0.0095\n",
      "epoch:222,loss:0.6583\n",
      "epoch:222,loss:0.5248\n",
      "epoch:222,loss:0.0333\n",
      "epoch:222,loss:0.2643\n",
      "epoch:222,loss:0.2182\n",
      "epoch:222,loss:0.5641\n",
      "epoch:222,loss:0.0886\n",
      "epoch:222,loss:0.1565\n",
      "epoch:222,loss:0.0146\n",
      "epoch:222,loss:0.0053\n",
      "epoch:222,loss:0.4338\n",
      "epoch:222,loss:0.0186\n",
      "epoch:222,loss:0.0732\n",
      "epoch:222,loss:0.2028\n",
      "epoch:222,loss:0.0297\n",
      "epoch:222,loss:0.2615\n",
      "epoch:222,loss:0.6206\n",
      "epoch:222,loss:0.0234\n",
      "epoch:222,loss:0.0885\n",
      "epoch:222,loss:0.0111\n",
      "epoch:222,loss:0.0305\n",
      "epoch:222,loss:0.7742\n",
      "epoch:222,loss:0.5069\n",
      "epoch:222,loss:0.1673\n",
      "epoch:222,loss:0.0556\n",
      "epoch:222,loss:0.0375\n",
      "epoch:222,loss:0.0085\n",
      "epoch:222,loss:0.1296\n",
      "epoch:222,loss:0.0156\n",
      "epoch:222,loss:0.0305\n",
      "epoch:222,loss:0.1044\n",
      "epoch:222,loss:0.0874\n",
      "epoch:222,loss:0.1332\n",
      "epoch:222,loss:0.1266\n",
      "epoch:222,loss:0.0838\n",
      "epoch:222,loss:0.0101\n",
      "epoch:222,loss:0.9634\n",
      "epoch:222,loss:1.0906\n",
      "============================================\n",
      "第222个epoch的识别准确率为：95%\n",
      "epoch:223,loss:0.1734\n",
      "epoch:223,loss:0.0677\n",
      "epoch:223,loss:0.2908\n",
      "epoch:223,loss:0.1298\n",
      "epoch:223,loss:0.2008\n",
      "epoch:223,loss:0.3196\n",
      "epoch:223,loss:0.3034\n",
      "epoch:223,loss:0.0177\n",
      "epoch:223,loss:0.0264\n",
      "epoch:223,loss:0.0227\n",
      "epoch:223,loss:0.0596\n",
      "epoch:223,loss:0.3892\n",
      "epoch:223,loss:0.0739\n",
      "epoch:223,loss:0.0044\n",
      "epoch:223,loss:0.1005\n",
      "epoch:223,loss:0.4463\n",
      "epoch:223,loss:0.0673\n",
      "epoch:223,loss:0.7844\n",
      "epoch:223,loss:0.1068\n",
      "epoch:223,loss:0.0191\n",
      "epoch:223,loss:0.0812\n",
      "epoch:223,loss:0.0047\n",
      "epoch:223,loss:0.0403\n",
      "epoch:223,loss:0.2864\n",
      "epoch:223,loss:0.0978\n",
      "epoch:223,loss:0.5674\n",
      "epoch:223,loss:0.0100\n",
      "epoch:223,loss:1.4088\n",
      "epoch:223,loss:0.2842\n",
      "epoch:223,loss:0.0967\n",
      "epoch:223,loss:0.3562\n",
      "epoch:223,loss:0.0187\n",
      "epoch:223,loss:0.1654\n",
      "epoch:223,loss:0.1096\n",
      "epoch:223,loss:0.0131\n",
      "epoch:223,loss:0.0207\n",
      "epoch:223,loss:0.1191\n",
      "epoch:223,loss:0.3253\n",
      "epoch:223,loss:0.4907\n",
      "epoch:223,loss:0.0985\n",
      "epoch:223,loss:0.0054\n",
      "epoch:223,loss:0.0501\n",
      "epoch:223,loss:0.0535\n",
      "epoch:223,loss:0.0424\n",
      "epoch:223,loss:0.1347\n",
      "epoch:223,loss:0.0847\n",
      "epoch:223,loss:0.1691\n",
      "epoch:223,loss:0.4692\n",
      "epoch:223,loss:0.0337\n",
      "epoch:223,loss:0.0795\n",
      "epoch:223,loss:0.0313\n",
      "epoch:223,loss:0.1091\n",
      "epoch:223,loss:0.0460\n",
      "epoch:223,loss:0.0190\n",
      "epoch:223,loss:0.0145\n",
      "epoch:223,loss:0.0374\n",
      "epoch:223,loss:0.7604\n",
      "epoch:223,loss:0.4250\n",
      "epoch:223,loss:0.8109\n",
      "epoch:223,loss:0.0086\n",
      "============================================\n",
      "第223个epoch的识别准确率为：95%\n",
      "epoch:224,loss:0.4359\n",
      "epoch:224,loss:0.0836\n",
      "epoch:224,loss:0.0778\n",
      "epoch:224,loss:0.0010\n",
      "epoch:224,loss:0.0117\n",
      "epoch:224,loss:0.0457\n",
      "epoch:224,loss:0.3784\n",
      "epoch:224,loss:0.8088\n",
      "epoch:224,loss:0.0743\n",
      "epoch:224,loss:0.0154\n",
      "epoch:224,loss:0.3704\n",
      "epoch:224,loss:0.0043\n",
      "epoch:224,loss:0.1723\n",
      "epoch:224,loss:0.1284\n",
      "epoch:224,loss:0.1340\n",
      "epoch:224,loss:0.0372\n",
      "epoch:224,loss:0.0253\n",
      "epoch:224,loss:0.0060\n",
      "epoch:224,loss:0.4222\n",
      "epoch:224,loss:0.0223\n",
      "epoch:224,loss:0.0133\n",
      "epoch:224,loss:0.0953\n",
      "epoch:224,loss:0.0145\n",
      "epoch:224,loss:0.0368\n",
      "epoch:224,loss:0.0351\n",
      "epoch:224,loss:0.0985\n",
      "epoch:224,loss:0.0037\n",
      "epoch:224,loss:0.0075\n",
      "epoch:224,loss:0.1109\n",
      "epoch:224,loss:0.0833\n",
      "epoch:224,loss:0.0784\n",
      "epoch:224,loss:0.0624\n",
      "epoch:224,loss:0.2544\n",
      "epoch:224,loss:0.1055\n",
      "epoch:224,loss:0.0353\n",
      "epoch:224,loss:0.8358\n",
      "epoch:224,loss:0.0214\n",
      "epoch:224,loss:0.0316\n",
      "epoch:224,loss:0.0630\n",
      "epoch:224,loss:0.0236\n",
      "epoch:224,loss:0.0146\n",
      "epoch:224,loss:0.1256\n",
      "epoch:224,loss:0.0650\n",
      "epoch:224,loss:0.0053\n",
      "epoch:224,loss:0.0487\n",
      "epoch:224,loss:0.0024\n",
      "epoch:224,loss:0.0286\n",
      "epoch:224,loss:0.2734\n",
      "epoch:224,loss:0.0096\n",
      "epoch:224,loss:0.0461\n",
      "epoch:224,loss:0.3042\n",
      "epoch:224,loss:0.2498\n",
      "epoch:224,loss:0.3020\n",
      "epoch:224,loss:0.0447\n",
      "epoch:224,loss:0.0486\n",
      "epoch:224,loss:0.0205\n",
      "epoch:224,loss:0.4093\n",
      "epoch:224,loss:0.0482\n",
      "epoch:224,loss:0.0040\n",
      "epoch:224,loss:0.1243\n",
      "============================================\n",
      "第224个epoch的识别准确率为：95%\n",
      "epoch:225,loss:0.0077\n",
      "epoch:225,loss:0.0436\n",
      "epoch:225,loss:0.1870\n",
      "epoch:225,loss:0.0820\n",
      "epoch:225,loss:0.0595\n",
      "epoch:225,loss:0.0071\n",
      "epoch:225,loss:0.3191\n",
      "epoch:225,loss:0.0285\n",
      "epoch:225,loss:0.1872\n",
      "epoch:225,loss:0.0187\n",
      "epoch:225,loss:0.0368\n",
      "epoch:225,loss:0.2348\n",
      "epoch:225,loss:0.4686\n",
      "epoch:225,loss:0.0323\n",
      "epoch:225,loss:0.3099\n",
      "epoch:225,loss:0.0857\n",
      "epoch:225,loss:0.0008\n",
      "epoch:225,loss:0.1653\n",
      "epoch:225,loss:0.1815\n",
      "epoch:225,loss:0.1137\n",
      "epoch:225,loss:0.0107\n",
      "epoch:225,loss:0.0059\n",
      "epoch:225,loss:0.0359\n",
      "epoch:225,loss:0.0048\n",
      "epoch:225,loss:0.0314\n",
      "epoch:225,loss:0.0157\n",
      "epoch:225,loss:0.0448\n",
      "epoch:225,loss:0.0202\n",
      "epoch:225,loss:0.0076\n",
      "epoch:225,loss:0.1144\n",
      "epoch:225,loss:0.1233\n",
      "epoch:225,loss:0.1797\n",
      "epoch:225,loss:0.0365\n",
      "epoch:225,loss:0.0566\n",
      "epoch:225,loss:1.1088\n",
      "epoch:225,loss:0.1083\n",
      "epoch:225,loss:0.0311\n",
      "epoch:225,loss:0.0551\n",
      "epoch:225,loss:0.0225\n",
      "epoch:225,loss:0.1352\n",
      "epoch:225,loss:0.0161\n",
      "epoch:225,loss:0.0204\n",
      "epoch:225,loss:0.2881\n",
      "epoch:225,loss:0.1524\n",
      "epoch:225,loss:0.0242\n",
      "epoch:225,loss:0.1940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:225,loss:0.0252\n",
      "epoch:225,loss:0.0594\n",
      "epoch:225,loss:0.2364\n",
      "epoch:225,loss:0.0266\n",
      "epoch:225,loss:0.1119\n",
      "epoch:225,loss:0.0054\n",
      "epoch:225,loss:0.0429\n",
      "epoch:225,loss:0.0282\n",
      "epoch:225,loss:0.0127\n",
      "epoch:225,loss:0.1659\n",
      "epoch:225,loss:0.0393\n",
      "epoch:225,loss:2.0551\n",
      "epoch:225,loss:0.5478\n",
      "epoch:225,loss:0.0191\n",
      "============================================\n",
      "第225个epoch的识别准确率为：96%\n",
      "epoch:226,loss:0.0428\n",
      "epoch:226,loss:0.0063\n",
      "epoch:226,loss:0.0493\n",
      "epoch:226,loss:0.1524\n",
      "epoch:226,loss:0.0301\n",
      "epoch:226,loss:0.0417\n",
      "epoch:226,loss:0.1627\n",
      "epoch:226,loss:0.0118\n",
      "epoch:226,loss:0.0074\n",
      "epoch:226,loss:0.0057\n",
      "epoch:226,loss:0.6152\n",
      "epoch:226,loss:0.3537\n",
      "epoch:226,loss:0.5607\n",
      "epoch:226,loss:1.0741\n",
      "epoch:226,loss:0.0954\n",
      "epoch:226,loss:0.1055\n",
      "epoch:226,loss:0.4798\n",
      "epoch:226,loss:0.0213\n",
      "epoch:226,loss:0.4276\n",
      "epoch:226,loss:0.4413\n",
      "epoch:226,loss:0.0995\n",
      "epoch:226,loss:0.7658\n",
      "epoch:226,loss:0.0942\n",
      "epoch:226,loss:0.1103\n",
      "epoch:226,loss:0.3049\n",
      "epoch:226,loss:0.0791\n",
      "epoch:226,loss:0.0450\n",
      "epoch:226,loss:0.4925\n",
      "epoch:226,loss:0.0714\n",
      "epoch:226,loss:0.0622\n",
      "epoch:226,loss:0.0565\n",
      "epoch:226,loss:1.6021\n",
      "epoch:226,loss:0.0289\n",
      "epoch:226,loss:0.1354\n",
      "epoch:226,loss:0.0240\n",
      "epoch:226,loss:0.2109\n",
      "epoch:226,loss:0.0147\n",
      "epoch:226,loss:0.8586\n",
      "epoch:226,loss:0.2760\n",
      "epoch:226,loss:0.0289\n",
      "epoch:226,loss:0.0230\n",
      "epoch:226,loss:0.8699\n",
      "epoch:226,loss:0.0327\n",
      "epoch:226,loss:0.0278\n",
      "epoch:226,loss:0.0608\n",
      "epoch:226,loss:0.2863\n",
      "epoch:226,loss:0.0324\n",
      "epoch:226,loss:0.2009\n",
      "epoch:226,loss:0.4721\n",
      "epoch:226,loss:0.0073\n",
      "epoch:226,loss:0.0774\n",
      "epoch:226,loss:0.1145\n",
      "epoch:226,loss:0.2569\n",
      "epoch:226,loss:0.0560\n",
      "epoch:226,loss:0.1915\n",
      "epoch:226,loss:0.4138\n",
      "epoch:226,loss:0.0226\n",
      "epoch:226,loss:0.6600\n",
      "epoch:226,loss:0.5026\n",
      "epoch:226,loss:0.1002\n",
      "============================================\n",
      "第226个epoch的识别准确率为：94%\n",
      "epoch:227,loss:0.0156\n",
      "epoch:227,loss:0.0038\n",
      "epoch:227,loss:0.0173\n",
      "epoch:227,loss:0.3031\n",
      "epoch:227,loss:0.2598\n",
      "epoch:227,loss:0.0258\n",
      "epoch:227,loss:0.0315\n",
      "epoch:227,loss:0.0858\n",
      "epoch:227,loss:0.0796\n",
      "epoch:227,loss:0.3811\n",
      "epoch:227,loss:0.0852\n",
      "epoch:227,loss:0.1455\n",
      "epoch:227,loss:0.2015\n",
      "epoch:227,loss:0.0762\n",
      "epoch:227,loss:0.0991\n",
      "epoch:227,loss:0.4074\n",
      "epoch:227,loss:0.1218\n",
      "epoch:227,loss:0.0135\n",
      "epoch:227,loss:0.0727\n",
      "epoch:227,loss:0.0184\n",
      "epoch:227,loss:0.0143\n",
      "epoch:227,loss:0.0541\n",
      "epoch:227,loss:0.9788\n",
      "epoch:227,loss:0.5363\n",
      "epoch:227,loss:0.2308\n",
      "epoch:227,loss:0.0608\n",
      "epoch:227,loss:0.0641\n",
      "epoch:227,loss:0.1418\n",
      "epoch:227,loss:0.1856\n",
      "epoch:227,loss:0.0179\n",
      "epoch:227,loss:0.7270\n",
      "epoch:227,loss:0.0045\n",
      "epoch:227,loss:0.8517\n",
      "epoch:227,loss:0.1958\n",
      "epoch:227,loss:0.0190\n",
      "epoch:227,loss:0.0050\n",
      "epoch:227,loss:0.0309\n",
      "epoch:227,loss:0.3919\n",
      "epoch:227,loss:0.0014\n",
      "epoch:227,loss:0.0493\n",
      "epoch:227,loss:0.2245\n",
      "epoch:227,loss:0.1719\n",
      "epoch:227,loss:0.6803\n",
      "epoch:227,loss:0.3789\n",
      "epoch:227,loss:0.0090\n",
      "epoch:227,loss:0.0338\n",
      "epoch:227,loss:0.2526\n",
      "epoch:227,loss:0.2494\n",
      "epoch:227,loss:0.3497\n",
      "epoch:227,loss:0.1988\n",
      "epoch:227,loss:0.0097\n",
      "epoch:227,loss:0.0228\n",
      "epoch:227,loss:0.0594\n",
      "epoch:227,loss:0.4226\n",
      "epoch:227,loss:0.0173\n",
      "epoch:227,loss:0.0558\n",
      "epoch:227,loss:0.0974\n",
      "epoch:227,loss:0.1312\n",
      "epoch:227,loss:0.7385\n",
      "epoch:227,loss:0.0829\n",
      "============================================\n",
      "第227个epoch的识别准确率为：96%\n",
      "epoch:228,loss:0.1033\n",
      "epoch:228,loss:0.0697\n",
      "epoch:228,loss:0.2030\n",
      "epoch:228,loss:0.4119\n",
      "epoch:228,loss:0.0366\n",
      "epoch:228,loss:0.0071\n",
      "epoch:228,loss:0.1132\n",
      "epoch:228,loss:0.0737\n",
      "epoch:228,loss:0.1101\n",
      "epoch:228,loss:1.0737\n",
      "epoch:228,loss:0.0198\n",
      "epoch:228,loss:0.0071\n",
      "epoch:228,loss:0.4327\n",
      "epoch:228,loss:0.4122\n",
      "epoch:228,loss:0.0801\n",
      "epoch:228,loss:0.0726\n",
      "epoch:228,loss:0.0085\n",
      "epoch:228,loss:0.0656\n",
      "epoch:228,loss:0.0255\n",
      "epoch:228,loss:0.0264\n",
      "epoch:228,loss:0.0129\n",
      "epoch:228,loss:0.3573\n",
      "epoch:228,loss:0.2153\n",
      "epoch:228,loss:0.0250\n",
      "epoch:228,loss:0.0396\n",
      "epoch:228,loss:0.0296\n",
      "epoch:228,loss:0.1187\n",
      "epoch:228,loss:0.0586\n",
      "epoch:228,loss:0.0096\n",
      "epoch:228,loss:0.0741\n",
      "epoch:228,loss:0.0845\n",
      "epoch:228,loss:0.0108\n",
      "epoch:228,loss:0.0305\n",
      "epoch:228,loss:0.0648\n",
      "epoch:228,loss:0.0096\n",
      "epoch:228,loss:0.0890\n",
      "epoch:228,loss:0.0393\n",
      "epoch:228,loss:0.0538\n",
      "epoch:228,loss:0.0340\n",
      "epoch:228,loss:0.0853\n",
      "epoch:228,loss:0.0345\n",
      "epoch:228,loss:0.0172\n",
      "epoch:228,loss:0.2157\n",
      "epoch:228,loss:0.0048\n",
      "epoch:228,loss:0.0159\n",
      "epoch:228,loss:0.0072\n",
      "epoch:228,loss:0.0239\n",
      "epoch:228,loss:0.1864\n",
      "epoch:228,loss:0.0470\n",
      "epoch:228,loss:1.4362\n",
      "epoch:228,loss:0.2751\n",
      "epoch:228,loss:0.0289\n",
      "epoch:228,loss:0.0462\n",
      "epoch:228,loss:0.0161\n",
      "epoch:228,loss:0.3210\n",
      "epoch:228,loss:1.2892\n",
      "epoch:228,loss:0.7202\n",
      "epoch:228,loss:0.6057\n",
      "epoch:228,loss:0.0143\n",
      "epoch:228,loss:0.4778\n",
      "============================================\n",
      "第228个epoch的识别准确率为：94%\n",
      "epoch:229,loss:0.0236\n",
      "epoch:229,loss:0.0272\n",
      "epoch:229,loss:0.0161\n",
      "epoch:229,loss:0.0885\n",
      "epoch:229,loss:0.1492\n",
      "epoch:229,loss:0.0074\n",
      "epoch:229,loss:0.6462\n",
      "epoch:229,loss:0.0459\n",
      "epoch:229,loss:0.1679\n",
      "epoch:229,loss:0.0688\n",
      "epoch:229,loss:0.0884\n",
      "epoch:229,loss:0.0381\n",
      "epoch:229,loss:0.0363\n",
      "epoch:229,loss:0.0046\n",
      "epoch:229,loss:0.0339\n",
      "epoch:229,loss:0.0235\n",
      "epoch:229,loss:0.0043\n",
      "epoch:229,loss:0.0075\n",
      "epoch:229,loss:0.1015\n",
      "epoch:229,loss:0.0795\n",
      "epoch:229,loss:0.0827\n",
      "epoch:229,loss:0.0400\n",
      "epoch:229,loss:0.0672\n",
      "epoch:229,loss:0.0530\n",
      "epoch:229,loss:0.0115\n",
      "epoch:229,loss:0.0142\n",
      "epoch:229,loss:1.1600\n",
      "epoch:229,loss:0.0162\n",
      "epoch:229,loss:0.1852\n",
      "epoch:229,loss:0.2248\n",
      "epoch:229,loss:0.0507\n",
      "epoch:229,loss:0.0544\n",
      "epoch:229,loss:0.0331\n",
      "epoch:229,loss:0.1241\n",
      "epoch:229,loss:1.3902\n",
      "epoch:229,loss:0.0255\n",
      "epoch:229,loss:0.1637\n",
      "epoch:229,loss:0.5430\n",
      "epoch:229,loss:0.4667\n",
      "epoch:229,loss:0.0101\n",
      "epoch:229,loss:0.0938\n",
      "epoch:229,loss:0.1802\n",
      "epoch:229,loss:0.0741\n",
      "epoch:229,loss:0.0436\n",
      "epoch:229,loss:0.4492\n",
      "epoch:229,loss:0.0446\n",
      "epoch:229,loss:0.1030\n",
      "epoch:229,loss:0.0419\n",
      "epoch:229,loss:0.0083\n",
      "epoch:229,loss:0.0094\n",
      "epoch:229,loss:0.0125\n",
      "epoch:229,loss:0.0122\n",
      "epoch:229,loss:0.0091\n",
      "epoch:229,loss:0.0534\n",
      "epoch:229,loss:0.0077\n",
      "epoch:229,loss:0.2434\n",
      "epoch:229,loss:0.0358\n",
      "epoch:229,loss:0.6352\n",
      "epoch:229,loss:0.0200\n",
      "epoch:229,loss:0.9048\n",
      "============================================\n",
      "第229个epoch的识别准确率为：94%\n",
      "epoch:230,loss:0.0772\n",
      "epoch:230,loss:0.2228\n",
      "epoch:230,loss:0.0575\n",
      "epoch:230,loss:0.8525\n",
      "epoch:230,loss:0.1542\n",
      "epoch:230,loss:0.6019\n",
      "epoch:230,loss:0.0950\n",
      "epoch:230,loss:0.1916\n",
      "epoch:230,loss:0.8697\n",
      "epoch:230,loss:0.0039\n",
      "epoch:230,loss:0.1529\n",
      "epoch:230,loss:0.0026\n",
      "epoch:230,loss:0.0913\n",
      "epoch:230,loss:0.0151\n",
      "epoch:230,loss:0.0343\n",
      "epoch:230,loss:0.0131\n",
      "epoch:230,loss:0.1878\n",
      "epoch:230,loss:0.1506\n",
      "epoch:230,loss:0.0333\n",
      "epoch:230,loss:0.0271\n",
      "epoch:230,loss:0.0160\n",
      "epoch:230,loss:0.0579\n",
      "epoch:230,loss:1.1597\n",
      "epoch:230,loss:0.0220\n",
      "epoch:230,loss:0.0645\n",
      "epoch:230,loss:0.7181\n",
      "epoch:230,loss:0.2027\n",
      "epoch:230,loss:0.3551\n",
      "epoch:230,loss:0.0583\n",
      "epoch:230,loss:0.0073\n",
      "epoch:230,loss:0.1090\n",
      "epoch:230,loss:0.0653\n",
      "epoch:230,loss:0.0227\n",
      "epoch:230,loss:0.0280\n",
      "epoch:230,loss:0.1490\n",
      "epoch:230,loss:0.1311\n",
      "epoch:230,loss:0.0450\n",
      "epoch:230,loss:0.0125\n",
      "epoch:230,loss:0.0158\n",
      "epoch:230,loss:0.1984\n",
      "epoch:230,loss:0.0251\n",
      "epoch:230,loss:0.0149\n",
      "epoch:230,loss:0.0121\n",
      "epoch:230,loss:0.1681\n",
      "epoch:230,loss:0.0843\n",
      "epoch:230,loss:0.1035\n",
      "epoch:230,loss:0.0191\n",
      "epoch:230,loss:0.3022\n",
      "epoch:230,loss:0.0955\n",
      "epoch:230,loss:0.0351\n",
      "epoch:230,loss:0.0058\n",
      "epoch:230,loss:0.7452\n",
      "epoch:230,loss:0.0210\n",
      "epoch:230,loss:0.5614\n",
      "epoch:230,loss:0.0197\n",
      "epoch:230,loss:0.1551\n",
      "epoch:230,loss:0.0172\n",
      "epoch:230,loss:1.0558\n",
      "epoch:230,loss:0.0385\n",
      "epoch:230,loss:0.2286\n",
      "============================================\n",
      "第230个epoch的识别准确率为：95%\n",
      "epoch:231,loss:0.1511\n",
      "epoch:231,loss:0.0358\n",
      "epoch:231,loss:0.0057\n",
      "epoch:231,loss:0.4811\n",
      "epoch:231,loss:0.2288\n",
      "epoch:231,loss:0.0672\n",
      "epoch:231,loss:0.4124\n",
      "epoch:231,loss:0.0062\n",
      "epoch:231,loss:0.0049\n",
      "epoch:231,loss:0.0970\n",
      "epoch:231,loss:0.1505\n",
      "epoch:231,loss:0.0626\n",
      "epoch:231,loss:0.0416\n",
      "epoch:231,loss:0.0222\n",
      "epoch:231,loss:0.0043\n",
      "epoch:231,loss:0.1213\n",
      "epoch:231,loss:0.2193\n",
      "epoch:231,loss:0.0296\n",
      "epoch:231,loss:0.0844\n",
      "epoch:231,loss:0.0851\n",
      "epoch:231,loss:0.0141\n",
      "epoch:231,loss:0.0312\n",
      "epoch:231,loss:0.2458\n",
      "epoch:231,loss:0.0545\n",
      "epoch:231,loss:0.0309\n",
      "epoch:231,loss:0.0122\n",
      "epoch:231,loss:0.0170\n",
      "epoch:231,loss:0.1169\n",
      "epoch:231,loss:0.0066\n",
      "epoch:231,loss:0.0429\n",
      "epoch:231,loss:0.0425\n",
      "epoch:231,loss:0.0233\n",
      "epoch:231,loss:0.0338\n",
      "epoch:231,loss:0.0348\n",
      "epoch:231,loss:0.6038\n",
      "epoch:231,loss:0.0831\n",
      "epoch:231,loss:0.0354\n",
      "epoch:231,loss:0.0124\n",
      "epoch:231,loss:0.5522\n",
      "epoch:231,loss:0.0395\n",
      "epoch:231,loss:0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:231,loss:0.0232\n",
      "epoch:231,loss:0.0024\n",
      "epoch:231,loss:0.0075\n",
      "epoch:231,loss:0.0132\n",
      "epoch:231,loss:0.6186\n",
      "epoch:231,loss:0.3032\n",
      "epoch:231,loss:0.0646\n",
      "epoch:231,loss:0.0325\n",
      "epoch:231,loss:0.1415\n",
      "epoch:231,loss:0.0442\n",
      "epoch:231,loss:0.0147\n",
      "epoch:231,loss:1.1966\n",
      "epoch:231,loss:0.0850\n",
      "epoch:231,loss:0.0009\n",
      "epoch:231,loss:0.0787\n",
      "epoch:231,loss:0.0085\n",
      "epoch:231,loss:0.0492\n",
      "epoch:231,loss:0.0159\n",
      "epoch:231,loss:0.0098\n",
      "============================================\n",
      "第231个epoch的识别准确率为：95%\n",
      "epoch:232,loss:0.0091\n",
      "epoch:232,loss:0.3946\n",
      "epoch:232,loss:0.1788\n",
      "epoch:232,loss:0.5174\n",
      "epoch:232,loss:0.0093\n",
      "epoch:232,loss:0.2846\n",
      "epoch:232,loss:0.0410\n",
      "epoch:232,loss:0.1073\n",
      "epoch:232,loss:0.6373\n",
      "epoch:232,loss:0.0395\n",
      "epoch:232,loss:0.1389\n",
      "epoch:232,loss:0.0514\n",
      "epoch:232,loss:0.0195\n",
      "epoch:232,loss:0.0982\n",
      "epoch:232,loss:0.0292\n",
      "epoch:232,loss:0.0159\n",
      "epoch:232,loss:0.0153\n",
      "epoch:232,loss:0.6668\n",
      "epoch:232,loss:0.1544\n",
      "epoch:232,loss:0.0309\n",
      "epoch:232,loss:1.1421\n",
      "epoch:232,loss:0.0008\n",
      "epoch:232,loss:0.5720\n",
      "epoch:232,loss:0.0963\n",
      "epoch:232,loss:0.0316\n",
      "epoch:232,loss:0.0735\n",
      "epoch:232,loss:0.0170\n",
      "epoch:232,loss:0.0787\n",
      "epoch:232,loss:0.0080\n",
      "epoch:232,loss:0.5709\n",
      "epoch:232,loss:0.2717\n",
      "epoch:232,loss:0.5081\n",
      "epoch:232,loss:0.0426\n",
      "epoch:232,loss:0.0827\n",
      "epoch:232,loss:0.0432\n",
      "epoch:232,loss:0.0361\n",
      "epoch:232,loss:0.0212\n",
      "epoch:232,loss:0.0620\n",
      "epoch:232,loss:0.0086\n",
      "epoch:232,loss:0.5782\n",
      "epoch:232,loss:0.0081\n",
      "epoch:232,loss:0.4263\n",
      "epoch:232,loss:0.1972\n",
      "epoch:232,loss:0.0089\n",
      "epoch:232,loss:0.1657\n",
      "epoch:232,loss:0.0110\n",
      "epoch:232,loss:0.0060\n",
      "epoch:232,loss:0.0477\n",
      "epoch:232,loss:0.9358\n",
      "epoch:232,loss:0.0295\n",
      "epoch:232,loss:0.5459\n",
      "epoch:232,loss:0.0300\n",
      "epoch:232,loss:0.3702\n",
      "epoch:232,loss:0.0474\n",
      "epoch:232,loss:0.3805\n",
      "epoch:232,loss:0.1076\n",
      "epoch:232,loss:0.3549\n",
      "epoch:232,loss:0.0020\n",
      "epoch:232,loss:0.1586\n",
      "epoch:232,loss:0.1213\n",
      "============================================\n",
      "第232个epoch的识别准确率为：95%\n",
      "epoch:233,loss:0.0502\n",
      "epoch:233,loss:0.2580\n",
      "epoch:233,loss:0.1325\n",
      "epoch:233,loss:0.0110\n",
      "epoch:233,loss:0.0046\n",
      "epoch:233,loss:0.1984\n",
      "epoch:233,loss:0.2781\n",
      "epoch:233,loss:0.2977\n",
      "epoch:233,loss:0.0535\n",
      "epoch:233,loss:0.0923\n",
      "epoch:233,loss:0.1211\n",
      "epoch:233,loss:0.0792\n",
      "epoch:233,loss:0.0151\n",
      "epoch:233,loss:1.0748\n",
      "epoch:233,loss:0.0196\n",
      "epoch:233,loss:0.0663\n",
      "epoch:233,loss:0.0483\n",
      "epoch:233,loss:0.5364\n",
      "epoch:233,loss:0.2984\n",
      "epoch:233,loss:0.0937\n",
      "epoch:233,loss:0.3367\n",
      "epoch:233,loss:0.0337\n",
      "epoch:233,loss:0.0759\n",
      "epoch:233,loss:0.0112\n",
      "epoch:233,loss:0.8103\n",
      "epoch:233,loss:0.1114\n",
      "epoch:233,loss:0.0982\n",
      "epoch:233,loss:0.0141\n",
      "epoch:233,loss:0.4037\n",
      "epoch:233,loss:0.0721\n",
      "epoch:233,loss:0.2818\n",
      "epoch:233,loss:0.0187\n",
      "epoch:233,loss:0.4628\n",
      "epoch:233,loss:0.3004\n",
      "epoch:233,loss:0.0142\n",
      "epoch:233,loss:0.4779\n",
      "epoch:233,loss:0.0248\n",
      "epoch:233,loss:0.2973\n",
      "epoch:233,loss:0.0659\n",
      "epoch:233,loss:0.0445\n",
      "epoch:233,loss:0.2400\n",
      "epoch:233,loss:0.0588\n",
      "epoch:233,loss:0.2776\n",
      "epoch:233,loss:0.0350\n",
      "epoch:233,loss:0.0176\n",
      "epoch:233,loss:0.1585\n",
      "epoch:233,loss:0.0552\n",
      "epoch:233,loss:0.0133\n",
      "epoch:233,loss:0.3786\n",
      "epoch:233,loss:0.1050\n",
      "epoch:233,loss:0.0729\n",
      "epoch:233,loss:0.0427\n",
      "epoch:233,loss:0.0629\n",
      "epoch:233,loss:0.0805\n",
      "epoch:233,loss:0.1342\n",
      "epoch:233,loss:0.0484\n",
      "epoch:233,loss:0.3170\n",
      "epoch:233,loss:0.0164\n",
      "epoch:233,loss:0.1289\n",
      "epoch:233,loss:0.2829\n",
      "============================================\n",
      "第233个epoch的识别准确率为：94%\n",
      "epoch:234,loss:0.0100\n",
      "epoch:234,loss:0.0700\n",
      "epoch:234,loss:0.0549\n",
      "epoch:234,loss:0.6006\n",
      "epoch:234,loss:0.0215\n",
      "epoch:234,loss:0.2521\n",
      "epoch:234,loss:0.0085\n",
      "epoch:234,loss:0.0767\n",
      "epoch:234,loss:1.6898\n",
      "epoch:234,loss:0.1820\n",
      "epoch:234,loss:0.3949\n",
      "epoch:234,loss:0.0370\n",
      "epoch:234,loss:0.0430\n",
      "epoch:234,loss:1.1585\n",
      "epoch:234,loss:0.0402\n",
      "epoch:234,loss:0.0670\n",
      "epoch:234,loss:0.0019\n",
      "epoch:234,loss:0.1218\n",
      "epoch:234,loss:0.0663\n",
      "epoch:234,loss:0.0988\n",
      "epoch:234,loss:0.0193\n",
      "epoch:234,loss:0.0547\n",
      "epoch:234,loss:0.1188\n",
      "epoch:234,loss:0.2968\n",
      "epoch:234,loss:0.2744\n",
      "epoch:234,loss:0.0228\n",
      "epoch:234,loss:0.1121\n",
      "epoch:234,loss:0.2906\n",
      "epoch:234,loss:0.0882\n",
      "epoch:234,loss:0.1375\n",
      "epoch:234,loss:0.8599\n",
      "epoch:234,loss:0.0759\n",
      "epoch:234,loss:0.1017\n",
      "epoch:234,loss:1.3817\n",
      "epoch:234,loss:0.0172\n",
      "epoch:234,loss:0.0450\n",
      "epoch:234,loss:0.0595\n",
      "epoch:234,loss:0.0280\n",
      "epoch:234,loss:0.2205\n",
      "epoch:234,loss:0.7828\n",
      "epoch:234,loss:0.0025\n",
      "epoch:234,loss:0.0564\n",
      "epoch:234,loss:0.1399\n",
      "epoch:234,loss:0.0043\n",
      "epoch:234,loss:0.0056\n",
      "epoch:234,loss:0.0345\n",
      "epoch:234,loss:0.0665\n",
      "epoch:234,loss:0.1193\n",
      "epoch:234,loss:0.0645\n",
      "epoch:234,loss:0.0320\n",
      "epoch:234,loss:0.0568\n",
      "epoch:234,loss:0.0140\n",
      "epoch:234,loss:0.0008\n",
      "epoch:234,loss:0.6517\n",
      "epoch:234,loss:0.0610\n",
      "epoch:234,loss:0.1850\n",
      "epoch:234,loss:0.0016\n",
      "epoch:234,loss:0.0391\n",
      "epoch:234,loss:0.0044\n",
      "epoch:234,loss:0.0851\n",
      "============================================\n",
      "准确率由： tensor(0.9642) 上升至： tensor(0.9660) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第234个epoch的识别准确率为：96%\n",
      "epoch:235,loss:0.0162\n",
      "epoch:235,loss:0.1354\n",
      "epoch:235,loss:0.0035\n",
      "epoch:235,loss:0.0057\n",
      "epoch:235,loss:0.6198\n",
      "epoch:235,loss:0.0044\n",
      "epoch:235,loss:0.0122\n",
      "epoch:235,loss:0.0231\n",
      "epoch:235,loss:0.0094\n",
      "epoch:235,loss:0.2066\n",
      "epoch:235,loss:0.0948\n",
      "epoch:235,loss:0.0550\n",
      "epoch:235,loss:0.0373\n",
      "epoch:235,loss:0.0160\n",
      "epoch:235,loss:0.0073\n",
      "epoch:235,loss:1.6472\n",
      "epoch:235,loss:0.0240\n",
      "epoch:235,loss:0.0336\n",
      "epoch:235,loss:0.0680\n",
      "epoch:235,loss:0.0105\n",
      "epoch:235,loss:0.1922\n",
      "epoch:235,loss:0.6073\n",
      "epoch:235,loss:0.0628\n",
      "epoch:235,loss:0.2302\n",
      "epoch:235,loss:0.0061\n",
      "epoch:235,loss:0.4660\n",
      "epoch:235,loss:0.3463\n",
      "epoch:235,loss:0.0401\n",
      "epoch:235,loss:0.0278\n",
      "epoch:235,loss:0.0146\n",
      "epoch:235,loss:0.2666\n",
      "epoch:235,loss:1.4446\n",
      "epoch:235,loss:0.1554\n",
      "epoch:235,loss:0.0171\n",
      "epoch:235,loss:0.0094\n",
      "epoch:235,loss:0.1262\n",
      "epoch:235,loss:0.1740\n",
      "epoch:235,loss:0.1165\n",
      "epoch:235,loss:0.0075\n",
      "epoch:235,loss:0.0242\n",
      "epoch:235,loss:0.0481\n",
      "epoch:235,loss:0.0920\n",
      "epoch:235,loss:0.0887\n",
      "epoch:235,loss:0.0543\n",
      "epoch:235,loss:0.0610\n",
      "epoch:235,loss:0.0360\n",
      "epoch:235,loss:0.0859\n",
      "epoch:235,loss:0.0955\n",
      "epoch:235,loss:0.1174\n",
      "epoch:235,loss:0.0424\n",
      "epoch:235,loss:0.2412\n",
      "epoch:235,loss:0.3923\n",
      "epoch:235,loss:0.0164\n",
      "epoch:235,loss:0.0544\n",
      "epoch:235,loss:0.0144\n",
      "epoch:235,loss:0.0041\n",
      "epoch:235,loss:0.0260\n",
      "epoch:235,loss:0.0084\n",
      "epoch:235,loss:0.0042\n",
      "epoch:235,loss:0.1796\n",
      "============================================\n",
      "第235个epoch的识别准确率为：95%\n",
      "epoch:236,loss:0.0033\n",
      "epoch:236,loss:0.0090\n",
      "epoch:236,loss:0.0050\n",
      "epoch:236,loss:0.0103\n",
      "epoch:236,loss:0.0404\n",
      "epoch:236,loss:0.0584\n",
      "epoch:236,loss:0.0695\n",
      "epoch:236,loss:0.0077\n",
      "epoch:236,loss:0.0104\n",
      "epoch:236,loss:0.0214\n",
      "epoch:236,loss:0.0297\n",
      "epoch:236,loss:0.0753\n",
      "epoch:236,loss:0.0925\n",
      "epoch:236,loss:0.0220\n",
      "epoch:236,loss:0.0099\n",
      "epoch:236,loss:0.2219\n",
      "epoch:236,loss:0.3605\n",
      "epoch:236,loss:0.0508\n",
      "epoch:236,loss:0.0088\n",
      "epoch:236,loss:0.0021\n",
      "epoch:236,loss:0.0162\n",
      "epoch:236,loss:0.0388\n",
      "epoch:236,loss:0.0057\n",
      "epoch:236,loss:0.0891\n",
      "epoch:236,loss:0.4522\n",
      "epoch:236,loss:0.1042\n",
      "epoch:236,loss:0.3129\n",
      "epoch:236,loss:0.2245\n",
      "epoch:236,loss:0.0056\n",
      "epoch:236,loss:0.0473\n",
      "epoch:236,loss:0.1304\n",
      "epoch:236,loss:0.4690\n",
      "epoch:236,loss:0.2586\n",
      "epoch:236,loss:0.0179\n",
      "epoch:236,loss:0.0045\n",
      "epoch:236,loss:0.0109\n",
      "epoch:236,loss:0.1638\n",
      "epoch:236,loss:0.0692\n",
      "epoch:236,loss:0.0108\n",
      "epoch:236,loss:0.2632\n",
      "epoch:236,loss:0.0358\n",
      "epoch:236,loss:0.0272\n",
      "epoch:236,loss:0.4260\n",
      "epoch:236,loss:1.1589\n",
      "epoch:236,loss:0.5567\n",
      "epoch:236,loss:0.1718\n",
      "epoch:236,loss:0.0152\n",
      "epoch:236,loss:0.3068\n",
      "epoch:236,loss:0.0104\n",
      "epoch:236,loss:0.0101\n",
      "epoch:236,loss:0.0978\n",
      "epoch:236,loss:0.0287\n",
      "epoch:236,loss:0.0566\n",
      "epoch:236,loss:0.1972\n",
      "epoch:236,loss:0.6485\n",
      "epoch:236,loss:0.0122\n",
      "epoch:236,loss:0.1388\n",
      "epoch:236,loss:0.3251\n",
      "epoch:236,loss:0.0299\n",
      "epoch:236,loss:0.7363\n",
      "============================================\n",
      "第236个epoch的识别准确率为：96%\n",
      "epoch:237,loss:0.2005\n",
      "epoch:237,loss:0.0372\n",
      "epoch:237,loss:1.1479\n",
      "epoch:237,loss:0.0101\n",
      "epoch:237,loss:0.0221\n",
      "epoch:237,loss:0.0889\n",
      "epoch:237,loss:0.0593\n",
      "epoch:237,loss:0.0241\n",
      "epoch:237,loss:0.0204\n",
      "epoch:237,loss:0.4797\n",
      "epoch:237,loss:0.7986\n",
      "epoch:237,loss:0.0405\n",
      "epoch:237,loss:0.0633\n",
      "epoch:237,loss:0.0099\n",
      "epoch:237,loss:0.0063\n",
      "epoch:237,loss:0.0602\n",
      "epoch:237,loss:0.0068\n",
      "epoch:237,loss:0.0292\n",
      "epoch:237,loss:0.0038\n",
      "epoch:237,loss:0.0431\n",
      "epoch:237,loss:0.0099\n",
      "epoch:237,loss:0.0064\n",
      "epoch:237,loss:0.0100\n",
      "epoch:237,loss:0.0028\n",
      "epoch:237,loss:0.0059\n",
      "epoch:237,loss:0.0273\n",
      "epoch:237,loss:0.0062\n",
      "epoch:237,loss:0.0141\n",
      "epoch:237,loss:0.1601\n",
      "epoch:237,loss:0.0278\n",
      "epoch:237,loss:0.0310\n",
      "epoch:237,loss:0.0457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:237,loss:0.0925\n",
      "epoch:237,loss:0.0048\n",
      "epoch:237,loss:0.8144\n",
      "epoch:237,loss:0.0456\n",
      "epoch:237,loss:0.3747\n",
      "epoch:237,loss:0.0145\n",
      "epoch:237,loss:0.0457\n",
      "epoch:237,loss:0.0054\n",
      "epoch:237,loss:0.0372\n",
      "epoch:237,loss:0.0120\n",
      "epoch:237,loss:0.0872\n",
      "epoch:237,loss:0.2158\n",
      "epoch:237,loss:0.0049\n",
      "epoch:237,loss:0.0147\n",
      "epoch:237,loss:0.1771\n",
      "epoch:237,loss:0.0128\n",
      "epoch:237,loss:0.0735\n",
      "epoch:237,loss:0.0323\n",
      "epoch:237,loss:0.0078\n",
      "epoch:237,loss:0.1396\n",
      "epoch:237,loss:0.0044\n",
      "epoch:237,loss:0.0158\n",
      "epoch:237,loss:0.5840\n",
      "epoch:237,loss:0.0153\n",
      "epoch:237,loss:0.0517\n",
      "epoch:237,loss:0.0101\n",
      "epoch:237,loss:0.4575\n",
      "epoch:237,loss:0.4098\n",
      "============================================\n",
      "第237个epoch的识别准确率为：95%\n",
      "epoch:238,loss:0.1120\n",
      "epoch:238,loss:0.2688\n",
      "epoch:238,loss:0.0337\n",
      "epoch:238,loss:0.0223\n",
      "epoch:238,loss:0.1975\n",
      "epoch:238,loss:0.0476\n",
      "epoch:238,loss:0.0266\n",
      "epoch:238,loss:0.0332\n",
      "epoch:238,loss:0.0372\n",
      "epoch:238,loss:0.0042\n",
      "epoch:238,loss:0.0114\n",
      "epoch:238,loss:0.0079\n",
      "epoch:238,loss:0.1288\n",
      "epoch:238,loss:0.0063\n",
      "epoch:238,loss:0.0006\n",
      "epoch:238,loss:0.0206\n",
      "epoch:238,loss:0.2565\n",
      "epoch:238,loss:0.0489\n",
      "epoch:238,loss:0.0759\n",
      "epoch:238,loss:0.1356\n",
      "epoch:238,loss:0.5628\n",
      "epoch:238,loss:0.1476\n",
      "epoch:238,loss:0.0247\n",
      "epoch:238,loss:0.2181\n",
      "epoch:238,loss:0.0815\n",
      "epoch:238,loss:0.0295\n",
      "epoch:238,loss:0.1549\n",
      "epoch:238,loss:0.0935\n",
      "epoch:238,loss:0.0616\n",
      "epoch:238,loss:1.6262\n",
      "epoch:238,loss:0.0413\n",
      "epoch:238,loss:0.0128\n",
      "epoch:238,loss:0.0076\n",
      "epoch:238,loss:0.0134\n",
      "epoch:238,loss:0.0442\n",
      "epoch:238,loss:1.0840\n",
      "epoch:238,loss:0.0155\n",
      "epoch:238,loss:0.0414\n",
      "epoch:238,loss:0.0543\n",
      "epoch:238,loss:0.0197\n",
      "epoch:238,loss:0.1659\n",
      "epoch:238,loss:0.0477\n",
      "epoch:238,loss:0.4864\n",
      "epoch:238,loss:0.0374\n",
      "epoch:238,loss:0.0313\n",
      "epoch:238,loss:0.6511\n",
      "epoch:238,loss:0.0265\n",
      "epoch:238,loss:0.5230\n",
      "epoch:238,loss:0.0068\n",
      "epoch:238,loss:0.0034\n",
      "epoch:238,loss:0.3337\n",
      "epoch:238,loss:0.5517\n",
      "epoch:238,loss:0.0229\n",
      "epoch:238,loss:0.7936\n",
      "epoch:238,loss:0.3134\n",
      "epoch:238,loss:0.0089\n",
      "epoch:238,loss:0.0994\n",
      "epoch:238,loss:0.1260\n",
      "epoch:238,loss:0.1882\n",
      "epoch:238,loss:0.0145\n",
      "============================================\n",
      "第238个epoch的识别准确率为：96%\n",
      "epoch:239,loss:0.0076\n",
      "epoch:239,loss:0.0098\n",
      "epoch:239,loss:0.4896\n",
      "epoch:239,loss:0.0196\n",
      "epoch:239,loss:0.0762\n",
      "epoch:239,loss:0.0082\n",
      "epoch:239,loss:0.9860\n",
      "epoch:239,loss:0.3951\n",
      "epoch:239,loss:0.0178\n",
      "epoch:239,loss:0.4107\n",
      "epoch:239,loss:0.1312\n",
      "epoch:239,loss:0.1817\n",
      "epoch:239,loss:0.1225\n",
      "epoch:239,loss:0.0039\n",
      "epoch:239,loss:0.0155\n",
      "epoch:239,loss:0.0731\n",
      "epoch:239,loss:0.0446\n",
      "epoch:239,loss:0.1067\n",
      "epoch:239,loss:0.0328\n",
      "epoch:239,loss:0.1607\n",
      "epoch:239,loss:0.0115\n",
      "epoch:239,loss:0.0036\n",
      "epoch:239,loss:0.0254\n",
      "epoch:239,loss:0.8037\n",
      "epoch:239,loss:0.0363\n",
      "epoch:239,loss:0.0831\n",
      "epoch:239,loss:0.0137\n",
      "epoch:239,loss:0.2046\n",
      "epoch:239,loss:0.2831\n",
      "epoch:239,loss:0.1651\n",
      "epoch:239,loss:0.0381\n",
      "epoch:239,loss:0.0059\n",
      "epoch:239,loss:0.0483\n",
      "epoch:239,loss:0.0115\n",
      "epoch:239,loss:0.0512\n",
      "epoch:239,loss:0.3237\n",
      "epoch:239,loss:0.0593\n",
      "epoch:239,loss:1.0693\n",
      "epoch:239,loss:0.0538\n",
      "epoch:239,loss:0.0250\n",
      "epoch:239,loss:0.0319\n",
      "epoch:239,loss:0.0039\n",
      "epoch:239,loss:1.2145\n",
      "epoch:239,loss:0.2655\n",
      "epoch:239,loss:0.1223\n",
      "epoch:239,loss:0.0117\n",
      "epoch:239,loss:0.0143\n",
      "epoch:239,loss:0.0071\n",
      "epoch:239,loss:0.0126\n",
      "epoch:239,loss:0.1381\n",
      "epoch:239,loss:0.2894\n",
      "epoch:239,loss:0.0321\n",
      "epoch:239,loss:0.0605\n",
      "epoch:239,loss:0.4123\n",
      "epoch:239,loss:0.0443\n",
      "epoch:239,loss:0.4933\n",
      "epoch:239,loss:0.5627\n",
      "epoch:239,loss:0.0794\n",
      "epoch:239,loss:0.3933\n",
      "epoch:239,loss:0.0313\n",
      "============================================\n",
      "第239个epoch的识别准确率为：96%\n",
      "epoch:240,loss:0.0076\n",
      "epoch:240,loss:0.0561\n",
      "epoch:240,loss:0.0076\n",
      "epoch:240,loss:0.0381\n",
      "epoch:240,loss:0.0299\n",
      "epoch:240,loss:0.0219\n",
      "epoch:240,loss:0.5204\n",
      "epoch:240,loss:0.0764\n",
      "epoch:240,loss:0.0485\n",
      "epoch:240,loss:0.0664\n",
      "epoch:240,loss:0.0211\n",
      "epoch:240,loss:0.0232\n",
      "epoch:240,loss:0.0019\n",
      "epoch:240,loss:0.0330\n",
      "epoch:240,loss:0.0132\n",
      "epoch:240,loss:0.0020\n",
      "epoch:240,loss:0.0420\n",
      "epoch:240,loss:0.0185\n",
      "epoch:240,loss:0.0127\n",
      "epoch:240,loss:0.0324\n",
      "epoch:240,loss:0.5162\n",
      "epoch:240,loss:0.0343\n",
      "epoch:240,loss:0.0205\n",
      "epoch:240,loss:0.4179\n",
      "epoch:240,loss:0.0167\n",
      "epoch:240,loss:0.3254\n",
      "epoch:240,loss:0.0308\n",
      "epoch:240,loss:0.0039\n",
      "epoch:240,loss:0.1953\n",
      "epoch:240,loss:0.0044\n",
      "epoch:240,loss:0.0008\n",
      "epoch:240,loss:0.0238\n",
      "epoch:240,loss:0.1743\n",
      "epoch:240,loss:0.1882\n",
      "epoch:240,loss:0.1046\n",
      "epoch:240,loss:0.0091\n",
      "epoch:240,loss:0.0569\n",
      "epoch:240,loss:0.0837\n",
      "epoch:240,loss:0.0383\n",
      "epoch:240,loss:0.0050\n",
      "epoch:240,loss:0.0047\n",
      "epoch:240,loss:0.0095\n",
      "epoch:240,loss:0.0169\n",
      "epoch:240,loss:0.0511\n",
      "epoch:240,loss:0.0320\n",
      "epoch:240,loss:0.0525\n",
      "epoch:240,loss:0.0862\n",
      "epoch:240,loss:0.0172\n",
      "epoch:240,loss:0.2088\n",
      "epoch:240,loss:0.0779\n",
      "epoch:240,loss:0.0258\n",
      "epoch:240,loss:0.0039\n",
      "epoch:240,loss:0.1628\n",
      "epoch:240,loss:0.4341\n",
      "epoch:240,loss:0.0404\n",
      "epoch:240,loss:0.1435\n",
      "epoch:240,loss:0.0384\n",
      "epoch:240,loss:0.0787\n",
      "epoch:240,loss:1.1813\n",
      "epoch:240,loss:0.0155\n",
      "============================================\n",
      "准确率由： tensor(0.9660) 上升至： tensor(0.9733) 已更新并保存权值为weights/mobilenetv2_Q_best.pt\n",
      "第240个epoch的识别准确率为：97%\n",
      "epoch:241,loss:0.0097\n",
      "epoch:241,loss:0.0016\n",
      "epoch:241,loss:0.0878\n",
      "epoch:241,loss:0.3502\n",
      "epoch:241,loss:1.2606\n",
      "epoch:241,loss:0.1797\n",
      "epoch:241,loss:0.1660\n",
      "epoch:241,loss:0.0735\n",
      "epoch:241,loss:0.0266\n",
      "epoch:241,loss:0.6756\n",
      "epoch:241,loss:0.1666\n",
      "epoch:241,loss:0.0279\n",
      "epoch:241,loss:0.2774\n",
      "epoch:241,loss:0.3905\n",
      "epoch:241,loss:0.0075\n",
      "epoch:241,loss:0.0341\n",
      "epoch:241,loss:0.0297\n",
      "epoch:241,loss:0.0767\n",
      "epoch:241,loss:0.0197\n",
      "epoch:241,loss:0.0490\n",
      "epoch:241,loss:0.0225\n",
      "epoch:241,loss:0.2017\n",
      "epoch:241,loss:0.0020\n",
      "epoch:241,loss:0.0108\n",
      "epoch:241,loss:0.0053\n",
      "epoch:241,loss:0.1137\n",
      "epoch:241,loss:0.0052\n",
      "epoch:241,loss:0.0947\n",
      "epoch:241,loss:0.5917\n",
      "epoch:241,loss:0.0387\n",
      "epoch:241,loss:0.4569\n",
      "epoch:241,loss:0.0565\n",
      "epoch:241,loss:0.0329\n",
      "epoch:241,loss:0.3411\n",
      "epoch:241,loss:0.0519\n",
      "epoch:241,loss:0.0194\n",
      "epoch:241,loss:0.1187\n",
      "epoch:241,loss:0.2306\n",
      "epoch:241,loss:0.0018\n",
      "epoch:241,loss:0.0498\n",
      "epoch:241,loss:0.0019\n",
      "epoch:241,loss:0.5367\n",
      "epoch:241,loss:0.0370\n",
      "epoch:241,loss:0.0409\n",
      "epoch:241,loss:0.1567\n",
      "epoch:241,loss:0.0729\n",
      "epoch:241,loss:0.3813\n",
      "epoch:241,loss:0.1145\n",
      "epoch:241,loss:0.0056\n",
      "epoch:241,loss:0.0021\n",
      "epoch:241,loss:0.1602\n",
      "epoch:241,loss:0.2359\n",
      "epoch:241,loss:0.0525\n",
      "epoch:241,loss:0.0579\n",
      "epoch:241,loss:0.3776\n",
      "epoch:241,loss:0.1507\n",
      "epoch:241,loss:0.0072\n",
      "epoch:241,loss:0.0068\n",
      "epoch:241,loss:0.2065\n",
      "epoch:241,loss:0.0187\n",
      "============================================\n",
      "第241个epoch的识别准确率为：94%\n",
      "epoch:242,loss:0.0079\n",
      "epoch:242,loss:0.0352\n",
      "epoch:242,loss:0.0548\n",
      "epoch:242,loss:0.0017\n",
      "epoch:242,loss:0.2942\n",
      "epoch:242,loss:0.0035\n",
      "epoch:242,loss:1.4647\n",
      "epoch:242,loss:0.7089\n",
      "epoch:242,loss:0.0106\n",
      "epoch:242,loss:0.0136\n",
      "epoch:242,loss:0.4278\n",
      "epoch:242,loss:0.2699\n",
      "epoch:242,loss:0.0082\n",
      "epoch:242,loss:0.4686\n",
      "epoch:242,loss:0.0180\n",
      "epoch:242,loss:0.0041\n",
      "epoch:242,loss:0.0514\n",
      "epoch:242,loss:0.1061\n",
      "epoch:242,loss:0.2234\n",
      "epoch:242,loss:0.0165\n",
      "epoch:242,loss:0.2179\n",
      "epoch:242,loss:0.1229\n",
      "epoch:242,loss:0.1484\n",
      "epoch:242,loss:0.3887\n",
      "epoch:242,loss:1.0890\n",
      "epoch:242,loss:0.0083\n",
      "epoch:242,loss:0.2624\n",
      "epoch:242,loss:0.0250\n",
      "epoch:242,loss:0.0055\n",
      "epoch:242,loss:0.0029\n",
      "epoch:242,loss:0.0080\n",
      "epoch:242,loss:0.5725\n",
      "epoch:242,loss:0.1121\n",
      "epoch:242,loss:0.0103\n",
      "epoch:242,loss:0.0068\n",
      "epoch:242,loss:0.0040\n",
      "epoch:242,loss:0.0018\n",
      "epoch:242,loss:0.0085\n",
      "epoch:242,loss:0.0412\n",
      "epoch:242,loss:0.0218\n",
      "epoch:242,loss:0.0088\n",
      "epoch:242,loss:0.4794\n",
      "epoch:242,loss:0.0407\n",
      "epoch:242,loss:0.1147\n",
      "epoch:242,loss:0.3790\n",
      "epoch:242,loss:0.0085\n",
      "epoch:242,loss:0.0463\n",
      "epoch:242,loss:0.1178\n",
      "epoch:242,loss:0.0810\n",
      "epoch:242,loss:0.0193\n",
      "epoch:242,loss:0.0390\n",
      "epoch:242,loss:0.0134\n",
      "epoch:242,loss:0.0511\n",
      "epoch:242,loss:0.0231\n",
      "epoch:242,loss:0.0170\n",
      "epoch:242,loss:0.0259\n",
      "epoch:242,loss:0.0152\n",
      "epoch:242,loss:0.0327\n",
      "epoch:242,loss:1.0852\n",
      "epoch:242,loss:0.1146\n",
      "============================================\n",
      "第242个epoch的识别准确率为：95%\n",
      "epoch:243,loss:0.1598\n",
      "epoch:243,loss:0.6847\n",
      "epoch:243,loss:0.1034\n",
      "epoch:243,loss:0.2018\n",
      "epoch:243,loss:0.0324\n",
      "epoch:243,loss:0.0742\n",
      "epoch:243,loss:0.5062\n",
      "epoch:243,loss:0.0578\n",
      "epoch:243,loss:0.3229\n",
      "epoch:243,loss:0.0935\n",
      "epoch:243,loss:0.1031\n",
      "epoch:243,loss:0.0576\n",
      "epoch:243,loss:3.3340\n",
      "epoch:243,loss:0.7151\n",
      "epoch:243,loss:0.0102\n",
      "epoch:243,loss:0.2230\n",
      "epoch:243,loss:0.0304\n",
      "epoch:243,loss:0.0110\n",
      "epoch:243,loss:0.3639\n",
      "epoch:243,loss:0.0073\n",
      "epoch:243,loss:0.0117\n",
      "epoch:243,loss:0.0248\n",
      "epoch:243,loss:0.0565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:243,loss:0.0344\n",
      "epoch:243,loss:0.1924\n",
      "epoch:243,loss:0.0008\n",
      "epoch:243,loss:0.0090\n",
      "epoch:243,loss:0.0976\n",
      "epoch:243,loss:0.0752\n",
      "epoch:243,loss:0.1632\n",
      "epoch:243,loss:0.0457\n",
      "epoch:243,loss:0.0084\n",
      "epoch:243,loss:0.0212\n",
      "epoch:243,loss:0.0801\n",
      "epoch:243,loss:0.0268\n",
      "epoch:243,loss:0.0405\n",
      "epoch:243,loss:0.0505\n",
      "epoch:243,loss:0.0243\n",
      "epoch:243,loss:0.0725\n",
      "epoch:243,loss:0.0130\n",
      "epoch:243,loss:0.0095\n",
      "epoch:243,loss:0.0213\n",
      "epoch:243,loss:0.0932\n",
      "epoch:243,loss:0.0153\n",
      "epoch:243,loss:0.0048\n",
      "epoch:243,loss:0.0245\n",
      "epoch:243,loss:0.3335\n",
      "epoch:243,loss:0.0115\n",
      "epoch:243,loss:0.0416\n",
      "epoch:243,loss:0.3614\n",
      "epoch:243,loss:0.0580\n",
      "epoch:243,loss:0.0635\n",
      "epoch:243,loss:0.0077\n",
      "epoch:243,loss:0.2488\n",
      "epoch:243,loss:0.0174\n",
      "epoch:243,loss:0.2313\n",
      "epoch:243,loss:0.1402\n",
      "epoch:243,loss:0.0614\n",
      "epoch:243,loss:0.0108\n",
      "epoch:243,loss:0.0537\n",
      "============================================\n",
      "第243个epoch的识别准确率为：95%\n",
      "epoch:244,loss:0.0566\n",
      "epoch:244,loss:0.1210\n",
      "epoch:244,loss:0.0693\n",
      "epoch:244,loss:0.1444\n",
      "epoch:244,loss:0.0736\n",
      "epoch:244,loss:0.3159\n",
      "epoch:244,loss:0.0488\n",
      "epoch:244,loss:0.0090\n",
      "epoch:244,loss:0.0349\n",
      "epoch:244,loss:0.0050\n",
      "epoch:244,loss:0.0273\n",
      "epoch:244,loss:0.0081\n",
      "epoch:244,loss:0.0192\n",
      "epoch:244,loss:0.5675\n",
      "epoch:244,loss:0.0148\n",
      "epoch:244,loss:0.1167\n",
      "epoch:244,loss:0.0862\n",
      "epoch:244,loss:0.6858\n",
      "epoch:244,loss:0.0412\n",
      "epoch:244,loss:0.0093\n",
      "epoch:244,loss:0.0628\n",
      "epoch:244,loss:0.0093\n",
      "epoch:244,loss:0.0079\n",
      "epoch:244,loss:0.6953\n",
      "epoch:244,loss:0.2128\n",
      "epoch:244,loss:0.0080\n",
      "epoch:244,loss:0.0181\n",
      "epoch:244,loss:0.1509\n",
      "epoch:244,loss:0.0162\n",
      "epoch:244,loss:0.1637\n",
      "epoch:244,loss:0.0135\n",
      "epoch:244,loss:1.3293\n",
      "epoch:244,loss:0.0365\n",
      "epoch:244,loss:0.0032\n",
      "epoch:244,loss:0.4128\n",
      "epoch:244,loss:0.0434\n",
      "epoch:244,loss:0.0074\n",
      "epoch:244,loss:0.0148\n",
      "epoch:244,loss:0.0063\n",
      "epoch:244,loss:0.0220\n",
      "epoch:244,loss:0.1354\n",
      "epoch:244,loss:0.5193\n",
      "epoch:244,loss:0.0251\n",
      "epoch:244,loss:0.3181\n",
      "epoch:244,loss:0.0028\n",
      "epoch:244,loss:0.0652\n",
      "epoch:244,loss:0.1145\n",
      "epoch:244,loss:0.0800\n",
      "epoch:244,loss:0.0616\n",
      "epoch:244,loss:0.0326\n",
      "epoch:244,loss:0.0454\n",
      "epoch:244,loss:0.0048\n",
      "epoch:244,loss:0.2652\n",
      "epoch:244,loss:0.0014\n",
      "epoch:244,loss:0.0407\n",
      "epoch:244,loss:0.0204\n",
      "epoch:244,loss:0.3041\n",
      "epoch:244,loss:0.0085\n",
      "epoch:244,loss:0.0373\n",
      "epoch:244,loss:0.1128\n",
      "============================================\n",
      "第244个epoch的识别准确率为：96%\n",
      "epoch:245,loss:0.0324\n",
      "epoch:245,loss:0.0271\n",
      "epoch:245,loss:0.0072\n",
      "epoch:245,loss:0.0575\n",
      "epoch:245,loss:0.0507\n",
      "epoch:245,loss:0.0107\n",
      "epoch:245,loss:0.0023\n",
      "epoch:245,loss:0.0265\n",
      "epoch:245,loss:0.1738\n",
      "epoch:245,loss:0.0425\n",
      "epoch:245,loss:0.0003\n",
      "epoch:245,loss:0.0011\n",
      "epoch:245,loss:0.0163\n",
      "epoch:245,loss:0.0056\n",
      "epoch:245,loss:0.0029\n",
      "epoch:245,loss:0.4537\n",
      "epoch:245,loss:0.0022\n",
      "epoch:245,loss:0.0129\n",
      "epoch:245,loss:0.1166\n",
      "epoch:245,loss:0.3590\n",
      "epoch:245,loss:0.0006\n",
      "epoch:245,loss:0.0265\n",
      "epoch:245,loss:0.0303\n",
      "epoch:245,loss:0.0234\n",
      "epoch:245,loss:0.0007\n",
      "epoch:245,loss:0.0095\n",
      "epoch:245,loss:0.0471\n",
      "epoch:245,loss:0.0029\n",
      "epoch:245,loss:0.0197\n",
      "epoch:245,loss:0.6866\n",
      "epoch:245,loss:0.0289\n",
      "epoch:245,loss:0.0204\n",
      "epoch:245,loss:0.0256\n",
      "epoch:245,loss:0.1154\n",
      "epoch:245,loss:0.0045\n",
      "epoch:245,loss:0.0185\n",
      "epoch:245,loss:0.0034\n",
      "epoch:245,loss:0.0220\n",
      "epoch:245,loss:1.1683\n",
      "epoch:245,loss:0.0249\n",
      "epoch:245,loss:0.1289\n",
      "epoch:245,loss:0.0026\n",
      "epoch:245,loss:0.0569\n",
      "epoch:245,loss:0.0939\n",
      "epoch:245,loss:0.0812\n",
      "epoch:245,loss:0.0595\n",
      "epoch:245,loss:0.0051\n",
      "epoch:245,loss:0.0386\n",
      "epoch:245,loss:0.0143\n",
      "epoch:245,loss:0.0015\n",
      "epoch:245,loss:0.1583\n",
      "epoch:245,loss:0.4763\n",
      "epoch:245,loss:0.0033\n",
      "epoch:245,loss:0.0769\n",
      "epoch:245,loss:0.0432\n",
      "epoch:245,loss:0.0222\n",
      "epoch:245,loss:0.0913\n",
      "epoch:245,loss:0.0048\n",
      "epoch:245,loss:0.0086\n",
      "epoch:245,loss:0.0448\n",
      "============================================\n",
      "第245个epoch的识别准确率为：96%\n",
      "epoch:246,loss:0.1237\n",
      "epoch:246,loss:0.0297\n",
      "epoch:246,loss:0.2545\n",
      "epoch:246,loss:0.1979\n",
      "epoch:246,loss:1.5098\n",
      "epoch:246,loss:0.1083\n",
      "epoch:246,loss:0.6122\n",
      "epoch:246,loss:0.0144\n",
      "epoch:246,loss:0.0752\n",
      "epoch:246,loss:0.2962\n",
      "epoch:246,loss:0.1678\n",
      "epoch:246,loss:0.0503\n",
      "epoch:246,loss:1.6512\n",
      "epoch:246,loss:0.0318\n",
      "epoch:246,loss:0.5447\n",
      "epoch:246,loss:0.0299\n",
      "epoch:246,loss:0.2352\n",
      "epoch:246,loss:0.0647\n",
      "epoch:246,loss:0.5306\n",
      "epoch:246,loss:0.0432\n",
      "epoch:246,loss:0.0030\n",
      "epoch:246,loss:0.1036\n",
      "epoch:246,loss:0.0140\n",
      "epoch:246,loss:0.0863\n",
      "epoch:246,loss:0.1343\n",
      "epoch:246,loss:0.4866\n",
      "epoch:246,loss:0.6030\n",
      "epoch:246,loss:0.1113\n",
      "epoch:246,loss:0.3728\n",
      "epoch:246,loss:0.3914\n",
      "epoch:246,loss:0.1677\n",
      "epoch:246,loss:0.0026\n",
      "epoch:246,loss:0.0244\n",
      "epoch:246,loss:0.0085\n",
      "epoch:246,loss:0.0197\n",
      "epoch:246,loss:0.0343\n",
      "epoch:246,loss:0.0049\n",
      "epoch:246,loss:0.4427\n",
      "epoch:246,loss:0.0243\n",
      "epoch:246,loss:0.0056\n",
      "epoch:246,loss:0.0416\n",
      "epoch:246,loss:0.0374\n",
      "epoch:246,loss:0.0827\n",
      "epoch:246,loss:0.0370\n",
      "epoch:246,loss:0.0091\n",
      "epoch:246,loss:0.0099\n",
      "epoch:246,loss:0.0019\n",
      "epoch:246,loss:0.0490\n",
      "epoch:246,loss:0.8232\n",
      "epoch:246,loss:0.0485\n",
      "epoch:246,loss:0.0899\n",
      "epoch:246,loss:0.0130\n",
      "epoch:246,loss:0.1007\n",
      "epoch:246,loss:0.5492\n",
      "epoch:246,loss:0.0097\n",
      "epoch:246,loss:0.4061\n",
      "epoch:246,loss:0.0043\n",
      "epoch:246,loss:1.3630\n",
      "epoch:246,loss:0.0293\n",
      "epoch:246,loss:0.0290\n",
      "============================================\n",
      "第246个epoch的识别准确率为：94%\n",
      "epoch:247,loss:0.4750\n",
      "epoch:247,loss:0.1939\n",
      "epoch:247,loss:0.0317\n",
      "epoch:247,loss:1.3976\n",
      "epoch:247,loss:0.1044\n",
      "epoch:247,loss:0.1630\n",
      "epoch:247,loss:0.0981\n",
      "epoch:247,loss:0.2062\n",
      "epoch:247,loss:0.0061\n",
      "epoch:247,loss:0.0446\n",
      "epoch:247,loss:0.0938\n",
      "epoch:247,loss:0.0056\n",
      "epoch:247,loss:0.0016\n",
      "epoch:247,loss:0.2423\n",
      "epoch:247,loss:0.0225\n",
      "epoch:247,loss:0.3070\n",
      "epoch:247,loss:0.2334\n",
      "epoch:247,loss:0.1270\n",
      "epoch:247,loss:1.4015\n",
      "epoch:247,loss:0.0337\n",
      "epoch:247,loss:0.4811\n",
      "epoch:247,loss:0.0122\n",
      "epoch:247,loss:0.0379\n",
      "epoch:247,loss:0.0044\n",
      "epoch:247,loss:0.0124\n",
      "epoch:247,loss:0.0066\n",
      "epoch:247,loss:0.0807\n",
      "epoch:247,loss:0.0747\n",
      "epoch:247,loss:0.0173\n",
      "epoch:247,loss:0.0646\n",
      "epoch:247,loss:0.0054\n",
      "epoch:247,loss:0.0272\n",
      "epoch:247,loss:0.0130\n",
      "epoch:247,loss:0.0402\n",
      "epoch:247,loss:0.0010\n",
      "epoch:247,loss:0.0146\n",
      "epoch:247,loss:0.0083\n",
      "epoch:247,loss:0.1755\n",
      "epoch:247,loss:0.3918\n",
      "epoch:247,loss:0.0160\n",
      "epoch:247,loss:0.0109\n",
      "epoch:247,loss:0.0135\n",
      "epoch:247,loss:0.1759\n",
      "epoch:247,loss:0.0143\n",
      "epoch:247,loss:0.1586\n",
      "epoch:247,loss:0.1072\n",
      "epoch:247,loss:0.9834\n",
      "epoch:247,loss:0.0318\n",
      "epoch:247,loss:0.0180\n",
      "epoch:247,loss:0.1881\n",
      "epoch:247,loss:0.0426\n",
      "epoch:247,loss:0.6427\n",
      "epoch:247,loss:0.0878\n",
      "epoch:247,loss:0.0102\n",
      "epoch:247,loss:0.0062\n",
      "epoch:247,loss:0.0431\n",
      "epoch:247,loss:0.0584\n",
      "epoch:247,loss:0.3737\n",
      "epoch:247,loss:0.7502\n",
      "epoch:247,loss:0.0060\n",
      "============================================\n",
      "第247个epoch的识别准确率为：96%\n",
      "epoch:248,loss:0.0272\n",
      "epoch:248,loss:0.0459\n",
      "epoch:248,loss:0.1004\n",
      "epoch:248,loss:0.0005\n",
      "epoch:248,loss:0.0364\n",
      "epoch:248,loss:0.0264\n",
      "epoch:248,loss:0.2156\n",
      "epoch:248,loss:0.0732\n",
      "epoch:248,loss:0.0543\n",
      "epoch:248,loss:0.0098\n",
      "epoch:248,loss:0.4462\n",
      "epoch:248,loss:0.0412\n",
      "epoch:248,loss:0.0282\n",
      "epoch:248,loss:0.1779\n",
      "epoch:248,loss:0.0110\n",
      "epoch:248,loss:0.0081\n",
      "epoch:248,loss:0.4254\n",
      "epoch:248,loss:0.0004\n",
      "epoch:248,loss:0.4852\n",
      "epoch:248,loss:0.0372\n",
      "epoch:248,loss:0.6020\n",
      "epoch:248,loss:0.4439\n",
      "epoch:248,loss:0.1374\n",
      "epoch:248,loss:0.1154\n",
      "epoch:248,loss:0.0304\n",
      "epoch:248,loss:0.0074\n",
      "epoch:248,loss:0.1174\n",
      "epoch:248,loss:0.0136\n",
      "epoch:248,loss:0.0310\n",
      "epoch:248,loss:0.0045\n",
      "epoch:248,loss:0.0098\n",
      "epoch:248,loss:0.1524\n",
      "epoch:248,loss:0.0076\n",
      "epoch:248,loss:0.0075\n",
      "epoch:248,loss:0.0042\n",
      "epoch:248,loss:0.2656\n",
      "epoch:248,loss:0.0676\n",
      "epoch:248,loss:0.0053\n",
      "epoch:248,loss:0.0577\n",
      "epoch:248,loss:0.7400\n",
      "epoch:248,loss:0.1036\n",
      "epoch:248,loss:0.0133\n",
      "epoch:248,loss:1.0765\n",
      "epoch:248,loss:0.0269\n",
      "epoch:248,loss:0.2018\n",
      "epoch:248,loss:0.0205\n",
      "epoch:248,loss:0.0103\n",
      "epoch:248,loss:0.0261\n",
      "epoch:248,loss:0.0025\n",
      "epoch:248,loss:0.0065\n",
      "epoch:248,loss:0.0284\n",
      "epoch:248,loss:0.0754\n",
      "epoch:248,loss:0.0096\n",
      "epoch:248,loss:0.0129\n",
      "epoch:248,loss:0.0152\n",
      "epoch:248,loss:0.0314\n",
      "epoch:248,loss:0.0541\n",
      "epoch:248,loss:0.1622\n",
      "epoch:248,loss:0.0129\n",
      "epoch:248,loss:0.0042\n",
      "============================================\n",
      "第248个epoch的识别准确率为：95%\n",
      "epoch:249,loss:0.0028\n",
      "epoch:249,loss:0.1920\n",
      "epoch:249,loss:0.0349\n",
      "epoch:249,loss:0.3957\n",
      "epoch:249,loss:0.1101\n",
      "epoch:249,loss:0.0636\n",
      "epoch:249,loss:0.0057\n",
      "epoch:249,loss:0.2660\n",
      "epoch:249,loss:0.0774\n",
      "epoch:249,loss:0.0208\n",
      "epoch:249,loss:0.3607\n",
      "epoch:249,loss:0.0997\n",
      "epoch:249,loss:0.2788\n",
      "epoch:249,loss:0.3106\n",
      "epoch:249,loss:0.0041\n",
      "epoch:249,loss:0.0250\n",
      "epoch:249,loss:0.2446\n",
      "epoch:249,loss:0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:249,loss:0.1227\n",
      "epoch:249,loss:0.0631\n",
      "epoch:249,loss:0.0136\n",
      "epoch:249,loss:0.0213\n",
      "epoch:249,loss:0.0150\n",
      "epoch:249,loss:0.0433\n",
      "epoch:249,loss:0.0753\n",
      "epoch:249,loss:0.0742\n",
      "epoch:249,loss:0.0107\n",
      "epoch:249,loss:0.0189\n",
      "epoch:249,loss:0.0263\n",
      "epoch:249,loss:0.0298\n",
      "epoch:249,loss:0.2100\n",
      "epoch:249,loss:0.0126\n",
      "epoch:249,loss:0.0126\n",
      "epoch:249,loss:0.0982\n",
      "epoch:249,loss:0.0063\n",
      "epoch:249,loss:0.0078\n",
      "epoch:249,loss:0.0055\n",
      "epoch:249,loss:0.0771\n",
      "epoch:249,loss:0.0448\n",
      "epoch:249,loss:0.1718\n",
      "epoch:249,loss:0.4298\n",
      "epoch:249,loss:0.1393\n",
      "epoch:249,loss:0.1874\n",
      "epoch:249,loss:0.0189\n",
      "epoch:249,loss:0.0019\n",
      "epoch:249,loss:0.0008\n",
      "epoch:249,loss:0.1162\n",
      "epoch:249,loss:0.0368\n",
      "epoch:249,loss:0.0065\n",
      "epoch:249,loss:0.0585\n",
      "epoch:249,loss:0.0151\n",
      "epoch:249,loss:0.0057\n",
      "epoch:249,loss:0.1973\n",
      "epoch:249,loss:0.0185\n",
      "epoch:249,loss:0.0329\n",
      "epoch:249,loss:0.5411\n",
      "epoch:249,loss:0.2545\n",
      "epoch:249,loss:0.0261\n",
      "epoch:249,loss:0.0849\n",
      "epoch:249,loss:0.1491\n",
      "============================================\n",
      "第249个epoch的识别准确率为：95%\n",
      "epoch:250,loss:0.0083\n",
      "epoch:250,loss:0.0078\n",
      "epoch:250,loss:0.3313\n",
      "epoch:250,loss:0.0298\n",
      "epoch:250,loss:0.0041\n",
      "epoch:250,loss:0.0367\n",
      "epoch:250,loss:0.0302\n",
      "epoch:250,loss:0.0504\n",
      "epoch:250,loss:0.3558\n",
      "epoch:250,loss:0.0158\n",
      "epoch:250,loss:0.2334\n",
      "epoch:250,loss:0.3836\n",
      "epoch:250,loss:0.3409\n",
      "epoch:250,loss:0.1817\n",
      "epoch:250,loss:0.3935\n",
      "epoch:250,loss:0.0214\n",
      "epoch:250,loss:0.0298\n",
      "epoch:250,loss:0.4250\n",
      "epoch:250,loss:0.0261\n",
      "epoch:250,loss:1.4005\n",
      "epoch:250,loss:0.0358\n",
      "epoch:250,loss:0.0698\n",
      "epoch:250,loss:0.0100\n",
      "epoch:250,loss:0.0756\n",
      "epoch:250,loss:0.0610\n",
      "epoch:250,loss:0.0052\n",
      "epoch:250,loss:0.0405\n",
      "epoch:250,loss:0.0098\n",
      "epoch:250,loss:0.0617\n",
      "epoch:250,loss:0.0941\n",
      "epoch:250,loss:0.0761\n",
      "epoch:250,loss:0.1833\n",
      "epoch:250,loss:0.0022\n",
      "epoch:250,loss:0.0149\n",
      "epoch:250,loss:0.0061\n",
      "epoch:250,loss:0.2157\n",
      "epoch:250,loss:0.0590\n",
      "epoch:250,loss:0.0743\n",
      "epoch:250,loss:0.1352\n",
      "epoch:250,loss:0.0272\n",
      "epoch:250,loss:0.0434\n",
      "epoch:250,loss:0.0422\n",
      "epoch:250,loss:0.2226\n",
      "epoch:250,loss:0.0366\n",
      "epoch:250,loss:0.4467\n",
      "epoch:250,loss:0.0163\n",
      "epoch:250,loss:0.8810\n",
      "epoch:250,loss:0.0346\n",
      "epoch:250,loss:0.4765\n",
      "epoch:250,loss:0.0058\n",
      "epoch:250,loss:0.0206\n",
      "epoch:250,loss:0.0337\n",
      "epoch:250,loss:0.0072\n",
      "epoch:250,loss:0.0368\n",
      "epoch:250,loss:0.1222\n",
      "epoch:250,loss:0.0143\n",
      "epoch:250,loss:0.1772\n",
      "epoch:250,loss:0.1890\n",
      "epoch:250,loss:0.0038\n",
      "epoch:250,loss:0.0055\n",
      "============================================\n",
      "第250个epoch的识别准确率为：96%\n",
      "训练完毕，权重已保存为：weights/mobilenetv2_Q_past.pt\n"
     ]
    }
   ],
   "source": [
    "# ============================ step 5/5 训练 ============================\n",
    "# 记录每一次的数据，方便绘图\n",
    "train_curve=list()\n",
    "valid_curve=list()\n",
    "net.train()\n",
    "accurancy_global=0.0\n",
    "\n",
    "for epoch in range(MAX_EPOCH):\n",
    "    loss_mean=0.\n",
    "    correct=0.\n",
    "    total=0.\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i,data in enumerate(train_loader):\n",
    "        img,label=data\n",
    "        img = Variable(img)\n",
    "        label = Variable(label)\n",
    "        if torch.cuda.is_available():\n",
    "            img=img.cuda()\n",
    "            label=label.cuda()\n",
    "            \n",
    "        # 前向传播\n",
    "        out=net(img)\n",
    "        optimizer.zero_grad()  # 归0梯度\n",
    "        loss=criterion(out,label)#得到损失函数\n",
    "\n",
    "        print_loss=loss.data.item()\n",
    "\n",
    "        loss.backward()#反向传播\n",
    "        optimizer.step()#优化\n",
    "        if (i+1)%log_interval==0:\n",
    "            print('epoch:{},loss:{:.4f}'.format(epoch+1,loss.data.item()))\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        total += label.size(0)\n",
    "\n",
    "        correct += (predicted == label).sum()\n",
    "    print(\"============================================\")\n",
    "    accurancy=correct / total\n",
    "    if accurancy>accurancy_global:\n",
    "        torch.save(net.state_dict(), './weights/mobilenetv2_Q_best.pt')\n",
    "        print(\"准确率由：\", accurancy_global, \"上升至：\", accurancy, \"已更新并保存权值为weights/mobilenetv2_Q_best.pt\")\n",
    "        accurancy_global=accurancy\n",
    "    print('第%d个epoch的识别准确率为：%d%%' % (epoch + 1, 100*accurancy))\n",
    "\n",
    "torch.save(net.state_dict(), './weights/mobilenetv2_Q_past.pt')\n",
    "print(\"训练完毕，权重已保存为：weights/mobilenetv2_Q_past.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "polyphonic-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "split_dir=os.path.join(\".\",\"data\",\"splitData\")\n",
    "test_dir=os.path.join(split_dir,\"test\")\n",
    "# test_dir = os.path.join(\".\", \"data\", \"rawData\")\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_data = flowerDataset(data_dir=test_dir, transform=test_transform)\n",
    "test_dataLoader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "liquid-digit",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: tensor([15, 15, 15])\n",
      "predict: tensor([ 4, 10, 15])\n",
      "label: tensor([15, 15, 15])\n",
      "predict: tensor([15, 15, 15])\n",
      "label: tensor([15, 15,  9])\n",
      "predict: tensor([10, 15,  9])\n",
      "label: tensor([9, 9, 9])\n",
      "predict: tensor([ 9,  9, 12])\n",
      "label: tensor([9, 9, 9])\n",
      "predict: tensor([9, 9, 9])\n",
      "label: tensor([9, 2, 2])\n",
      "predict: tensor([2, 2, 2])\n",
      "label: tensor([2, 2, 2])\n",
      "predict: tensor([ 2, 15,  2])\n",
      "label: tensor([2, 2, 2])\n",
      "predict: tensor([2, 2, 2])\n",
      "label: tensor([4, 4, 4])\n",
      "predict: tensor([16,  5,  4])\n",
      "label: tensor([4, 4, 4])\n",
      "predict: tensor([2, 4, 1])\n",
      "label: tensor([4, 4, 0])\n",
      "predict: tensor([4, 1, 0])\n",
      "label: tensor([0, 0, 0])\n",
      "predict: tensor([0, 0, 0])\n",
      "label: tensor([0, 0, 0])\n",
      "predict: tensor([ 0, 11,  0])\n",
      "label: tensor([ 0, 11, 11])\n",
      "predict: tensor([ 0, 12, 12])\n",
      "label: tensor([11, 11, 11])\n",
      "predict: tensor([11, 11, 11])\n",
      "label: tensor([11, 11, 11])\n",
      "predict: tensor([14, 12, 11])\n",
      "label: tensor([8, 8, 8])\n",
      "predict: tensor([8, 8, 8])\n",
      "label: tensor([8, 8, 8])\n",
      "predict: tensor([8, 6, 6])\n",
      "label: tensor([8, 8, 3])\n",
      "predict: tensor([1, 6, 2])\n",
      "label: tensor([3, 3, 3])\n",
      "predict: tensor([3, 3, 5])\n",
      "label: tensor([3, 3, 3])\n",
      "predict: tensor([3, 3, 4])\n",
      "label: tensor([ 3, 13, 13])\n",
      "predict: tensor([ 5, 13, 13])\n",
      "label: tensor([13, 13, 13])\n",
      "predict: tensor([13,  7, 13])\n",
      "label: tensor([13, 13, 13])\n",
      "predict: tensor([13, 11,  7])\n",
      "label: tensor([5, 5, 5])\n",
      "predict: tensor([11,  5,  5])\n",
      "label: tensor([5, 5, 5])\n",
      "predict: tensor([ 5, 15,  5])\n",
      "label: tensor([ 5,  5, 16])\n",
      "predict: tensor([ 5, 14, 15])\n",
      "label: tensor([16, 16, 16])\n",
      "predict: tensor([16,  2,  3])\n",
      "label: tensor([16, 16, 16])\n",
      "predict: tensor([16,  0, 16])\n",
      "label: tensor([16,  1,  1])\n",
      "predict: tensor([16,  1,  1])\n",
      "label: tensor([1, 1, 1])\n",
      "predict: tensor([ 1,  1, 15])\n",
      "label: tensor([1, 1, 1])\n",
      "predict: tensor([2, 2, 1])\n",
      "label: tensor([7, 7, 7])\n",
      "predict: tensor([ 3, 13,  7])\n",
      "label: tensor([7, 7, 7])\n",
      "predict: tensor([7, 0, 2])\n",
      "label: tensor([ 7,  7, 14])\n",
      "predict: tensor([ 2, 12,  7])\n",
      "label: tensor([14, 14, 14])\n",
      "predict: tensor([14, 14, 13])\n",
      "label: tensor([14, 14, 14])\n",
      "predict: tensor([14,  0,  0])\n",
      "label: tensor([14, 12, 12])\n",
      "predict: tensor([14, 12,  0])\n",
      "label: tensor([12, 12, 12])\n",
      "predict: tensor([ 0, 12,  7])\n",
      "label: tensor([12, 12, 12])\n",
      "predict: tensor([12,  7, 12])\n",
      "label: tensor([6, 6, 6])\n",
      "predict: tensor([6, 6, 6])\n",
      "label: tensor([6, 6, 6])\n",
      "predict: tensor([6, 6, 6])\n",
      "label: tensor([ 6,  6, 10])\n",
      "predict: tensor([ 6,  8, 10])\n",
      "label: tensor([10, 10, 10])\n",
      "predict: tensor([10, 15, 10])\n",
      "label: tensor([10, 10, 10])\n",
      "predict: tensor([10, 10, 10])\n",
      "label: tensor([10])\n",
      "predict: tensor([10])\n",
      "Total: 136.0\n",
      "Accuracy:61.02941131591797%\n"
     ]
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(\"./weights/mobilenetv2_Q_best.pt\"))\n",
    "net.eval()\n",
    "correct = 0.\n",
    "total=0.\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_dataLoader):\n",
    "        img, label = data\n",
    "        img = Variable(img)\n",
    "        label = Variable(label)\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        print(\"label:\", label)\n",
    "        output = net(img)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        print(\"predict:\", predicted)\n",
    "        total += label.size(0)\n",
    "        correct += (predicted == label).sum()\n",
    "\n",
    "acc = correct/total * 100.\n",
    "print(\"Total:\", total)\n",
    "print(\"Accuracy:{}%\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-coffee",
   "metadata": {},
   "source": [
    "### export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "collectible-beginning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_config(model, in_shape):\n",
    "    feature_map_shape = in_shape\n",
    "    print(in_shape)\n",
    "    dic = {}\n",
    "    conv_cnt = 0\n",
    "    pool_cnt = 0\n",
    "    linear_cnt = 0\n",
    "    # cnt = 0\n",
    "    for sub_module in model.modules():\n",
    "        if type(sub_module).__base__ is torch.nn.Conv2d:\n",
    "            conv_cur = {}\n",
    "            conv_cur['in_shape'] = feature_map_shape[:]         \n",
    "            feature_map_shape[0] = sub_module.out_channels\n",
    "            feature_map_shape[1] = (feature_map_shape[1] + 2 * sub_module.padding[0] - sub_module.kernel_size[0]) // sub_module.stride[0] + 1\n",
    "            feature_map_shape[2] = (feature_map_shape[2] + 2 * sub_module.padding[0] - sub_module.kernel_size[0]) // sub_module.stride[0] + 1\n",
    "            conv_cur['out_shape'] = feature_map_shape[:]\n",
    "            conv_cur['k'] = sub_module.kernel_size[0]\n",
    "            conv_cur['s'] = sub_module.stride[0]\n",
    "            conv_cur['p'] = sub_module.padding[0]\n",
    "            \n",
    "            dic['conv_' + str(conv_cnt)] = conv_cur\n",
    "            \n",
    "            conv_cnt = conv_cnt + 1\n",
    "            # cnt = cnt + 1\n",
    "\n",
    "        elif type(sub_module) is torch.nn.MaxPool2d:\n",
    "            pool_cur = {}\n",
    "            pool_cur['in_shape'] = feature_map_shape[:]\n",
    "            pool_cur['p'] =  sub_module.kernel_size\n",
    "\n",
    "            feature_map_shape[1] = feature_map_shape[1] // sub_module.kernel_size\n",
    "            feature_map_shape[2] = feature_map_shape[2] // sub_module.kernel_size\n",
    "\n",
    "            pool_cur['out_shape'] = feature_map_shape[:]\n",
    "\n",
    "            dic['pool_' + str(pool_cnt)] = pool_cur\n",
    "\n",
    "            pool_cnt = pool_cnt + 1\n",
    "            # cnt = cnt + 1\n",
    "        elif type(sub_module) is torch.nn.Linear:\n",
    "            linear_cur = {}\n",
    "            linear_cur['in_len'] = sub_module.in_features\n",
    "            linear_cur['out_len'] = sub_module.out_features\n",
    "\n",
    "            dic['linear_' + str(linear_cnt)] = linear_cur\n",
    "            linear_cnt = linear_cnt + 1\n",
    "            # cnt = cnt + 1\n",
    "    \n",
    "    return dic\n",
    "    \n",
    "\n",
    "def generate_params(model):\n",
    "    dic = {}\n",
    "    cnt = 0\n",
    "    for sub_module in model.modules():\n",
    "        if type(sub_module).__base__ is torch.nn.Conv2d:\n",
    "            w = sub_module.weight.detach().numpy()\n",
    "            dic['arr_' + str(cnt)] = w\n",
    "            cnt = cnt + 1\n",
    "            if sub_module.bias is not None:\n",
    "                w = sub_module.bias.detach().numpy()\n",
    "                dic['arr_' + str(cnt)] = w\n",
    "                cnt = cnt + 1\n",
    "        elif type(sub_module) is torch.nn.Linear:\n",
    "            w = sub_module.weight.detach().numpy()\n",
    "            dic['arr_' + str(cnt)] = w\n",
    "            cnt = cnt + 1\n",
    "        elif type(sub_module) is torch.nn.BatchNorm2d or type(sub_module) is torch.nn.BatchNorm1d:\n",
    "            gamma = sub_module.weight.detach().numpy()\n",
    "            dic['arr_' + str(cnt)] = gamma\n",
    "            cnt = cnt + 1\n",
    "            beta = sub_module.bias.detach().numpy()\n",
    "            dic['arr_' + str(cnt)] = beta\n",
    "            cnt = cnt + 1\n",
    "            mean = sub_module.running_mean.numpy()\n",
    "            dic['arr_' + str(cnt)] = mean\n",
    "            cnt = cnt + 1\n",
    "            var = sub_module.running_var.numpy()\n",
    "            dic['arr_' + str(cnt)] = var\n",
    "            cnt = cnt + 1\n",
    "            eps = sub_module.eps\n",
    "            dic['arr_' + str(cnt)] = eps\n",
    "            cnt = cnt + 1\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "celtic-yellow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2_Q(\n",
      "  (features): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d_Q(\n",
      "        3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "        (quantize_fn): weight_quantize_fn()\n",
      "      )\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): activation_quantize_fn()\n",
      "    )\n",
      "    (1): InvertedResidual_Q(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d_Q(\n",
      "          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): activation_quantize_fn()\n",
      "        (3): Conv2d_Q(\n",
      "          32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual_Q(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d_Q(\n",
      "          16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): activation_quantize_fn()\n",
      "        (3): Conv2d_Q(\n",
      "          96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): activation_quantize_fn()\n",
      "        (6): Conv2d_Q(\n",
      "          96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual_Q(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d_Q(\n",
      "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): activation_quantize_fn()\n",
      "        (3): Conv2d_Q(\n",
      "          144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): activation_quantize_fn()\n",
      "        (6): Conv2d_Q(\n",
      "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual_Q(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d_Q(\n",
      "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): activation_quantize_fn()\n",
      "        (3): Conv2d_Q(\n",
      "          144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): activation_quantize_fn()\n",
      "        (6): Conv2d_Q(\n",
      "          144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual_Q(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d_Q(\n",
      "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): activation_quantize_fn()\n",
      "        (3): Conv2d_Q(\n",
      "          192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): activation_quantize_fn()\n",
      "        (6): Conv2d_Q(\n",
      "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual_Q(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d_Q(\n",
      "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): activation_quantize_fn()\n",
      "        (3): Conv2d_Q(\n",
      "          192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): activation_quantize_fn()\n",
      "        (6): Conv2d_Q(\n",
      "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual_Q(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d_Q(\n",
      "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): activation_quantize_fn()\n",
      "        (3): Conv2d_Q(\n",
      "          192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): activation_quantize_fn()\n",
      "        (6): Conv2d_Q(\n",
      "          192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual_Q(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d_Q(\n",
      "          64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): activation_quantize_fn()\n",
      "        (3): Conv2d_Q(\n",
      "          384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): activation_quantize_fn()\n",
      "        (6): Conv2d_Q(\n",
      "          384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual_Q(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d_Q(\n",
      "          64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): activation_quantize_fn()\n",
      "        (3): Conv2d_Q(\n",
      "          384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): activation_quantize_fn()\n",
      "        (6): Conv2d_Q(\n",
      "          384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual_Q(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d_Q(\n",
      "          64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): activation_quantize_fn()\n",
      "        (3): Conv2d_Q(\n",
      "          384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): activation_quantize_fn()\n",
      "        (6): Conv2d_Q(\n",
      "          384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual_Q(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d_Q(\n",
      "          64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): activation_quantize_fn()\n",
      "        (3): Conv2d_Q(\n",
      "          384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): activation_quantize_fn()\n",
      "        (6): Conv2d_Q(\n",
      "          384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual_Q(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d_Q(\n",
      "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): activation_quantize_fn()\n",
      "        (3): Conv2d_Q(\n",
      "          576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): activation_quantize_fn()\n",
      "        (6): Conv2d_Q(\n",
      "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual_Q(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d_Q(\n",
      "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): activation_quantize_fn()\n",
      "        (3): Conv2d_Q(\n",
      "          576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): activation_quantize_fn()\n",
      "        (6): Conv2d_Q(\n",
      "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual_Q(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d_Q(\n",
      "          96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): activation_quantize_fn()\n",
      "        (3): Conv2d_Q(\n",
      "          576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): activation_quantize_fn()\n",
      "        (6): Conv2d_Q(\n",
      "          576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual_Q(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d_Q(\n",
      "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): activation_quantize_fn()\n",
      "        (3): Conv2d_Q(\n",
      "          960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): activation_quantize_fn()\n",
      "        (6): Conv2d_Q(\n",
      "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual_Q(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d_Q(\n",
      "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): activation_quantize_fn()\n",
      "        (3): Conv2d_Q(\n",
      "          960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): activation_quantize_fn()\n",
      "        (6): Conv2d_Q(\n",
      "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual_Q(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d_Q(\n",
      "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): activation_quantize_fn()\n",
      "        (3): Conv2d_Q(\n",
      "          960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): activation_quantize_fn()\n",
      "        (6): Conv2d_Q(\n",
      "          960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_fn): weight_quantize_fn()\n",
      "        )\n",
      "        (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d_Q(\n",
      "      320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (quantize_fn): weight_quantize_fn()\n",
      "    )\n",
      "    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): activation_quantize_fn()\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (classifier): Linear(in_features=1280, out_features=17, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MobileNetV2_Q(num_classes=17, width_mult=1.)\n",
    "model.load_state_dict(torch.load(\"./weights/mobilenetv2_Q_best.pt\"))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "collect-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = generate_params(model)\n",
    "np.savez('mobilenetv2_Q_4w4a.npz', **dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "conditional-specialist",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 224, 224]\n",
      "{'conv_0': {'in_shape': [3, 224, 224], 'out_shape': [32, 112, 112], 'k': 3, 's': 2, 'p': 1}, 'conv_1': {'in_shape': [32, 112, 112], 'out_shape': [32, 112, 112], 'k': 3, 's': 1, 'p': 1}, 'conv_2': {'in_shape': [32, 112, 112], 'out_shape': [16, 112, 112], 'k': 1, 's': 1, 'p': 0}, 'conv_3': {'in_shape': [16, 112, 112], 'out_shape': [96, 112, 112], 'k': 1, 's': 1, 'p': 0}, 'conv_4': {'in_shape': [96, 112, 112], 'out_shape': [96, 56, 56], 'k': 3, 's': 2, 'p': 1}, 'conv_5': {'in_shape': [96, 56, 56], 'out_shape': [24, 56, 56], 'k': 1, 's': 1, 'p': 0}, 'conv_6': {'in_shape': [24, 56, 56], 'out_shape': [144, 56, 56], 'k': 1, 's': 1, 'p': 0}, 'conv_7': {'in_shape': [144, 56, 56], 'out_shape': [144, 56, 56], 'k': 3, 's': 1, 'p': 1}, 'conv_8': {'in_shape': [144, 56, 56], 'out_shape': [24, 56, 56], 'k': 1, 's': 1, 'p': 0}, 'conv_9': {'in_shape': [24, 56, 56], 'out_shape': [144, 56, 56], 'k': 1, 's': 1, 'p': 0}, 'conv_10': {'in_shape': [144, 56, 56], 'out_shape': [144, 28, 28], 'k': 3, 's': 2, 'p': 1}, 'conv_11': {'in_shape': [144, 28, 28], 'out_shape': [32, 28, 28], 'k': 1, 's': 1, 'p': 0}, 'conv_12': {'in_shape': [32, 28, 28], 'out_shape': [192, 28, 28], 'k': 1, 's': 1, 'p': 0}, 'conv_13': {'in_shape': [192, 28, 28], 'out_shape': [192, 28, 28], 'k': 3, 's': 1, 'p': 1}, 'conv_14': {'in_shape': [192, 28, 28], 'out_shape': [32, 28, 28], 'k': 1, 's': 1, 'p': 0}, 'conv_15': {'in_shape': [32, 28, 28], 'out_shape': [192, 28, 28], 'k': 1, 's': 1, 'p': 0}, 'conv_16': {'in_shape': [192, 28, 28], 'out_shape': [192, 28, 28], 'k': 3, 's': 1, 'p': 1}, 'conv_17': {'in_shape': [192, 28, 28], 'out_shape': [32, 28, 28], 'k': 1, 's': 1, 'p': 0}, 'conv_18': {'in_shape': [32, 28, 28], 'out_shape': [192, 28, 28], 'k': 1, 's': 1, 'p': 0}, 'conv_19': {'in_shape': [192, 28, 28], 'out_shape': [192, 14, 14], 'k': 3, 's': 2, 'p': 1}, 'conv_20': {'in_shape': [192, 14, 14], 'out_shape': [64, 14, 14], 'k': 1, 's': 1, 'p': 0}, 'conv_21': {'in_shape': [64, 14, 14], 'out_shape': [384, 14, 14], 'k': 1, 's': 1, 'p': 0}, 'conv_22': {'in_shape': [384, 14, 14], 'out_shape': [384, 14, 14], 'k': 3, 's': 1, 'p': 1}, 'conv_23': {'in_shape': [384, 14, 14], 'out_shape': [64, 14, 14], 'k': 1, 's': 1, 'p': 0}, 'conv_24': {'in_shape': [64, 14, 14], 'out_shape': [384, 14, 14], 'k': 1, 's': 1, 'p': 0}, 'conv_25': {'in_shape': [384, 14, 14], 'out_shape': [384, 14, 14], 'k': 3, 's': 1, 'p': 1}, 'conv_26': {'in_shape': [384, 14, 14], 'out_shape': [64, 14, 14], 'k': 1, 's': 1, 'p': 0}, 'conv_27': {'in_shape': [64, 14, 14], 'out_shape': [384, 14, 14], 'k': 1, 's': 1, 'p': 0}, 'conv_28': {'in_shape': [384, 14, 14], 'out_shape': [384, 14, 14], 'k': 3, 's': 1, 'p': 1}, 'conv_29': {'in_shape': [384, 14, 14], 'out_shape': [64, 14, 14], 'k': 1, 's': 1, 'p': 0}, 'conv_30': {'in_shape': [64, 14, 14], 'out_shape': [384, 14, 14], 'k': 1, 's': 1, 'p': 0}, 'conv_31': {'in_shape': [384, 14, 14], 'out_shape': [384, 14, 14], 'k': 3, 's': 1, 'p': 1}, 'conv_32': {'in_shape': [384, 14, 14], 'out_shape': [96, 14, 14], 'k': 1, 's': 1, 'p': 0}, 'conv_33': {'in_shape': [96, 14, 14], 'out_shape': [576, 14, 14], 'k': 1, 's': 1, 'p': 0}, 'conv_34': {'in_shape': [576, 14, 14], 'out_shape': [576, 14, 14], 'k': 3, 's': 1, 'p': 1}, 'conv_35': {'in_shape': [576, 14, 14], 'out_shape': [96, 14, 14], 'k': 1, 's': 1, 'p': 0}, 'conv_36': {'in_shape': [96, 14, 14], 'out_shape': [576, 14, 14], 'k': 1, 's': 1, 'p': 0}, 'conv_37': {'in_shape': [576, 14, 14], 'out_shape': [576, 14, 14], 'k': 3, 's': 1, 'p': 1}, 'conv_38': {'in_shape': [576, 14, 14], 'out_shape': [96, 14, 14], 'k': 1, 's': 1, 'p': 0}, 'conv_39': {'in_shape': [96, 14, 14], 'out_shape': [576, 14, 14], 'k': 1, 's': 1, 'p': 0}, 'conv_40': {'in_shape': [576, 14, 14], 'out_shape': [576, 7, 7], 'k': 3, 's': 2, 'p': 1}, 'conv_41': {'in_shape': [576, 7, 7], 'out_shape': [160, 7, 7], 'k': 1, 's': 1, 'p': 0}, 'conv_42': {'in_shape': [160, 7, 7], 'out_shape': [960, 7, 7], 'k': 1, 's': 1, 'p': 0}, 'conv_43': {'in_shape': [960, 7, 7], 'out_shape': [960, 7, 7], 'k': 3, 's': 1, 'p': 1}, 'conv_44': {'in_shape': [960, 7, 7], 'out_shape': [160, 7, 7], 'k': 1, 's': 1, 'p': 0}, 'conv_45': {'in_shape': [160, 7, 7], 'out_shape': [960, 7, 7], 'k': 1, 's': 1, 'p': 0}, 'conv_46': {'in_shape': [960, 7, 7], 'out_shape': [960, 7, 7], 'k': 3, 's': 1, 'p': 1}, 'conv_47': {'in_shape': [960, 7, 7], 'out_shape': [160, 7, 7], 'k': 1, 's': 1, 'p': 0}, 'conv_48': {'in_shape': [160, 7, 7], 'out_shape': [960, 7, 7], 'k': 1, 's': 1, 'p': 0}, 'conv_49': {'in_shape': [960, 7, 7], 'out_shape': [960, 7, 7], 'k': 3, 's': 1, 'p': 1}, 'conv_50': {'in_shape': [960, 7, 7], 'out_shape': [320, 7, 7], 'k': 1, 's': 1, 'p': 0}, 'conv_51': {'in_shape': [320, 7, 7], 'out_shape': [1280, 7, 7], 'k': 1, 's': 1, 'p': 0}, 'linear_0': {'in_len': 1280, 'out_len': 17}}\n"
     ]
    }
   ],
   "source": [
    "dic = generate_config(model, [3, 224, 224])\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "supposed-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#indent参数根据数据格式缩进显示，读起来更加清晰, indent的值，代表缩进空格式\n",
    "json_str = json.dumps(dic, indent=4)\n",
    "with open('config.json', 'w') as json_file:\n",
    "    json_file.write(json_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-characteristic",
   "metadata": {},
   "source": [
    "#### read param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "authentic-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Quantization import quantization\n",
    "\n",
    "# 读出参数\n",
    "# 然后根据量化规则将其处理量化为指定位宽\n",
    "# 使用int32类型储存\n",
    "class QNNParamReader:\n",
    "    def __init__(self, paramFile):\n",
    "        self.param_dict = np.load(paramFile)\n",
    "        self.current_param_cnt = 0\n",
    "    \n",
    "    def get_last(self):\n",
    "        ret = self.param_dict[\"arr_\" + str(self.current_param_cnt)]\n",
    "        # self.current_param_cnt += 1\n",
    "        return ret\n",
    "\n",
    "    def __get_current(self):\n",
    "        ret = self.param_dict[\"arr_\" + str(self.current_param_cnt)]\n",
    "        self.current_param_cnt += 1\n",
    "        return ret\n",
    "\n",
    "    def read_conv_raw(self):\n",
    "        w = self.__get_current()\n",
    "        return w\n",
    "\n",
    "    def read_linear_raw(self):\n",
    "        w = self.__get_current()\n",
    "        return w\n",
    "\n",
    "    def read_batch_norm_raw(self):\n",
    "        gamma = self.__get_current()\n",
    "        beta = self.__get_current()\n",
    "        mean = self.__get_current()\n",
    "        var = self.__get_current()\n",
    "        eps = self.__get_current()\n",
    "        return (gamma, beta, mean, var, eps)\n",
    "\n",
    "    # 读量化后卷积层参数\n",
    "    # 量化后用 int32 表示每个数据\n",
    "    # 默认将卷积层位宽参数量化到2个bit\n",
    "    # 符号位占用一个bit\n",
    "    def read_qconv_weight(self, w_bit=2):\n",
    "        w = self.read_conv_raw()\n",
    "        # 执行 w 量化\n",
    "        qw = quantization.weight_quantize_int(w, w_bit)\n",
    "        return qw\n",
    "\n",
    "    # 读量化后的全连接层的参数\n",
    "    # 量化后用 int32 表示每个数据 实际有效的只有 w_bit\n",
    "    # 符号位占用一个 bit\n",
    "    def read_qlinear_weight(self, w_bit=2):\n",
    "        w = self.read_linear_raw()\n",
    "        qw = quantization.weight_quantize_int(w, w_bit)\n",
    "        return qw\n",
    "\n",
    "    # 读取量化后的 bn 层参数\n",
    "    # 将bn层和act层放在一起处理，量化后其可以用一个等差数列表示\n",
    "    # 其中inc表示公差， bias表示初始值\n",
    "    def read_qbarch_norm_act_param(self, w_bit=2, in_bit=4, out_bit=4, l_shift=4):\n",
    "        gamma, beta, mean, var, eps = self.read_batch_norm_raw()\n",
    "        qinc, qbias = quantization.bn_act_quantize_int(gamma, beta, mean, var, eps, w_bit=w_bit, in_bit=in_bit, out_bit=out_bit, l_shift=l_shift)\n",
    "        return qinc, qbias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "numerous-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数组中元素拼接组合\n",
    "# 例如 输入 [1, 1, 1] elem_bit = 1, 返回 111\n",
    "# 返回值是 int 类型 其程度可能超过 64位\n",
    "def array_to_string(array, elem_bit):\n",
    "        val = 0\t\n",
    "        #for i in range(len(array)-1, -1, -1):\n",
    "        for i in range(len(array)):\n",
    "            tmp = array[i]\n",
    "            tmp2 = tmp\n",
    "\n",
    "            if tmp < 0:\n",
    "                tmp2 = 2**(elem_bit) + tmp \n",
    "\n",
    "            tmp2 = int(tmp2)\n",
    "            tmp3 = tmp2 * 2**(elem_bit*i)\n",
    "            val = val + tmp3\n",
    "        return val\n",
    "\n",
    "# 处理一层的参数\n",
    "#  处理得到 转化后的w矩阵和 bn的inc，bias\n",
    "# w矩阵为二维矩阵，row为输出通道数\n",
    "# 相对于原始w张量，其内存排列顺序转换为 out_ch, row, col, in_ch\n",
    "# class ParamProcess:\n",
    "#     def __init__(self, w, inc, bias, w_bit, in_bit, out_bit, l_shift):\n",
    "#         # self.qnn_read = QNNParamReader(file_name)\n",
    "#         self.w = w\n",
    "#         self.inc = inc\n",
    "#         self.bias = bias\n",
    "#         self.w_bit = w_bit\n",
    "#         self.in_bit = in_bit\n",
    "#         self.out_bit = out_bit\n",
    "#         self.l_shift = l_shift\n",
    "\n",
    "#     def conv_process(self):\n",
    "#         # con_w 是一个4维张量\n",
    "#         # 将输入通道维度放到最后\n",
    "#         con_w = self.w\n",
    "#         con_w.transpose(0, 2, 3, 1)\n",
    "#         # 处理为二维矩阵\n",
    "#         con_w = con_w.reshape(con_w.shape[0], -1)\n",
    "\n",
    "#         # qinc, qbias 当前不需要处理\n",
    "#         return con_w, self.inc, self.bias\n",
    "    \n",
    "#     def linear_process(self, w_bit, in_bit, out_bit, l_shift):\n",
    "#         # linear_w0 是一个二维矩阵不需要处理\n",
    "#         linear_w0 = self.qnn_read.read_qlinear_weight(w_bit)\n",
    "#         linear_bn0_inc, linear_bn0_bias = self.qnn_read.read_qbarch_norm_act_param(w_bit, in_bit, out_bit, l_shift)\n",
    "\n",
    "#         return linear_w0, linear_bn0_inc, linear_bn0_bias\n",
    "\n",
    "#     def last_linear_process(self, w_bit):\n",
    "#         # 全连接层\n",
    "#         linear_w0 = self.qnn_read.read_qlinear_weight(w_bit=2)\n",
    "#         return linear_w0\n",
    "\n",
    "# 处理一层参数\n",
    "# 这里的一层指的是 将conv 与 bn act 合并为一层\n",
    "# 将参数整理成满足 硬件设计需求的形式\n",
    "class QNNLayerMemProcess:\n",
    "    # 处理 中间层用\n",
    "    def __init__(self, name, reader, config, w_bit, in_bit, out_bit, l_shift, pe, simd, conv_linear=False):\n",
    "        \n",
    "        self.name = name\n",
    "        self.reader = reader\n",
    "        self.w_bit = w_bit\n",
    "        self.in_bit = in_bit\n",
    "        self.out_bit = out_bit\n",
    "        self.l_shift = l_shift\n",
    "        self.pe = pe\n",
    "        self.simd = simd\n",
    "        self.config = config[name] \n",
    "        self.conv_linear = conv_linear\n",
    "    \n",
    "    # 将矩阵整理成所需要的储存样式\n",
    "    # 转化位 pe * tiles 矩阵\n",
    "    def w_to_hls_array(self, w):\n",
    "        # print(\"w shape :\", w.shape)\n",
    "        assert w.shape[0] % self.pe == 0, 'out_ch mod pe must 0'\n",
    "        # w 矩阵的宽 其值 为 k * k * in_ch\n",
    "        h = w.shape[1]\n",
    "        # res0 size = out_ch, k * k * in_ch // simd + (0 or 1)\n",
    "        res0 = [[0 for i in range(h // self.simd)] for j in range(w.shape[0])]\n",
    "        for out_ch in range(w.shape[0]):\n",
    "            for i in range(h // self.simd):\n",
    "                arr = w[out_ch][i*self.simd:(i+1)*self.simd]\n",
    "                res0[out_ch][i] = array_to_string(arr, self.w_bit)\n",
    "            \n",
    "        # 处理不够整除的部分\n",
    "        if h % self.simd != 0:\n",
    "            print('h mod simd != 0')\n",
    "            for out_ch in range(w.shape[0]):\n",
    "                arr = w[out_ch][h // self.simd * self.simd:]\n",
    "                res0[out_ch].append(array_to_string(arr, self.w_bit))\n",
    "\n",
    "        # print('res0 = ', len(res0), len(res0[0]))\n",
    "        # print(np.array(res0))\n",
    "        \n",
    "        tiles = len(res0[0]) * (len(res0) // self.pe) \n",
    "        self.w_tiles = tiles\n",
    "        # print('tiles', tiles)\n",
    "        res = [[0 for i in range(tiles)] for i in range(self.pe)]\n",
    "\n",
    "        tiles_cnt = 0\n",
    "        for i in range(len(res0) // self.pe):\n",
    "            for j in range(len(res0[0])):\n",
    "\n",
    "                for pe_cnt in range(self.pe):\n",
    "                    res[pe_cnt][tiles_cnt] = res0[i * self.pe + pe_cnt][j]\n",
    "                tiles_cnt += 1  \n",
    "        return res\n",
    "\n",
    "    # 处理 inc 和 bias\n",
    "    def inc_bias_to_hls_array(self, inc, bias):\n",
    "        inc = inc.reshape(-1, self.pe)\n",
    "        inc = inc.T\n",
    "        bias = bias.reshape(-1, self.pe)\n",
    "        bias = bias.T\n",
    "        self.a_tiles = inc.shape[1]\n",
    "        \n",
    "        return inc, bias\n",
    "    \n",
    "    # 卷积参数整理\n",
    "    # 返回的w因为元素可能大于64位 所以用list储存\n",
    "    # inc, bias 是numpy.array类型\n",
    "    def conv(self):\n",
    "        w = self.reader.read_qconv_weight(self.w_bit)\n",
    "        inc, bias = self.reader.read_qbarch_norm_act_param(w_bit=self.w_bit, in_bit=self.in_bit, out_bit=self.out_bit, l_shift=self.l_shift)\n",
    "        # w 是二维矩阵形式\n",
    "        con_w = w.transpose(0, 2, 3, 1)\n",
    "        # 处理为二维矩阵\n",
    "        con_w = con_w.reshape(con_w.shape[0], -1)\n",
    "        # print(w)\n",
    "        # 先把 w 处理为每个元素位宽都是 simd * w_bit 形式\n",
    "        con_w = self.w_to_hls_array(con_w)\n",
    "\n",
    "        inc, bias = self.inc_bias_to_hls_array(inc, bias)\n",
    "\n",
    "        self.hls_w = con_w\n",
    "        self.hls_inc = inc\n",
    "        self.hls_bias = bias\n",
    "\n",
    "        self.inc_bit_width = self.get_inc_bit_width(inc)\n",
    "        self.bias_bit_width = self.get_bias_bit_width(bias)\n",
    "        return con_w, inc, bias\n",
    "    \n",
    "    def last_conv(self):\n",
    "        w = self.reader.read_qconv_weight(self.w_bit)\n",
    "        # inc, bias = self.reader.read_qbarch_norm_act_param(w_bit=self.w_bit, in_bit=self.in_bit, out_bit=self.out_bit, l_shift=self.l_shift)\n",
    "        # w 是二维矩阵形式\n",
    "        con_w = w.transpose(0, 2, 3, 1)\n",
    "        # 处理为二维矩阵\n",
    "        con_w = con_w.reshape(con_w.shape[0], -1)\n",
    "        # print(w)\n",
    "        # 先把 w 处理为每个元素位宽都是 simd * w_bit 形式\n",
    "        con_w = self.w_to_hls_array(con_w)\n",
    "\n",
    "        # inc, bias = self.inc_bias_to_hls_array(inc, bias)\n",
    "\n",
    "        self.hls_w = con_w\n",
    "        # self.hls_inc = inc\n",
    "        # self.hls_bias = bias\n",
    "\n",
    "        # self.inc_bit_width = self.get_inc_bit_width(inc)\n",
    "        # self.bias_bit_width = self.get_bias_bit_width(bias)\n",
    "        return con_w #, inc, bias\n",
    "\n",
    "\n",
    "    def linear(self):\n",
    "        w = self.reader.read_qlinear_weight(self.w_bit)\n",
    "        inc, bias = self.reader.read_qbarch_norm_act_param(w_bit=self.w_bit, in_bit=self.in_bit, out_bit=self.out_bit, l_shift=self.l_shift)\n",
    "\n",
    "        # w = self.\n",
    "        # m * n\n",
    "        # 如果上一层是卷积层 需要调整参数位置\n",
    "        if(self.conv_linear == True):\n",
    "            last_conv_shape = self.config[\"last_layer_shape\"]\n",
    "            w = w.reshape(w.shape[0], last_conv_shape[0], last_conv_shape[1], last_conv_shape[2])\n",
    "            w = w.transpose(0, 2, 3, 1)\n",
    "            w = w.reshape(w.shape[0], -1)\n",
    "        w = self.w_to_hls_array(w)\n",
    "        inc, bias = self.inc_bias_to_hls_array(inc, bias)\n",
    "\n",
    "        self.hls_w = w\n",
    "        self.hls_inc = inc\n",
    "        self.hls_bias = bias\n",
    "\n",
    "        self.inc_bit_width = self.get_inc_bit_width(inc)\n",
    "        self.bias_bit_width = self.get_bias_bit_width(bias)\n",
    "        return w, inc, bias\n",
    "    \n",
    "\n",
    "    # 最后一个全连接层\n",
    "    def last_linear(self):\n",
    "        w = self.reader.read_qlinear_weight(self.w_bit)\n",
    "        w = self.w_to_hls_array(w)\n",
    "        self.hls_w = w\n",
    "        return w\n",
    "    \n",
    "    def w_to_hls_init_str(self, w) -> str:\n",
    "        w_mem_type = \"const ap_uint<\"+str(self.w_bit * self.simd)+\">\"\n",
    "\n",
    "        res = '// ' + self.name + '_w\\n'\n",
    "        res += \"//PEs = %d, SIMD = %d\\n\" % (self.pe, self.simd)\n",
    "        res += '//bit = %d\\n' % self.w_bit\n",
    "        res += w_mem_type\n",
    "        res += (' ' + self.name + '_w') \n",
    "        res += '[%d][%d] = {\\n' % (len(w), len(w[0]))\n",
    "\n",
    "        res += \",\\n\".join(map(lambda pe:\"{\\\"\"+(\"\\\", \\\"\".join(map(hex, pe)))+\"\\\"}\", w))\n",
    "        res += '};\\n'\n",
    "\n",
    "        return res\n",
    "    \n",
    "\n",
    "    # 确定 inc 位宽 \n",
    "    def get_inc_bit_width(self, inc):\n",
    "        abs_max = np.abs(inc).max()\n",
    "        bit_width = len(str(bin(abs_max))) - 2\n",
    "        return bit_width + 1\n",
    "    \n",
    "    # 确定bias的位宽\n",
    "    # bias 有整数和负数\n",
    "    # 当前算法得出的还不是最优\n",
    "    def get_bias_bit_width(self, bias):\n",
    "        abs_max = np.abs(bias).max()\n",
    "        bit_width = len(str(bin(abs_max))) - 2\n",
    "        return bit_width + 1\n",
    "    \n",
    "    def inc_to_hls_init_str(self, inc) -> str:\n",
    "        inc_bit_width = self.inc_bit_width\n",
    "\n",
    "        w_mem_type = \"const ap_int<\"+str(inc_bit_width)+\">\"\n",
    "\n",
    "        res = '// inc\\n'\n",
    "        res += '// ' + self.name + '_inc\\n'\n",
    "        res += '// w_bit = %d\\n' % inc_bit_width\n",
    "        res += w_mem_type\n",
    "        res += (' ' + self.name + '_inc') \n",
    "        res += '[%d][%d] = {\\n' % (len(inc), len(inc[0]))\n",
    "\n",
    "        res += \",\\n\".join(map(lambda pe:\"{\\\"\"+(\"\\\", \\\"\".join(map(hex, pe)))+\"\\\"}\", inc))\n",
    "        res += '};\\n'\n",
    "\n",
    "        return res  \n",
    "    \n",
    "    def bias_to_hls_init_str(self, bias) -> str:\n",
    "        bias_bit_width = self.bias_bit_width\n",
    "\n",
    "        w_mem_type = \"const ap_int<\"+str(bias_bit_width)+\">\"\n",
    "        res = '// bias\\n'\n",
    "        res += '// ' + self.name + '_bias\\n'\n",
    "        res += '// w_bit = %d\\n' % bias_bit_width\n",
    "        res += w_mem_type\n",
    "        res += (' ' + self.name + '_bias') \n",
    "        res += '[%d][%d] = {\\n' % (len(bias), len(bias[0]))\n",
    "\n",
    "        res += \",\\n\".join(map(lambda pe:\"{\\\"\"+(\"\\\", \\\"\".join(map(hex, pe)))+\"\\\"}\", bias))\n",
    "        res += '};\\n'\n",
    "\n",
    "        return res\n",
    "\n",
    "    def layer_param_to_init_str(self, w, inc, bias) -> str:\n",
    "        res = self.w_to_hls_init_str(w)\n",
    "        res += self.inc_to_hls_init_str(inc)\n",
    "        res += self.bias_to_hls_init_str(bias)\n",
    "\n",
    "        return res\n",
    "    \n",
    "    def last_layer_param_to_init_str(self, w) -> str:\n",
    "        res = self.w_to_hls_init_str(w)\n",
    "       \n",
    "        return res\n",
    "\n",
    "    def add_a_config_str(self, config_name, value) -> str:\n",
    "        res = '#define %s_%s %d \\n' % (self.name.upper(), config_name.upper(), value)\n",
    "        return res\n",
    "\n",
    "    def conv_config_str(self) -> str:\n",
    "        res = '// ' + self.name + '\\n'\n",
    "        res += self.add_a_config_str('K', self.config['k'])\n",
    "        res += self.add_a_config_str('S', self.config['s'])\n",
    "        res += self.add_a_config_str('P', self.config['p'])\n",
    "        res += self.add_a_config_str('IFM_CH', self.config['in_shape'][0])\n",
    "        res += self.add_a_config_str('IFM_ROW', self.config['in_shape'][1])\n",
    "        res += self.add_a_config_str('IFM_COL', self.config['in_shape'][2])\n",
    "\n",
    "        res += self.add_a_config_str('OFM_CH', self.config['out_shape'][0])\n",
    "        res += self.add_a_config_str('OFM_ROW', self.config['out_shape'][1])\n",
    "        res += self.add_a_config_str('OFM_COL', self.config['out_shape'][2])\n",
    "\n",
    "        res += self.add_a_config_str('SIMD', self.simd)\n",
    "        res += self.add_a_config_str('PE', self.pe)\n",
    "\n",
    "        res += self.add_a_config_str('IN_BIT', self.in_bit)\n",
    "        res += self.add_a_config_str('OUT_BIT', self.out_bit)\n",
    "        res += self.add_a_config_str('W_BIT', self.w_bit)\n",
    "        res += self.add_a_config_str('INC_BIT', self.inc_bit_width)\n",
    "        res += self.add_a_config_str('BIAS_BIT', self.bias_bit_width)\n",
    "\n",
    "        res += self.add_a_config_str('W_TILES', self.w_tiles)\n",
    "        res += self.add_a_config_str('A_TILES', self.a_tiles)\n",
    "        res += self.add_a_config_str('L_SHIFT', self.l_shift)\n",
    "\n",
    "        res += '\\n'\n",
    "\n",
    "        return res\n",
    "\n",
    "    def last_conv_config_str(self) -> str:\n",
    "        res = '// ' + self.name + '\\n'\n",
    "        res += self.add_a_config_str('K', self.config['k'])\n",
    "        res += self.add_a_config_str('S', self.config['s'])\n",
    "        res += self.add_a_config_str('P', self.config['p'])\n",
    "        res += self.add_a_config_str('IFM_CH', self.config['in_shape'][0])\n",
    "        res += self.add_a_config_str('IFM_ROW', self.config['in_shape'][1])\n",
    "        res += self.add_a_config_str('IFM_COL', self.config['in_shape'][2])\n",
    "\n",
    "        res += self.add_a_config_str('OFM_CH', self.config['out_shape'][0])\n",
    "        res += self.add_a_config_str('OFM_ROW', self.config['out_shape'][1])\n",
    "        res += self.add_a_config_str('OFM_COL', self.config['out_shape'][2])\n",
    "\n",
    "        res += self.add_a_config_str('SIMD', self.simd)\n",
    "        res += self.add_a_config_str('PE', self.pe)\n",
    "\n",
    "        res += self.add_a_config_str('IN_BIT', self.in_bit)\n",
    "        # res += self.add_a_config_str('OUT_BIT', self.out_bit)\n",
    "        res += self.add_a_config_str('W_BIT', self.w_bit)\n",
    "        # res += self.add_a_config_str('INC_BIT', self.inc_bit_width)\n",
    "        # res += self.add_a_config_str('BIAS_BIT', self.bias_bit_width)\n",
    "\n",
    "        res += self.add_a_config_str('W_TILES', self.w_tiles)\n",
    "        res += self.add_a_config_str('L_SHIFT', self.l_shift)\n",
    "        # res += self.add_a_config_str('A_TILES', self.a_tiles)\n",
    "\n",
    "        res += '\\n'\n",
    "\n",
    "        return res\n",
    "\n",
    "    def linear_config_str(self) -> str:\n",
    "        res = '// ' + self.name + '\\n'\n",
    "\n",
    "        res += self.add_a_config_str('IN_LEN', self.config['in_len'])\n",
    "        res += self.add_a_config_str('OUT_LEN', self.config['out_len'])\n",
    "\n",
    "        res += self.add_a_config_str('SIMD', self.simd)\n",
    "        res += self.add_a_config_str('PE', self.pe)\n",
    "\n",
    "        res += self.add_a_config_str('IN_BIT', self.in_bit)\n",
    "        res += self.add_a_config_str('OUT_BIT', self.out_bit)\n",
    "        res += self.add_a_config_str('W_BIT', self.w_bit)\n",
    "        res += self.add_a_config_str('INC_BIT', self.inc_bit_width)\n",
    "        res += self.add_a_config_str('BIAS_BIT', self.bias_bit_width)\n",
    "\n",
    "        res += self.add_a_config_str('W_TILES', self.w_tiles)\n",
    "        res += self.add_a_config_str('A_TILES', self.a_tiles)\n",
    "        res += self.add_a_config_str('L_SHIFT', self.l_shift)\n",
    "\n",
    "        res += '\\n'\n",
    "        return res\n",
    "\n",
    "    def last_linear_config_str(self) -> str:\n",
    "        res = '// ' + self.name + '\\n'\n",
    "\n",
    "        res += self.add_a_config_str('IN_LEN', self.config['in_len'])\n",
    "        res += self.add_a_config_str('OUT_LEN', self.config['out_len'])\n",
    "\n",
    "        res += self.add_a_config_str('SIMD', self.simd)\n",
    "        res += self.add_a_config_str('PE', self.pe)\n",
    "\n",
    "        res += self.add_a_config_str('IN_BIT', self.in_bit)\n",
    "        # res += self.add_a_config_str('OUT_BIT', self.out_bit)\n",
    "        res += self.add_a_config_str('W_BIT', self.w_bit)\n",
    "\n",
    "        res += self.add_a_config_str('L_SHIFT', self.l_shift)\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "expensive-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv       0      1   2       3   4   5\n",
    "w_bit   =   [4,     4,  4,      4,  4,   8]\n",
    "in_bit  =   [8,     4,  4,      4,  4,   4]\n",
    "out_bit =   [4,     4,  4,      4,  4,  32]\n",
    "l_shift =   [6,     6,  6,      6,  6,   6]\n",
    "simd    =   [3,     16,  16,    16, 8,   8]\n",
    "pe      =   [16,    8,   8,     4,  2,   2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "secret-bulgarian",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "52\n",
      "52\n",
      "52\n",
      "52\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "w_bit = [4]\n",
    "for i in range(50):\n",
    "    w_bit.append(4)\n",
    "w_bit.append(8)\n",
    "\n",
    "in_bit = [8]\n",
    "for i in range(51):\n",
    "    in_bit.append(4)\n",
    "    \n",
    "out_bit = [4]\n",
    "for i in range(50):\n",
    "    out_bit.append(4)\n",
    "out_bit.append(32)\n",
    "\n",
    "l_shift = [6]\n",
    "for i in range(51):\n",
    "    l_shift.append(6)\n",
    "    \n",
    "simd = [3]\n",
    "for i in range(51):\n",
    "    simd.append(4)\n",
    "    \n",
    "pe = [4]\n",
    "for i in range(51):\n",
    "    pe.append(4)\n",
    "    \n",
    "print(len(w_bit))\n",
    "print(len(in_bit))\n",
    "print(len(out_bit))\n",
    "print(len(l_shift))\n",
    "print(len(simd))\n",
    "print(len(pe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "generic-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir_hls_param = './param_hls/'\n",
    "if not os.path.exists(target_dir_hls_param):\n",
    "        os.makedirs(target_dir_hls_param)\n",
    "        \n",
    "hls_param_file = open(target_dir_hls_param + 'param.h', 'w')\n",
    "hls_config_file = open(target_dir_hls_param + 'config.h', 'w')\n",
    "\n",
    "config_file = open('config.json', 'r', encoding='utf-8')\n",
    "config = json.load(config_file)\n",
    "reader = QNNParamReader('mobilenetv2_Q_4w4a.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "directed-technique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inc_q:  [ 1718  3217  3440  3388  6805 11248  4710  3036  1939  1629  1712  1260\n",
      "  5252  1488  2435  2417  2805  5062  5475  5060  4090  2670  2049  1876\n",
      "  1195  2084  1488  2937  5583  3927  4732  4829]\n",
      "bias_q:  [ 3196797 -2766567  3428500 -3030807  -786042   901033 -2779695 -3381277\n",
      "  3422814 -3472048 -3332624  3546237   235535  3249129  3136051  3142266\n",
      " -3161740  -255425 -1228256   116228  3094371 -2222455  3215699 -3301166\n",
      " -3405159  3142988 -3460788 -1467740  -915785 -2967526 -2587377  2649444]\n",
      "inc_q:  [ 1858  5990  1176  2425  2830  7083  2412  2284  7946 10039  1385  1887\n",
      "  2230  2967  6222  2848  2902  5622  4609  3422  7422  2645  3885  2891\n",
      "  7835  4706  5918  5251  5396  1430  2036  1782]\n",
      "bias_q:  [-112955  -82615  118252  103440   29649   -5992 -101489 -100250   85115\n",
      "   -6282 -101943  122169 -107052  -95973   -8782  122856  -91200  -75841\n",
      "   42659 -109784   49887  -87099 -102382 -100091  -37747  104357  -36337\n",
      "  -90812  -19603   92598  -99322 -114387]\n",
      "h mod simd != 0\n",
      "inc_q:  [2163 1588 1457  855 1929  728 1264 1414 1462 1310 1849 1392 1461 1487\n",
      "  883 1899]\n",
      "bias_q:  [-191811  245877   99813   13702   90637   17690  -49927   72272   28692\n",
      "   45102   -5049   22251  202051   76405   22699   -4332]\n",
      "inc_q:  [ 920 1222  889 1528  913 1222  970 1379 1495 1282 1173 1537  906  875\n",
      "  812 1300 1258  899  777 1081  917 1205 1037 1336  894 1021 1101 1196\n",
      " 1394  981  971 1229 1012 1395 1009 1894 1161 1184  932 1236 1471 1126\n",
      "  958 1024 1218 2097  719 2073 1807  587  655  667 1279  925 1021  912\n",
      " 1117 1153  905 1103 1014 1771  972  916 1584  591 1157 1118  972 1098\n",
      " 1064  964 1123 1142 1158 1077 1136 1292 1081 1484  885  673 1248  718\n",
      " 1286  866  758 1319  993 1069  797  809  735  974  794 1699]\n",
      "bias_q:  [ -7088   -657  -8424   7650   7365  -5820   6116  -1396  -2168  -7251\n",
      "     97  -1544   1796   -557  -3148   1795   7732  10267   5814   4202\n",
      "   1212   7788  -6226  -2148  -6534   9785  -1743   5492  -6369  -5665\n",
      "  -6694  -1213   1953  -1310  -5612  -1336   5448   5287  10521    746\n",
      "  -8686  -7211    -36  -3284  -1172  -3998   -517    206   4919  -1985\n",
      "   6521  -2999   2035  10310  -7533  -6156  -6117   5948   5177  -6196\n",
      "  -4935   3326   7556  -5595   5785   6220    -72  -3587   -711  -8826\n",
      "    550  -7133   2196   1435   6343    171  -8430   1037 -10984   -549\n",
      "  -6978 -10067   4887   6016   6790    -91    867  -1184  -7960    744\n",
      "   -558  15039    174  -3500   3905  -1040]\n",
      "inc_q:  [3811 3096 3177 2524 2255 2552 1566 4004 2649 2275 3734 3988 2956 2761\n",
      " 4806 2103 3918 4423 5313 2191 1872 2894 1747 1954 1835 2783 2466 1705\n",
      " 3460 3291 3081 3787 2489 3994 5712 3017 2210 3003 3121 4072 2018 3409\n",
      " 2581 2345 5869 3330 1997 2642 3629 1785 1321 7259 1541 2572 1752 1629\n",
      " 2385 2374 1821 2918 2186 2670 1455 3153 2220 5099 2105 2143 2829 3510\n",
      " 2145 1978 2535 2546 2250 2633 1498 3074 2085 1676 3779 2093 2127 2905\n",
      " 2919 2088 1527 1901 3162 3040 2583 2903 3941 2277 2055 2086]\n",
      "bias_q:  [  73180   24788   94596  -96911  126131  105789 -127621  -52612  122500\n",
      " -107370  -49585  -23470   80705   94759   -1425  106858    3117   37253\n",
      "  -48652 -132420  115201  100665  112931 -126743  122619  107378 -101084\n",
      "  109680  -47033  -57877  -94620   16588  -38487  115351  -30094 -106580\n",
      "  114890  115495 -101716   16456   93959   69029   99331 -107519  -28091\n",
      "   85978  103079  -87889 -111490 -115039 -109310    1924 -104419 -108246\n",
      "  -96463  110766 -100178  121968  109819  -64648 -103202  142543  138474\n",
      " -101119  106178   57509  131782  106407   63084   82074  124910  114250\n",
      "  120856 -127447   95459  -14309 -105266  -12447 -104293  120277  -52981\n",
      " -104892   94798  110174   90576   99490  110462 -102244  -98429 -119517\n",
      "   96176 -102544   68751  118473 -106938  142580]\n",
      "h mod simd != 0\n",
      "inc_q:  [ 869  751  665  892  656  860  835  530  844  679  775 1084 1044  659\n",
      "  630  765  834  982  859  718  646  808  635  897]\n",
      "bias_q:  [ 192648  -87208   78542   92030   -8209  -60601   57158    3050     696\n",
      "   72989 -153434  -35224  -38275  123478   49059   93492    7740 -134919\n",
      "   -7225 -104946  106766   59119  -95790  -71011]\n",
      "inc_q:  [ 933 1031  746  749 1043  825  932  967  803  866  797  930  794 1011\n",
      " 1160  818 1054  688  830  690  733 1099  655  956  932  688  770 1036\n",
      "  944 1215 1073  551  866  482  841  983  798  933 1107  916  748  687\n",
      "  859  609  938  931  609 1112  747 1120  909 1000  759 1099  782  798\n",
      "  868  836  743 1186  894  715 1180 1006  725  933  780  997  907  820\n",
      "  965  786  738  934  872 1009  644 1070  765 1247  655  811  923  744\n",
      " 1094  943  815  957  735  865  727  650  834  709  603 1337 1619  612\n",
      "  838  645 1065  896 1035  652  779  686 1036 1106  626  810 1060  808\n",
      "  763  625 1147 1029  742  987  852 1188 1117  934  574  857 1197 1034\n",
      " 1301  835  865  925  749  929  863  696 1012 1074 1380  944  818  951\n",
      "  750  621  737  666]\n",
      "bias_q:  [ -4023  -7581   -314   -916   4545  -8519  -4839   -990    972  -7240\n",
      "    200   -916   5149   8262   5674   2924   4722 -15172   8952  -7978\n",
      "     60  -1368  -4089  10583   3495   -490   3423   3443  13575   7520\n",
      "    883   5157  -7485  -2122  -1021  -4624   2900   3478   6580  -1133\n",
      "   8336 -11850   3767  -2065   -174   2539  -2155 -12697  -5407   7132\n",
      "  -7409    973   -376   5740  -1275  -1777  -2631   1888   -150   3561\n",
      "  -7015   -874   5899 -10502  -1806  -7467   6281  -7807  -2549  -2284\n",
      "   1155   4171  -6085   6370   4801   1557   -589   -378  -5218   8630\n",
      "   3108   -603   4030  -3020  -4948  10649 -13993   3338   7498   5550\n",
      "   4934   3755  -5319   6183   9350   -373   6730  -5891   1542  -7310\n",
      "   3066  -1518  -1169    252  -7211   -353  -8739     10   8351  -4821\n",
      "   1530  -1834   5339   2960   3966   6405   -663    -74   4333  -4545\n",
      "   5252   5569  -1068   2559   6156   1780   5679   3270  -7272 -11678\n",
      "   1168  -1987  -1259  -4965  -2594  -2457   1825   5547   6180   5751\n",
      "    828   1220   -531   2566]\n",
      "inc_q:  [2667 3610 2904 2535 1588 3612 3158 3018 2871 4119 2140 3281 3013 3169\n",
      " 4025 2743 2410 2015 3030 4005 1940 2227 3757 2305 3702 2556 2190 3089\n",
      " 3532 4076 3706 2329 3694 2528 3328 2103 3151 2210 2179 3344 2539 2676\n",
      " 2292 3639 2075 2777 4232 4312 2901 2804 2521 3533 4577 2212 3918 3666\n",
      " 2439 2148 3228 2556 3842 2880 3273 2867 2646 3088 2527 1724 1678 4120\n",
      " 2452 2946 2342 1999 5493 3789 2728 2012 3810 3006 1604 3717 2242 1913\n",
      " 3721 3077 2214 3832 2835 3173 4119 2410 2574 3676 3516 2293 2621 3677\n",
      " 2368 1940 3505 2768 2650 2504 4571 2971 4567 2487 2733 3083 3977 1644\n",
      " 2427 2679 3017 2000 2228 3251 2763 2595 3284 2310 2154 2305 2522 2398\n",
      " 2429 2552 2132 3252 4403 3945 4046 3402 3440 2314 2327 2320 4410 3139\n",
      " 4302 3612 2104 3673]\n",
      "bias_q:  [ 125578  -15367  -41213  129384 -132127  -21864 -115233  102339   78388\n",
      "   15779  119791  -89200  -42784  107194  -96077  104888 -117187  104726\n",
      "  105725  127556  108710 -122112   49765 -146616   76757 -128771 -132311\n",
      " -117764  -59929   -2232  123290 -117066    2931   98402  -40271 -120328\n",
      "  -93146 -126999  147052   43190  138019  -84990 -115113   49070 -124732\n",
      "   89535  -61982  -53436  -91945  -56937 -115487  -50249   60886  125518\n",
      "   95995   29536  128040  132965   73671  131105  112472   83692   61871\n",
      " -135107  106598  121069   90036 -124805  143504  -18263 -126095 -112839\n",
      " -127153 -130785  -57526   16921 -105511 -128353   70385  -19975  124914\n",
      "  -38643 -163546 -103663   64236 -107731  124328   27572  114578  -30472\n",
      "  -89273 -126737  103599  -68900 -115695   35002 -128773  -90363  102902\n",
      "  129117   -8260  -92151 -110065  105777   39138   82143   41233 -124735\n",
      " -127493  -89909    2416 -113455  105189  111613 -107690  128049  131915\n",
      "  -98495 -101058  -76426   55899  132606 -114788 -137872 -132232  -29189\n",
      "  130381 -140552   89508  117759 -105263  112818   68895  101138   -1445\n",
      "  107331 -146976  141522   84937   17054  -69750  -31404 -125434  -81692]\n",
      "h mod simd != 0\n",
      "inc_q:  [587 632 506 492 695 590 614 687 622 668 672 682 574 660 730 533 619 587\n",
      " 426 410 625 698 636 783]\n",
      "bias_q:  [  91033  -49856  -64092   31441  -68406 -116295  -52977   21721   -7161\n",
      "   59096 -118073  -33499      83  177720 -190691   92870   57843 -169295\n",
      "   51521  -89545   84310  202176   23756   19886]\n",
      "inc_q:  [822 537 647 607 651 390 684 731 640 402 481 564 720 634 653 770 598 574\n",
      " 637 512 673 746 656 628 705 555 818 686 547 774 589 426 563 842 726 670\n",
      " 727 516 538 846 687 985 629 773 530 356 388 703 833 584 622 555 988 567\n",
      " 569 776 482 405 479 549 621 791 535 474 489 816 532 511 637 725 701 676\n",
      " 638 483 410 598 949 706 492 378 602 588 762 492 503 605 586 657 512 535\n",
      " 602 686 712 648 807 671 788 700 380 554 635 591 734 687 920 632 615 469\n",
      " 472 468 825 620 650 747 632 702 501 571 692 648 532 453 654 640 607 436\n",
      " 504 355 471 373 826 601 485 538 513 578 711 974 767 469 529 604 917 448]\n",
      "bias_q:  [  4882   -434  -3112   4946    914   1739    872    874  -7043   2628\n",
      "   2436   7926  -1012  -2478   5343    431  10638  -3023   7785   8496\n",
      "  -4852  -4344  -4698   9351  -5380  -2912  -6096  -7322 -17290   1404\n",
      "    851  10544  -8124   8756  -7346  -2391   1083   1636   1213  -4348\n",
      "  -7910   5729  -5451  -2300   3635   -198  -2529   2829 -12217   -935\n",
      "     -1  -3065   5697   -971 -11801  12618    217  -9113  -6340   3826\n",
      "   4641   4710 -11417  -7990  -3080   5807  -1273   8547   4304  -3808\n",
      "  -2620   6822   6345  12713   2023  -4856  -3441   -876  10473   2959\n",
      "   3555   1008   -626  -2800   8510    955   4060  14944  -5734   3490\n",
      "   8372   1935   8146   7747  13410  -3777   1428     67   -667    852\n",
      "   1228   6165  -1137  -7879  -6232  15750   7509  -2621  -5328   2832\n",
      "   -803   4550    844   1080   1458   6227  -3336   2812  10578   4525\n",
      "   -883   1424  -3786    509   6390   1697  -1769   6038  -8024 -11636\n",
      "   4234  -3316  -1652  -3597   5219  -5937  -2673    326   8647   -984\n",
      "  -3121  -2117   8290  -4038]\n",
      "inc_q:  [2805 4303 2473 2213 1809 6530 2831 2144 2441 2592 3228 2872 2402 2992\n",
      " 2602 3470 2483 2772 3378 4609 2777 3469 3316 1536 2136 2438 3213 2965\n",
      " 3383 4031 2892 2073 1771 2399 2761 1774 4551 1893 2223 2717 1696 2556\n",
      " 2363 2544 2168 3028 2601 3246 3716 2498 1667 1963 2908 3987 2731 3464\n",
      " 2434 3395 1874 3142 3024 1612 3748 3993 3401 2355 3309 1873 2393 3074\n",
      " 2895 3771 3659 1897 2812 2607 3180 3572 3234 2453 3170 3842 3210 2526\n",
      " 2629 2047 1824 2390 2080 3583 3175 3745 3878 3426 2246 2885 2436 2295\n",
      " 3414 2972 2315 3588 4992 3233 3647 1657 2277 3574 3320 2162 2806 3272\n",
      " 3440 2949 2563 2705 2330 2865 2789 2141 1832 1705 2409 1957 2667 5226\n",
      " 3044 2912 3380 2861 2383 3696 3234 2039 2456 3408 4088 3450 3192 2727\n",
      " 3094 2998 1709 2188]\n",
      "bias_q:  [-118531    1313  119021  145712 -145672   63585  -35214 -122506  -98621\n",
      " -107751  -66491  -97022  113427   77303 -127323   35177 -129301  -36399\n",
      " -117760  -28305  136610   71975 -122364  135941  151066  108951   46720\n",
      "  -83775  -69825  -41367  139695  112896  118012  -99974 -122632 -140977\n",
      "   19013  121582  142590 -135044  111782   97958 -107808   68201  133373\n",
      "   94517 -109399 -101457  -51317 -108805 -124518  117715   -9354  -56125\n",
      "  -67234 -110087 -133821 -119934 -126016 -107799 -111051 -151591  -31953\n",
      "  -77909 -104224  147931  110052  117124  127828   74690  133809   76561\n",
      "  -84116 -112024  124323  -80840   29598   77171 -102035 -114024   11588\n",
      "   -8061   82181 -109234 -118315  123178  105884  -97670 -115396   94142\n",
      "  -73648    2454  -72936 -122881 -128984  135619  -81228  107612  -66859\n",
      " -111648  112542 -103946   58241  -90597   12967  127081 -115563 -111143\n",
      "  -57671 -115134   65565  -88435   77819  -75105 -113468  103550 -118621\n",
      " -108530  101586  134753 -109656 -116145  148116  142340 -119615  -16769\n",
      " -110659 -100551   31492 -109397  132887  -16421  103024  116055  121585\n",
      "  102748    5951  -77653  -56093  155996 -104726 -112432 -147100  105236]\n",
      "h mod simd != 0\n",
      "inc_q:  [726 667 605 645 507 697 645 648 519 700 846 710 468 443 682 522 495 573\n",
      " 618 657 730 611 702 840 614 579 528 557 696 538 666 614]\n",
      "bias_q:  [  41448  -39470   64125  -16757   -8541 -126377  144061    4542   -2056\n",
      " -142971  -57770   -4213   94820   46350    -437   21670  -20748 -195601\n",
      "  -69512  176975 -145502  -71708    9718 -125339  -61021  -36886  -65582\n",
      "  -84133  -86102    4013   98608  144510]\n",
      "inc_q:  [ 707  543  709  834  751  959  702  490  605  598  547  621  544  705\n",
      "  914  631  469  847  799  775  603  661  758  985  550  611  527  706\n",
      "  668  599  734  430  696  745  757  741  643  530  850  553  781  722\n",
      "  995  557  754  600  627  593  698  810  832  588  631  827  625  569\n",
      "  768  424  540  872  475  500  530  464  638  742  742  678  647  666\n",
      "  750  690  701  959  616  599  633  642  657  669  644  478  869  567\n",
      "  540  520  483  717  648  438  556  646  673  533  582  682  598  601\n",
      "  661  832  526  526  615  759  668  608  607  375 1008  534  912  723\n",
      "  717  737  656  682  634  728  547  768  811  750  423  714  576  595\n",
      "  637  507  637  680  772  702  755  481  697  629  875  740  679  533\n",
      "  629  810  498  611  682  711  626  496  627  676  575  626  739  535\n",
      "  749  637  615  562  668  879  540  669  897  562  707  634  427  578\n",
      "  618  602  646  617  645  751  676  637  637  563  646  592  833  672\n",
      "  744  550  608  605  772  477  632  721  819  470]\n",
      "bias_q:  [  4272   2794   1742  -4995  -4078   2132  -4435  -7727   3458   7752\n",
      "   4722    313   -887   1346  -2041  -6623  -4621    596   1857  -7431\n",
      "   5171   6140   1722  16768   -634  -3029  -4957   2180   -178   4738\n",
      "  13452  -6891  -4550  -5752   4240   6596    749  -3497   1622    509\n",
      "  -6019    954   -804   6727  -3796  -1493   3135   2966   1844   -391\n",
      "   1556   -574  -2054  -4378   3092  -4658   1692   -610   1870   -145\n",
      "  -2265  -6789   7928  -8471  -1520    691   1063     54  -4782  -9784\n",
      "   5054    588   5066  -7002 -10153  -6014  -5122   1152   2506   2692\n",
      "   8444  -2698  -9633  -4259  -1150  -2091   1805  -1591  -4622   4464\n",
      "  -2680  -2973   6230   4502    869  -2385   2524  -2544   2177  -1812\n",
      "  -5232  -3358  -5075  -3351  -4494   1178   -261   2554   1415   6156\n",
      "  -3102   5387   7070   1927   5321   5673   6527  -2968   1591  -3591\n",
      "   2069  11760  -4621  -1649  -1466  -4647   5170   1995  -5088  -5677\n",
      "   2445   2987    881  -1943   4934  -4547   3088  -3672   6837   6357\n",
      "  -1838   1307  -2044  -2178  -5361   5384  -1042  -4929   5454   -921\n",
      "   -688  -6892   5709  10508   8395   5188   3252  -4730   -493   3899\n",
      "   4323  -5045   8148  -4172  11666   4000  -1364  -4385  -4323   8199\n",
      "   -962  -5805  -2887  -2292   1253  -4652   1829  -4027  -7452  -2651\n",
      "  -5092    -59 -12074  -3183   6142  -3933  -4505   7817    944  -3240\n",
      "   1562  -2970]\n",
      "inc_q:  [2425 4822 3527 2900 2520 3043 3491 3906 3771 2510 3047 3145 2141 2441\n",
      " 3078 3817 4251 3965 3151 3832 4066 2572 2437 3532 3110 2022 3188 3664\n",
      " 3525 3355 3805 4493 2178 3998 2980 2518 3760 3359 3463 2873 2547 2281\n",
      " 3021 2352 2902 2691 2906 3272 4202 2976 2878 1925 3333 2285 2364 2372\n",
      " 3258 2805 4978 2867 2995 2137 2512 3069 2571 3274 3143 3615 2914 3372\n",
      " 3465 4921 2314 3396 3033 1950 2955 2806 2467 2645 2722 4358 3280 1964\n",
      " 2436 1866 2997 4475 2777 2130 4422 2037 3821 3235 2579 2971 3475 3279\n",
      " 4103 2828 2746 2410 4072 3850 2028 2642 2060 1834 3142 3533 3054 3166\n",
      " 3190 3036 3254 2804 2001 3137 2061 2469 3150 2329 1483 3907 2617 2712\n",
      " 3633 1798 2984 2688 3735 2610 4689 2985 2418 3198 3303 2706 3625 3142\n",
      " 3617 2709 2232 2897 4106 2837 3112 2950 2110 2409 2858 3257 3031 2266\n",
      " 3403 2475 2909 2855 2465 2955 2403 4072 2379 3507 4245 2592 2548 4475\n",
      " 2979 3697 3868 2079 2853 3059 2478 3092 2968 2514 2009 2532 2318 2605\n",
      " 3344 2285 2648 3234 2847 3282 3780 3744 3944 2434]\n",
      "bias_q:  [-108291  -21081   76172  -62798 -112822  131748  -55979  -75849   69297\n",
      "  150976  110637  124785  141317 -127327  127253  -70743   93645   29774\n",
      "   -6034  -71283  -36518  113774 -111500  -99884  -58060  115574 -108884\n",
      "   67636  -76418   33835 -140929  -67968  127873   22163 -104271 -107026\n",
      "   20510  -71341   21288 -127606  -77075 -117228 -107878 -121988  -51376\n",
      "  -97734 -130720   72711  -38393  124278   18583  118465  -86322  129467\n",
      " -111238   77919  -19215   95792   -3282 -134677   92490  124830   93834\n",
      "  -79982 -103498   65814  -36182  -69652  -25042   73470   44928  -59495\n",
      "  124021   57204   85317 -110034   95310 -111822  134018  119638 -103459\n",
      "  -20166  -94251  139324 -112951  118411  -64588  -39346   42411  106248\n",
      "  -63168 -145311   53178  -80045  115993   58155   -3076  -65503  -17127\n",
      "  -28146 -117416 -134445  -46940  -66263 -104369   86668 -120446  128869\n",
      "  -61208  -20759   67064   39201 -110303   69943   92776  118984 -152215\n",
      "  -64771 -133268  110946  -19828  150279 -118752  -90759   95125  -68688\n",
      "   52787  145501  -17759  -90289   73506  105706  -34968   30106 -118166\n",
      "  -57395 -115635  119040   50222  -83022  101301  137799  123114  -76794\n",
      "  -35669  133071 -129985  -73629 -115260  122232  -96398  -59345  -71284\n",
      "  128697   26813   92551  -75357  112049 -141924   49486  121627  -68869\n",
      "  111383   30079  -63111 -121971  -79767   33339  145345   75678  -87450\n",
      "  125053   77921   73752  159125  105371 -132432  -97996 -106187  141133\n",
      "  132414  161038   12027   38342  110086   55631  -30831  117679  -57551\n",
      "  -50306    1883   95489]\n",
      "h mod simd != 0\n",
      "inc_q:  [626 594 536 537 774 614 676 660 527 597 564 634 640 568 644 620 603 599\n",
      " 605 622 638 547 573 436 672 688 601 646 611 569 445 614]\n",
      "bias_q:  [  17090  130252  -18411    8151 -219495 -293636  -86483  -75902   34052\n",
      "  -49413  142188   55866  142439   74581   12661  -19077 -207616 -159726\n",
      "  -44836 -165800   56973   41143 -156055  -65717  101749   46309  -79887\n",
      "  -30501   -6329  -51857   24677  -98583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inc_q:  [427 472 407 580 441 502 684 522 481 450 549 696 558 486 645 855 408 488\n",
      " 503 670 416 409 478 464 636 483 338 392 285 393 331 371 533 530 353 443\n",
      " 455 501 397 425 471 412 428 330 381 383 360 404 391 442 450 557 394 470\n",
      " 636 439 278 461 393 420 285 354 385 424 331 336 389 321 548 347 502 424\n",
      " 591 477 453 350 397 348 408 534 307 493 543 422 347 420 331 420 582 552\n",
      " 407 522 375 589 529 519 489 425 338 297 473 508 514 426 451 530 480 509\n",
      " 467 473 338 382 510 385 427 483 395 373 484 464 517 460 478 432 544 423\n",
      " 327 472 473 363 525 518 298 613 400 426 550 566 467 352 388 374 293 373\n",
      " 411 331 599 469 701 393 554 337 406 529 538 524 323 320 628 625 378 563\n",
      " 608 485 486 452 467 540 472 441 510 471 582 598 529 562 343 523 434 497\n",
      " 419 377 547 619 354 439 454 346 546 517 518 326]\n",
      "bias_q:  [  2646   1696   2063   3516  -4912    604   7524  16482   3851   5202\n",
      "  -2790  -1259   2660   1294  -2725  -3831  -3964  10915   3455    743\n",
      "  -3950   2726  -1004   2749   4085   2428   1633   4155  -2513   4742\n",
      "  -3043  -1543   7017   6356   -466   1033   4570 -17028    180  11326\n",
      "   3231  -1585   -615  -1757  -4448   5979  -4889   -533   -963   2098\n",
      "  -1058   4682   4034  -6719   1519  -6734  -5556   2970   2119   1639\n",
      "   4687   7436  -3178  15283  -6303  -9120   5898   -984  -2541   -311\n",
      "   2366    118   4786    706  -5820   7346 -10778   5658   4386  -7377\n",
      "  -2259   6710  -2975    -82  -9399   -946   2328   5975  -4479   8765\n",
      "  -4922   8201   -876   7817  -1956  -4865   -279   1756   1057   1939\n",
      "  -5700  -1297   1924  -8564  -2036   1577  -4931    403   7575  -2368\n",
      "   -225  -6366   -670  -1588  -1593   1526   1392    414   7721  -3896\n",
      "   8406   2010   4803  -1248   5422  -8308  -2248   4130  -1354   5219\n",
      "  -4011  -7100  -2316   1849  -1457   -958  -8669  -1626  -2346   2557\n",
      "   2804  -6997  -8383  -4219   4425  -1852  12003    792  -8063  -3842\n",
      "  15002    542   1283  -6373  -3668  -5720   7396   5477   5477   2237\n",
      "  -3851   7903   5763   1739    234  -2426  -7756   4113   1883   9596\n",
      "  -3159   3957  -3155    774  -2175 -13979  -2085  -2758   -700  -4368\n",
      "   2867   1397  -9312    491    375   1968  11939   3923  -6226   9061\n",
      "    959  -2097]\n",
      "inc_q:  [5124 4467 3295 3249 3995 4612 2677 3942 4028 3696 3385 5607 4328 2502\n",
      " 3163 4034 3055 2759 3713 3098 2948 2416 3629 4290 2567 4450 2285 3186\n",
      " 2555 2254 3186 4716 2084 3904 3066 2731 2386 4078 4414 3872 5051 3064\n",
      " 3850 3681 3654 6561 4331 2151 5110 3860 5173 4828 5376 5809 3693 4585\n",
      " 4620 2717 3713 3158 5881 5421 4573 3072 4084 6435 3394 4494 5478 2368\n",
      " 3165 4191 3967 4949 3098 3783 4757 3511 4580 4915 4087 3056 3658 3641\n",
      " 3595 6734 3938 3128 4344 3874 4375 3618 4218 3983 4352 2890 3152 2931\n",
      " 3548 2763 2305 4572 3488 2856 3596 4654 2530 3060 3434 3356 4277 3335\n",
      " 3087 6188 4278 2657 4089 5010 2978 4101 2670 3591 3012 2645 4076 3563\n",
      " 2437 7093 4725 2149 4725 3930 2302 4154 6749 2762 4782 3573 2796 4421\n",
      " 4128 3481 4504 2344 2940 3094 2290 2910 4119 5372 2415 2758 4900 3901\n",
      " 4504 3086 4185 4230 2419 4334 4374 3716 2757 4376 3424 4232 4553 3652\n",
      " 4719 4514 3823 5180 3671 4332 3578 3580 4004 4647 3340 4762 4260 3700\n",
      " 3737 3755 2468 4638 3366 4262 2609 2922 3039 3533]\n",
      "bias_q:  [  35976   -2412   84702  130710   85721   21086  136272   98143 -119181\n",
      " -121195   -7858  -48297 -102557  150193  121812   45437  -64917  115685\n",
      "   30715  131627  -86060 -126710   49237 -100249 -119049  -43487  143297\n",
      " -119368  126663 -113864  101250  -65648  143343    8666 -113845  128479\n",
      "  125173   24130  -89426  114520   46024  -97931  105506  -69725   88690\n",
      "    1273   36725 -121310  -74622 -119727  -24445  -94095  -26211   84555\n",
      "  -99188 -117912   48865 -141008   95019 -106390  -25351  -78560 -103067\n",
      "  139514 -101263  -62941 -117093  -57353  -47682  103986  141701 -129276\n",
      "  110099  -29499  133934 -118768  -97291   92229  -76413  -21331   -1111\n",
      "  136634  -92277  -70477  -98039   29075  122007  -92876  -79191   79765\n",
      "  108418   99953 -106284   43225  -97890  -76634  -85825 -144189  -91541\n",
      " -118745 -130603  -23622  171311  139758  -97098   65878 -121681  166520\n",
      " -136080 -133765  -93171 -115007  126209  -22108  -80805 -138195   78214\n",
      "  -70094   91956 -125164  107927  -87292 -135600  107970 -105121  -97563\n",
      "  138463   -7488  -87814 -112907   82143   86071  131492   -5022  -36555\n",
      " -142475   -2171  124302  142427  -81382  103244  112169   -5453 -126237\n",
      " -108852  105573  112045  125513 -102410   34603  102128  -88208   -2516\n",
      "  100240  -89539  -87405 -102046  -84286  154266  128316  -65821 -107063\n",
      "  135289  -97559 -109820  -54519    9636   25946  114076   70580  -90871\n",
      "   48374  -38828   60070   22853  -64260   61032  -43720 -121080   -3413\n",
      "  102283  -91530  -39967  -49251 -117785 -105353  141366   81295 -118361\n",
      " -154281 -100499   97625]\n",
      "h mod simd != 0\n",
      "inc_q:  [667 614 615 560 661 516 619 641 569 598 745 493 443 459 611 494 515 424\n",
      " 721 610 460 567 548 681 563 426 691 658 586 615 626 476]\n",
      "bias_q:  [ 104679  -61130 -100322 -119047  -24796  104255  -89086 -134238   48730\n",
      "   70708   24738  111487  -20574   22838  204520  -96288 -140237  -70879\n",
      "  -36742   66715  -54167   82745  150135  -12942   51967   39787  -10129\n",
      "   51771  -14309 -105208  137043   72365]\n",
      "inc_q:  [399 381 413 359 293 290 270 302 503 335 277 336 479 285 359 341 403 346\n",
      " 242 463 269 304 273 427 437 302 324 248 298 514 288 470 401 297 281 387\n",
      " 243 263 254 447 361 415 474 411 438 326 317 431 457 279 384 233 275 345\n",
      " 286 200 215 413 364 497 324 363 320 325 302 312 424 308 250 411 355 278\n",
      " 401 327 477 314 394 310 179 327 294 341 265 317 307 374 276 438 352 363\n",
      " 430 332 365 324 414 307 285 416 264 372 424 453 412 454 244 335 347 397\n",
      " 311 377 394 299 329 327 331 323 337 388 331 380 285 331 417 356 260 317\n",
      " 310 264 303 329 335 485 298 254 283 316 223 494 214 430 465 342 321 321\n",
      " 227 303 430 427 261 335 333 330 266 361 316 416 310 250 534 297 385 294\n",
      " 366 442 407 359 381 363 500 488 542 362 464 268 388 293 404 303 486 404\n",
      " 409 411 360 237 329 501 288 261 317 348 511 407]\n",
      "bias_q:  [  7538   -353   5255  -1211  -2003   2285  -6891      1  -1495   2790\n",
      "   3091    480  -8858   8442   2760   5236   2428  -5785  -1939  -5651\n",
      "   1457    620  -2688  -7847   1508   3372  -3643  -7451  12692  -1097\n",
      "  -2829   3354   2506  -4638  -8529  -6495  -1483  -8479    400  -2075\n",
      "  -6127    662   3313  11379   6295   -792  -1640   6720   1229   -590\n",
      "   8127  10089  -3184   6359   -858   9798   -102   -150  -3716  -8038\n",
      "  -6431  -6270  -5632  -8386  -6693   6699   5266  -3877  -1388  -4768\n",
      "  -3570   6142   9628   3818  -3840  -7514   3878  -4618  -5119   4791\n",
      "  -4689   2110  -1388  -7197  -3528   6938    818   4698    -88  -1701\n",
      "   2423  -1934   7255   7430   -777   5611  -4379  -6855  -3792  -5656\n",
      "   4955  -9871     66   -415  -8367  14275  -1037  -1747   1200   1698\n",
      "     68   1393  -1216   4151  -2957   4564   8161   -432  -7064   6191\n",
      "   2363  -8869  -8025   1544  -3703  -5249  -4527   6342   8351   3067\n",
      "  -8623    631  -1377  -2018    879   -713   -470  -5474  -1833  -1508\n",
      "   -804  -1570   1965   5278  -3886 -10604  -2788  -2787  -7007  -1785\n",
      "   8246   3348   7778   3782    125  -7213  -4121  -1114  -4243  -3664\n",
      "  -2817  -5478  -6143  -1219   7380   -349   4080  -4440   2041  -4726\n",
      "    688 -10105  -7541  -1299   3714  -4929   3142  -5587  -2480   -762\n",
      "    408   4334   8181  -3224   -882  16001  -2609  -2221  -3119   2506\n",
      "  -6290    915]\n",
      "inc_q:  [4291 4074 3092 2813 2926 3135 4484 2664 3197 1911 4154 2513 3693 3016\n",
      " 2689 5516 3452 2373 1954 2662 5685 2932 2924 3086 2877 2175 3436 3013\n",
      " 3014 3257 4146 3839 2637 4433 3605 4283 3369 2025 4693 4261 3872 3703\n",
      " 2453 2871 5725 1798 2532 2182 2647 3617 2987 3234 5684 4400 1897 2268\n",
      " 2817 3891 3334 3525 6272 2280 2307 2035 2126 2688 3157 3167 2038 2388\n",
      " 2204 3049 3060 2660 1837 1954 4817 2977 3385 2849 3030 3279 3321 3083\n",
      " 3348 3178 3179 3343 3648 2683 1806 2679 2770 2657 2653 2726 4477 3410\n",
      " 3304 3206 2648 2798 2434 4232 4390 2586 3109 2611 3029 4137 4305 2284\n",
      " 4700 2352 2761 2482 2350 3583 4407 3386 2499 4640 4333 2613 2663 4355\n",
      " 2304 2866 2002 4524 2625 2062 1798 3136 2704 2647 2315 3658 3616 1994\n",
      " 2756 3630 3753 2714 3336 2685 2883 4232 2148 3612 2555 2687 3601 2483\n",
      " 2680 2957 2584 2100 3677 2819 3028 4060 2510 3495 2300 2199 2724 4578\n",
      " 4511 3621 4702 2704 3107 3123 3715 3960 3164 2837 4217 3119 3985 4362\n",
      " 3430 1831 2242 2749 3452 2731 1708 2349 2818 3822]\n",
      "bias_q:  [ -76842  -75729  132172  -99503   84692  -83063  -37420  115368 -108281\n",
      " -124228  -97130  128920  -88365  146824   93976   -5662  120296  140264\n",
      " -123385  142517   53615 -111993 -100519   25733  144304  115873  -76131\n",
      "  -79990 -122180  156974  -43407  126159  145027  -49967   74136  -69655\n",
      "  -71660 -102313   55054  -64527   29709 -100670  121423  101872   -3421\n",
      "  127048   81731 -126687 -134555  -43444 -110009   97052  -57285  -88260\n",
      " -118228 -130791  -88674  109240  -91050   -2305    -743 -106684  100126\n",
      "  119676  111289  104936  141061  111947  112355  119888 -123215 -102158\n",
      "   76702 -130874  124055 -127588   67947 -110780   71110   96246 -107300\n",
      "  104510  -90965   55188   82687  121045  -90238 -119246  -24175 -122165\n",
      " -128365 -123492  142194  130499  158600 -103496   -2175   16076  -86104\n",
      "  -86489  164933 -137641  134309  -69159   64678 -130876  -92708  152354\n",
      "   39299   52088  -74768  124777  -55275   99948   89957  112661  135806\n",
      "    8421   41861  102185  103493 -110104   38272 -114768  -92434  -13602\n",
      "  123367 -104904  122743  -58478  121330  143188 -113516   68282 -117645\n",
      "  116382 -107888   58188  -44165  159322  108089  115843  -26068  129615\n",
      "  -58998 -108404  -69819   76963 -114105   96051  -96036  127387  -90273\n",
      "  121364 -101469  116637 -115174  126277 -123888  123208 -138161  -64257\n",
      "  128129 -115670 -111631 -132469  123238   15871  -69845     878  -25693\n",
      " -120709 -112326  -22456   68048  -69746    6213 -104583  -13096   66752\n",
      "  -67601 -109141  -22572  119915  139360   65240 -101018  120138  133342\n",
      "   95175  154737    9806]\n",
      "h mod simd != 0\n",
      "inc_q:  [650 572 671 565 640 391 554 691 508 453 783 489 527 778 629 597 614 843\n",
      " 519 842 629 693 595 573 543 616 519 490 491 567 418 585 824 594 715 645\n",
      " 508 537 570 660 582 650 601 633 611 660 635 586 596 493 679 722 569 691\n",
      " 625 449 506 745 626 584 633 484 713 454]\n",
      "bias_q:  [-172689  117992   46366  140662  -21982   29211  -67714  -27526  -44048\n",
      "  -12896  -63558  -95963  181881   48923   25966 -117785  152911    3557\n",
      "   97303 -164378 -112730 -104881  -44424   -7205  -54613   49650  -98317\n",
      "  -98821    3642   50773   72647   95804  -47816  -30472 -143746 -192880\n",
      "  108327  123841   58267  102083   -6734 -125808  321889 -145675   30469\n",
      " -112878   62120  -80607   16112 -171714   27599  167248    5653 -196570\n",
      " -125078  -62572   36633   86677 -177809   42254   60702   66570   -9652\n",
      "   28500]\n",
      "inc_q:  [454 346 319 437 396 469 449 283 661 406 538 372 473 443 390 720 404 434\n",
      " 514 371 475 395 636 440 529 562 281 536 435 532 496 428 654 398 411 578\n",
      " 526 550 346 658 360 584 325 431 353 434 502 403 382 421 559 490 488 609\n",
      " 717 379 611 462 447 502 542 474 407 469 414 378 611 420 414 456 710 554\n",
      " 404 355 594 579 453 447 400 473 530 435 415 620 559 456 434 501 390 402\n",
      " 301 672 463 392 596 360 474 498 325 379 603 529 568 441 464 447 645 615\n",
      " 520 467 540 451 423 594 596 403 473 382 586 475 355 695 366 461 471 424\n",
      " 441 767 515 327 483 579 686 570 345 484 629 527 404 816 585 472 595 586\n",
      " 354 442 390 449 489 494 584 656 401 373 432 542 350 626 533 435 570 682\n",
      " 378 375 495 504 435 561 673 413 309 340 367 441 441 565 350 444 399 535\n",
      " 416 282 432 426 566 451 375 330 671 311 678 490 493 559 518 491 522 451\n",
      " 431 287 387 509 365 366 341 419 629 502 322 470 358 412 509 422 718 495\n",
      " 446 597 444 588 610 551 593 422 513 447 437 451 482 485 450 548 393 498\n",
      " 562 642 417 626 529 466 457 547 413 407 348 454 716 473 440 476 661 453\n",
      " 476 466 527 597 548 518 386 612 557 482 607 454 376 418 504 348 453 359\n",
      " 461 461 480 457 500 564 402 588 630 556 459 370 470 713 312 522 491 365\n",
      " 519 521 450 357 499 502 525 555 550 415 493 441 369 412 549 429 399 536\n",
      " 475 420 484 533 487 492 418 682 600 448 564 407 407 420 651 525 607 577\n",
      " 383 497 469 454 518 330 529 575 425 476 390 325 466 581 527 470 371 499\n",
      " 466 458 608 422 428 440 647 473 517 701 370 346 458 394 362 420 356 327\n",
      " 586 570 409 577 488 536 564 400 448 408 575 355 376 453 432 432 516 646\n",
      " 667 578 416 425 418 396]\n",
      "bias_q:  [  2377   5635   1255    -75   5290   -485   2201   3282   4926  -4044\n",
      "      3    715  -2683   3070  -1300     65    216   6381   3623  -1674\n",
      "   5053  -6916  -2271  -3035  -8350   -685  -5093  -3145  -5368   3737\n",
      "  -3173  14094   2496  -2771  -5939   1910    580  -1105  -3207  -1589\n",
      "   4947   1339  -2434  -2310  -5406  -3497  -9595    625  -1253   8001\n",
      "  -3602  -6414   1056   7230   1959  -1369   8569   3635  -3149   5013\n",
      "    553   8908   7052  11275   6221  -2878   4410   9918   3554   1272\n",
      "  -6522   -376  -2568   -678   4595  -1290   2322  -7213   5254  -1749\n",
      "   4984   5638  -8016  -9009    661  -5060  -2831  -6922  -7755  -4516\n",
      "  -4478  10499  -6014  -9514   1134   2351  -3705  -4911   3080  -1089\n",
      "   7736  -1190   7939   6533  -3230  -1699  11373  10953    -14   7009\n",
      "   -121   3101   3893   1473   1453   -650  -3090   4732   3225  -4913\n",
      "   -640    757    922    660   2307    101   5760  -1621  -7383  -2875\n",
      "   1746  -4853   3036  10788  -4009   1167   2180   2561  -5139  -1176\n",
      "   3681   2429  11532  -4988   2331  -5077  -3870    554   3466   1886\n",
      "  -3950  -5635  -2370   3786   1015    571  -4461  -4684  -1933  -9264\n",
      "  -3872   3255   5570  -3081  -6846  -4134   7461   3761   -243  -4750\n",
      "  -5187   4610   3424    962   4528  -1660  -3309   2169   6213  -3339\n",
      "   -655   3159  11083   4569   4161   2913   8469   -903  -1035   -970\n",
      "  -4792    492   9682   5638  -7459     -3   3761  -1169  -3822    818\n",
      "   -776  -5534  -3663   2939   4742   5499   2750  -1596  -5493  -1490\n",
      "  -3414    149   3376    177  -4453  -2412    748  -3899   9885    308\n",
      "   3034   3555  -1721 -12255    668    433  -2374   2124   8936  -3414\n",
      "   1449   2397  -6948  -2800  -3318   -577   -751  -3440  -1901   6983\n",
      "  -5503     35  -3433  -1371  -6282  -3199  -2676   2462   1524   3980\n",
      "   8017   3591  -1883   1477   -333   6580   4890   3506  -3540   -347\n",
      "  -2262   1476  -4075   1878  -3847   3634  -7937  -5558   -316  -8997\n",
      "   1485   5974   3778  -4413   9350  -3845  -7316  -2897   -206  -2123\n",
      "   3362  -1067  -3332  -3958   -978   -612   1220   -292   4908    872\n",
      "   -266  -2047   4048  -2088   4589   3470   -169  -3345  -1980   8394\n",
      "  -1437   1576   1965   3215   9575    334    667   2427   2993  -6159\n",
      "  -2307   1199    280    387  -1522   5165   4539   1989  -1235  -5517\n",
      "   7344   3730  -6770   3341   -509   1760  -6394  -2380   6522   6618\n",
      "  -3753   8298    284   4873   3219    -70   4527   1708   8727   -885\n",
      "   1084   -650  -3175   4549   6543   1749   1929  -3020   6184   3044\n",
      "   1644   2847   1543   5445   9083  -3499   7581   -916   -468   -702\n",
      "    677  -1934  -1573  -2886   3848  -8713  -3288   -140    733   5594\n",
      "  -3558   1631   3432   1141    308    988  -2705   -517   1115   7622\n",
      "   3062   3318  -1303   8158]\n",
      "inc_q:  [4245 3016 2959 2954 2852 2865 2760 2814 2201 2449 3066 3830 2822 3433\n",
      " 2624 2759 2711 3761 3271 3232 3069 3372 3261 3193 2077 4415 2782 2685\n",
      " 2602 2733 2339 3113 4259 3632 4386 3543 2788 3437 3061 2543 2194 2904\n",
      " 4254 3501 1990 3196 3162 3224 4073 3124 2980 3889 2450 2777 3639 2564\n",
      " 3025 3440 3217 2909 2004 2612 2167 2283 2030 2769 3424 3454 2125 3485\n",
      " 3470 3644 2887 3698 3279 2182 3024 2642 2765 2656 3447 2465 3561 2463\n",
      " 2891 2974 3112 2862 3180 2984 2368 2946 3924 4037 3428 2045 2112 4303\n",
      " 2846 4007 2803 4174 2498 3247 2920 2819 2898 3616 4121 3767 3457 2644\n",
      " 2440 4595 3660 2749 2225 2292 4481 3854 3324 3366 3246 2340 2708 3467\n",
      " 2063 3485 3573 2785 4311 2663 3263 2573 3590 3338 2272 3879 2901 3265\n",
      " 3200 2716 3648 3905 1516 4424 1721 3262 2641 3889 3258 4038 1853 1932\n",
      " 3439 3525 2900 3477 2908 3420 3086 3792 2944 3348 3222 2460 3540 3100\n",
      " 2858 3713 2544 2590 2838 2770 3168 3405 3544 3432 1679 3154 2640 2421\n",
      " 1957 3010 3257 2834 2121 2715 3059 1847 1996 3078 3848 3462 3813 2761\n",
      " 3203 3706 3169 4465 4077 2985 2249 2968 1718 3680 2259 3603 2913 2866\n",
      " 4792 2261 1735 3796 3918 2542 2744 3855 3483 2979 4753 3472 3430 2766\n",
      " 3167 3172 3550 2563 3190 2671 2991 3171 2409 2028 2010 2892 2954 2514\n",
      " 3351 3396 2899 2767 2907 3817 2434 2839 2724 4253 2224 2572 2931 2701\n",
      " 4333 3000 3458 2784 3026 2089 2947 3160 2870 3176 4065 2520 3916 2728\n",
      " 3769 3462 2710 2963 3945 1886 4194 2815 2154 2976 5236 3694 3536 2821\n",
      " 3160 3210 2846 3255 4780 3101 4350 2523 2196 4910 2401 2009 2001 3661\n",
      " 3582 2595 1892 3476 2621 2537 2090 3116 2850 4541 3549 2426 2118 3844\n",
      " 2322 2977 3381 3627 3079 3607 2481 2489 3320 3803 2984 2487 2552 2783\n",
      " 3253 2720 2594 4137 3930 2335 3040 3181 3898 2566 2498 3381 3135 2213\n",
      " 2627 2791 2938 4080 2584 3589 2763 2402 3134 3515 1823 3265 3063 1523\n",
      " 3134 3583 2657 2413 2498 2373 3115 2094 2828 3122 3572 3398 3066 2772\n",
      " 3768 1997 3520 2797 3371 2136 3675 4141 2959 2798 2329 3047 2155 3138\n",
      " 2838 2862 1813 3173 1889 2046]\n",
      "bias_q:  [   3992  -96436  -66890  -37429  101002   62752  106666  124980  100251\n",
      " -119925  -48955   33346  114205   28254  120234   85052   88570  106369\n",
      "  -76847  -53668  -97880   39053  118416  -54225  144070  -64553  -98346\n",
      " -121635  -85253 -111026  -89510   94183  -11055   -8839  -32606   17734\n",
      "   18004   34466  -99264   54244 -135133 -117244  -30909  -62136   97454\n",
      "   23600  -76168   64514  -72291  -91738  -58849  -49306 -109563   58161\n",
      "  -71930   85656  115036  -52455 -110526   72190  149698  -60236 -115935\n",
      "  123239  120986 -105492   85042   93797 -114577  -10953   48313   56652\n",
      " -106707   13080   88638 -102561  -94069  -95961  116103 -100855   85306\n",
      " -131577   16369 -133642  -99199  -27515   27380 -106907  -20246 -106133\n",
      "  111074  -11745   75231  -47194 -102317 -145082  114729  -90516  -70605\n",
      "  -54782  120134  -39211  122671 -110094   37537  -94382   62025  -60643\n",
      "   55822   30358  -94985  109738   98210    -495   53623    -919 -119383\n",
      "  112342   55408   43511  110336  -68103  -82345 -107811  -85851   69404\n",
      "  131467   42093  -34099  -74123   32526  -62053   84608 -133054  -53597\n",
      "   -9205  122434  -73907  -55211  -39045   31711 -122240   70145    3155\n",
      "  127806  -42054  102697  102200 -119855  -42992  101138  -17848 -143863\n",
      "  102498   76329   27388 -108802   40007   70994  -74210  -90141  -54657\n",
      "  -73866   56722  139191  116221   75372 -102793  -82707  107647  -81493\n",
      "  -69714 -123541  -31677   16314  -67341   50953   45885  136397   -5320\n",
      "  -92342  115630  136143  118069 -101131 -105988 -115425   60395  -81462\n",
      "  103774  109120  -87146   24602  -73644  -16346   60541   82894  -37162\n",
      "   68869  -34325  -28240 -100082  -81352  -90804 -127299    7417  116312\n",
      "  -65454  -91713  -22969  -23194  123316 -123937   -7167 -111532   92772\n",
      "   82495   87383    9663  -19503    -781  -87459   99647 -101637  -62783\n",
      "   52221  -86274   81385   40126  -92702 -107757   75217 -114260  124231\n",
      "  129387  -98115   68641  122958  -56092  -42649  -35773  -96870  -75230\n",
      "  -60593  -87765  -96495  101462    4225 -136619  126490  -73568   68618\n",
      "  -32420  119047  -80436   47924  105582  116850  117733   96767   63973\n",
      "  129346  -33369  136825  -98280  -68349  -57854  -22689  -78028  109316\n",
      "   72017 -130922   41358  105179 -132676  -76236  -28301   35316   62722\n",
      " -109987  103433  112960  115171   84745  -29927 -101233   72988  109752\n",
      "  122219   25279  121461  135680  126856   18542  -29720 -153835  108138\n",
      "  -99591 -122349   89499  107960   48686 -134773   -5275   14957 -128325\n",
      " -142754   96562 -142833  -96470   64930 -109508  105923   23380 -134838\n",
      "   98378  -56794   95350 -101456   98213   88353  -86188   -3687 -107602\n",
      "  -84234   80667  100951  132336   84718  -32444  -89013 -128983  -75142\n",
      "   99708   71146  -86414 -107886  119197  120828   42303  -91403   95627\n",
      " -113839 -103430   72768   61548 -129894  -80122   20693  132800  -99277\n",
      "   32217 -108336 -109976 -145488 -101434   73308  116035  -75643  -91400\n",
      "   -9450   94295  -52326  103564   79534  124598 -132051  124052   35283\n",
      "  127484 -109181   79810 -132489 -114447  104055   80564   94645   71978\n",
      "  115218  132321  131220  105316 -124225 -127831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h mod simd != 0\n",
      "inc_q:  [390 422 403 448 498 443 405 419 345 427 340 399 464 353 461 428 490 525\n",
      " 377 528 436 467 424 458 526 512 540 393 419 415 457 501 357 423 521 385\n",
      " 361 418 426 412 494 448 398 471 469 451 469 434 434 342 473 412 441 415\n",
      " 385 339 438 401 451 353 420 430 418 478]\n",
      "bias_q:  [ -87795  -61158    3399 -110352  -79316  107570  -43383   31079   13471\n",
      "  133555   17508  -48132 -113029   19115  118430   80583  -70703  103516\n",
      " -135507 -140719  -77274   71853   -1523   45147   32234  118353 -168648\n",
      "  -95176  115432   61691     869 -164675   89225  -73320 -117889 -112150\n",
      "   32957   80918   28952  -34773 -140588  -97063   87106   12935  -94193\n",
      "    7013  -35051   78801    8042   31960  220802  -62425   33838  -93534\n",
      "   36649   92463   -9442  -68394  -81495   52061   -2757  -65761   81219\n",
      "   -7488]\n",
      "inc_q:  [361 345 344 419 380 355 290 303 275 286 424 324 322 276 340 398 310 251\n",
      " 411 395 509 290 363 423 305 353 331 292 308 268 313 353 227 329 218 305\n",
      " 383 410 309 349 479 375 374 278 310 300 211 252 373 305 286 349 332 266\n",
      " 357 337 313 291 412 328 484 304 245 226 376 324 346 265 265 373 366 432\n",
      " 345 374 332 281 354 263 317 505 349 241 413 306 331 257 316 243 266 406\n",
      " 435 322 225 340 330 232 248 263 457 314 332 308 274 483 286 337 423 320\n",
      " 256 179 252 304 262 316 292 442 304 428 326 248 335 434 313 363 286 386\n",
      " 295 251 480 350 314 382 495 304 288 345 218 393 377 230 335 303 270 340\n",
      " 362 396 238 294 281 255 335 257 404 300 242 478 309 271 323 270 382 365\n",
      " 269 176 396 322 270 357 268 405 355 261 169 256 311 313 192 245 240 362\n",
      " 370 340 306 196 268 311 329 358 425 239 291 283 398 226 355 332 223 274\n",
      " 314 265 404 237 272 263 423 304 260 314 217 213 324 301 367 293 255 340\n",
      " 228 373 257 345 261 303 246 293 425 347 329 281 318 430 314 236 371 405\n",
      " 399 295 435 241 231 303 273 363 364 305 227 349 233 336 436 317 240 313\n",
      " 332 294 248 240 221 304 296 407 322 335 223 398 420 201 332 333 267 297\n",
      " 264 268 385 427 256 328 312 357 283 246 323 347 343 311 270 253 318 308\n",
      " 300 483 326 358 334 312 296 282 213 262 416 300 224 320 287 333 242 225\n",
      " 336 388 238 209 380 292 397 293 232 422 334 329 378 467 336 332 198 303\n",
      " 364 273 385 291 226 371 291 344 306 253 245 281 377 284 246 337 458 288\n",
      " 210 378 309 445 424 308 352 359 394 305 370 342 215 240 237 299 323 280\n",
      " 330 402 381 366 223 344 275 404 286 359 502 311 219 295 294 358 324 465\n",
      " 437 304 348 309 313 281]\n",
      "bias_q:  [   937  -2261   2798   -498   7748   8039    164  -1689   4947  -4878\n",
      "  -3173  -9732   3112   3351    763  -1672   2646   2198   -894   7192\n",
      "  -4557   4290   1810   6950   6915  10044   4189   3665   5348  10940\n",
      "   1514  -3793   1029   1820   2396  -1733   4099   2353  -2414  -1437\n",
      "  -5040  -3670  -4423   5675   1071   1767  -5825   2489   -384  -1307\n",
      "   1230  -1802  -8039  -2341   7091  -5026   6384  -1515   3900  -3801\n",
      "   5690   6988  -4582   2965   -560   2085  -6509  -9599   1405   2442\n",
      "  -1610   1830    559  -3555  -2770   2699  -5709   7942   1539  -4109\n",
      "   2131  -3147   6339   1390   2116  -4745   2431   3052   6141    786\n",
      "   3114   1572   2852  -3525   7807   5366   2311   3295  -1366  -2792\n",
      "    486  -1826   4238   -183   5790    680  -2502   1107  -6843  -2880\n",
      "   3223    472  -1196   4174   -375   6131  -2475   2687    183    190\n",
      "  -2984   7298  -4869    385  -1297   3740   2089   2750  -2890  -1651\n",
      "   4374  -6243   2219   4052  -2870    469   3410   3162   2682   -216\n",
      "   -383  -6468   1906   -215  -4581  -5304   3709   -551  -5959  -7010\n",
      "   1541   9202   2613   -798  -2252   1501   -501   2301   1887   -802\n",
      "   7558  -8472 -11286   2934   4436   4338  -1253   -549    334  -8218\n",
      "    829   2916  -7434   -379   5483   2701  -2021  -1887    390   3192\n",
      "  15411  -1667  -2308  -2335   2739   2551  -5795   2119   3420    611\n",
      "   4239   7058  -7358  -6958   1692  -4090    288    359   -326   1352\n",
      "  -1222   2555  -5912   2013   4001  -1488  -2953     33   4360    755\n",
      "  -5106   5830   5678  -2267    995  -1451    186   5259   4526   -359\n",
      "  -5365   1387   2321  -8688  -1052   2347  -3768  -4300   1127   1204\n",
      "  -2432  -2952  -1875   3364  -1686  -4207   -800   4148   -760  -2601\n",
      "   3584  -2214  -4274   1539   3583  -3325  -7520   1086  -1837 -10849\n",
      "   -420   4214  -1240   5704    413   1272  -7408   8789   5189   -197\n",
      "   6582  -1304   -431  -2465  -3602  -2049   -295    984   3193  -4402\n",
      "  -2501  -1807     44   2199     45  -2226   -906   8097   8718  -1640\n",
      "  -4957   2061   2266   2651  -2319   5984   5251    576  -2528   1546\n",
      "   2734  -3539   -515   3804   7791    441   -258   3021   6263   8910\n",
      "   1089   2492   1219   4826  -4478  -1432  -2685  -2290  -4296  -4237\n",
      "   5514  -4490   -804   2490  -1487    884   1374  -5499  12584   -907\n",
      "  -3076   4157  -2870   2045  -4030  -9589  -5900  -3512   3099   7597\n",
      "   -625   1532   5402    626     27   2285    291  -4966  -5990   6079\n",
      "   1439  10573  -2411    137   6896    795   3305   4173  -9389  -4712\n",
      "   1094  -5611   4891   1062  -2312    460    397   1530   4650   -423\n",
      "  -3831  -2133   3087  -3483   2799   2045  -3755   6494    702   2351\n",
      "  -2640   1610   3513   1814   5237   2052   5934  -3072   2556  -5879\n",
      "   2372    532    316   -524]\n",
      "inc_q:  [3530 3934 3978 3016 2632 4372 2698 3324 3035 3955 4922 3291 3908 3548\n",
      " 3112 3065 3276 2853 3473 3404 3685 2560 4632 2363 2360 3577 3341 4686\n",
      " 4834 4524 3654 3412 2542 2877 3085 2627 3200 3105 3458 2431 3439 3272\n",
      " 4157 2717 2676 3183 5106 4035 2675 2259 2215 2551 2660 4169 4179 3312\n",
      " 3814 2531 3945 3497 3329 2693 3574 1884 2946 4352 2857 2634 2175 3809\n",
      " 3189 3433 3128 4594 4652 2901 3218 2353 3041 3029 3767 3179 2348 2784\n",
      " 2586 2496 3243 3087 4420 4509 4018 2595 3850 2313 2943 1953 2124 2305\n",
      " 4729 2600 2754 2370 3058 3716 2246 3610 3307 3259 2849 2238 2093 3131\n",
      " 2344 3804 2408 3621 3967 3438 3437 3178 2305 3567 3413 3981 2989 4117\n",
      " 4158 2364 2527 2829 3211 3680 3147 3771 2823 4579 1915 3893 3440 3587\n",
      " 2995 3781 3903 2726 3024 3464 3101 2387 2134 2630 3637 1874 3152 3861\n",
      " 4071 2705 3024 3266 3637 3684 3798 4278 2713 2526 4184 3404 5413 3499\n",
      " 3723 3864 3648 3989 3722 3016 2367 3141 4061 2746 2321 3426 3113 3591\n",
      " 3346 3208 3736 3939 3088 2921 2932 2314 4103 2829 2968 3848 2985 2992\n",
      " 3058 2061 4340 2602 3587 3178 3528 3224 3568 4105 1932 3018 1999 2866\n",
      " 3178 4023 3628 2568 2547 3481 3251 4483 2672 3031 3220 3922 2887 3449\n",
      " 3461 3445 3564 2483 2004 4878 3274 2489 4113 4087 3716 4985 2845 2652\n",
      " 1808 3408 3406 3272 2375 4256 2321 3694 3561 3731 4161 3201 3729 4303\n",
      " 3715 1911 4216 2681 2384 3528 3307 3041 2232 2357 2718 2767 3588 2881\n",
      " 3062 4051 2267 3763 2727 3941 3341 4381 5608 3344 2721 4037 2760 3071\n",
      " 3069 4019 2382 3825 2357 4064 2342 4445 2304 4289 3094 4035 2367 3182\n",
      " 4326 2389 2138 3285 3021 3062 3276 2801 3071 3446 2452 3966 3121 2790\n",
      " 2968 2729 2177 3880 3191 3078 3386 4144 2825 4473 3739 3920 2625 2076\n",
      " 3209 3947 4336 3370 3490 3472 1790 3319 4135 3941 3611 2894 3659 2219\n",
      " 3231 2341 2467 2327 3495 3111 3315 4302 3040 3904 4668 3816 3022 4380\n",
      " 3783 3142 3568 3101 2391 3922 3169 4888 4736 4520 3352 3064 3716 3249\n",
      " 2819 2936 3416 2866 3599 2597 4198 4124 2010 4083 4071 4837 4228 2691\n",
      " 3619 2713 3030 4030 2482 3267]\n",
      "bias_q:  [  65061   62519  -74653  119326  129539  -36947 -112478   -7695  -97962\n",
      "  -35845  -25787 -115685  110282 -105578  112469  115346  -57312  120867\n",
      "  -33677  -73594   24949   88668   28136  135734  115874    8529  -61144\n",
      "  103688   16679  -55898 -115174    4908 -109384   96743  -95178   93899\n",
      "   74445  111541  -76029  113364  -18010   76971  101546   55582 -115626\n",
      "   92422   47112  -49285 -102782 -111449 -129429   74821  114687  -97244\n",
      "  -23240   90547 -105032 -117557  106125  -33245   16895   94863   20187\n",
      "   95354 -105153  -16926  116811  134681  117638  -48377   52147  -11381\n",
      "  117929    1549  -11164  118573  -74904  105839   83556  -29420   75983\n",
      "  -89811  106554 -103791  134609  101592 -110286  -95066    7363  -72099\n",
      "  -15197  114916   -6996  134586  122778 -119145 -114580  135142  -39602\n",
      "  -83811 -144394 -122679  -83779  -75271 -120222 -115439  111030  -18389\n",
      "  -73104  122795 -128588   93040 -108448   99585 -127260   96581  -52250\n",
      "   59652  -94029  -59329 -118543   32782  -98873   -2460   64343   22194\n",
      "  -62357  102012  -59512 -103621  -89894  -26610   61432 -128432   76954\n",
      "  -89763 -111322   46998  -79837   14345  113730 -100570  -60296 -135805\n",
      " -118551 -110400   91908  131323 -104154  -96721  -57122  136681   77305\n",
      "   83383  -14045 -132180   41260 -101312  100050 -106309  -40374  -18638\n",
      " -119069   81507   65057  -94526  -10064   70288   62209  -61610  -22223\n",
      "  -64482  -79011  -49736 -123022   98616  -15048   72506 -110631  -85517\n",
      "   69188   93048  -95959   90713   78308  -20100  -47585   84557   96922\n",
      " -116738    2357 -110035   -5459   62103  141447   92734  -53604  132933\n",
      "   21129 -123352   81044  -71110  -85935  -96547   30786  -91799  116387\n",
      "  -96950  117575  -58363 -105466  -16770   97424 -115710  120481    9835\n",
      "  -91775  -29258  -75494  -61434  -84436  -38215   64326  110219   14729\n",
      "   25116   -8737  106103  133199    -468  -56791  117004  -73221   29400\n",
      "  -80114   11821 -118795 -105180  123416   98078  -94983   84285  118659\n",
      "  -13724 -124644 -102102   43823   47748    6719  -85626   76427  -67612\n",
      "   -1303  130845   16881  -83173  110232   49444 -104182  100722  146202\n",
      " -109696 -125041  102151   55021  115036   75453  104280  120821  -61510\n",
      "   71327   -5495   97624   65357   -6929  -82558 -119454  -10479  101114\n",
      " -102934  -84921   64805  121355   55823  129185   -8868   96035   75683\n",
      "  113150   -4361   50108    6488  120243  100292   -8233  112955 -121959\n",
      "  -58154   31127   85175  -70306  -86596  -99828   89952 -113258   52248\n",
      "  106199  113931  -94880  112958  115389  -48923   99444 -101920   58369\n",
      "   84933 -123629  -49701  -45272 -132604  104489  114777  -74732  103529\n",
      "  -22479 -107532   71951  -77943  129771   82114  -71593   57596   55800\n",
      "  107983   72495  120762   -8613   86313  103936 -115894 -131719  -91502\n",
      "   61566  -53692   93700    7885  -20775  -31185  -92059  -15640  -44976\n",
      "    9775  -50963  118810   85517  -69085  120431   28312   32929  -31865\n",
      "   89530   -7966   68709   26944   94968   73650  -80257   53100  -87257\n",
      " -109903   36616   71964  125511  -58387   62667   40347  -33622  107177\n",
      "  122688 -111800   10514  -10927  123805  -93865]\n",
      "h mod simd != 0\n",
      "inc_q:  [485 393 476 431 418 430 496 469 476 425 432 503 437 523 439 453 565 447\n",
      " 512 325 498 427 500 412 452 453 342 397 359 385 376 406 410 542 424 516\n",
      " 433 443 364 426 460 468 444 364 446 438 512 474 390 348 407 445 398 513\n",
      " 417 343 451 434 420 429 498 452 363 471]\n",
      "bias_q:  [  28903  -81456   52920  -76512     261   -2415   62949   73138 -113478\n",
      " -109305   11611    9125  -81842   43380 -110027    4273   -4635  -99558\n",
      "   72549   60517  -99829    3699  -27591   56592   18674 -169420  -47862\n",
      "  133347   68026  -65457  -25114   36552 -159442   -5383  -30263   -9500\n",
      "  -85635   41999  -34110   22838   16220 -169100  -23457  -49246    5306\n",
      "  -12422 -150308  -30370   57166  -97018  -26007    5040  153061   51476\n",
      "  -21651  100785   73327   -1570 -152566  -51352  105743   81372  111720\n",
      "  -44248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inc_q:  [234 245 331 256 263 315 287 308 325 185 259 300 313 251 214 275 223 237\n",
      " 425 333 291 317 267 341 229 292 327 248 213 249 258 352 422 282 240 236\n",
      " 165 313 312 304 222 232 247 273 234 324 310 204 278 383 210 280 250 233\n",
      " 288 306 358 256 311 185 296 266 420 289 250 206 277 281 338 269 271 383\n",
      " 284 335 255 328 213 232 232 319 282 239 201 300 368 182 304 281 227 312\n",
      " 230 282 324 266 222 247 426 251 242 261 314 333 312 182 196 261 276 224\n",
      " 349 204 210 254 313 253 281 217 208 339 290 183 322 350 237 391 193 234\n",
      " 353 281 230 211 318 342 268 333 318 299 256 272 300 271 296 301 236 208\n",
      " 229 314 300 271 261 209 253 212 200 242 193 298 262 204 219 267 244 353\n",
      " 382 286 233 264 237 375 200 328 250 317 179 283 189 268 196 277 326 227\n",
      " 206 197 349 263 270 308 256 250 249 210 265 197 231 325 301 338 337 339\n",
      " 222 215 278 274 206 225 359 213 337 279 362 226 287 264 258 346 204 339\n",
      " 266 301 263 298 204 268 253 192 266 336 329 314 229 340 393 268 325 253\n",
      " 303 282 224 369 268 389 249 206 214 220 289 376 216 252 343 214 259 341\n",
      " 379 219 281 339 245 263 331 290 220 236 298 384 208 332 236 345 274 231\n",
      " 186 250 323 228 279 364 198 277 304 264 249 229 314 213 430 388 207 329\n",
      " 395 188 255 287 303 352 258 261 276 246 214 276 223 282 322 248 309 228\n",
      " 275 278 283 158 384 263 205 307 262 222 345 205 306 205 332 235 307 285\n",
      " 208 260 267 311 251 336 299 330 243 243 310 229 297 374 274 271 254 324\n",
      " 315 335 354 238 336 281 264 341 385 228 287 348 245 355 274 285 233 315\n",
      " 321 247 242 313 265 245 221 238 200 244 231 328 201 241 179 273 165 264\n",
      " 319 258 186 267 244 262]\n",
      "bias_q:  [  7670  -3799   1908  -1984   1300   7774  -1729    403  -8429  -3046\n",
      "  -2083   1360  -3018   2326  -1548  -3176  -2555    875   2314  -1265\n",
      "   2201   9760   2255  -7969  -1457  -3040   9696    197   4979   3878\n",
      "    725   7648    483   5520  -2614   1679   -245   7643   3847   1632\n",
      "  -2225  -4051  -2944   4759  -1828   3093  -4694  -1128   4032   6647\n",
      "    517    535   5421  -6920   5532   3076   5855  -7672  -4113   4913\n",
      "   1515  -4860  -4008  -3099  -5057   5815   1431   4728  -3589  -6240\n",
      "  -1497   5612  -2318   3535  -6636  -1481    499    765   9456    305\n",
      "   3256  -2973    535  -1903   4837 -10109  -4484   1802  -3805  -3750\n",
      "   4995   -815  -9298    117   -304   4488   5653    421   4853   2753\n",
      "   -581    190  -2645  -1664   2433  10475   1941   3781  -4383   1900\n",
      "  -5181  -4079    330   4902  -7684  -2416  -6685   1956   3815    985\n",
      "   1164   2215  -3561   4921  -4472  -3116   1440   5309  -4915   1424\n",
      "   -543   1364    208    682   2358   8507   1636   -209   -300   6367\n",
      "  -5228    830   3706   -845   5149   1000  -4720   -838   -806   -580\n",
      "   2115    711  -4790   5068   4287   4486  -4918  -8252   4259  -7064\n",
      "  -7059   1838   2202   5708    229   2246   2780    695  -3098   1426\n",
      "   -107  -1714  -2202   5854    785   1853   2317  -6829   1136   1771\n",
      "   -946  -7893   6516  -4898   1922   4012  -3298   4425   2915   1180\n",
      "   -658   4768  -1151  -5016  -4242   -693   8363  -6336   -612  -7029\n",
      "  -3165  -5329  -1652  -2703  -6383  -5172   -572  -5388   -371   5285\n",
      "  -2852    106  -1975   3808   4518   1112  -1372   5460   -716   3816\n",
      "  -9563  -8993   1280  -1293   -868  -1821   6509   3285   2835  -2103\n",
      "  -3655  -2610   1114   1365   5615  -3373   1811   1400   5055   4506\n",
      "  -5203  -1908   -278  -5235  -2597   6249   7593   4213   3507  -8273\n",
      "  -1902  -2550  14240  -4301  -3140   4352   4446    368   5275  -5299\n",
      "   -894   2275  -2095   -692   1564  -3710     82  -4130   3116   3794\n",
      "    -32    696   7027  -1177   1313   4245   3618   -250  -1244  -4543\n",
      "   5077  -3321  -2478   -855  -2192  -1978   1978  -1604     -2    881\n",
      "    767  -4306     64   3215  -5315  -3094   9653  -8248  -2901  -3082\n",
      "   -515  -2515   5290  -5910   -540   3361   1370  -6029   3940   3167\n",
      "   1208    140  -1211   -935  -2204   2866   9679   -533    -66  -2991\n",
      "  -8741  -1976  -2492   2316   -509  -4844   5151 -13233    816  -1529\n",
      "    164  -3681    -65   4283  -3953  -2198    660   -194    282  -1249\n",
      "  -1733  -3513  -3101   1602   1204  -4774   1702  -7164  -4639   4488\n",
      "   4982  -2857  -2786  -8315   4214  -2241   -376   4424    982   1500\n",
      "  -1816  -3706   2896  -2252   8577  -1058  -4813   5639   1240   5934\n",
      "   5964   1709   -958     -6    -54  -4588  -4563  -5305   -414    141\n",
      "  -2528  -1913   1350   6540]\n",
      "inc_q:  [1964 2303 4101 2667 2813 3275 3766 3162 3282 3378 2666 3528 3666 3725\n",
      " 2701 3253 2713 2365 3197 2698 2580 2264 2629 4474 2554 2763 2960 3480\n",
      " 3636 2914 1872 3408 2797 2011 3637 2748 4669 3942 2989 2904 2892 2855\n",
      " 4400 1935 3069 4170 3732 1762 3997 3399 3328 4106 2230 2206 2525 2606\n",
      " 4013 3697 4032 1617 3442 3095 3239 3880 2300 2388 2940 2219 3205 3384\n",
      " 3361 3376 2372 3427 3451 4768 1965 3079 2112 3436 2810 3153 3597 2083\n",
      " 3446 2703 3732 3250 2951 3844 2508 2685 4769 2962 2319 3624 3427 3126\n",
      " 2164 2567 2574 2842 3698 3503 3095 2524 4368 3919 3248 2181 2494 3586\n",
      " 3580 2943 4157 3433 2088 4411 2782 3066 2992 2423 3158 4154 2274 2557\n",
      " 3695 3097 3788 2063 3403 3024 2406 2430 3145 2421 3618 3909 3224 3789\n",
      " 2640 3511 2413 4586 2085 3729 4451 2090 2276 3003 2572 1843 2353 3329\n",
      " 3127 2415 3075 2938 2200 3364 3717 4156 3010 2040 3290 1923 2376 3189\n",
      " 2347 3850 3722 3738 2951 3257 1599 3564 3116 3589 3392 2936 3413 3991\n",
      " 3114 3740 2535 2895 3174 3355 3557 4332 3058 4007 3984 3062 4355 2628\n",
      " 3253 3803 4350 4008 2678 3709 2693 4016 3717 3086 2917 3554 3413 4341\n",
      " 4242 3126 5421 2632 2014 2726 2813 2238 2813 3177 2352 4000 4942 4395\n",
      " 3801 2478 3144 2093 3107 4521 3603 2147 3418 2076 4674 3370 2184 2717\n",
      " 3662 2441 3081 2777 2314 2435 2336 3146 2363 2674 1922 3327 2481 2969\n",
      " 2148 2399 2694 3736 2522 3610 3629 4043 3188 3704 3671 3897 2689 3238\n",
      " 3380 3732 3105 3423 2627 3493 4350 4525 2692 2937 3449 2438 5114 3708\n",
      " 2283 3663 4270 3528 3252 3353 2793 3417 2779 1915 2445 3628 3499 2525\n",
      " 3934 2873 3988 4334 3878 3978 2320 3212 3440 3797 2993 3936 3104 3435\n",
      " 2180 1876 3306 3432 3980 3644 3126 2273 2861 2628 3421 2601 3649 1971\n",
      " 2972 4070 1988 2269 2699 3061 2689 3058 4204 2779 2899 2783 3272 2822\n",
      " 2538 2810 3018 3265 2717 2811 3757 3305 2720 3509 3677 2522 3020 2796\n",
      " 4393 2297 3662 4251 3416 3868 3551 2390 2341 3160 2909 4612 2310 3709\n",
      " 2634 3054 2954 2293 2878 5339 2733 2639 2568 2137 1723 2327 1854 3347\n",
      " 3712 3436 2772 3405 2002 2736]\n",
      "bias_q:  [-118649  144990  -72512  -53516 -123617   31568  -13080   19379  -86962\n",
      "  -82796   51861  -59690  -42178   17148  122692 -111092  -70044   99378\n",
      "  -83584  -65661 -121421 -121738   94887   41536 -117468  107953  136705\n",
      "  -91838  -22544 -117923  123866  -19364  -70065  114039   85920 -107113\n",
      "   42694   77470  106845   98462   -6396  -94687  -14530  122548  -87419\n",
      "    6994  -28864 -122983   17997   56440    1624  -80090  129765 -110970\n",
      "  115180   69053  -38281  -12994  107354  119924  -55844  -91085   96670\n",
      "   84446  108593  100973   -3125  114313   91667  113564  -47266   91127\n",
      " -111830  -37924   -9005  -11115  117416  105808  116509   83395   98670\n",
      "    -968  -92846  136056  -14192   52339 -104028  -88233    9904   53969\n",
      "  129423   67916    3313  -84174 -105659  -12535   90962   75708  106630\n",
      "  104294  121400  127130   -7748  -84979   79242  121200  -76600  -78455\n",
      " -100683  135722 -116832   48923 -111922 -101569  -80531   68935 -111601\n",
      "  -20863 -108619  136221   84205  121380  -95087   62447 -111520 -107054\n",
      "   45523   43359  -54885  133995  -65919   29851 -115898 -126456   19703\n",
      "  117062   39960   -2039  -46086  -75877  112343   38642  -97933   -2645\n",
      "  -93504  -44299   27184  121359  106881   98672 -122540  131257  -92908\n",
      "  -80363  -75180   92224  -93898   99070 -112738   17288   70837  -35058\n",
      " -103957  103396   75866 -124542 -109040   69355 -101732 -106014   75426\n",
      "  -15675   27796   12379 -133584  -70177  -41914  -91357   79140  -95043\n",
      "   31655  -93924   70995  -29852  129007  121805 -107845  -72093   69186\n",
      "  -57306 -133270  -39680   75936  -55732   50860  144853  -77617  -83499\n",
      "  -23087  -35582   31573  -77110   55333   52547   77363   78033   82356\n",
      "  -99546  117577    8473   69412   -8186   58765 -129223  -93987 -106844\n",
      " -109303  149503   95572  -95403 -128654  -85689  -32187    -306  -46924\n",
      "   70342  102174  103197   69019   28796 -112191  135190 -102515  112116\n",
      "    7484   76152  105587 -120301    2373 -114649 -108915  122694  129066\n",
      " -130825 -116926   98440   84992  101554 -134513  -98525   97558  -79777\n",
      "  117397 -121517  -51612  -73982 -114807  -68111   62364   70567  -89453\n",
      "   -2764   51920   14237  118961   48832  -83068  103509  -16472   93189\n",
      "  106982  -46299  -46825   61711   81788  -96106  -89362  136355  -49156\n",
      "  -49128   93384   20078  -24573   96273  -47058  -89244  109368   25202\n",
      "  153674 -130665  111390  -13804   25118  103400   25909   78290  -48047\n",
      "   15132   79069  -87496  109053  -87431   85071  -52925  140378   79339\n",
      "   66794  -17612 -111829 -116968   93555  110955  -51013  -44749   91504\n",
      " -113030   81710 -103393  120559   96853  -59485  119269   90562  -59288\n",
      "  123601 -126784  105119  124069   98024  122033  -43456    4303   93927\n",
      "  -36993    4109  -72228  -97802  104123  -91897   -1442  -93402  112029\n",
      "   32859  140840  -48218   97668  -84909  106117  -91786  104349   10921\n",
      "  111976  -73222   37125  105232  -51676  -86007  131217  108791  107661\n",
      " -106204  -22718   94420   83338   94051  -57026  -68569 -139390  -66932\n",
      "   55278 -104580   96508   80734  109544  115378  130559 -130701 -102726\n",
      "  -30634   11694 -109822   68556  126032  -95858]\n",
      "h mod simd != 0\n",
      "inc_q:  [431 500 417 444 447 495 521 462 517 520 564 485 615 453 588 490 598 436\n",
      " 548 506 538 437 410 359 429 483 474 412 493 459 466 429 419 481 468 471\n",
      " 500 469 538 503 480 469 419 530 479 504 580 507 502 386 424 447 474 499\n",
      " 491 469 522 517 475 416 507 489 484 496]\n",
      "bias_q:  [   7272  -42824   40196   42959 -106567  109132  -75261  101602 -128277\n",
      "   28087  101140  -69147  -42088  156752   59571  -55409  -45158  168512\n",
      "  -98629 -147488  -79597   -3061   67393   -5237   15815   97452   65112\n",
      "   28214   11607   52302 -193297   40345  -81462   49175  -69083   -1490\n",
      "  -41373   65774   38750  -94474   66070 -102952   -1069  -77051 -111897\n",
      "   14748   26171   93285  -33244  -26113  -34045    2530  126706   37590\n",
      "  128061   19793 -165051  -35684 -179148   -9493   48451  -34288  -42296\n",
      "  112617]\n",
      "inc_q:  [167 148 164 273 212 172 231 243 195 249 158 132 262 234 248 240 188 179\n",
      " 153 233 138 221 144 191 253 217 230 203 172 217 178 229 154 163 224 226\n",
      " 145 273 213 197 232 195 195 250 174 227 172 172 234 145 202 181 228 172\n",
      " 331 220 160 163 303 172 270 217 229 242 229 213 245 211 150 217 207 168\n",
      " 167 150 244 215 224 219 300 252 195 202 249 184 198 169 209 246 275 185\n",
      " 215 289 177 233 202 247 189 193 218 186 142 177 223 219 181 194 282 244\n",
      " 245 247 145 240 202 184 196 151 175 222 177 244 219 276 188 164 294 243\n",
      " 255 235 216 247 236 180 255 146 189 186 219 142 191 139 156 193 208 140\n",
      " 292 190 224 217 231 170 275 192 208 166 240 192 232 189 199 223 195 240\n",
      " 213 186 195 211 201 217 154 246 188 187 170 187 269 177 192 192 189 190\n",
      " 173 193 218 273 183 185 249 271 202 230 283 173 208 206 197 200 211 216\n",
      " 290 217 158 231 220 268 209 200 156 243 213 231 176 230 246 170 256 145\n",
      " 205 135 178 158 167 189 171 137 148 188 145 202 235 161 172 228 229 156\n",
      " 218 199 158 240 255 245 197 218 184 201 240 235 232 175 296 221 203 228\n",
      " 194 142 146 198 237 203 206 145 212 228 251 199 197 195 242 226 191 262\n",
      " 239 193 172 212 201 149 246 200 193 198 327 237 237 212 229 179 174 233\n",
      " 193 188 233 188 197 208 250 193 248 174 174 299 254 172 190 152 174 248\n",
      " 151 213 161 217 280 192 207 180 203 319 220 233 155 139 214 231 194 159\n",
      " 160 174 171 160 209 231 291 219 225 283 148 230 178 202 222 222 197 243\n",
      " 192 265 159 172 213 193 160 207 218 158 185 204 204 240 217 216 174 233\n",
      " 188 176 248 256 160 228 186 216 235 168 159 202 225 187 238 194 192 251\n",
      " 162 207 198 238 313 234]\n",
      "bias_q:  [ -2413    564   3726  -2429   2855   1177  -1005   1900   3302   -375\n",
      "  -3643    526   4688  -3708   3543   1731  -5328   -507   1929   -354\n",
      "    115   4659  -3502  -1809   5175  -2597   2043   2097   4235  -5157\n",
      "   2810  -4794  -1526    929  -1958   -615     72    674  -2927  -9904\n",
      "   1402   1488   8279   3748   -574   1986    219  -3315  -8916   6252\n",
      "   5070   6149   -357   3240   -635  -5885   2480   2611  -7505  -2118\n",
      "  -2610   6937   7204   1002  -5105  -2147  -2842    103  -1137  -5637\n",
      "   -700     82  -4957  -2218    170  -3120   7164   5668  -1499   1874\n",
      "  -4731   6021   3287  -6614   -625  -4246  -7959   4260   2655   2330\n",
      "   1780   7525  -1081  -2096   5958   1446   6230    436  -3358  -1156\n",
      "  -6454   2627   -852   5643  -7478  10240   8938   9910  -2197   1180\n",
      "  -3363  -6149  -3924   2927   1594  -1201  -1618   5955  -2496   4759\n",
      "  -2341   3478    727  -4936   3653   3882   -512   3168    564  -3864\n",
      "  -6139  -7056   8037   8205  -3322   1836   -882  -3704   5249  -4088\n",
      "   1721   7874  -1366   4663   1105   -556  -8328  -1803   3120   6879\n",
      "    331   4169  -1493    800   5765   2854   3855  -5378    783   1066\n",
      "    262  10582  -6318    934   -798  -3955   5721   -502   4705    288\n",
      "   2909  -3709   5396   7454  -5218  -5067   4322   7276  -2574   4181\n",
      "   1239  -1987  -5622  -1748  -2437  -7845   5522  -3067   2861  -3682\n",
      "   5534  -1405   3874   5605   7532  -4567   6519  -5441   2965  -8353\n",
      "  -1928   1846  -1779  -3785   8601   6052  -3771   -747    -90   8018\n",
      "   4048  -3871   3292   4142   4011   5648  -3376   1752   6011  -5087\n",
      "  -4189  -2469   4448   3233  -2761 -12070  -7238   3380  -1873  -9488\n",
      "  -7331   8106    247   6947   -614   6125    -34   2769  -5511   5197\n",
      "  -1558   2488   3720    -13  -3422   5921   5483  12149   6863  -1229\n",
      "  -4157  -7125   -818   6086    853   1560   6724    245   3937  -5636\n",
      "  11233   5700  -3644   6607  -3023   3319   6163   2084  -4907  -2563\n",
      "   3733  -7872  -1551   5798   5085   -137  -2414  -2400  -6477   4180\n",
      "   2833  -1839  -5294   3976   4679  -8889  -5045    910    430   5719\n",
      "   4759    976  -4594    516   2726   5362  -6272   2093    985   3905\n",
      "    690   5563   4436   2623   3283  -1721   1644   1738  -3936   2504\n",
      "  -1042   4219  -4101   -861  -2322  -2072  -4351   -664  -4318  -8263\n",
      "   -707   4581   3967   2233  -2600  -4126  -3685   2111  -1186   -264\n",
      "   9176  -3294   2243   2668   2412  -6986   1784   3306   2546  -4219\n",
      "  -1313   4097  -4751   2681  -2506  -1713   8235   4314   1608   2543\n",
      "   2497  -4723   2413   -441   2124  -4235    106  -2747   1832   5165\n",
      "  -2734   1531   3147   5540  -2387   6479  -6451  -1458   4305   3349\n",
      "   3849   2474  -1200   1012  -3396  -2998  -9963  -2598   -510   1639\n",
      "   3301   1554  -1194   5303]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inc_q:  [4492 2739 2677 2711 2292 2221 3668 2230 2058 2693 3509 2334 2900 2999\n",
      " 3201 2723 5308 2647 2432 2526 2689 2490 2965 3329 2043 4489 3100 2708\n",
      " 2525 3479 3850 2736 3575 2564 2821 3143 2789 4015 2791 3070 3218 3725\n",
      " 1993 2646 3238 2947 2611 2700 1923 1818 3337 2012 2950 2001 3079 3156\n",
      " 1895 3160 3598 2694 3450 3372 1953 3722 2647 1664 3639 1900 3190 3181\n",
      " 2535 2409 2564 2847 3424 3149 2571 3380 2887 3104 3642 3363 3517 2875\n",
      " 3049 3056 2846 3994 2774 2263 2855 1589 2686 3512 2294 4262 1896 2319\n",
      " 3633 2720 2711 2767 3032 3469 2720 2296 4050 3465 3261 2561 2929 2859\n",
      " 2041 2201 2403 2745 2973 3173 3119 3210 3245 2604 2631 3512 2655 3467\n",
      " 3380 2066 3774 2383 3211 2891 3724 1917 3379 2746 2606 2877 2191 2802\n",
      " 2766 1945 3388 1818 2214 3082 2246 3109 2367 1895 2325 3765 2406 3037\n",
      " 2623 2149 1672 2871 3337 4327 3000 3704 3210 3728 2516 3113 2371 2777\n",
      " 2897 2608 1848 3575 3204 2569 2978 2613 2442 1980 3605 4698 3181 4622\n",
      " 4004 4167 2464 2224 3092 2160 3000 3064 2790 2406 3398 3134 2810 3531\n",
      " 3139 2824 4013 1878 3597 1687 2773 2434 2775 2931 2995 2971 3638 2816\n",
      " 3004 3429 2670 3417 2477 2516 3608 3157 3053 2765 2404 3011 1967 3471\n",
      " 3395 2407 3334 2121 2735 2878 2428 2046 2091 1942 3092 3556 3176 1881\n",
      " 3258 3414 3752 2341 2093 2527 3851 2943 3056 2042 2250 3659 3294 3617\n",
      " 3787 1985 2314 2271 4518 2256 2431 3274 1970 3727 3408 3756 3246 2256\n",
      " 1812 2609 2592 2788 2833 2713 3749 2022 2924 2909 3864 2961 2755 2797\n",
      " 2605 3697 3381 2591 2397 3230 3599 2759 3643 1907 3470 3118 2753 3460\n",
      " 3507 3047 3271 3223 2829 3703 2562 2826 2796 3134 2955 2839 2002 2733\n",
      " 3613 3903 3394 3107 3196 3334 3104 3498 3137 2346 4334 2952 3072 2792\n",
      " 3059 3081 3135 2132 3915 3296 1840 3241 2782 2571 2789 3400 2527 2671\n",
      " 3191 2993 2590 2185 2383 2881 3277 3256 2787 4108 3781 2592 3494 2600\n",
      " 2755 3027 2364 2229 2355 3020 4008 2624 3642 4284 2177 2798 2684 2125\n",
      " 3469 2159 3364 4756 2431 1977 2382 3669 2787 2558 3831 2698 2410 3376\n",
      " 1726 2776 3032 2814 3256 2901]\n",
      "bias_q:  [  48295   73832   91299   91010  -91513 -104158   82804   95625  122350\n",
      "  -93755   14978  -93423  124592 -124125  -97791  -95330   21962   97697\n",
      "  129730   98815  -58426  -52664  -90271  -66947 -120369    6740  110657\n",
      "  106057  114422  -76925  -65773  -77034  -58876    9338  -80825  -41522\n",
      "  -70661   12387  -63536  -81685     140  -67442  143450   84018   86421\n",
      "   98073  115084  115353  100962  101792  -70137  135495  -30847  113390\n",
      "   58743   74998   90539  -25689   31372  -94099   79212   34862 -131945\n",
      "  -21067   96108  126389   53245 -120490   39473  -45598   53624   89437\n",
      "  113199  -60431  -97259   71822   98005   74949  -55861  -15702   21541\n",
      "  -12966  -83176  -86787   -2417  -72440  112586   63893  125010 -131566\n",
      " -112258  126748  -60886   48375  106510   17609  112832  -97811  -48234\n",
      "  -91453  -60622  -70445  -61039  -46420  -90367  111654   10066  -20470\n",
      "   26764 -127336   60289    3499 -124659  134080  117532  126064  -91206\n",
      "  -32382  -10100   66398   -5716 -100516   52098  -33371   87982   70568\n",
      "   83576 -123792   44145  127125   43266  -79237  -52723  122476  -96158\n",
      "   81332 -127825   89702 -112890  -74472  -89231  124138   78888 -126736\n",
      "  123355    9316 -102332   90544   34870  121797  109376  -13186 -123143\n",
      "   27992   94351  139230  124038 -103836  104785   42002  -73619   46441\n",
      "   72700    2371  -89684  -85149   93352  -90199 -105225  100428  109385\n",
      "   90643  -67782  113207  -49519 -125505  129089 -115171   -7790  -63621\n",
      "  -68634  -14728  -76608  -28232 -125863  125362   16394  161774   14033\n",
      "   37130  -55538 -106499   -3634   30387  -80609   20578 -113072  -90885\n",
      "  -29574  106585   56628  130475  -86532  -98006 -131486   38909   83486\n",
      "   70754  -78894  118803   21600   36189  -91775  -24467   90336   89713\n",
      "  -22447  -52936    7342  -36843  -30576   61956   89710  -75915   34389\n",
      "  -97929   72647  118443   36560 -103391  -62314   77882  121185  137756\n",
      "  -48908    3464  117763  133204  -39218  -41642  -65035  -96061  119745\n",
      " -114207   59818 -106578  -67681  112506  130371    8226 -101889  -36037\n",
      "   81644  -93906  -41146 -143960   46550   79051   76935  -56571  119111\n",
      "    2699   56140  -31075  -85006  126808  108268  -93112 -102317 -114341\n",
      "  -76679   99188  -48948  120515  -78165  -96340  -23855  -53668  100869\n",
      "  -39016   98689  -67331  -32340  109088 -112300 -104205  -50504   68049\n",
      "   38982 -126403  -39216   20161  107024  133251  -90195   64271   -4900\n",
      "  -44279  -47292   69068  -42162  -13104  -64388  -40043  102558 -102825\n",
      " -123845  117257   64558  -32162    3383  -50279  -49466   48259  116243\n",
      "   61546   42154  123498  -18496  -64006 -100664  -83618   76114   52903\n",
      "  -55793  -92537  -45627  -89649 -133162   47053  -15592  -73997   62172\n",
      "  -16120  -36435  116285     431   22233  147650  134030   99712  -20554\n",
      "  -60477  102296 -103203    2172   56356 -126869  -68311  116340   84865\n",
      "  -61535 -115814 -132925   97581   39497  -37445   75430   40217  -65174\n",
      " -109260   65413   72173 -124328  -61426 -128088    6630  -58920  -92152\n",
      "  124107   96193  -51685  -89278   30515   57890  116928 -115263  -38206\n",
      " -126259  -36209  -47542   90380  -19965  -73014]\n",
      "h mod simd != 0\n",
      "inc_q:  [415 402 461 493 409 409 405 362 422 316 410 376 355 368 444 448 407 430\n",
      " 361 442 425 351 347 476 441 436 449 385 393 374 406 453 374 483 339 322\n",
      " 510 359 425 378 445 500 360 321 389 432 335 466 385 368 455 470 368 379\n",
      " 387 488 362 364 367 547 432 372 424 379 405 439 411 431 497 340 400 356\n",
      " 391 394 427 467 469 450 467 320 437 383 438 423 381 362 425 411 415 403\n",
      " 418 327 383 382 443 453]\n",
      "bias_q:  [-107921 -154360   11737 -134765  -29465  -85323   29960   14481 -156017\n",
      "   25117  123495   69579   39576   16459 -136294  -84078  -77033  -12882\n",
      "  -19681   17087  100734    1226  -44989   15066   25829  -14103 -173476\n",
      "   95707   -7236   23402    1983  -74471  -27340  -86926 -149681  142146\n",
      "  -36452  -60932   -1280   40527 -129398 -120995  -95724   97224  -88548\n",
      "   52252   81222    9750  -99831  -88563  -40901  202847   11282   94607\n",
      "  -56146  -42700  104536   -7657  -35651   -9074 -182934   33305   93670\n",
      "  -28895   15890   31866  -18462   24543  -47168   51517  -42942   72325\n",
      "  -80847  -95676     833  -41764  -31474  -19483   53498  -27575   80652\n",
      "   72517  -32847   90797    -636   55016  -81371   21832    -176   50783\n",
      "   35868   -7118  -33550  -22398   77827 -131401]\n",
      "inc_q:  [332 262 431 354 454 280 304 313 341 329 426 405 296 417 238 381 524 279\n",
      " 369 296 336 390 339 301 280 317 329 259 294 435 327 331 323 289 397 497\n",
      " 326 322 336 330 288 376 337 330 288 313 330 341 307 418 420 243 381 300\n",
      " 372 349 316 365 353 392 388 313 345 440 239 254 381 397 365 275 381 259\n",
      " 358 253 378 319 302 356 277 348 367 320 299 377 348 299 419 411 410 225\n",
      " 605 340 274 308 283 297 369 335 305 308 271 367 319 290 349 325 395 268\n",
      " 231 311 418 323 383 302 275 347 238 340 384 416 295 374 334 351 360 259\n",
      " 325 318 614 373 337 321 251 286 296 360 257 300 312 390 299 324 353 316\n",
      " 290 376 304 315 338 293 253 334 457 377 313 489 218 447 505 330 338 283\n",
      " 309 331 392 280 264 309 347 237 335 492 400 336 278 297 324 343 350 310\n",
      " 295 329 380 331 368 298 333 322 515 349 543 386 285 343 413 424 393 321\n",
      " 325 338 432 327 357 331 349 326 294 298 305 317 331 253 371 446 377 357\n",
      " 487 296 414 313 397 399 237 375 261 312 338 384 262 531 291 375 316 340\n",
      " 360 356 292 259 319 399 329 445 397 390 258 335 349 262 308 328 289 307\n",
      " 517 321 352 304 271 324 431 336 374 327 292 281 391 299 324 353 429 371\n",
      " 356 320 379 241 374 266 246 362 374 278 308 349 358 278 304 406 249 277\n",
      " 303 328 373 314 551 284 278 318 398 377 319 346 346 306 316 264 393 365\n",
      " 333 404 322 430 313 341 312 309 351 269 332 290 332 341 328 325 410 311\n",
      " 387 448 303 277 419 306 298 289 367 295 311 332 362 370 404 276 399 388\n",
      " 287 389 371 324 294 387 281 375 304 354 353 277 379 304 322 420 372 272\n",
      " 255 376 255 304 429 308 427 376 342 359 411 303 379 379 250 256 358 488\n",
      " 324 282 363 412 366 270 349 365 349 295 333 389 321 310 372 394 419 320\n",
      " 441 442 327 322 374 312 322 414 307 384 203 435 363 438 258 275 377 348\n",
      " 322 287 332 306 250 361 256 370 462 320 342 484 373 268 270 320 257 444\n",
      " 228 465 366 318 456 429 298 308 466 239 326 323 338 350 347 389 333 362\n",
      " 364 320 449 349 322 319 353 333 378 351 300 312 310 254 383 307 350 254\n",
      " 271 253 287 316 226 263 315 393 280 378 286 408 208 406 271 303 413 301\n",
      " 407 254 404 368 407 370 318 355 381 269 427 390 337 228 368 297 301 359\n",
      " 223 315 337 297 375 321 464 324 427 333 316 407 252 298 389 330 308 318\n",
      " 544 307 292 413 446 369 367 377 261 367 260 341 333 319 416 376 362 433\n",
      " 298 379 419 259 368 404 370 322 301 422 414 302 252 300 360 289 282 352\n",
      " 320 295 421 414 288 342 301 347 345 338 434 343 302 365 242 404 315 447]\n",
      "bias_q:  [  1022  -2740   5082   2961   7902  -2641   -488   -927   3076  -4473\n",
      "  -3949  -3591    997    246   5326  -1112   -851   2203  -1467   1302\n",
      "   5324    203  -4292   3720   1055  -9417   4046  -4091   -448  -2313\n",
      "  -5392   2669  -1997   4021   3567   2756  -4683  -3616   1202  -3909\n",
      "    345   1348   7703   3100   1921  -8441  -2012  -3099  -1215  -3059\n",
      "  -1151   4036   3222  -3092   -274   3715   -379  11225   1196   2784\n",
      "    -47  -1531   1328   -496   4259   1042    240  -2060   3776   3005\n",
      "   -717 -11973   3129  -2547   5499   3150    935   4951   1953   3390\n",
      "  -6892  -2720    731    -65   5966   3918   5892   -184   2641  -2569\n",
      "    381   -909  -1328  -2456   7661   8801   -854   3586   1871   -871\n",
      "  -6445   -937  -2480  -1063   7072  -1541     17   2533  -7691   -199\n",
      "    520  -1298   4128  -5361  -4654   1691  -1091   9833   -283  -6023\n",
      "    110  -3213   4055  -4189   1908  -4971   -933  -1555  -4770  -1575\n",
      "  -4202  -5540   -725   -115  11233  -6292  -1291   -114   4826 -10724\n",
      "   2743  -3004   3132   6430  -7518   4448  -4000    484    -13   2807\n",
      "   4148  -2664   1940   1786    348  -3585  -2838   7132    467   -736\n",
      "  -2445   8337   7664   -719   3791  -2186  -7597   8191  -7923  -4397\n",
      "   1429  -3695  -1612  -5874  -1717   3274  -4131   4151  -3531   2013\n",
      "   2509   1251   1782   4179   2413   5521    442   5045  -2037   2676\n",
      "  -3258   5556  -4526  -1415  -2212    210  -1152   -986   -662   1111\n",
      "   5108   2846   1664  12321  -2949  -3253   1002   3174   -839  -1253\n",
      "   2563   3979   2836  -1202    832  -4376  -1411   -972   2824   4084\n",
      "   -595   -717   -705   4317   6913  -1370   1928  -1369   3112  -9559\n",
      "  -4330   1072   2592   1963  -8387    -98  -1659  -7979   3540   -323\n",
      "   1478   3477   4941   3941   3089   5435  -1231  -1160   3089   2661\n",
      "   7225   5950   2415  -1460   2331   3160   5412   2406   1049   8425\n",
      "  -4803  -5818   1197   -265   1173   4808   1168  -4045   2045   6097\n",
      "    809   3079   1330   -486   2708   3890  -3243   2016   1769   3062\n",
      "  -2590   2129   5210   2004  -6738   6574  -7572  -2080   3563  -1254\n",
      "   3860   2860   1202   4444  -9053   -890   3436  -2240   1166   3619\n",
      "   3991    549  -1913   1286   3259   -426   1701   7567    904  -3875\n",
      " -10642   5390  -4258  -2192  -3710   3465   6739   3937  -5218  -4355\n",
      "    862   1384   4512  -4665    175  -4344  -1820   1525   5374   2976\n",
      "    904  -8030   -742  -2859    718  -3137   5134   3983    294  -1577\n",
      "   -824  -3209   4298   4531   7010  -2882  -4982  -2206   1012   3646\n",
      "   -957   2626  -1254     90   -525   3679  -2743  -3219  -6087    169\n",
      "   -626  -2681  -6486   4980   1999   5718   2079   -478   6081  -4698\n",
      "   8540  -1672  -6615  -2996  -2849  -2453  -1466  -5077   -520  -4485\n",
      "  -2702    615  -3767   -884    639   1114   2743    123  -1272  -3121\n",
      "   2092  -2091  -6037  -3658   2451   2916   4051  -1896   1571     40\n",
      "  -1443   -662  -5164   3730    647  -3504   -498  -1078   8198   4282\n",
      "  -1596   8533   3649   -376   1975    -58   6146  -5151  -6096  -2583\n",
      "  -5143  -2786   4463   4916   9258  -1677   3463  -3444   1103   8196\n",
      "     79   1428  -2604  -1948   2205   -227   -362   2956   2937  -2056\n",
      "   7651   5785  -1786   -612   1416   5190   1936  -1263  -4637   1978\n",
      "   3676   3794   1644   1732  -2734  -1181  -4967  -2576     47   6969\n",
      "   -267    -28  -1753  -3397    472  -1372  -6426    816    527   1638\n",
      "   1645  -2000    861  -4828  -3591  -9194   -491  -5090   1040   3007\n",
      "  -6940   2462   2124   4153  -5798   -631  -6300   3197    221  -5419\n",
      "    914   -340    567   3641   5461   -349  -6768   4845  -5112  -8526\n",
      "  -3348  -2727    252   4440   2617   -423  -4498  -2432  -2412   1733\n",
      "   -155   2962   3417   5482  -1626   4473  -6311   3928  -1297   2340\n",
      "   7341   5255   9214  -4090  -6784   5321  -1616   6081   4704   7571\n",
      "   3537  -2762  -3519   2115    317  -3849  -1814   2708   2457   3968\n",
      "  -5747   3735  -2811  -1721    172   3960  -5004   3217 -10514   4315\n",
      "  -1051  -3631  -3349  -3841   1757  -3550   3799   1589   -903   4746\n",
      "   -535  -1369   2358   2706  -6879    -71  -4740   -114  -3347  -4788\n",
      "  -1108  -4366  -3507   4672  -1188  -1062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inc_q:  [3972 3202 3413 2783 3268 2950 2674 3675 3050 2940 2421 3144 3688 3368\n",
      " 1564 3293 2702 1835 2968 2750 2369 2163 2566 4581 1808 3906 3507 2703\n",
      " 4177 2972 2789 3158 3556 3169 3434 3164 3109 2424 2370 3092 2471 3555\n",
      " 2470 3119 2448 3512 2329 2526 2475 3017 3054 3766 3143 3935 3152 2481\n",
      " 3514 2787 4431 2103 3200 2674 3791 3115 2174 3880 3157 5353 2222 2074\n",
      " 2212 3278 2756 2546 3681 2106 3269 2777 2221 2472 3318 2430 3715 2247\n",
      " 2850 2695 2270 3064 3610 2435 2864 3514 3304 2537 1913 1900 2531 3219\n",
      " 1936 2343 2890 2342 2739 2280 3235 3226 3241 2577 3365 3746 2446 4118\n",
      " 3204 4378 4048 2787 2217 1934 3373 4280 2389 2945 1797 3427 2548 2414\n",
      " 3194 3377 2598 3318 3903 3208 2683 3589 1614 3346 3920 2678 3723 4185\n",
      " 3283 2805 3185 2250 2975 2674 2491 3048 3018 2747 2328 2580 3674 2877\n",
      " 2534 3120 3181 3544 3423 3467 2268 3135 1988 2249 3697 1738 4159 1846\n",
      " 3115 3146 2524 3644 3333 3012 2472 1857 3117 3266 3355 2479 2625 3822\n",
      " 3744 2666 2462 3343 3069 2277 3672 3543 2480 2664 2659 3316 2670 4457\n",
      " 4565 2908 2061 4343 2243 2698 2743 1786 4181 3492 2292 2056 2529 2484\n",
      " 2914 1641 1950 2627 3551 3273 3733 2205 2682 2207 4068 2753 2196 1997\n",
      " 2017 3446 2204 2704 3743 3800 3772 3801 4111 2766 3239 2688 2750 2592\n",
      " 3109 3360 3025 2583 4133 3338 3454 3254 3442 3405 3088 3092 2843 2720\n",
      " 4528 2726 3124 3774 3580 2670 2779 1886 2576 4529 2692 2269 2682 1986\n",
      " 3194 4824 2385 2228 3779 2572 2629 3415 4562 1547 1628 2511 2905 2560\n",
      " 2582 2977 2258 2521 3299 2106 3073 2772 1913 3818 3554 1894 2992 2529\n",
      " 3303 2420 2624 2972 2480 3057 4125 3350 3634 3302 2721 2861 2289 3159\n",
      " 3456 2238 2909 3299 2198 2883 3171 3120 2238 2521 2931 2742 3274 3585\n",
      " 2965 3616 2949 3038 3347 2590 2198 2073 2205 2890 3049 3227 1903 2412\n",
      " 3806 2498 2869 3509 2612 3713 2529 2156 2827 1235 3128 2530 2737 3473\n",
      " 3165 3151 3370 2510 2930 2299 2687 3032 3852 2660 2243 3271 2062 1862\n",
      " 2668 1972 2621 3487 2298 2995 2150 4320 3173 2515 3498 2889 1998 4020\n",
      " 2539 2999 3531 3471 3219 3100 3767 3722 2932 1956 2556 2384 2563 2870\n",
      " 2560 2276 2161 3003 3590 3232 2786 2969 3345 1852 2539 2270 2606 2697\n",
      " 3196 4189 2575 3113 3745 1745 2478 3370 2360 2708 2156 2976 2983 5636\n",
      " 3948 3418 3118 3059 1855 3405 3691 3733 3410 2872 2651 3066 3218 3367\n",
      " 3360 3314 4114 2236 1681 2425 3414 2570 3829 3554 3321 3295 4580 3458\n",
      " 3461 2242 3703 3042 2209 2704 4164 2361 2901 3595 3782 4048 4618 2960\n",
      " 2407 3326 2359 2378 3597 2590 3222 3502 2990 3714 3351 3413 2325 4240\n",
      " 2729 2051 1815 4576 2934 3312 3115 2153 4078 1975 3824 1864 2874 2574\n",
      " 4494 3474 3677 2593 3436 2591 4637 3666 2820 4114 4522 2569 2523 2367\n",
      " 2962 2999 2204 3354 4635 3368 3614 2702 4514 2301 2564 3227 3033 3052\n",
      " 2973 2327 2255 3210 2480 2098 4133 3011 2627 2309 2480 2670 2803 3677\n",
      " 2691 2983 2350 3045 3563 1702 3147 2661 2865 2191 2451 2493 4113 4463\n",
      " 3644 3385 2714 2021 3215 3972 2471 3113 2858 3904 2439 3836 2474 2082\n",
      " 3282 2597 2466 3841 3448 4164 3678 2932 2984 3327 3922 3693 2349 3672\n",
      " 4228 2466]\n",
      "bias_q:  [  85705 -112395  -36109 -104099  115979  116857  -66635  -69139   11419\n",
      "  109411 -113236  -14794  -64262  -35159  131069  -35444 -132174  148100\n",
      "   27380  -93634  101188 -142252 -108476  -13064   89249  -52118   34549\n",
      " -103570   45298  -65867  -54001   58302   92204   45959     150  106571\n",
      "   84173   15207  -68163  101730   84407    2357  -81826   39066 -107793\n",
      "   -7100  -95373   96050   80616 -121017 -109932 -101736  -61496  -30683\n",
      "    1551   93865  -71579   64025   84711  104246   78031 -130021   90049\n",
      "  -79711  116660  -19092   66474    2470   70459   82237  143436    5761\n",
      "  -37659  113018   69248 -105450   28477   81736 -124285   73937  -95647\n",
      " -122076   16738 -122965 -108045  -75605   86019  109582   29819  -84134\n",
      "   41430   47249  -33443 -121074 -124937  123098 -138500  -18059  123432\n",
      "  -89866   -5789  -40987 -104124 -119732 -122357  -68498    5247  108302\n",
      "  -86579  -88208 -108445  -92699  -11559  -46906    5888   59796 -106028\n",
      " -147982  -41046   71557 -124591   97419  131054  -60372   80708   86863\n",
      "  -73927  -77674   90254   45288  -83409  -58192   70742  -81564  139068\n",
      "   66772  -49143  -68180  -44426  -46930  -99156   39093  -91451   89740\n",
      "   -7671   99231  -46516   10756   93376   80637   75517  101178   70739\n",
      "   49820   85892  -42451  -27657  -75511 -111069  -53173 -105709  109848\n",
      "  131993 -117592   75110  143417  -25976  154592 -104644  -86615 -126311\n",
      "   -1858   23795  -70903  111783  131003   68076  -78826  -99129   38241\n",
      " -103991  -41517   17748   71140  -55114   63750   65972  106486   94240\n",
      "   77250  152192  -75921  -36341     -51   73103   60775 -102464   -9810\n",
      "  131271  -22211  101985 -118198   73153  107730   25403   79064  -96440\n",
      "  111899  106426  -99763 -101272  117876 -126026  104234   84567   43762\n",
      "   -6828 -126468   62282  -61041  -64313   64736  -94335  109872 -117318\n",
      "   72630  135744   70538   20434   35701   21291   25671  -14062 -106608\n",
      "  -60428   33149   44153  -83912  -39119  -56875   69540  -81906   15441\n",
      "  -72586  -18865  -70666    3832   67269    2494   78694  117392 -109502\n",
      "  -35764  -29152  -85364  -61779   69099   86034  116853  130734  -13936\n",
      "   71008  120235 -123490  -83076  -98428   66149    8270 -126284   77705\n",
      " -101239   28924  110759  -67075   -2178 -119185 -123639  100946  121494\n",
      "   83154   82158  -15542   94699  -31834  -39836 -103698  -81127  -12540\n",
      "  112014   55556  -44964 -136231  -89384   55116  -69980   54755  -70288\n",
      " -107587 -103059 -117536   65674   -8955  -72576   92764  110632  -92348\n",
      "  117487   56923   30202 -130357  -79994  -58250  -97526 -109751   86378\n",
      "   83079  144579 -100253  -57127  -99784  -91246   72343   44965   -3629\n",
      "  135007  -87718   40836  108877  138410  118047 -103117   -5347  -90920\n",
      "  -82158   96582  -87784  -31215  120186  -43882  -91342   68592  -34172\n",
      "   37064  128187  -35074  109890  -21970   -5624   49557  -87140  -92104\n",
      " -106493  -61200  -92163  -68015 -112642 -100757  -60496  -11525   82228\n",
      "  -99733   77794 -112769   53782   42747   77120   -2242   94596   77095\n",
      "  -82618   86091  -20895  -42427 -104863 -100426  -14968 -119152  -20137\n",
      " -131595  -90180   46789  -15322  -76826  -72672 -116719   43810    2432\n",
      " -111594 -101639 -105872   91339   98999   67805  111827   83808  -88908\n",
      "  -49747   54698  -84815  -86643 -102883  133120 -102172  121221  -91722\n",
      "  -49358  -58208   90800  104826     452   63800  133498   52702   22040\n",
      "  -71907   74546 -119406 -114308   63936   43663  -40854   23440  -50030\n",
      "  106856  123866   21202   37224   30711 -116521  -30885  -93086  -19325\n",
      "  -83090  -46071  -13209  -52482   30352  142026 -121391  110410   57163\n",
      "  -76875   29241  -25256   25524  -27579   -1801   45955  -87877  -99518\n",
      "   82787   83750  119798  -31547  -54850  101254  -83479   89562   44199\n",
      "  -98157   -4248  -65971   77891  -94481  106369   42401   -8364   98370\n",
      "  -88123   16918  -65695   -3311  -69507   -2203  101484  -54272  -81201\n",
      "  123210  124701   51670  -91916  -34237  -53946  149950  -60220 -115130\n",
      "  -36280  126684  -84140  -71771   -2576   -8828  -18800  -73297  -61396\n",
      "  -87816  -14387   35333  129303   42480   -8748  -96496   88294   72561\n",
      "  -63801  -97451  134688  -20191   73711   85139  -50279  123051   30453\n",
      "   96280  111737    5709   67049   86518   61955 -124740   85119  -69040\n",
      "  122376  107208  -21869   12118  102601  117310  125360  118976  -92189\n",
      "  -57909  -69560  -38832  120627  -67849    4002  107788   12486   76342\n",
      "   37667  130176  -93483  -66519  -46436  -68161  -73440  -70807  -79891\n",
      "  139366   24907  -85510 -107495  -65538  -92453   27391  133379   92983\n",
      "  105355   71913  -25173  110392 -111446  -10862  110648  -41396  -94262\n",
      " -106412  -54687    8558   68266  -15950 -100992  -30886   47912  125870]\n",
      "h mod simd != 0\n",
      "inc_q:  [329 331 304 394 274 320 316 290 293 318 294 247 339 312 331 340 314 354\n",
      " 326 277 391 340 367 319 298 315 301 301 332 310 308 289 310 310 283 283\n",
      " 293 285 323 321 307 297 332 237 317 297 304 325 298 279 291 306 306 322\n",
      " 391 289 335 246 281 367 317 282 268 289 355 305 318 335 373 300 297 372\n",
      " 275 295 274 335 303 316 289 276 322 297 313 353 257 345 253 274 353 296\n",
      " 308 276 354 327 304 315]\n",
      "bias_q:  [  94966  -25536   27275 -123093   -9465  -99227   44949    4457   -6090\n",
      "  -50821    5078  -87226   28462  -66947   71597  -39940   18154   -9184\n",
      "  -47906   25149  -12497  -69258  142435   -7704   29351   83441  112883\n",
      " -207234  -86276  -99621  -14662  -95425    8244   31290  -43771   15658\n",
      "  118379  -22691   55169  -47493   25568   60528  -70006   32478  -52152\n",
      "  -63219  191826    7652   78183  -22265   -5686  -89057   48967  135388\n",
      "  -52230   80308   11772  104299  -93779  -15256   29879   72649   43027\n",
      "   36901    6350  -69107   21778  -16931  -76886   22657  -27982  -11496\n",
      "  -74294  -93328  -59493    9832   29739  130630   23399 -128443  179338\n",
      "   33334  111021  -75749    5674   21551  -78973  113316  -53381  -82773\n",
      "  -84992  -93805   46037 -147488  -25357   45938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inc_q:  [262 211 228 363 174 180 191 199 192 224 227 219 208 189 159 208 137 227\n",
      " 242 181 251 184 243 270 264 169 214 253 192 217 205 198 237 164 204 206\n",
      " 297 243 168 267 185 210 259 255 187 189 200 214 234 192 207 163 240 218\n",
      " 146 274 229 192 191 195 181 182 202 198 220 173 242 204 222 207 277 324\n",
      " 193 257 231 237 188 175 192 213 206 188 180 163 277 141 198 247 222 209\n",
      " 281 172 194 241 209 217 219 236 203 214 209 160 155 223 284 306 239 176\n",
      " 226 206 225 199 249 225 233 283 245 270 235 200 152 173 244 164 230 249\n",
      " 190 208 166 207 162 191 232 218 188 369 202 206 224 203 221 190 211 181\n",
      " 233 157 152 194 216 242 239 273 269 157 173 220 247 175 199 229 203 186\n",
      " 200 193 239 207 252 337 263 235 298 229 178 244 193 219 245 176 153 178\n",
      " 286 249 181 194 221 177 348 161 144 127 206 166 179 194 288 215 231 204\n",
      " 183 200 148 272 119 250 221 262 199 176 156 213 240 260 248 247 223 244\n",
      " 161 254 247 169 239 186 289 199 190 224 253 205 286 253 244 186 201 187\n",
      " 214 283 253 214 230 242 240 217 232 201 166 285 194 276 256 223 239 299\n",
      " 213 169 236 272 171 307 189 230 201 263 214 223 203 241 252 216 173 160\n",
      " 183 230 251 175 220 173 175 165 224 196 291 299 225 152 209 227 233 182\n",
      " 192 210 202 209 241 172 270 219 227 194 153 245 189 219 256 262 186 203\n",
      " 231 165 321 204 223 185 231 201 214 258 217 215 204 281 211 188 188 273\n",
      " 260 215 222 192 255 134 194 187 266 111 163 219 213 226 238 230 214 208\n",
      " 226 285 169 286 191 273 205 208 283 182 272 245 229 211 231 198 203 261\n",
      " 175 218 171 222 198 205 226 220 160 205 214 184 187 201 156 266 200 150\n",
      " 176 248 245 258 212 248 246 223 259 169 185 227 195 180 236 195 186 174\n",
      " 167 189 210 235 214 195 233 222 213 211 251 299 209 188 164 182 200 193\n",
      " 236 162 187 244 197 177 225 250 276 221 293 272 208 180 242 240 215 143\n",
      " 181 276 293 167 193 244 158 216 217 179 203 177 224 242 220 191 196 197\n",
      " 213 205 221 228 248 208 171 181 163 161 291 158 256 154 219 192 293 195\n",
      " 235 168 220 138 194 176 238 249 210 262 293 226 194 216 169 174 261 161\n",
      " 253 194 181 270 221 212 209 335 301 292 237 255 151 123 148 247 235 218\n",
      " 211 217 268 224 209 214 139 227 215 248 235 259 201 183 209 250 164 264\n",
      " 264 199 212 216 314 206 194 234 175 134 161 214 242 210 246 219 195 193\n",
      " 205 211 187 149 180 196 211 176 249 195 199 202 196 233 190 174 274 248\n",
      " 207 200 153 177 156 167 166 205 207 183 195 256 166 179 225 317 254 277]\n",
      "bias_q:  [ 4102  5539    72  3313 -5664  -277  -334 -2433  6000 -4168  4820 -4819\n",
      "  3460   608 -7248 -5655   175  3229  4238 -4531  8926  3168 -2624  1120\n",
      "  -204  3024  2389  3927  5008  4909 -8862 -1458 -2029  2783 -1539  2743\n",
      "  3058 -4165 -1396   985  -789  1178  6767  4095   493  1469  8510   307\n",
      "  1679  1157 -1313 -2795  2394  2121 -1400  7511 -2365  1404  6322 -4163\n",
      "  4300  2555 -3122  6587 -1967 -8834 -2270  6782  4188 -6474  2056  8418\n",
      " -5428  4612   213 -4068 -4190 -1933  4403  2727  -691 -2480 -6036 -4397\n",
      "  -953 -6248  3137  2727  1451 -4303  4032  5358  2864 -1901  8518  5153\n",
      "  1959  -271  4642   711  3230  -337 -3240   330   845  3256  1382 -2972\n",
      "   523 -4785 -1179  3099 -5649  4812 11465  4876   968 -3218  6778  2510\n",
      "   397  2633  2124 -4102  3583  4050 -2727 -1144   836   359  8093  6178\n",
      "  8855  1672 -1566 -2798   909 -3226  5649  4163 -2642 -5224 -4580 -8598\n",
      " -4240 -1238  -260 10524   132 -5852  5783  9882  1442  1091  5125  4907\n",
      " -4158  3953  2854 -2532 -3498  3091   532 -4939 -6176  4153   -37   888\n",
      " -2381 -1609  2499  6390  2373   571  3282  8323  2993 -3447 -3743  2110\n",
      "  -484 -2005  3056    10 -4857  2418  4238  -905  1948 -2868   -68  -627\n",
      " -1527  4229 -5609  1291 -2089  2418  4088  2615  2206 -6621 -7857 -1239\n",
      "   333  4802  3103   683  4340  2072  1840 -4719  5665  7857    35   277\n",
      "   106  9419  -621 -1648  4789 -3194  6171 -3982   619  5295  7291  3967\n",
      "  -748  2797  4578  4115 -1144  3575  2414  3812  3980  2148   -50 -3699\n",
      " -5018  1515  4891  1541  3605 -1871  3144  4873 -1055  -662  3792  4056\n",
      " -2877  5913  -137  -265  6055   127  1150  3434 -2544 -1386  8304  1268\n",
      "  1888  3431   427  1607 -2559  6655 -1978  7951 -8013 -1849 -1459  -805\n",
      "   507  4103  -312 -7913   128 -1423  -637 -5830 -5414  3446  1596 -1848\n",
      " -5563  1465 -2603  6318 -1234 -6629 -5445    93   702  1489  2187 -4848\n",
      "  -881   307  -162  -927  3578  2713  -493 -1828   -75 -2543   585  -597\n",
      " -5006   252 -3436 -4307 -1077 -8369  1346  6798  9840 -4914  3134 -9151\n",
      "  1595 -1267    -1 -1882  2450 -4737   272  2804  3531 -4401 -2053 -2724\n",
      "  7004  2061  3937  5668  -901 -1512 -1479  2578  9368  4445 -2082  -227\n",
      "  1858 -2791 -4442  4470 -1479 -4356  1631 -1967 -1552  -187 -2076  3775\n",
      "  1598  6016  1622  3325 -1645 -1088   647 -2386 -2397 -1422 -3161   117\n",
      " -1061 -2934   313  1126  2022 -3713 -3173  -940  -586  1537 -9516 -2021\n",
      "  4456  2320  -689 -4354 -4218  5439  3990  2840  2388  4406 -2645 -2314\n",
      " -1037  2473  1381  -390 -1773 -3021  3614  4484  1093  -644 -1567  -696\n",
      "  4068  8929  2969  5501 -1911   708 -1152  5320 -7188 -2931  -968 -5823\n",
      "  5986   736  5538  3249    77   452  1547 -2898  1022   -19  2018  5420\n",
      " -2782  4875   366  3491 -3312  2362 -1403  5090  5551  2841  2248 -3029\n",
      " -6254  2511  2128  8045 -5005   -37 -5428 -1477  1898 -8762  3904   699\n",
      " -5645  9033 -1852 -1235  4729 -1405 -2453 -2402 -2878 -2754 -1136 -2101\n",
      " -1557 -5032 -2026 -4671 -1290  -665   519 -6001  1627 -6863  -499 -1037\n",
      " -1660  2370  3285 -4623 -1685 -4746  4033  6127  2871 -2861  -695 -2989\n",
      "   990  5609  3997 -1700 -4647 -4430 -6073 -3338 -9102  -638 -6277  1814\n",
      "  -770 -2326  1071  7696  1388  -934 -2617  2121  -518 -2638  3169 -1733\n",
      " -7404  2668  3387  2508  3238  2753  2670  -653  3595   736  2582 -3113\n",
      "  5125  2750  -568 -7097 -3358 -3659  1859 -1297  2341 -1250  1598  -219\n",
      "  3978  2142 13303  -894  4500  3839  1654 -9135  2772  1097  3585 -1134\n",
      "  -940 -3442  3327 -6092  1394  1575 -3952 -4954 -4956  7159  -622 -5820\n",
      "  -664 -1730 -4557   229  -698  5912  4514 -3573  3098  8109  5745   416]\n",
      "inc_q:  [4009 2935 3089 4665 3113 2317 3305 2338 2420 2428 3790 2564 2390 4478\n",
      " 3596 2481 3529 2178 3554 2247 3782 2277 3266 3544 3636 4059 4312 2955\n",
      " 2604 2927 2506 4328 3481 2528 2863 3570 2879 2666 2978 3778 1849 3622\n",
      " 2559 2208 2834 2670 2771 2304 2886 2082 2054 2831 3789 2857 2492 3600\n",
      " 4085 2656 2601 3258 3306 1925 3698 2793 2525 3082 3280 2235 2271 3533\n",
      " 2848 2719 3133 4137 3833 2848 3980 3262 3513 2919 2662 3036 2612 2298\n",
      " 3113 3671 2214 3167 2634 2905 3412 2328 3877 3328 2533 2948 3110 4009\n",
      " 3448 4031 2282 2480 2397 3688 4927 3194 3492 2485 2111 3161 3925 2245\n",
      " 3114 3558 1897 3882 2319 3613 2293 2627 1999 2018 3720 2922 2462 2892\n",
      " 3155 3833 4451 2412 3030 3803 3271 3384 2108 3232 2034 3117 2558 2570\n",
      " 3769 2903 1928 3621 3509 3569 2508 2075 2257 3493 4429 3113 3759 2130\n",
      " 2026 3036 3958 2470 1856 3427 2005 1926 4115 2937 3895 2703 2655 5114\n",
      " 2834 3709 2449 2716 3062 3225 3535 2301 4651 3312 1770 2234 2765 3174\n",
      " 2172 2944 3600 3440 2888 3476 2301 2514 2676 2895 3134 3721 4590 1934\n",
      " 2408 3103 2675 3766 2426 3573 1867 2874 2600 3370 4654 3417 4935 3094\n",
      " 3246 2294 2597 2587 2259 3109 2309 2180 3078 1820 3037 3106 2415 3330\n",
      " 2972 3650 2991 2113 3130 2461 2347 1982 2368 3990 2442 2791 2492 2426\n",
      " 2600 3521 3213 2610 3154 3777 2011 2353 2486 3209 3915 2604 2704 2647\n",
      " 3402 2776 3275 2681 3223 3421 2886 3528 2543 3991 3040 5370 2811 2233\n",
      " 2935 3792 4094 3119 3664 2119 2728 2050 3689 2540 2614 2058 2873 3502\n",
      " 1713 3552 3188 2697 2461 3646 2777 2492 4357 3582 2326 2271 2933 3401\n",
      " 5038 3041 2815 2794 2433 3784 3478 3579 3461 3023 2588 3002 2876 2821\n",
      " 3461 3004 4678 4082 3119 3507 1950 3134 5077 4420 4817 4206 1849 3009\n",
      " 2767 3842 3964 3126 3678 2763 3067 2844 2831 1935 4511 2667 2914 4090\n",
      " 3812 3862 3562 3354 3754 3270 3692 3187 2620 2508 5120 2498 3461 3909\n",
      " 3461 2258 3859 3114 2792 3407 4346 3046 2290 3117 3308 2230 4331 2163\n",
      " 2042 1752 2614 3780 2062 3054 2112 2296 2932 3477 3201 3201 4490 2102\n",
      " 3261 2855 3443 1950 2338 2532 2906 3141 4833 2809 1632 3197 2540 2171\n",
      " 2617 3325 2754 2962 2234 2118 2784 3727 2823 3354 3898 2988 3649 2402\n",
      " 4166 3794 2996 1704 3780 2782 1977 4246 4062 2516 2525 3510 2961 3281\n",
      " 3425 2990 3958 3669 2886 2693 2830 3427 3173 2397 2622 2605 2924 3037\n",
      " 3806 2386 5065 3527 2500 3403 2108 3110 2510 3006 4401 3081 3157 2062\n",
      " 2004 3166 3971 2995 3329 2444 3590 4042 3009 2590 3773 2476 3225 5262\n",
      " 3878 1952 4345 3567 3375 2934 1846 4705 2851 4208 2213 3372 3031 2267\n",
      " 2679 3828 2852 3784 2198 3452 3056 2420 3706 2688 2598 2561 2323 3067\n",
      " 3055 4954 3084 3080 2537 3969 2671 2600 2611 2051 2816 3078 4900 3447\n",
      " 2360 1926 3198 2103 3992 2028 3266 2459 4528 2471 2377 4446 5417 1774\n",
      " 2420 3725 2419 2840 3751 3617 3561 3602 3913 3365 3730 2450 4290 3216\n",
      " 3759 4420 3602 2506 3335 2234 3162 3088 3651 3024 1843 2924 1754 2772\n",
      " 3718 2440 3783 2159 2338 3512 3108 2645 2240 2491 3698 2285 2273 3447\n",
      " 3513 2640 2155 3103 2862 3607 3781 2019 4165 2860 3005 1713 2368 2593\n",
      " 2432 3095]\n",
      "bias_q:  [ -36529   88485  -27150  -70678  -77791   89697  -69195  114794 -117538\n",
      "   96179    -897 -102899  -84700  -26948   81239  116741 -101787  102352\n",
      "  -78901   86228 -111940 -105274  -73594   44000   -6711  -18214  -59254\n",
      "   84915 -108715  -75672   65513  -68886   85242  -80282  -27959  -33303\n",
      "  -76045 -102795  -23521  -48151  136434   66453 -120842 -100420   60008\n",
      "  -36219   92908  -97600  -43607   96793  104247  -72705  -69374  -96174\n",
      "   64568  -46064  -34950  -92166   80953  -19720  -52675  109310  -51865\n",
      "   79327  -59959  -37714  115216 -135110 -118682   50668  119359  147435\n",
      "  -34685  -84685 -100256  117278  -43592  -97777  -55589  108835 -114266\n",
      "  130084  105492  -92631  -89435  -15134 -118137    7572 -106466  -67469\n",
      "   13684   90278   -4090   75313  -22168  -94431  -72592  -99619   60071\n",
      "  -30870  114131   98948  -77559   65627   66772    1353   29278 -112160\n",
      "  -85581  -85542  -41600 -124578  -31292 -120200  134127   89969   75926\n",
      "   88938 -119530   84322 -113256  122494  -48085  -77664   72415    3953\n",
      " -120197  -91947  -86809  -97061  -33966   77619  118037  -94545   54164\n",
      "   32027   99701 -110658   78052  -72271   81078   29673 -112130  -92679\n",
      "   10922  -26591 -122533  123535 -117457    9167  -27721   82919  -84451\n",
      "  108633  118738   29212   84227  123130 -129792   38788 -114825   84612\n",
      "  -32497  -81470   43927 -121707  138972  -43215   45378  -21214  112450\n",
      " -129857  -22506   39981   -5007  149378  -67930  -68234   93264 -103153\n",
      "  128018  -82537  103681   56445   55159   18107  -78382  -53750 -103971\n",
      " -103752  -77018  121814  -74315   74949   64716  128519 -114111   98453\n",
      "   96061  105890   67532   15996 -101487  105631   35263   15782   23827\n",
      "  -72732   -7466  -95843  -84440 -113032 -103769  118262 -117170  -32937\n",
      "  143869  111884  -76448 -115677 -108756    3147  104841  -20429   32029\n",
      "  115101  -41167   67914   11462 -117664  116414  102735   96899   30520\n",
      "  104397  -81895  -69038  105708  103858  105154 -105930  -56150 -106400\n",
      "  -20129  140584   82575   79309   94502   -6452 -130860 -111211  123853\n",
      "    1319  126905 -117540  114453   71564  114433  -76219   23992   79119\n",
      "  -69002  -62158   -1517  -85270  118640  109674  -79486  -84638   -4034\n",
      "   34502  108428  -96554 -117821  -61558  -99018 -118816   93062  -55244\n",
      "   61100  112021   29736 -111471  -90920 -112563  120960   73666 -111695\n",
      "   -2916  -26753  100361   81635  107947  -91330  -13988  -67194  -95541\n",
      " -106379 -106032   60306  -19148  -27735  -67222  -99134   87804 -116890\n",
      "   81120  -86364  -58382   56261  -66922   87079  -97896   69484  123148\n",
      " -106195  -15741  -55406  -47674   22161  138749  -71497  -83954   60795\n",
      "   16958   99332  -19702   92130   66345  115772   89201  116258   17258\n",
      "  -90006 -122414  -21253  -31589   38146   28283  -36956   44765   16155\n",
      "   39887   97343   72129  136259  -88366 -123686    6170   67737  -66053\n",
      "   95286  -36863   74333  -90012 -101153  -67963   19250 -119912  103695\n",
      " -126492  100237  -86295  129130 -118873 -137293 -126892   52282 -100104\n",
      "  -65683  102243  -85314   24672  109551  101446 -123588   58093  128559\n",
      "  -34887  101064   69182  134216 -117599 -139123   98592  -67279  -21393\n",
      " -108320  108458   56490   73422   97822  -20587   23402  119994   49088\n",
      "  126618   90959  -64067 -120172 -113360    7610   21597   56105  -37486\n",
      "  109875  -46982  -84251  -19437  120088   44798  -87773 -137670   25407\n",
      "  -98685  136800 -123147  -26914   92304  -38854   -7481 -103816   -2839\n",
      "   31193  -39736  114410   78009   10426  -46736  120772 -104241  117015\n",
      "  -48231  -44704  -78943  -95853   23157   22352  -87866  110009   91491\n",
      "  111519  124973  120599  -67218   75148    8883  -94861  135199   41379\n",
      "  -18291   61747   30476 -118759   26595   15683  -60204   95958  -93573\n",
      "  100373   75591  -59083  -95209 -128272   50993  -13594  -37494   74395\n",
      "  110519  -93076  -77915   54170   86462   91127   86367 -105663   96157\n",
      "  -59381  -77402  -31172   98099  -57333  -21538  127041  -55685   50633\n",
      "  -80840   90578   89365  -40717  107331   28962  -91303   78722  138228\n",
      "   92936   85969 -111298  129616 -129597  109284  -28484  -60477  -10937\n",
      " -105568  136272   13753  110170  -96401  151879   74589   92522   43541\n",
      "  -90004 -126700  -14625   16928 -136899   88262  -33589  126366  113992\n",
      "   -8668  -47008  -72051  -42450  -31215  -73003   88869 -112400   47280\n",
      "  -69157  -64711 -103349   41608  122564   69888   93959   90460 -111604\n",
      "  -59458  -64572  140828  -62366  122501  123891  -64086 -108311   47342\n",
      " -122711 -123407   25295   47791 -109062 -127718  -83687   25075 -100467\n",
      " -110679   73242  -38845  -73075 -108878  101405   27133  -43631  -85597\n",
      "  110548  -61226   79542  -96559 -109597  117411  -35138   73580   15473]\n",
      "h mod simd != 0\n",
      "inc_q:  [351 280 222 365 282 329 308 323 402 359 297 315 354 308 259 405 328 305\n",
      " 283 299 379 284 335 353 374 292 351 389 259 348 311 268 332 359 323 324\n",
      " 351 349 325 264 304 317 304 300 366 406 263 330 317 335 359 319 276 312\n",
      " 369 323 371 279 267 342 304 323 304 347 334 348 285 317 334 260 337 300\n",
      " 275 298 302 318 228 336 301 314 349 278 283 322 304 347 301 310 307 290\n",
      " 320 315 386 302 289 366]\n",
      "bias_q:  [ -80700  -42806  -28312   54311  -88362  -89024   55771   17443   75215\n",
      "    5461   57160  -19065   53217   -3675   87872    7940   98297   56734\n",
      "    1351    8837  -92608  -17242   27436   34755   60261  -44137   44813\n",
      " -131054 -121272  188034  -43764  -69226  -17636  117412  -62795  -56853\n",
      "   82411 -142663  -13375   61751  -38038   36761  -17651  -10482 -126717\n",
      "   32692  -73861 -142425   -2003  -65287  -37435   83385   47185   -3115\n",
      " -129663  -25922  125537 -154721  -70860   66004  -26039  -21742 -158906\n",
      "   13493   76957   -3911  152363  -30874   22778  -46703   32540  -23533\n",
      " -110786  -26631     857    7697   29059  -17215   13575   68330   -4140\n",
      "  -27346  -91405  -79254  100488   49899 -129208    6807  -18941  -97959\n",
      "   59688  -90088   64060   84040  -39116  -64071]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inc_q:  [138  99 169 108 140 121 119 111 166 162 150 169 133 134 133 129 138 135\n",
      "  96 111 132 136 144 159 105 192 121 131 134 105 155 117 112 137 128 121\n",
      " 112 126  93 107 110 138 124 112 149 129  92 152 107  84 201 127 133 144\n",
      " 157 157 133 150 153 208 119 144 141  95 117  94 127 125 106 129 121 127\n",
      " 127 115 110 117 105 120 137 135 121 123 131  90 118 114 125 137 115 116\n",
      " 152 125 134  96 125 119  98 114 132 145 134 129 127 131 110 136 118 138\n",
      " 110 103  88 146 147 122 106 117 105 146 170 102 133  92 132 112 126 102\n",
      "  89 141 145 112 141 111 118 107 138 104 139 112 121  96  99  96 122 105\n",
      " 112  90 168  94 125 122 140  80 129  94 109 149 130 115 113 157 117 130\n",
      " 127 167 143 158 105  94 176 107 123 130 162 129 124 144  91 117 115 123\n",
      " 117 100 112 134  89 135 149 114 117 105 104  93 115 115 130  92  92 178\n",
      "  89 166 142 154 100  95  92 100 161 144 121 127 113 126 147  85 136 110\n",
      " 141 111 118 124 117 161 118 154 164 116 130 125 127  93 113 116 101 144\n",
      " 156 139 100 149 121 140 135 115 106 129 134 122 143 126 145 125 127  85\n",
      " 132 113 137 124 147 114 133  93 102 122 112 145 101 141 145 163 126 187\n",
      " 128 117 114 101 136 140  96 115  94 119 102 140 122 128 148 115 130 179\n",
      " 186 107 103 154 119 148 141 112 128 108 117 109 121 121  94 101  88 157\n",
      " 128 141 132 100 134 150 135  96 126 100 117 161  99 144 105 124 115 118\n",
      " 132 127 124 127 140 142 122 132 104 113 127 134 140 109 133 142 125 131\n",
      " 120 130 117 134  75 126 116 124 127  91  84 117 143 122 115 118 127 115\n",
      " 142 120 117 115 104 163 170 100 130 105 168 134 136 123 110 120 110 120\n",
      " 116 105 123 123 130  99  88 150 130 109 108 131 107 173 122 129 125 143\n",
      " 145 131 116 131 113 161 158 119 154 108 137 115 125 102 135 142 139 129\n",
      " 114  99 120 110 111 116  94 105 143 105 113 139 124 121 126 135 114 144\n",
      " 120 112 114  97 144 130 125 128 112 131 116 131 157 119 139 124 104 107\n",
      " 105 122 115 132 113 116 139 108 121  89 136 131 142 110 119 114  83 131\n",
      "  89 121 131 134 138 134 142 126 117 101 104 129 120 126 108  81 124 123\n",
      " 106 131 122 112 134 102 139 111 129 104  99 174 107 109 158 108 149 144\n",
      " 137 117 117 114 106 102 151  94 104 100 106 118 141  99 129 124 114 135\n",
      " 102 113 102 138 171 133 138  75 143  98 141 112 149 145 144 173 142 107\n",
      " 132  92 124 104 202 132 144 161 159 136 107 156 125 114 105 135 146  93\n",
      " 128 124 116 103  96 130 116 119  91 106 146 128 133 107  94 133 100 133]\n",
      "bias_q:  [ -1445   2307   4542   5270  -2499   8559   2729  -2596   5118   1562\n",
      "  -4894   2538   1207  -2012  -2407  -3454   2436   3858  -4641    793\n",
      "   9773    -67     24  11866    776   6092   4797  -3771  -5512   6825\n",
      "  -1051   3813   2443  -2655  -2720   7931   6605    294  -6215   8690\n",
      "   1266  -9532  -7712   5019   5033    916  -5253  -1845   -131  10128\n",
      "   9596   3292  -1612   4276   4744  -1211   -799   2811   8408   -526\n",
      "  -4359  -5737   1699  -7949   4255   1064  13603  -4351   4493  -4065\n",
      "    -87   3634  -6377    600  -3886  -1137   2443   5367   4389    923\n",
      "   6213   1839   5845   1315   5053    358  -5194   2036  -1789   1189\n",
      "  -2209   5697  -1243  -6842   -996   5745   1151   1844  -1453   -800\n",
      "  -3190   1199  -3156   3513   4370   2484     43  -1459   3984   6336\n",
      "   3025   7392    209  -8569   2266   4419   -209   4728   3157   1547\n",
      "   5228   -514   2991    210  -1079  -1482   9046  13085  -1758    783\n",
      "   2623    605   -558    924   -451   -717    261   9123   -684  -1636\n",
      "   -507   4205  -2426  -1012   2662   -878   3219  -4321    997   2584\n",
      "   1799   1501    918   -216  -2781   3477   2060  -3099   3292   3841\n",
      "  -1052  -2606   -496  -3572   -796   3559  -2319    -32  -3101  -8232\n",
      "  -9170   1978   5656  10944   7179  -3900  -2891  -3153   1803  -2751\n",
      "    751   5266   4483   2976  -7951   6788    742  -9237   1008   2377\n",
      "  -2438  -4995   4373   2378   4257 -12704  -7788    347  -8671   7358\n",
      "   6929   8595   -263 -10039  -8203   9821  -7431   -490   4865   6524\n",
      "   1632   -888   -650  -4047  -3395  -5715   5367    540  -3677   -666\n",
      "    263   1526   8262    439   5802   7967   3850   1588   4753   1064\n",
      " -14062   1052   2111   5866  10059   1325   2394   -985    712    241\n",
      "   5508   -282   6451     20    448    676   7509    999   5215  -2344\n",
      "   4415  -8767   -584   -102   2209  -1298   1194  -8016  -1732   4095\n",
      "   4878   -403  -2804  -2119  -2558   -178  -3444  -1653   2049   4860\n",
      "  -2416  -3669   -716   6066   4054   5431  -2988   1842  -5907  -6431\n",
      "  -6327  11031  14634  -3380   -213  -7588    865   1119   6671   3926\n",
      " -11092   1108  -1698  -3075   7605   1638   5986  -5682  -4704   4596\n",
      "   2834  -7284   1418   1395   4742   4249   -513   8352   2904  -3548\n",
      "  -2790   4853   4430  -2790   2427  -4922  -3327  -2855  -1530   -525\n",
      "   1277  -3784  -1409  -5358  -2052   2963   3170   4620  -3194    189\n",
      "   -575  -4721   1175    827  -8890   4306   3627   3353  -5530   2590\n",
      "  -7245   6362   2832   1533    523   1627   -593   7977  -3663  -2708\n",
      "    209   3176  -1376   9872   -458   2233  -3930   -806     -9   1977\n",
      "  -4083   -109  -5256   3013  -7786   7349    821  -8720   9400  -1614\n",
      "   8687  -2362   2505    380  -2002    528  -7449  -4556   -429  -4114\n",
      "   7327   2981   5599   5678   2552    -28   2979   5691   4270   1700\n",
      "   -954  10209   1252  -4872   5020  -2186  13874   -243   5830   1158\n",
      "    811   -288   1019  -6949   6332   7945   4146  -5310   -445  -3662\n",
      "  -9553   -768   2403   -527  -1564  -1265   5422  -5043  -3007   6819\n",
      "   4938   -763   2957   1295  -2861  -3427   6470  -3093  -3314    553\n",
      "  -4488   3975  -3863  -2765   4456   6625   -706   3717   6599  -2760\n",
      "  -3901  -5430   4285   2130  -3240   1239   1812     23  -2587  -3826\n",
      "  -7094  -7672  -3740   6389  11851   1274  -3496  -5881    448   8861\n",
      "   1238   6909   -107  -2502   1044  -5077   6729   -884   4412   1061\n",
      "  -3192   2878   1125  -3675  -1381  11248   3904  -5237  -4379   2528\n",
      "  -9959   -493    592    157  -3374   6651  -4087   4442   6397   4931\n",
      "   3728    204    388   6085  -7072   6158   -385   8963   9712    378\n",
      "   4425  -4694   4810  -2515   -519   3370  -5636    659  -3703   1942\n",
      "    725  -5148   3762  -4155     81   4278   2545   2084   -607  -1704\n",
      "   1498   4821  -1288   3242  -7346   1539   -668   4604   3323 -11531\n",
      "  -3888   6089   6298  -2822  -2820   4310    204   2958   3971   4635\n",
      "  -5691  -7403   4735  -4361   2389     -1   6074    398  13570   1874\n",
      "   5140   6182  -1557    111  -8204  10326   7081   2942   7595   1450\n",
      "     39  -6160  -5237   -547  11212   2523   2456   1790   7099   3153\n",
      "   6465  -6816  -2684   5881  -3144   5932]\n",
      "inc_q:  [2055 1720 2919 2665 3208 2006 2039 3436 2153 1717 7383 3219 1980 1811\n",
      " 2486 2319 2313 2950 1896 1909 1530 2539 1816 2223 2404 2644 1858 2612\n",
      " 2061 1873 1925 2464 2775 3211 2183 2297 2211 2943 2135 1901 2759 2562\n",
      " 2621 1933 1806 2551 2473 2684 2386 1959 2247 2078 3088 1655 2882 2428\n",
      " 2388 1444 2452 3199 3045 2918 2213 2419 1753 1969 1486 3215 2920 1985\n",
      " 2734 2277 2179 2328 2809 2690 2350 1583 1887 2313 1460 1811 3711 2350\n",
      " 2739 3111 2580 1990 2215 2419 2121 1881 2260 2291 1679 2005 1395 2402\n",
      " 3094 2501 3035 2211 2202 2147 1894 1942 2114 2426 1842 1907 2204 1971\n",
      " 3328 2987 1952 1873 3246 1742 2979 3494 3003 2263 2046 2506 2441 1421\n",
      " 2103 1787 4811 2930 2726 2975 1602 1644 2766 2155 1745 2722 3300 2102\n",
      " 2410 1744 2618 2479 1781 2468 2985 2030 2024 2317 2923 1909 3052 2914\n",
      " 2253 2180 3330 2844 2273 2634 2276 2770 2581 2731 4068 2647 2172 2287\n",
      " 2392 1810 2855 2282 1837 2106 3247 2108 2806 1983 1933 2283 2506 2125\n",
      " 2729 3145 1873 1592 2581 2354 2164 2622 2931 1753 3002 2653 1762 2562\n",
      " 1607 2194 2306 1898 1716 2135 1911 1716 1745 2158 2889 2684 2850 1863\n",
      " 2437 2570 2341 2465 3309 2773 2604 2328 2334 2595 2594 2992 2055 2644\n",
      " 2077 1552 1878 2235 1584 2359 4121 2100 1838 2156 2073 1296 2625 2641\n",
      " 3023 2486 2291 2366 1972 1963 2023 2593 1934 3044 3055 1478 2350 2534\n",
      " 2010 2288 1585 3044 3788 2051 2208 2257 1554 2477 2260 1932 2910 2429\n",
      " 3389 2669 1811 2719 2801 1994 2052 2087 2142 2261 2388 2004 3988 2734\n",
      " 2449 1850 1984 2660 2150 3708 2080 3879 2860 2432 2107 3241 2642 2682\n",
      " 2097 3479 2149 2061 2285 1923 2671 2627 1714 2518 1907 2059 2846 2049\n",
      " 2579 3730 3438 2630 1485 2093 2789 3115 2761 3107 3025 2389 2515 2132\n",
      " 2541 1992 2578 1680 2296 1548 2884 1816 3732 2082 3264 2101 3139 1938\n",
      " 2970 2656 2284 1963 3423 3343 2298 1775 2342 2277 2089 2506 2117 2557\n",
      " 3300 1559 2144 2370 3659 3207 2546 3787 1871 1925 2893 2249 2766 2267\n",
      " 2470 1788 1962 2114 1673 2491 2678 4797 2262 2216 2667 2090 3083 2233\n",
      " 3626 3106 2127 1702 2871 2803 1619 2365 1872 1680 1990 2646 2452 2178\n",
      " 2739 2988 1950 2161 1640 2379 2051 4044 1918 1755 3097 2015 2480 1744\n",
      " 1751 3454 2689 1965 1668 2681 1761 2605 2163 1945 1579 1655 1896 1930\n",
      " 1471 1257 1718 4161 2652 2446 2060 2574 2551 2321 2096 1871 2598 2943\n",
      " 2605 2798 2277 1635 2450 2896 2510 2482 2132 1891 3086 2279 2101 2864\n",
      " 2061 3063 2399 2586 2877 3070 1503 2329 2335 1997 4306 1381 2298 2192\n",
      " 1950 1857 1580 2449 1335 2164 1786 1896 3031 2781 2455 3597 2531 1915\n",
      " 1649 3185 1794 2292 2637 2393 2123 1876 3096 2087 3195 2038 1709 2840\n",
      " 3182 3334 2189 2847 2293 1791 1754 3059 2346 2908 2446 2954 3403 3491\n",
      " 1641 2560 3054 2411 3015 2409 1549 3407 2310 2278 2624 2398 2619 1973\n",
      " 1387 3183 1492 3737 2901 1619 2064 2489 2189 2075 2123 2015 2655 3391\n",
      " 2430 3183 2427 3349 1692 2184 2930 2355 2330 2149 2206 1574 2551 2304\n",
      " 1543 1980 1474 2250 2291 1876 3775 1596 2353 2133 2438 1625 2101 2438\n",
      " 1343 1818 2230 2629 2095 2184 3737 1942 2271 1967 2823 2733 1849 1832\n",
      " 2999 1902]\n",
      "bias_q:  [  97464  124305   30986   65884  -75503  135086  100547  -67916  114266\n",
      "  110140   -6072   -3800   95176  113288    6593  -84965  -88988  -25637\n",
      " -121084 -106518  127962  -65145  134198   40521  -95739   84863 -108102\n",
      "  -88824  -72552  118386   97131 -108881    3947  -33199  110205 -114143\n",
      "  109754   85119  -80119  102415   -2205 -122663  -36507 -112434  127140\n",
      "  -70243 -113365   78798  -31831  138252   50954  -93197   37982  132146\n",
      "   65917 -101829 -103520  103849  -89756   78549  -42235 -105044    -492\n",
      " -122658  116486  136232  123900    -246   68701 -114688  -92679  -81675\n",
      "  -49269   76806  -33673   57669  123028  106788 -119858 -107356 -128141\n",
      "  118442   30107   -3055  -46825  -85507  -16565 -118776  -59604  -34582\n",
      "  107496  -77642  108895  -72333 -117918  119350  134708  -77509  -34251\n",
      "  -72935   23980  107916  -70651   81781  124472  138085   73894    7914\n",
      "   86277  -80282  -59440   99174   52469   20876  137422  132794   74045\n",
      "  134418  -29425  -92258   36716   21520  118957  -37731   11513  112134\n",
      "  113425  133627  -64502  -70026   53286  -38237   92525  127558  -47175\n",
      "  -14206 -113751 -120645   21095  -70126   82182  127770   90213  -58251\n",
      "  118842 -102959  -77519 -103384 -118945 -104156  -63441  113230  -48386\n",
      "  -91730  -78286   89940   74160   -9534  106730  -44800  -69024   58072\n",
      " -118637 -114200  -75059   62338  114421  -85561  -84260 -108209  -78466\n",
      " -115712   69438   62275  -40465 -112924  -94297  111515  129369 -101607\n",
      "  -99254  143585  -64980   61426 -107794  120471  -86397 -109240  -38822\n",
      "  -15021  -69253 -122268   75724   51939 -115755  133455 -115406 -104699\n",
      "  -13952 -149395 -115654   80843   56230 -111572 -134506   68330   37552\n",
      "   21857    8373 -111613   35099   88837 -107672  114325  -46432   91934\n",
      "    5278  -80031   78193   47073    5726  -50763   47182  -11657   78682\n",
      "  127301  102776   84531  122904   86046  -95123  101739  126992 -111345\n",
      "   79145  108147  -78286   71528  -75800  113514  -43189 -109449  121857\n",
      " -112518  100652   97029  117043  -59544   32907 -107937   46345  -76275\n",
      " -127061  -75249 -134067  -22615  -43393  -87948  -94764  127399   98415\n",
      "  -35454  -77998  -77449 -103971  -95874  -19991   53477  127352   39129\n",
      "   22906  -91976  120740   79650 -152719 -126580  -99846 -127523  -38059\n",
      "   54063  -94114  108572  109270  -99772 -114243  -53846   85150  -78970\n",
      "   60278  -98614 -129553   84113   49267  -21656  -13913  -78043   53115\n",
      "  120776 -104568  116708 -119730 -112123 -125134   80409  -50682   19371\n",
      "   43602   85277  159246   73158  -45194 -121686  119126  109094 -115939\n",
      "  -90042  -30041 -109838   53685  109572   42579 -104176  -72104 -112349\n",
      "   83965  125045 -139860  118760  -64525 -110809  -26689  119620  -72146\n",
      "  144788  -40669 -130363  -45719  -37455  119085  136133   12588  -20999\n",
      "   43965 -119222  -80070  126409 -139128 -119695 -107505  -66065   14043\n",
      "  126016  -95499  -74091   27708  -22108   67649  -12658   72289 -102482\n",
      "   76157 -104634   11038  142693  -75624  121352 -103685   78738  115298\n",
      "  122178   37959  -59005 -105894  -57219  -92822   99050  123316  -74564\n",
      "  -22798  -36043   81112 -118696   43583    -700 -114751  -42842  133062\n",
      "  128311   63015   -8151   36532   73873  -35910 -101909 -107064  128836\n",
      "  126561   27841  131453  -14900 -106801   60414    5011  139865  -61735\n",
      "  113247   76872  -52624  135649   99766   97778   60207   96617  -81325\n",
      "  122470  132129  -99735  111703 -112558  145219  132267 -123970  129955\n",
      "   39352  -89120   20629  -39299  -65569 -102220   86682  -96232   86342\n",
      "   53338 -100114  -77104  -47167  -32422 -122402   98814   36240   -9458\n",
      "  125750  101736 -105463  -85127   65074 -107611   20405 -100228  -53730\n",
      "   99867 -120314   38585  -69213   88538  110080  111305 -109014   74531\n",
      "  108355  -53412 -119514  139106  115195  106402 -109708  117995 -123798\n",
      "   97824   99712  -56851   72381  -82080  -68611   50529 -107006  119792\n",
      "   -6255 -120873 -121742 -108067 -105094  124728  127077  -36618    3764\n",
      "  -72436   99362   78064   84530  -18906   48447  131045  -49319 -118247\n",
      "  111712 -120492   71703   78644   38800   82861   70157   47509  -89332\n",
      "  -91304  -82996  -99446  -57588  116982  -81478 -134335  -30442 -119207\n",
      "   98913  -73239 -120662    7457  103812 -113757   60750  100741  -87203\n",
      "   -6447  123474 -121829  -44843   98497  106517  123458 -137891  -36907\n",
      "  -36229  -67988  -40852  -82512   57943 -109629  -84308    7963 -108697\n",
      "  -60286 -121758 -105908  127820  155404  -97289  127661  -78267  120320\n",
      " -116919  -52884   49189   19697  123413  -68231  -23051   57045  147762\n",
      "   90571  104725  103012 -102756 -124343  -82445  115555   56373  -61759\n",
      " -114440  101135  113444   95874  -99633 -122048 -106116  -26044  129238]\n",
      "h mod simd != 0\n",
      "inc_q:  [191 210 230 187 175 214 205 220 195 195 209 205 197 257 201 152 178 188\n",
      " 200 176 184 213 216 202 213 212 174 244 219 215 231 186 224 197 286 224\n",
      " 195 221 240 221 219 219 222 211 232 261 213 204 196 193 195 269 294 202\n",
      " 223 219 210 189 210 229 218 217 208 219 208 200 264 190 231 187 192 255\n",
      " 202 230 279 201 228 251 250 223 243 209 233 193 194 183 215 265 209 199\n",
      " 228 198 182 215 210 260 203 230 209 237 206 228 203 218 210 248 267 212\n",
      " 220 234 215 217 222 225 151 206 214 238 221 237 200 214 255 244 211 196\n",
      " 198 199 184 237 250 215 215 231 235 181 202 192 232 243 251 224 196 239\n",
      " 207 214 230 244 221 158 232 191 199 237 254 198 204 201 244 209]\n",
      "bias_q:  [   7932   41182  -30482   47402   -3108  -20733   31218  -77213  109835\n",
      "  -84373  -49153   25407  -65984  -75555  -51005  -66546   49246  -69242\n",
      "  -98022  -53038  -48939   -3800  -14516  -22776    8101  -83072  -38623\n",
      "  -92795  -36577   52123  -42282  -82140   -3117   40177   34214    4881\n",
      "   53060  -80596  -46157    1356   -7658   25576   19556  -54335    9020\n",
      " -144017 -181178   20586  -55449   50160  -40802  -65671    4478   67306\n",
      "  -87271   44244   92273  -51990  -10537   95399   33953   88962  -37094\n",
      "   41700   27442   50000  -51553  126118  -23743  -84336   26529  -93715\n",
      "   32143     776  -69063   25381  113574  -46245 -113311  -23920   56440\n",
      "   37204  -91135    1148  -24971   22407  -23576   78933  -61615    8107\n",
      "   48737  -18688  -31223  -78492  -13845   60724 -117214   89067   13421\n",
      "  -80792   80217  -15106   88479   13415   13979   70956  -52927 -107114\n",
      "   53099  -54008    9564  -10042  -36940  -54017    1989   -8200  -37985\n",
      "  -78581  -76550 -129314  -55831  -18027  105187   24307  128438  -42423\n",
      "  -19437  -48818   59929    1121  145665   92734    3560  -44765  -39438\n",
      "   -8843 -103149  -83553      15   66787   44811    5273  -97052   56484\n",
      "   28685 -102894   40621  -47572   -5724   96712  -37107  -47552  -99326\n",
      "   96183   -1541  -29928    5618   36299   59557   70240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inc_q:  [178 187 201 177 155 232 203 229 185 156 155 161 125 173 133 188 180 165\n",
      " 208 149 160 206 212 207 175 143 271 127 138 254 166 186 176 157 143 158\n",
      " 154 170 156 192 178 164 229 141 245 130 229 163 125 199 141 136 205 168\n",
      " 156 176 186 172 153 189 243 147 189 141 154 174 143 154 174 176 126 162\n",
      " 171 225 185 167 184 194 166 140 182 168 154 153 200 140 187 122 169 189\n",
      " 200 170 207 141 178 169 177 166 149 142 154 165 167 218 161 141 193 203\n",
      " 183 149 173 154 161 140 186 182 172 198 132 211 174 176 144 175 196 178\n",
      " 160 209 150 148 182 176 183 166 131 148 134 160 201 201 130 143 153 160\n",
      " 178 159 114 210 130 145 154 214 185 182 181 175 188 145 221 176 194 214\n",
      " 200 134 174 159 255 161 163 140 154 198 225 149 159 173 228 188 201 193\n",
      " 125 162 135 187 124 201 147 185 169 131 131 173 182 203 152 109 189 170\n",
      " 190 117 132 234 144 226 206 196 192 147 189 171 144 167 198 201 182 192\n",
      " 196 193 218 150 206 171 231 165 188 157 132 156 187 219 153 154 210 206\n",
      " 162 149 223 189 127 178 280 209 171 168 129 142 161 166 166 132 221 195\n",
      " 202 209 212 170 158 175 177 141 200 167 188 172 221 104 207 118 126 218\n",
      " 166 161 226 179 196 174 134 211 190 165 180 165 163 194 153 154 206 162\n",
      " 227 197 180 220 127 186 127 242 202 220 151 188 187 117 221 185 119 139\n",
      " 173 214 231 121 199 150 164 146 103 194 147 191 201 181 202 240 245 184\n",
      " 180 200 160 173 151 171 148 177 230 196 186 168 201 175 157 135 135 118\n",
      " 183 138 173 162 173 193 188 170 204 183 131 251 179 160 197 163 175 130\n",
      " 185 195 193 139 180 168 119 161 153 137 191 158 172 187 188 198 185 166\n",
      " 211 214 211 181 165 170 180 203 213 202 156 174 162 180 188 147 139 206\n",
      " 208 133 189 221 170 133 201 134 217 226 203 194 193 147 170 211 172 134\n",
      " 129 138 142 142 199 167 199 144 128 137 213 186 173 137 194 229 146 182\n",
      " 200 134 155 151 151 121 206 170 200 175 160 200 171 190 183 135 155 176\n",
      " 168 181 204 208 194 198 189 152 165 167 171 153 168 141 172 129 193 180\n",
      " 131 190 123 177 212 182 205 200 165 178 209 156 191 193 293 187 176 229\n",
      " 113 151 144 218 238 179 188 206 142 201 133 168 222 185 160 200 191 167\n",
      " 225 177 120 183 191 155 228 182 170 182 234 226 174 174 239 149 175 146\n",
      " 192 117 144 161 263 177 198 209 191 164 172 216 190  97 164 129 232 214\n",
      " 185 197 116 186 196 194 170 151 186 169 208 150 168 186 156 125 173 145\n",
      " 162 202 171 164 192 157 174 147 189 205 194 174 134 253 149 202 145 169\n",
      " 175 124 149 104 165 142 206 121 128 199 151 158 131 152 198 172 193 173\n",
      " 153 170 181 167 141 214 161 162 152 124 173 132 155 218 132 132 163 171\n",
      " 126 136 150 192 159 142 129 167 174 175 172 175 145 223 144 202 183 187\n",
      " 198 148 149 179 162 139 173 222 216 135 176 168 229 172 165 171 147 250\n",
      " 265 213 168 200 163 188 196 136 102 135 124 182 204 202 200 195 185 203\n",
      " 193 158 133 193 215 193 152 190 176 144 190 169 165 175 144 186 175 161\n",
      " 148 206 171 165 158 181 130 115 192 183 227 202 206 209 218 192 172 166\n",
      " 132 115 158 167 198 169 169 111 162 169 158 116 128 130 155 190 157 178\n",
      " 187 246 168 175 144 218 174 176 175 194 192 163 181 210 156 226 180 172\n",
      " 233 193 125 153 169 187 125 191 174 109 147 158 203 141 156 173 165 118\n",
      " 146 202 207 171 167 188 176 185 173 172 176 212 151 174 147 175 190 147\n",
      " 198 192 201 142 153 103 152 148 182 176 191 203 183 192 210 144 163 139\n",
      " 201 153 170 228 253 163 193 173 148 192 244 205 151 206 131 181 215 151\n",
      " 153 113 181 185 115 186 168 140 193 152 141 130 129 185 159 174 178 123\n",
      " 204 175 155 163 140 184 167 210 175 125 141 145 206 176 132 199 186 206\n",
      " 180 193 167 190 266 215 151 210 173 157 173 120 169 167 159 174 161 182\n",
      " 165 170 172 138 151 182 189 160 192 185 126 157 207 182 206 185 141 201\n",
      " 157 176 198 196 165 180 121 147 171 151 216 179 114 177 184 165 185 173\n",
      " 207 175 170 202 199 208 248 238 214 210 191 140 161 156 173 173 120 169\n",
      " 231 246 255 143 136 123 187 175 129 230 173 223 164 176 165 166 199 203\n",
      " 156 146 193 191 129 124 165 214 132 170 191 212 189 126 159 130 149 164\n",
      " 130 145 180 150 128 232]\n",
      "bias_q:  [  6265   2498   1524   2573  -7709   7119   1043    201   4082   2694\n",
      "   4635   4202   3835   5172   3064   4306   5850  -1590   -646  -5260\n",
      "  -5509   4784   -710  -1005  -3096  -4306   8233 -14483  -2715   4184\n",
      "  -3209   1289   1017   6341   1686  -5746    748  -1504  -2004    568\n",
      "   3631   3038  -2804 -12840   5187  -7696   -770   2898   2909    908\n",
      "   1731    642   1173   3759  -1280   3751   6294  -2789   1808  -4691\n",
      "  -4430  -2240  -3329  -6888   1254   4394  -4807   -281  -2603   5034\n",
      "     14  -2239  -2378   3211   3603   2793   1636   1716   4940  -8896\n",
      "  -2982  -8558  -8259   5406 -10072  -8585   7311  -4061   3626  -6163\n",
      "  -5708  -3372   1969   7805  -5154  -8647  -2098  -1054   -110   3069\n",
      "  -3139   1373   4073  -3094   2729  -7463    700   2942   2704  -1794\n",
      "   2639  -8232   2639   5609   3541  -4732   -504  -1608  -3052   -382\n",
      "   9204  -4525   2728   -936   3797    756   2247   4709  -8361  -5635\n",
      "  -4474    838  -1769   -247  -1006    833  -5126   -284  -3817  -4654\n",
      "  -3104  -2328  -3784  -4252  -2499 -12780    919   4427  -1156    553\n",
      "    419   5598  -6312  -8833    -15   4824   2587  -8244   4231   1488\n",
      "   4649   3530    245   7058   -425  -7624  -1083   1788  -2811   1625\n",
      "  -6893   3013   5020   1981  -2180  -6536  -7957  -2073   1539   2430\n",
      "  -9175    264   -610    582   -793  -3333   1373  -3304    300   3579\n",
      "   4261  -3156    -77    349  -1873 -12006   7325   -413  -2187   5253\n",
      "   8956   -597    325   2908  -6384   -700   3050  -4135  -2949   2881\n",
      "  -6706    -77   5610  -1297   1830   5562  -1501   2390  -1584  -2133\n",
      "   6158    700  -3994  -1441  -1865  -8071  -7807   4201    226   5965\n",
      "   6782  -2790   7566  -3733  -2606  -4057  -1494  -4466  -1009  -4426\n",
      "  -2015   3977  -3553   1430   3522   1583   -440  -5027  -1549   5811\n",
      "  -2345  -1454  -1800   -400   3853  -2255  -4390   2266   5154  -1488\n",
      "   3409   4916  -3332   6196   5586  -2838  -4808  -1569  -3827  -2728\n",
      "    327  -1212   7376  -5103   2799   7635   1887   1006   5119    423\n",
      "   4015  -5570  -3891  -5043   4658  -2163   4771   4658   2478  -3628\n",
      "  -7293   4324   3149  -3620    -99   -298  -2846    354  -4489  -1310\n",
      "   -501  -6551  -1634  -7448  -3913   3012   7618   2635   -504  -4209\n",
      " -12637   -254  -2446  -9122    -30  -2728   5238   5782  -6676    159\n",
      "  -3809  -4002  -4615  -3659    357  -1996  -1208   1776  -1597   6755\n",
      "   7540   4694    556   -275   1409  -3524    838    149  -5549   -160\n",
      "  -6290  -5822   5405  -2849   -188   1643  -4919   7299  -1729  -2942\n",
      "   -338   3246  -4534  -1948  -2815  -9134  -1451  -2179  -1221    925\n",
      "   -189  -1663  -2482   6677   1051  -4779  -7139  -5012  -2891  -3038\n",
      "    -12   -555  -5334   2410   2311     87  -5343   4628   2946    226\n",
      "   1928  -7920   5595   3802     33  -3672   3962  -5978  -4752  -7702\n",
      "   4467  -4611  -3501  -2455   4985   3537   7401   3045  -8862   5411\n",
      "    237  -2093   3856   7375   -993  -2502   4798   -727  -3081   1304\n",
      "  -4710   -508   6607   6108  -2318  -1579  -5418  -4013  -5061   3311\n",
      "   1392   2691  -9712  -1380  -5167  -4851   2165   1292   -457  -5070\n",
      "   8328  -4110   4448  -4903  -3922  -1287   4410   4342  -5074  -1366\n",
      "    981  -7531  -7785   4295  -1381  10804  -4604  -3144   5475   2501\n",
      "    449   -338  -6789   2227     85   7686   -428   2293  -6713    -41\n",
      "   -607    939   5530  -1060  -4581   4422   3186  -3939  -2640   4804\n",
      "  -6403   -800    350  -4711  -3444  -3657  -8513   8538   2456  -3334\n",
      "   -730  -6854  -1800   2925  -6614   2912  -2285    640   4338  -1045\n",
      "   4512   3731   -114   2258  -2829   2594   2885   4015  -1072   2383\n",
      "  -6324  -5633  -5961    738   4708   2369  -1640  -7646   7426   1042\n",
      "   3989   1861   -177   6480   2220    374   2458     38   3397  -3105\n",
      "  -2303  -2212    582  -5754   3777    148    811   9784   5267  -7436\n",
      "   2293   -556    696  -2939   3281  -2697    993   1126   4733   4075\n",
      "  -3193   4679  -6612   2975  -3939   -121  -4155  -3739  -2850  -3340\n",
      "   7013 -13039  -4147  -1711  -4767  -2954   5354   -643   3456   2144\n",
      "  -7115   -258    907  -3131   2055  -1810  -5286  -8475   1311  -5969\n",
      "  -4726  11140  -7984   3179  -6820   2602  -6615  -8401    326   -121\n",
      "  -1392  -3294  -3505  -4616  -1466  -2613  -1527  -1561   7225   -743\n",
      "     57   -728   1759  -9307   4862   6815    586  -2679  -2443   1860\n",
      "  -2482  -9208  -3561   5896   3257  -8421   1789   1174  -5345  -5399\n",
      "   4404  -3106   4575  -1202  -1321  -4361   2572   1976   5064   3553\n",
      "  -2607  -2292   2727   6305   1630  -4123    626   1208    201    390\n",
      "   1665   5973   4705   3210  -5131  -4450   8217   3498  -7600   5872\n",
      "  12178   2701   4454   -356   -870  -6675   3433   9631  -1405   6606\n",
      "   5726   6773    843  -1093  -1656  -8417  -2495   1932  -3951  -1913\n",
      "  -2199  -1549   3419   -159   2787  -2582   2066  -7111    178   5815\n",
      "   4161   4265   4948  -2251   4359    217   3055  -4323  -3768   -858\n",
      "  10499  -4004   2069   3227  -3015   5580  -2020   6140  11873  -1416\n",
      "    482  -4652   1965   6286   -140  -1992    779  -5485  -1187  -9808\n",
      "   1141     54    157  -3114  -2829   1688  10060   3049   1446  -2330\n",
      "   3246   2144   8734  -1425  -2059  -2322   1032  -3533   1179  -3849\n",
      "  12490   5918   3204    745  -6182   -394   4615  -2582   5113   1768\n",
      "   1590  -2297  -1429   2783    743   3555   2048  -1088   -893   6097\n",
      "   -207  -9049   5107   3907   3888  -3351   9572  -5452  -7899   9632\n",
      "    327  -1879   1384  -5382  -1409  -3624  -2680    491  -2804   4214\n",
      "   2317  -3725   4163   6963  -4816   2692  -1568  -1356  -7453   2733\n",
      "  -9156  -6427   3665   -365   1230  -6662   6778   4770   5706  -6134\n",
      "   -508   9172 -10369   -614  -2331   2108   1205  -2749   1248  -1811\n",
      "   2420  -2563   -324   -832   2320   2965   1388   -879  -6983   2666\n",
      "  -1044   -489   2535  -2174   -752  -1461   3616  -2052   7448  -5040\n",
      "    503  -1307  10214   -644  -2733  -1593   -378  -1811  11874  -1969\n",
      "    830    268   6481  -6487  -1316  -2857   6771  -1284 -11261  -7249\n",
      "   -211  -4997   1796  -3627   1399   -848   1637  -2543  -8917   1486\n",
      "  11567   1302    186   3671   3036  -3665   3740 -11996    699  -5766\n",
      "   5503  -1564   6762   3434  -2486   -797   4121   4870   -572   2229\n",
      "   3252    861  -9796    737   1739   -116   5523    176   1005  -1849\n",
      "  -5509   -693  -1498   6047  -6833  -5651   2562  -4844    -91  -6702\n",
      "  -5619  -2986  -2487    190    225    228   1755  -4252  -5448  -5950\n",
      "  -5348  -4933   1302     97  -4318   4787  -4684  -3181   9105  -4093\n",
      "  -4104  -7069   1126  -2870   -309  -1593   4531    623   -582   4902\n",
      "  -2934  -2298    128  -2593  -2752  -2582  -5540  -1114  -2427   3159\n",
      "  -3309  -8141  -5228  -7428  -1270    570  -4357   2325   1665   -366\n",
      "     67   2940  -4860   4074   1790  -1358  -4305  -5240   4222   2097\n",
      "   2365   2703   3712   2005  -5069  -2739   7463   5122   4493  -6103\n",
      "  -6400  -9147  -3754  -6470   6017  -9133   1176   8753    564  -3261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inc_q:  [2163 2579 2086 2077 3386 3236 1780 1565 1965 2220 1942 3037 2582 2453\n",
      " 1855 2456 1948 2354 2260 3280 2931 2960 2132 2731 2141 2912 1991 2505\n",
      " 2408 1758 3856 2958 2824 2442 2311 2245 1595 2571 2315 2487 1968 1954\n",
      " 2335 2469 2030 3047 2548 2315 2395 2631 2547 2335 3039 2425 1910 2040\n",
      " 1853 2406 2065 2418 2497 2209 2740 2702 2151 2609 2508 2444 1827 1960\n",
      " 1981 2323 2983 2784 2589 2065 2151 2615 2756 2601 2577 2226 2002 2550\n",
      " 2175 2857 2726 2763 2095 2145 2570 2918 2590 2327 2431 2506 2179 2728\n",
      " 3335 2649 1854 2251 2112 2750 1728 2630 2620 2310 2337 2526 2481 2416\n",
      " 2685 2434 2689 2852 2967 1754 2617 2092 2063 2525 2187 3331 1726 2127\n",
      " 2331 2035 2944 2259 3008 2779 2070 2264 2307 2492 2388 2346 2846 2767\n",
      " 2510 2905 2731 2426 2077 3478 3250 1614 2305 2645 2932 2015 3061 2896\n",
      " 2102 2429 2161 2377 1749 1865 1777 1806 2426 2233 2090 2667 2421 2013\n",
      " 2071 2165 2456 1914 1661 2207 1912 2242 2232 2241 2850 3017 2759 2103\n",
      " 2580 1804 2960 2400 1761 2421 2980 2036 2523 2635 2915 2367 2892 3310\n",
      " 2704 2158 1915 2640 2044 2256 2098 2015 2477 2579 2212 2558 2583 3056\n",
      " 2367 2380 1913 2082 2505 3002 2517 2306 2045 2219 2655 1976 2495 2561\n",
      " 2299 2736 2347 2742 3285 2406 2253 1758 1965 2840 2130 2329 2659 2432\n",
      " 1617 2359 2434 2115 2514 1990 2207 2249 2162 2819 2285 1970 2209 2280\n",
      " 2392 2373 1792 2941 2609 2592 2410 2836 1727 2386 3059 1968 2064 2895\n",
      " 3963 2348 3038 2545 2044 2256 2344 2435 1894 1949 2432 2447 2117 2440\n",
      " 2121 2285 2267 2519 2157 2403 1995 2964 2341 2630 2358 2317 2151 2501\n",
      " 2392 3203 2354 2737 1893 3297 2012 2754 2582 2847 2287 2774 1963 1949\n",
      " 2280 3080 2784 2697 2070 3000 2676 2716 2227 2589 2641 2631 2337 1754\n",
      " 2698 2645 2792 2171 2082 2434 1828 2232 2025 2382 2283 2039 2330 2186\n",
      " 1672 2352 2137 2265 2174 2275 1962 2507 2673 2214 2722 2556 2462 2454\n",
      " 2696 2483 2356 2445 2204 2010 2675 2890 2040 2421 2026 2422 2342 2128\n",
      " 2237 2611 3090 2781 2102 2294 1841 1975 1878 2771 1883 2339 3098 2229\n",
      " 2242 1740 2280 1859 2168 2707 2409 2204 2322 3013 2305 2004 2662 2696\n",
      " 2677 2579 2916 2369 2149 2228 1766 1721 2518 2498 2539 2532 2105 2587\n",
      " 2643 2484 2623 2452 2447 2857 2566 2465 1662 2081 3917 3215 2820 1906\n",
      " 2799 1954 2267 2652 2349 2358 2428 1844 1780 2408 2270 2407 2486 3133\n",
      " 2338 2199 1899 2274 2703 2695 2558 2508 2624 1955 2581 2644 3171 2803\n",
      " 2351 2353 2231 2609 3052 2239 2352 1816 2582 2790 1933 3009 2057 2493\n",
      " 2435 2289 2073 2412 2439 2879 2949 2014 1979 2203 1841 2275 2350 2725\n",
      " 2099 2521 2374 2529 2810 2672 3209 1948 2144 2759 3123 1933 2183 3012\n",
      " 2661 2355 2596 2021 2358 1963 2803 2019 2291 2853 2404 2209 2324 2717\n",
      " 1983 1803 2286 2106 1778 1909 2584 2268 2616 2302 1991 2941 2420 2616\n",
      " 2200 2315 1405 2196 2375 2409 2352 2329 2240 2113 1973 2550 1789 2235\n",
      " 1849 2229 1914 2080 3095 2396 2182 2398 2016 2237 2235 2270 3219 2308\n",
      " 2959 3102 2325 2498 1973 4422 2903 2688 2090 2535 1966 3064 2275 2376\n",
      " 1897 2182 2092 2693 3088 2261 2485 3349 2185 3015 2295 2561 2653 2212\n",
      " 2957 2563 2395 2394 2582 3183 2811 2460 3185 2227 2948 2434 2843 2700\n",
      " 2164 2523 2585 2466 2868 2166 1778 2379 2150 2807 2808 3001 2466 2665\n",
      " 1691 1929 2097 2260 3438 2845 2624 2206 2247 1986 2417 2986 2297 2986\n",
      " 2318 2423 1967 1734 2659 2924 2173 2540 1956 2212 2202 1806 1989 1906\n",
      " 2405 2147 2255 2109 2676 1920 2428 2086 2670 2172 2271 1949 2325 1913\n",
      " 2324 2128 2780 2179 2785 1894 2652 2377 2158 1774 2646 2830 2253 2306\n",
      " 2239 2740 2510 2869 2110 2053 2485 3035 2683 3835 2613 1894 2306 1600\n",
      " 2044 2249 2198 2577 2345 2651 1855 2347 2155 2886 1659 2765 3059 2175\n",
      " 1733 2494 2007 2054 1737 2755 3161 1936 1992 2378 2184 3110 2169 2210\n",
      " 2094 2699 1974 2750 2301 2544 2260 2813 2282 1720 3000 2125 1926 2368\n",
      " 1666 1533 2073 2610 2574 2355 2398 2949 2276 2413 2244 3073 2322 2333\n",
      " 2779 1841 2340 2966 2665 2200 2135 2608 2559 2232 1838 1986 2825 2802\n",
      " 1691 2516 2234 2748 1882 3060 2572 3123 1859 3372 1863 2810 2268 2623\n",
      " 2342 2312 1818 2690 2267 2554 2253 2211 2235 2232 2163 2293 2444 3196\n",
      " 2989 3754 1941 2700 2711 2304 2198 2496 2419 2237 2795 1721 2945 2378\n",
      " 2825 1991 2408 2365 2118 2415 2243 2483 2337 2310 2449 2163 2428 1750\n",
      " 3033 2530 2729 2455 2734 2505 2206 2326 2665 2480 2002 2246 1958 2241\n",
      " 2098 3009 2965 2944 2973 3096 1791 2681 2878 2309 1732 1999 3500 2294\n",
      " 1686 2145 2431 3089 2761 3287 2940 2526 1913 2069 2288 2219 2753 2027\n",
      " 2105 2927 3371 2226 2041 2278 2436 2584 2483 1980 1631 2364 1834 2428\n",
      " 2677 2459 2537 2649 2431 2721 2168 2184 2348 2292 2102 1843 2510 2250\n",
      " 2091 2549 2471 2477 2186 1792 2020 2958 1801 2865 2696 2212 3081 2365\n",
      " 2616 2346 2101 2355 2840 2304 3364 2147 2639 2132 2438 2357 2339 1947\n",
      " 2100 1981 2289 2559 1870 2022 3049 2769 3119 1647 1682 2449 1945 2051\n",
      " 2638 1719 2412 3213 2330 2269 2659 2388 2635 2243 2113 1849 2514 3390\n",
      " 2452 2466 2377 2827 2565 1921 2345 2665 3179 2340 2160 1870 1779 2706\n",
      " 1852 2261 2315 2525 2003 2975 2456 2393 2099 2773 2721 1899 2448 2371\n",
      " 2662 1849 3437 2693 2386 2410 3567 2017]\n",
      "bias_q:  [ 119712   -5768   25270    7038  -23158  -68989   28910   91372  134447\n",
      "  -49595    3651  -23101  -29411  -46212  -24920   71625  -41408  -39242\n",
      "  -10844   22766  -51230  -98334  182601  -31810   94454   -6700   87062\n",
      "  134201   41047   99886  -24809  -40182   40367  -38032  122187  -71796\n",
      "   89665  -23902  -26526  -57301  110712  156209    7747  -15018  102214\n",
      "     730  -29176  -94769  -92519 -136639   30481   68310   53441  -54627\n",
      "   69357  116341  103121   86603  104397  -64238  -87608  -62615 -104102\n",
      "  -85416   34538   85229  -22523  -38049   50379   57022    1606   24867\n",
      "   22794  -63348  -38626   18670   25723   17681 -101645  -97728   45548\n",
      "   49792  -79497   27075  -87894   -1300  -20314   -5596  144692  -91078\n",
      "   -6138  -26550   13541   58017   22208  -89801   61957   16488   27042\n",
      "   10316 -140456  -65368   15632  -22676   95986  -27714    5867  -25093\n",
      "   47964   20844   76563  151508  -16157  -37171   34919    3918   70850\n",
      "  156053   14690   68767   92348   -1032  -96051  -36398   65951 -134753\n",
      "  -36793   -8903   62962  -60989  -26110   37574  -45597   -5985  -29637\n",
      "  -17929  -35223   -6862  -10411   41438    1379  -84996  -46544  -72533\n",
      " -137051    2818  -20839   97470  -16703  115705  -27743  -88761  -19669\n",
      "  -67390  -50316  -34403  -18921   -6940 -155811  -47301  -91572   40790\n",
      "  -23597   83249 -110822   26969    6915  160417   14254  -52248  -45492\n",
      "   30267  115276   28740    5727  132505 -133214  -77959  -22498  -16991\n",
      "  -73073   62099   74694   92277   -8569  -40312   94163  101169  -16077\n",
      "    7122   89947  -18470  -38487  -46436   -8374   22474   75441  -18351\n",
      " -129489  -52400  -31785   26948  -93222   47801   24577   59960   35037\n",
      "  -84959   35688   21038  130414  -62821   19650  127658    8468  -59961\n",
      "   32353 -117050 -112520   14569   59686   17348  107331  -97372 -105848\n",
      "   99313  126479   31568   73989  125383   67831  138877   50539   30220\n",
      "   -9402 -133477   37885   47008  105026  113829  142072   92032  -45162\n",
      "   74660  -42627     168 -111608  -25663  -20221   28549   89485  -31678\n",
      "   19879   77883   41540  -33571  -38715    2498  -41715 -105891  129695\n",
      "  -84556  -20974   70310  -48119  -54393  -17465  108231  -31963   -8981\n",
      "  -33272   36962  -12401  -67619   21287   74211  -35499  173194   96868\n",
      "  -85439   26241  -83506  121889  -68968  -39590  -64693    7574  -56773\n",
      "   53126    3630  -11769 -100371   66311  -86261  -40767   38196 -117282\n",
      "  -45238   52138  -59171  -90754  -23956  -12495  -96760 -113686   87391\n",
      "   68193   44578 -119449   50579  -75118  -22903 -100519   75012  135227\n",
      "  -55414  -46987  -62619  101637  -35695   24413   96455  -22805   27277\n",
      "  -25991   35592   68732   92907   59303   35012 -141870   -1511  136288\n",
      "   29485  161260   81414  119263   60742   50049   55266  -72102  -53910\n",
      " -123932  -91263  -96650  -17845   80541  147417 -106950  114019  -15329\n",
      "  139555    1057  -70338   97210 -130715   63526   -6276 -121116   17568\n",
      "  -10516   28470  123305 -143109   54453  -75240  -66873  -11992 -128401\n",
      "    1705  113126 -135969 -130146 -119623   36240  -50398  -28206  128298\n",
      "    9905   84172   24669  -41999   75321  -50185 -110234  -25139   11806\n",
      "  -66376  -26091  -60380  -80186   -5516  -30972 -106476    4863   -1905\n",
      "   72735   52571  114159   35764  -11850  -21075  -50772  -68925  -10793\n",
      "   54935   20525  -20303  -82458  -34940 -105558  -39016   -9772   79368\n",
      "   71405  -10519  -30928   -7756   83504   65574   68681   18066   25055\n",
      "  -38117  117454  -53468  -41026  -31330   69605   83762  138110  -22993\n",
      " -123284  -68612    8969  -10507 -132061    5786  -26094  -79641   44130\n",
      " -106379  -76582  149221  -33767  -54980  -28534  -31252   28578  -91865\n",
      "   29754   51835   -8061   12207  -62045   68499  -62233  -36126   50196\n",
      "   -9600   15960   89562   -6602   23575  138684   34720  -28369   -5076\n",
      "  -44177  -81390  124560    8763   94482   -7990   17205   -7094  -53918\n",
      " -105198  -89593  -79378  -84655  -21820  -82383  -16636  -40627   12357\n",
      "  -10046   50270   83068   21566  -53843   28789   46604  -78200    5249\n",
      "   72144  -38910  -96821  -71744  -11597  -53714   19616 -101358    6296\n",
      "  -63737   87779   75319 -103619  -23046  114951  -31919   26358    1608\n",
      " -126091   17408  -73354  -44069  -46896  117104  -85528  137054  -46281\n",
      "  -60124  -20493  -53978  100691   44486   68396  130933  -48471   55868\n",
      "  -45869 -162064   79421   71278   33005  -30939    6547   49243 -107745\n",
      "   30683   28346  134158  -42948   28904  -93719      69   -6880  -59258\n",
      "   39802  127306   -4344  -37373   61775    7067   12115  104082  -34613\n",
      "  -46374  -66777  143766   11658   57269  -63860  -38386   58372  -18275\n",
      "  -18996   80015  -77035   53194   24163  -43168  -90774  -49217  -51385\n",
      "   33821  -81780  135035   50387  -17541  119511  -88865  -83483  101266\n",
      "  -62017   -5805   49186   13412   18130   40168   12253    9355  115569\n",
      "  144382   57267   83625  -45474  -58901   67172  -61572  -34969 -114412\n",
      "  -38205  -73469  133862   55732   20127  -38710  -27435   96003  -82781\n",
      "  -84735  -51046  -29564  -58338 -114697  -81556  123729  102195   10906\n",
      "  -61702   20320  -64611  100015   67647   21264  111365  -52527  121578\n",
      "   -2784   52830 -173815  -97947 -119344  -71167  -66778  -12400  -70168\n",
      "  121725  -61265   79596  -94339   72624  120481 -107642  116550 -134106\n",
      "  -26782   41215  101508  -28442  -40752   72074  -32552  -59787 -114107\n",
      "  -89140   17646   -8827  126238     386   38679 -127318   80413  -32004\n",
      "  -61248    4262   96005   87039  -84695  135698 -102215   31181  -74138\n",
      "  -87170   58295   68977  142514   21711   12787   12895 -143951   75820\n",
      "  -49942   30598   79525   36058  124590   83250   91083  -62470  -51262\n",
      "   68584  -92386  -65027   -5520  -78986   50497   65797   -7522    7391\n",
      "  -51112   51202   18936 -135787   72992   13475   -7453  -58209   51764\n",
      " -124113   26855   81535 -163653   84426   84261   -8757  -14047   -6957\n",
      "  -79871   40181   -3179  129776    7161   17353 -150955  -61859   58881\n",
      "  132663  -39541  -34530   26869  -50650  -52844  -82929  -59266   58623\n",
      "   68260   54020  -41405  -69706 -128306  -15774   77762   26625    9051\n",
      "   16598 -108602  -42711 -117367  -15248   99529   75189   98295  -78859\n",
      "   65261   36931   70917  143530  -12320  -60515  126961  -29983   58698\n",
      "  -98383 -111729  -10475 -108522  -11748  -90018   77934  117317   37524\n",
      "   12829   -8090  -89383   17155 -142189   74238   66113   47554   57871\n",
      "   39603  -75298   88800  -71244 -127919  -92509 -112192   33740  -33095\n",
      "  -37462  148568  113688   99234   82833   68934   -7143  -73516  -41131\n",
      "   28349   -2283   41921   73079  -99751   15621   36822  137849 -138448\n",
      "  122464  106388  119252   41647   15277   19039   31472  -99613  169961\n",
      "  -27490  -27322  -84839 -142124 -127293  -42976  117426   74428  -59141\n",
      "    6539  -48412     300  -53103  -99592 -110789  -98714   20761   86430\n",
      "  -73074   24401  144017 -176483   -7315  -71938   -4193  152365  -81450\n",
      "    4813  120065   15573  106041   80571   84064   32924   54676    -230\n",
      "   62692  -53077  -41076  -54246  112877   32270  125407   36858 -181098\n",
      "  -77696   32914   -8804  -31418 -105254   36125   20805  -16326   28204\n",
      "  148064 -155648  -40462 -135291   41398  -83945  -53539   59344  -77412\n",
      "   -7555  -57596   81107  -32310  -34346   76485   31204 -104681  -14502\n",
      "  -23096   25606   49565  -35136 -115833   98867   -6323  -16731  -51568\n",
      "  -18651 -144328  -25393   -8180  -62843   86659  -56650  -65492   89075\n",
      "  -16884   84788 -102857  152206    3139   37001   39852   35746  -20462\n",
      "  -52953  -20279   92945 -131136 -101926  -47386 -104906  -51589   -8793\n",
      "   -4643  -82958   35598    4445  -42999  124282   48450   68378 -138818\n",
      "  -30319  153357   -1909  -71670  -67572  -96662   18394  -26248   12153\n",
      "  -79387   38734  -63934   46276  -77997 -118625  -45953  -15105 -112148\n",
      "  -11151  -23996   15578  107060    -825  -82452]\n",
      "h mod simd != 0\n",
      "inc_q:  [202 186 236 230 229 182 244 207 205 220 193 243 207 239 200 229 205 212\n",
      " 234 240 247 207 239 206 247 177 226 296 245 227 220 267 240 209 210 235\n",
      " 276 200 224 221 217 237 215 167 221 214 219 223 206 237 244 191 221 241\n",
      " 234 245 171 303 230 260 222 251 187 247 210 220 257 258 237 235 181 237\n",
      " 243 216 197 233 202 204 224 282 238 233 214 229 188 198 244 187 212 248\n",
      " 184 239 188 243 226 206 240 228 228 232 197 202 272 241 210 210 267 258\n",
      " 258 289 204 233 178 206 245 217 246 240 173 185 220 205 220 214 228 203\n",
      " 250 222 197 194 275 222 277 230 203 230 257 268 227 250 232 276 233 226\n",
      " 226 253 213 286 210 238 237 198 206 229 248 203 208 230 205 220]\n",
      "bias_q:  [ 113586   35598  -43186  -24854 -130444   61443   19513  -71415   32375\n",
      "  146648   49110  123915   10884   78038  -21949   16265  -65748  -88946\n",
      "  -39330  -12622   -4605   72325 -111760  -81001  -84305  -26364    3453\n",
      "  -86661 -101958   29696  -67501  -63607  127616  140116  -36262 -106493\n",
      "  -23109   14983  -80577  -72312   30436  -30054   23043   11468  -64561\n",
      "   37575  115180    1691    3554  -96997  -10676   20024  172351   21419\n",
      "  -57284   34748  -35083 -117657  -67849   47424  -54754  -39697    2257\n",
      " -134809 -107509   -3849  -59407   67200  194266   29173   81257  -29562\n",
      "  -30052   46784  -47376  -86242  -86026  -50064 -102927   92600   18186\n",
      "  112457  -95606  -61065  -59891  -66553  -73287   47603 -103563  -99030\n",
      "   80393    9809  130745  -60036  -78419    6152    3185   61431 -132997\n",
      "   81360  -66714   23773  -48615  -59817  116666   61110  -14521  -45343\n",
      "  -34056  -47581  -11600  -88737   12245   72111  121017   10670  -49641\n",
      "   58139  -92057 -121350   89833    6493   38633  -52494   68359   48621\n",
      "   58077   92692    -510  -33262  135104   77379    3853  -10927   48520\n",
      "  -28637 -177440  -43899   35155  101233   -1164   -4508   59516  -14642\n",
      "   43269  -53805   85375  -52237   54085  -17912    -940  -79636   31614\n",
      "   47985  -15362 -114893   55694   62976  -91707  186325]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inc_q:  [148 137 130 116 141  99 139 130 123 176 147 119 105 127 149 132 144 196\n",
      " 115 129 115 134 139 125  99 156 124 144 124 125 123 154 124 110  99 111\n",
      " 132 126  93 109 127 145 122 148 116 126 117 108 102 139  89 173 106 124\n",
      " 139 117 122 119 132  86  88  81 125 149 108 116 102 124 122 137 130 104\n",
      " 123 131 140 137 136 111 136 132 179 117 164 110 131 123 119 143 128 136\n",
      " 124 107 147 132 131 129 141 156 105 127 118 117 148 136 102 104 123 123\n",
      " 121 129 113 147 101 130 114 130 116 107 134 110 106 110 111 150 115 104\n",
      " 142 111 146 158 109 131 115 118 146  85 113 111 151 130 122 136 162 124\n",
      " 115 104 137 124 120 134 173 116 134 130 138 126 109 125 134 111 124 156\n",
      " 106 140 161  97 139 131 108 124 121 132 146 146 129 124 113 138 112 151\n",
      " 128 112 124 155 127 183 124 121  99 142 136 146 101 130 132 133 117 117\n",
      " 148 108 116 138 106 132 120 103 152 105  92 153 158 152 112 127 145 129\n",
      " 130 125 124 124 118 113 100 122 124 113 111 131 108 146 118 121 103 126\n",
      " 146 117 162 109 114 124 153 119 102 101 137 109 128 127 118 129 105 134\n",
      " 119 113 135  99 138 135 131 129 138 124 120 118 122 149 120 138 137 104\n",
      " 159 135 152 123 121 116 148 144 119 166 113 124 125 128 138 140 162 113\n",
      " 148 109 143 134 123 138 111 135 116 102 152 194 136 142 179 166 133 139\n",
      " 116 103 164 139 126 140 133 114 105 123 117 134 112 135 120 143 157 138\n",
      " 134 140 108 138 132 142 145 131  89 132 110 117 151 105 131 146 111 156\n",
      " 123 136 103 141 119 129 118 149 149 147 134 107 127 129 103 168 137 122\n",
      " 101 143 126 113 144 105 131 117 113 134 145 128 134 117 145 104 104 115\n",
      " 127 155 133 195 131 114 130 118 106 136 146 125 111 116  99 133 135 136\n",
      " 128 121 165 118 127 133 151 135 157 111 139 166 138 147 119 100 109 109\n",
      " 136 145 151 139 109 128 136 125 131 110 111 146 122 141 135 139 116 108\n",
      " 119 151 144 163 140 122 144 114 120 106 121 138 124 123 129 129 136 120\n",
      " 128 164 111 125 131 177 123 182 128 114 114 179 134 125 141 127 120 117\n",
      " 137 114 136 145 129 120 111 109 134 135 123 136 117 100 125 153 140 120\n",
      " 126 128 115 115 126 142 149 132 135 134 113  95 110 132 130 124 135 158\n",
      " 135 117 131 143 123 128 123 123 156 106 123 139 114 150 131 139 109 125\n",
      " 146 136 104 131 122 133 127  93 144 121 128 125 138  93 121 121 119 149\n",
      " 126 131 120 108 138 141  94 137 127 110 123 111 121 127 140 154 120 111\n",
      " 101 104 101 125 138 108 156 137 102 129 126 118 116 112 126 124 162 121\n",
      " 115 104 127 105 143 122 108 106 119 106 131 132  96 114 153 127 128 134\n",
      " 122 143 123 156 126  87 122 110 114 133 120 132 108 154 133 174 134 123\n",
      " 143 129 117 119 128 141  97 128 116 103 143 129 123 127 180 110 114  98\n",
      " 119 129 116 116 121 142 107 140 147 188 140 136 127 126 128 149 157 108\n",
      " 143 129 139 152 171 156 116 125 138 120 117 145 138 159 108 126 139 166\n",
      "  85  93 128 140 126 126 135 127 133 117 167 106 158  88 129 141 113  98\n",
      " 122 157 112 119 153 114 130 138 114 193 110 117 129 138 105 137  97 110\n",
      "  99 127 138 128 151 112 121 115 139 124 122 120 127 121 138 112 115 114\n",
      " 118 103 111 116 142 105 132 148 158 128 114 131 149 122 121 104 104 122\n",
      " 154 144 124 129 183 165 110 134 108 101 117 144 115 132 148 149 126 158\n",
      " 126 149 137 104 137 127 141 116 123 149 120 133 131 110 119 106 118 133\n",
      " 131 174 137 106 135 173 141 140 135 132 122 143 135 101 130 126 122 115\n",
      " 145 130 109 131 134 128 160 128 145 130 123 116 118 131 118 126 158 126\n",
      " 108 124 152 139 131 121 145 127 141 131 108 116 140 176 123 134 120 134\n",
      "  90 146 134 131 134 139 153 117 113 119 139 132 136 112 175 131 129 144\n",
      " 134 159 128 126 138 143 131 109 102 138 134 118 146 133 136 125 146 113\n",
      " 114 143 115 123 160 141 138 119  99 136 111 132 138 135 125 137 105 107\n",
      " 152 153 123 128 117  88 132 171 125 139 127 168 102 151 127 103 118 121\n",
      " 108 155 120 122 154 122 123 106 137 160 133 117 115 125 114 137 185 155\n",
      " 137 147 140 123 108 127 118 143 150 152 124 141  97 158 133 162 126 137\n",
      " 124 116 137 123 140 171 134 112 129 126 128 107 122 130 135 127 115 132\n",
      " 117 113 122 122 128 130]\n",
      "bias_q:  [ -5357  -2905   1656   3525   -966  -2075   5802   -880    -18   -930\n",
      "   3001   1851   9311  -1403  -5274    472   1721   1090  -3531   -456\n",
      "    419  -1413   -683   5036  -4256  -3005  -2545   -944  -1300   2403\n",
      "  -1902   7595    316  -9164  -8460  -1004   1720  -4087  -5212  -6186\n",
      "  -5485    118  -6551  -1688  -3892   4290  -2445  -6226  -4279  -1634\n",
      "  -5100   -160  -3522   2774  -9081 -10407   1694   3842  -2709  -1991\n",
      "   -852  -4899  -8948   4625  -9044   2189  -7375   3788  -7663   -381\n",
      "   2434  -2038  -1119   4259   3740  -3097  -1079    712  -4182  -4313\n",
      "  -1942    874   2473  -7138   6697  -2627   1888  -1828 -13028   4987\n",
      "   1905  -2918  10038   1163  -1559  -4321   1638  -5881  -4136    740\n",
      "   4103   9097    694   2823 -13437  -3459   4944   4420   1656   2283\n",
      "   4325   1887  -2741   6754    542  -3283  -2454  -3121    311  -1736\n",
      "   4271  -4722  -4625  -1864    273  -5490   -570   1961   -837   2878\n",
      "  -6928   7556    509  -5617    172  -6578  -3364  -8059   1759    684\n",
      "   2088   6242   -433  -8440  -1011  -9190  -5334  -6472   1940  -1925\n",
      "  -1166  -5534   3619  -4025   1690  -6533   1396   -302  -2232   5534\n",
      "  -3612    274  -8551   2973   2254  -7078  -2554  -1216  -6437  -7516\n",
      "  -3522   -565   -929  -3776  -6202   3487  -3215  -2927   2154  -3674\n",
      "  -1582  -5524  -1146   2059    903  -3758   1684    255   -787  -2302\n",
      "   -481     34  -1891  -6213  -6519    491   2277  -2007  -5934   5268\n",
      "  -5347    199  -4238   3340   5283 -11113  -3879   8451   2395  -2572\n",
      "    379    569  -7568  -5451   3523  -4724    250    887   -113   4127\n",
      "  -3401   -752  -3313  -6445   1474  -1624  -1364  -4994  -6502   1361\n",
      "  -6813    671   4118   1339   5059   1316   4559  -2317   1114    496\n",
      "    224   8652  -7032   1371     14  -2901    960  -9676  -9479  -2540\n",
      "  -1596  -5156  -4700  -7704   1593  -4958   1412   1703  -3357   -842\n",
      "  -2123   -811   1232 -12621  -6073    978  -1066   -594  -2166  -5497\n",
      "  -3411   -694   6106  -3073  -2198     15   5392    413  -1947  -3195\n",
      "  -7986  -1166   -458   2296  -6319  -9963   6173  -4774    725   1555\n",
      "   -461   1767    395   4581  -2820  -2234  -4155   6163   -477   1868\n",
      "   2340  -1893    -43   9116   5911  -4642   8387  -5975   3451   -265\n",
      "   3052   4313   1402   1422   1420   3918  -2113  -1083   4921   -300\n",
      "  -8733   6294   -619   3666   1565   1708   2467     77  -7780  -2130\n",
      "   1244   1508   2692   2352  -3239   1358   2906  -3414   3466  -2663\n",
      "  -1239   4400  -2509  -1755    718    483   5051  -3793  -6006    231\n",
      "  -3922  -3033   2289  -2227  -5529   2777    876   1865  -3887  -1447\n",
      "  -8630  -1929  -4252   8752  -1101  -3079  -4595  -4041  -4280   1143\n",
      "    279 -12678  -2135   -243   4623  -7361    332  -4184 -10247  -4778\n",
      "   5990   5366   2723   -235  -3096    392  -4262  -4299   4583  -3754\n",
      "  -3798  -1674  -4773  -2187  -1320   -845   6568    583   3679  -4569\n",
      "  -1041  -4957  -4711     89  -2151   1844  -3615  10090  -1661   3028\n",
      "   2259  -2075   3392  -6507   6336   2054  -3020  -1281  -3039  -7007\n",
      "   5203  -1474   -705  -6561  -5076  -2129    562   3214   1527   -771\n",
      "  -4385  -2815  -4072  -7684  -2778   5334  -7450  -1447   3214   -972\n",
      "   1711  -6089   1512   -514   -772   3363  -1209   1810    232  -4737\n",
      "   4819   5109  -2527   -105   -476   6712   2565   4706  -2472   2598\n",
      "   4040   5045  -4880   4132    -95  -1354  -1921  12363    120   1325\n",
      "  -1953   3982  -3763   2498 -11636    118  -2330   3669  -6387  -1310\n",
      "  -4700  -3834  -7159   1416  -3567  -3585  -1470  -3424  -5023  -4818\n",
      "  -1837  -5011   1766  -1298   6978    808  -2991  -4352   5349  -6237\n",
      "   -356  -2274  -1765   3664   2180  -6518   5580  -8100   2920   -601\n",
      "   3478  -8139   5286   2070  -4025  -3210   4022   2064  -2035   2615\n",
      "   -688   3797  -3033  -2587  -8840  -4380  -9601    468  -2507  -7854\n",
      "  -6726   4659      5   6253   3811   2488    677  -1909   1081  -9016\n",
      "   -652  -5849  -5268  -5499   2978  -2032  -7252   -829   7771  -2839\n",
      "    882  -5088  -4074  -1699  -3888   1696  -8164   2607  -7322  -4808\n",
      "  -6981   -869  -3530  -6571   3345    611  -4459   4199  -1029  -6286\n",
      "  -1066   5408 -10250  -3880   2740  -2434    208  -3260   3938  -1025\n",
      "  -5418  -8698  -5577  -2114  -8355  -8649  -2662  -4909  -3359  -4324\n",
      "  -6739  -2892  -1118  -1279   3818  -7774  -4712   8869   6281  -3108\n",
      "   4752  -4628  -2163  -4109  -8016  -3969  -1375   2387   6753  -1349\n",
      "   4221  -5598    804    796  -3307  -1938  -9454  -1849  -6709   2113\n",
      "  -2551   -522   1931   1550  -2776  -4943   1487   4381  -2073  -5779\n",
      "   2813  -3958  -7681  -7975   -328  -2774  -2376  -3863  -7474   5020\n",
      "     69  -3118  -4940 -11255   2775  -3567  -3038   1830   1813   -329\n",
      "   1811  -7070   7128   -896   3525  -1439    265  -1838 -10162   1447\n",
      "  -1958   1643   4429    519  -2588    174  -1128   -592  -5059  -2929\n",
      "   5117   1920  -1103   -893   5781   1930   5326   5286   2443   -947\n",
      "   2174   3576  -4769  -2150   5742   3470  -1616   -544   5114   3157\n",
      "  -1127  -6616 -11013   6296    866    463   4172    -86  -1010    416\n",
      "  -4822   9209 -11303      2 -10273   4103   3269 -14758   -364   -543\n",
      "  -1031   1383   3628  -2884  -2847  -5466   5307   -749  -3609  -8024\n",
      "   1989  -1192  -4949   -894  -3468  -4033  -6029  -1280   1742   3452\n",
      "  -6307   6893  -1060  10282    571    177  -4993  11253  -1481   4721\n",
      "  -4636  -6294  -4024    786  -4072  -2577   1756  -9652  -4512   5016\n",
      "  -8596  -7576  -9733   2962  -5457   9168  -3329   -442   4993 -10727\n",
      "  -1735  -2097  -3524  -8009     17   1808  -5660  -2208   1352   1358\n",
      "   -700   1744    901  -5431   9437   6552  -2057   -147   1133    274\n",
      "  -3957   2275  -2204   -747  -4627  -2054   6703   1807    408   1831\n",
      "    555  -1098    624  -1734   -473   3191  -5125  -3098   -916   4086\n",
      "  -3189  -2431    714  -2650  -2507  -1657   3336  -1598   -758  -9269\n",
      "   2421    941   6043    920   -901  -3437  -6797  -4755   1135   1258\n",
      "   2268  -3881  -1006    577    204   6570   -251  -4281 -10699   8982\n",
      "  -7274    961  -5995  -7492    780   4355  -5789  -3759  -4037   2325\n",
      "     84  -1090   -976   -143   5325  -5360   -825  -5331   -103   3076\n",
      "   -566     26  -3297  -1491  -2470   1040   1671   -591   1214  -4143\n",
      "   4744   3852   4453  -6923  -9726  -2742    262   3712  -6426   3289\n",
      "   1542  -2883  -2587    814    -68   1577    901  -6313  -4272  -3039\n",
      "   -453   4492   1657   5510  -5871  -1467   5597  -4974  -2966  -2440\n",
      "  -8237   5749  -2473   1486  -1142  -1849  -4455 -23527    680  -1599\n",
      "  -5162   7393   1656  -8098   -969    289  -3208  -7924  -2275   -835\n",
      "  -2883 -10785   2269  -1238  -1859   1603    127   6206   5138   -367\n",
      "   -249    517  -2837  -2681  -2970  -1663   2442   1248  -5627   2924\n",
      "   -362     58   3196   3732   -891  -4989   -340  -4083  -4489  -2719\n",
      "  -3220  -7675  -6262   -638    400  -2697   1604  -3647  -2846   2450\n",
      "  -2855    191   1392  -3662  -6199   5800    190  -3332  -3005  -1807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inc_q:  [2060 2212 2087 2538 2385 2156 2166 2036 2075 2325 2512 2494 2014 2734\n",
      " 1876 2505 2671 1718 1950 2817 2196 2256 2305 1428 1843 2308 2394 2277\n",
      " 2454 2380 2934 1635 2100 2125 2301 2859 2380 2266 1903 2093 1918 1786\n",
      " 2689 2294 2165 2047 1864 2201 1871 2389 2636 1825 2440 2169 2642 2892\n",
      " 2268 1973 2956 2277 2481 1948 2605 2283 2153 2280 2321 2023 2113 2184\n",
      " 2812 2520 2943 1721 2737 2331 2179 2420 2855 2149 2318 1854 2675 2098\n",
      " 1655 2461 2463 2232 2187 2579 1734 2482 2557 1878 2848 2840 2388 2336\n",
      " 2506 2160 1633 2350 2194 2261 2604 2218 1858 1957 1752 1920 2108 2354\n",
      " 2000 1889 2025 2320 2252 2408 2203 2291 1887 2773 1781 2190 2236 2411\n",
      " 1908 1912 1982 1803 3233 1963 2721 2336 2511 3338 2224 2348 2099 2161\n",
      " 2298 2025 2212 2469 3042 2455 2081 2628 2546 2753 2343 2107 2733 2587\n",
      " 2033 3713 2995 2379 2411 1321 2091 2262 3001 1861 2708 2246 2249 2048\n",
      " 3205 2258 2259 2297 2240 2316 2644 1687 2096 2286 1731 2573 2408 2317\n",
      " 1877 2280 1797 1945 2171 1577 2677 2357 2442 2104 2229 2369 2009 1867\n",
      " 1722 2348 1732 2625 1892 2256 2391 1675 2021 2350 2481 2248 2096 2472\n",
      " 2254 2211 1756 2035 2223 2443 2031 2192 1981 2261 2502 2359 3079 2539\n",
      " 1855 2577 2329 2289 2057 2018 2203 3176 2554 2753 2297 1933 2012 2833\n",
      " 2349 1929 1800 2307 2275 1995 2178 2581 1816 3344 2558 2201 2680 2019\n",
      " 2960 2043 2499 2303 1855 2831 2336 1973 2808 2159 2323 2737 2319 2101\n",
      " 1901 1979 2383 2808 2878 2124 1712 2578 2028 2180 2211 2025 2174 2201\n",
      " 2076 1830 1967 1689 2254 2018 1907 2203 2452 1976 2314 2141 2068 2268\n",
      " 2143 1431 1946 1570 1715 2333 1787 2965 2376 1774 2532 2089 2029 2829\n",
      " 2148 1773 2674 1814 2240 2160 2457 1896 1836 1618 2527 2138 3011 2575\n",
      " 1769 2006 1697 1861 2151 2186 2143 2261 2531 2458 2872 2008 3074 2089\n",
      " 2378 2166 2280 1592 2684 2315 2106 2123 2507 2266 1922 2438 2294 2326\n",
      " 2509 2062 2260 2284 1920 2127 2161 2144 3276 2374 2911 2521 3078 2571\n",
      " 2157 1781 2430 2534 2326 2713 2299 2077 1987 2008 2073 2268 2057 2190\n",
      " 2661 2281 2473 1792 1719 1274 2510 2427 2757 2124 2021 2059 1930 2022\n",
      " 2723 2188 2815 1994 2009 1977 2046 2215 1934 2948 2420 2148 1825 1661\n",
      " 2325 1816 2206 2069 1777 2369 2080 2095 3132 2476 2148 2112 2017 2002\n",
      " 2014 1925 1789 2449 2382 1527 1611 2002 2191 2294 2581 2136 1733 2316\n",
      " 2076 2070 2222 1854 2150 2554 2051 2231 2412 1968 2818 1845 2325 2265\n",
      " 2279 2639 2249 1836 2307 1818 1932 2577 2641 2189 1563 2397 1661 2265\n",
      " 2974 2244 2863 2283 2119 2071 1881 1811 2052 2136 2893 2459 2360 1985\n",
      " 2798 2842 3006 1957 1640 2174 2545 1834 2092 1843 2026 2101 2283 2034\n",
      " 2017 2328 2123 2677 1989 2075 2263 2424 2183 2620 2406 2275 2380 1775\n",
      " 1997 2804 2245 2496 2457 1843 2291 2736 1522 2208 2095 1677 2140 2456\n",
      " 2422 2611 2498 1892 1928 2071 2161 2608 2582 2682 2752 3013 1801 1790\n",
      " 2157 1989 2061 1990 1899 2287 2237 2789 2222 2423 2192 2942 2152 2073\n",
      " 2777 2057 2208 1935 2710 2371 1967 2577 2073 2644 2070 2522 3283 1902\n",
      " 2155 1988 2171 3778 1933 2423 1840 1984 2430 2624 1962 2358 2246 2133\n",
      " 1678 1820 2528 2641 1748 2542 1816 2047 2373 2443 2770 2192 1683 2267\n",
      " 2098 2782 2664 2102 2333 2453 1730 2242 2414 1813 2010 2760 2216 2140\n",
      " 2368 2169 2250 1868 2834 2454 1871 2461 2226 2653 2607 1895 2480 2049\n",
      " 1904 1915 2555 3363 2419 1888 1733 1869 2750 2328 2390 2280 2333 2562\n",
      " 1789 1976 1967 2029 2374 2278 2412 2144 2815 1948 2904 1702 2263 2469\n",
      " 2317 2267 1701 2153 2013 1975 3648 1915 2246 2703 1996 2416 2216 2108\n",
      " 2016 2177 2096 1866 2876 1978 1957 1673 2674 2754 2159 2464 1708 2735\n",
      " 2007 2179 1808 2643 2444 1632 2267 2500 1996 2026 2427 1965 1440 1725\n",
      " 2029 2558 1925 3623 2544 2614 2508 1694 2371 2070 1824 1682 2906 2253\n",
      " 2322 1725 2654 1971 1816 1871 2421 2763 2275 1910 2421 1904 1810 1918\n",
      " 2096 2707 2360 2313 2318 2111 1862 2327 2210 1649 2017 2651 2694 2412\n",
      " 2363 2449 2375 2097 1937 1859 1950 2131 3853 1872 2079 2013 2476 3147\n",
      " 2584 2159 2340 1659 3288 2207 2629 1784 2108 2303 2651 2476 2589 2423\n",
      " 2316 2327 2708 2501 2904 1976 2176 2607 2008 1739 1824 2219 2463 1868\n",
      " 2104 2959 1876 2219 2086 2047 2159 1913 2074 2824 1873 1855 2067 2442\n",
      " 3246 2327 3124 1980 2385 2241 2068 1862 1962 1849 2330 1866 1839 2102\n",
      " 2093 2200 2010 1818 2409 1819 2241 1809 2385 1689 1868 2261 1999 1650\n",
      " 1939 2340 2525 1779 2468 1789 1732 2132 1913 2108 1888 1693 2357 2077\n",
      " 2426 3145 3305 1803 2264 2251 2350 2575 2721 2130 2758 2598 2177 2180\n",
      " 2401 3008 2052 2357 1878 2584 2073 2720 2052 1921 2118 1569 2367 1966\n",
      " 2680 2227 1892 1975 2108 1986 2680 2506 2022 2072 2862 2358 1753 2567\n",
      " 2617 1981 2175 2342 2732 2283 2211 1901 1810 2610 1695 2156 2388 2061\n",
      " 2523 1841 2014 2734 1905 2825 1756 2529 2426 2145 2696 2120 2394 2146\n",
      " 2333 3173 2321 2441 2250 1611 2123 2892 2727 2007 2519 2049 1825 2276\n",
      " 2057 2031 1859 2399 2695 2687 2762 2442 1828 2788 2126 2300 2493 1897\n",
      " 1541 2451 2311 2111 2632 2162 2428 1785 2016 1979 1486 2186 2854 2046\n",
      " 2302 2329 2018 3270 1756 2162 2107 2507 2479 2656 2496 1671 1593 2149\n",
      " 1779 2310 2206 2865 2012 1629 2129 2182]\n",
      "bias_q:  [-124374  -22895  144774    4685 -110967   58990   40601  149933 -113463\n",
      "  -25522  -97301   78464  -11571   35190  139446   74951  -26542 -131954\n",
      "  -89312 -125678   23434  -74029 -129168   98733   -3251   22953  114902\n",
      "   11964   93809  -70875 -119558  126650   12704  143995    7635  -34984\n",
      "  117568   14807   85816  104127  -43978 -124272   37196   72314   -6972\n",
      "  -75662 -129723  -17954  -56927  -11002  148106   72169  -81480  -54176\n",
      "  -73593  -50036  -65403  108525  133523 -100165    4918  -44531 -116358\n",
      "  -87427  -62021   61488  -15247 -133355 -118489  -68520  -10660   -8297\n",
      "  -73503   91242  101720   39566  -56900   66643   -7775   18441 -107495\n",
      "   61471   29452  -24731  120295  136284   -9622  -18184  -72261  -49410\n",
      " -126639   14014    7092  -42313   11999  -54024  -13435  118069   34485\n",
      " -133463 -178321  143806  -99145  175441 -130485  -59046  165691  155950\n",
      "  122987  -33661   42710  -56104   78089 -160588  -56692  -19308  -29833\n",
      "  -21223   23162   19467   66306  181102  -11649   30777  -44127  -74371\n",
      "   45083  121072 -110860  148103  118847   48144  -85017    7543   -3686\n",
      "   15958 -128285 -108403  -12286   69415  137577  134361   26952  -92856\n",
      "  -16308  -68245  -75741   74746  -95296  177420 -129035  -26361  -50516\n",
      "   42712   70367   25206   14994   -3368   69589  133734  130967  -26246\n",
      "  135837   20625  -33301  -31043   -5544   53048   86725  168831  157037\n",
      "    9968 -106907 -123020   -2882  136366   98333 -139811 -104360  -32124\n",
      " -143955  -70491 -121111   39215  119124   32432  -67192  167050  -44234\n",
      "   17537   16996   93784  -43320   45926 -117913   65851 -156655  -52679\n",
      "  -43634 -123083   99226   21097 -100223  137334  179997  165962   60668\n",
      "  171342   66435  -23520 -100124  114615   73899  149793  -69103  122748\n",
      "  134008   75258  113228   91374 -130563  -67441  -65748 -104834  131994\n",
      "  -20750  -25070   -3005   20642  -82382  -83171  -30089   63088   67393\n",
      "   72441   11856  -96766  -17603 -130361  111121   58515  121066  -29136\n",
      "   47629  -19600   54636 -120853 -124000   74416  -30786 -105316 -123161\n",
      "  -42805  123803  -14276   -5614  159701  -25071   80035   72602  -21568\n",
      " -101746   69323 -111515 -107371   10707  -77695  106423  -65782  -36152\n",
      "   11146  -84999  152965  -36117  133043 -113476   97403  145387 -161344\n",
      "   -8990 -123718  -82006   55353  133118   98040  154674  131653 -118787\n",
      "  -65547   95811   66223  131568  126851 -141747  136806  115770  -19584\n",
      "   -2141   94360   97721  142102  -81475 -122553  118710  -39045 -117883\n",
      "  -20973  -49278   22692   89157   -9447   87126   53624   18445  100918\n",
      "  124224 -159201  141601   18065  -82333  -18750  -45587   42862  -69114\n",
      " -124203   20348  -40742   31086 -101299  -90975  -50966  102342   11473\n",
      "  -20738  150174   84380   53879   53906  187153   71401  -71452   51541\n",
      "  103648  -23520     914   16365  107601  -85349  -10343    7775   41478\n",
      "   52356   14012 -148170   -1034 -132306  138485   14677  129920  -23823\n",
      "  -32722  -76502  -71776  -79790  -47508 -103411   26414  143734  -42098\n",
      "  -64721   30164  -29919  120727 -130146  -33924  -90341 -145692  115479\n",
      "   49975   59924   40098   35128  103018  136894   -1239  132171    -925\n",
      "  -29179   90375   70604  144294  121610   38034 -134553  -40883 -155481\n",
      "  -10516  -90310   98067  -67451   -5878   32100  176758  -28839  -11864\n",
      "  134083   -6444   80917  106463   65083   91025  134526 -126005  -82799\n",
      "   35554   36306  -55405 -148836  -92310   60485 -125951  -21053 -132782\n",
      " -122240  -98239 -123847  103953  127288   96598  -81273   42175 -156039\n",
      "   18454 -116843  -61880  -51021 -113912  111212  -24216  -65927  148813\n",
      "  -15598  -30082    7991   14464  143050  -40593  -35549  157961  -91110\n",
      "  112824 -140398    8347  112261  123908  -82673  -85936   74356  114357\n",
      " -118891    -362  -25614  -35665  117594  -37515 -139778  -63018   -4281\n",
      "  -46764  -49776  -13082 -106421   12302   58026  -48943  -86900  -79384\n",
      "  -10341  -61708  146782    6104   39211  129523   18311   50116 -115022\n",
      " -105099  -98251  -55354  -77521 -126395  -61996   88800    2528   29259\n",
      "   68249  168641  -39497 -150664  -81580  -35924    7963   75450   78767\n",
      "  -48410  -47205  -56591   36588   53265  -27158  -65543   -7905   43745\n",
      "  -23335  160181   56538  -51949  -16991  129325  -37675  -60857   -9234\n",
      "   42819   -4740 -117918   42116  -19476  -38669  143592  -66276   55707\n",
      "  123684  -20727  -48602   55808   -5471  -74097   28253  124820  -55294\n",
      "  -71729   93255  -36734 -135474 -147316   27675  -11463    -651  -46411\n",
      "  118003  120734  163924   17149  -16092  -71774  -50059  -35523  145956\n",
      "  -68319  -80462  -32390  -95085  -64724   74576  144707  109351   30692\n",
      " -148947  -58843  -83522   34128    7939 -114506  -57371   61012  -35742\n",
      "  -93333  -63715 -117506  -88695  128550   73167  -98472  -36737  -54391\n",
      "  139277 -121406  -75138 -131840  -20171   39131  -16035   -3959   29399\n",
      " -125523 -129432  -68362 -118889  -27304  -54632  -42851   -8168  101952\n",
      "   18580  -22591  107833   31541  -50173   34472   32546  169494  -59603\n",
      "  -58167 -101328   39320  -15458  -42105   84680 -141583    4147   11279\n",
      "   77896   61815  105646    6013   31568  -29589  -36083  -26674  -89689\n",
      "  -25129   86471  131726 -116387  -73350   53555  133683  128635  -95651\n",
      "   64314   83884   93516   40118  -40195   69837  106544  116451  -25546\n",
      "   68642   63155  -87724 -107812   -7919    2529  -73930  129442  141897\n",
      "   91034  -98063   15532   59054 -162117  112311  106278  138809    2816\n",
      "  -42763  -66239    1484  -45481 -172307 -156272  -16039  -87639   67419\n",
      "  -28004   78244  -10174    5505   31111 -159163  163445   -2679 -112637\n",
      " -155515  128165  138934  -18387   34244  -17159  118071 -116399 -155687\n",
      "  131140  -16472    4664 -156360   72654  -38904   78603    5781  159242\n",
      " -154867   33971  147101  102224  -25487  -65284   73663 -126745    1542\n",
      "  135128   61997 -103685  -56313  -97504 -127093   69361 -133169  -24985\n",
      "   35827  154672  -24075   36318  121170 -104243   -3918  100778   42187\n",
      "  167025   43832  -70016 -150716   23495   -5739  -58287  130861   66353\n",
      "   -6551   34526  -40229  -33880  -47444  -35073   69620   64664  -58872\n",
      "  -32905   90471  -17036  -69037  -32694  -73896  -58509 -114064  -55191\n",
      " -102113   69753  -18749  -63972  -57095  164779  -38353   99800  111616\n",
      "   46695   59503   -7654   12985  -51529   76379  -46135  113876  -63626\n",
      "   60036   97708   13772 -129396 -153738  -24458  -55741  -64404  171575\n",
      "    6222  -69852  102404   24307  118884  -28860  -14129  -91551   89612\n",
      "  -66456  120188  -53561 -127515  -45102  -45067   11476   70782 -108071\n",
      "  145774  171236  -93645  -57510   30389  -53746    6967  117341 -146210\n",
      "  -12011   74167   65525  -54477  -28100   83205 -116368  104127  -90115\n",
      "  -73382  116346 -124838  139496  139791   54693   12171   77466   26248\n",
      " -112993   45609  -31876   38231  120020  -34572  -70942  -44078  -54287\n",
      "    6281  -97324  -18637   90140  -27818   93564  -35294   85485    3946\n",
      "  134434  -19521  -61261  -73512   67827  148225  -45535   18775  -30792\n",
      "  -18498 -115716  -37550  117352  -35224    2659  -16986   22767 -118715\n",
      "  -14510  -62689   35645  115232   25545   62819    3737   28150   79550\n",
      " -108867  -63979 -125344   11399   98803  109353  -28763  106328  -57089\n",
      "   99796  112598  -99957  -32245  125639  -79247 -139210  -42917  -41566\n",
      "   48684  -12782  141484  158140  -11482 -126237  159269  130406  116780\n",
      "   52329 -112075  -38696 -101198  -49117   -2551 -116241  -79518   65520\n",
      "  -12695   10360   88573  147661   79106   80591  148723   35012  -22219\n",
      "   53695   29271   44272   -9067  150608 -131396 -141719  136437   38875\n",
      "  124102  125171 -142801 -106638  121153  132860   99697  100650  -36129\n",
      "  -33080   16635  123168    -475   -2033  -63055 -130545  139608   30680\n",
      "   78698    6182  -33485   27284  125577  107594  -53720 -162951  -66267\n",
      "  121939  119813  107371  -18928   80966   78716]\n",
      "h mod simd != 0\n",
      "inc_q:  [284 228 355 372 280 280 346 308 291 282 317 357 275 293 336 287 282 340\n",
      " 252 287 310 295 337 327 301 319 350 300 360 323 274 277 227 341 269 305\n",
      " 335 282 270 374 325 217 354 243 322 311 314 347 325 212 383 282 331 253\n",
      " 340 240 344 279 263 295 372 322 367 389 348 359 344 312 246 354 386 258\n",
      " 267 369 297 310 297 312 298 349 358 313 323 316 279 246 286 220 223 321\n",
      " 326 294 290 271 278 307 370 294 337 331 311 338 270 249 394 329 320 282\n",
      " 336 289 309 287 279 340 264 352 306 321 255 293 298 316 351 351 359 356\n",
      " 301 318 278 309 264 284 307 251 378 380 298 394 339 334 268 327 311 293\n",
      " 278 346 317 294 388 346 353 314 342 387 307 350 328 295 284 305]\n",
      "bias_q:  [  -2591   13741  -74766  -46359 -140436   60670   78666  -35126   90314\n",
      "  130569  -75084   36488   60634  131709   47544  -62615   13008   24406\n",
      "   59101  -52183 -103637   19527 -189059  -96431 -237559 -252042  -26827\n",
      "  -23019   -8482   96243 -299192  142625  -46094  -40630 -123099  -91566\n",
      "   45454 -108115   49676  -67496   63235   14787  202289   73606   81943\n",
      "  -33737  112454  -88982   10861  -31128  203852   -7206  -61038   -5897\n",
      " -134279  -44324  -12363   -3593  -17667  -63811 -173542   69894   -5201\n",
      " -358899   99487  -52864    7268  258683  -12764  312298   18674   -3915\n",
      "   20590 -133501   17875   91905 -101416    6390 -105675    8877 -136450\n",
      "   40684 -161186   57386 -105575  -22300  -88045   67344  -39750   30896\n",
      "   -8415   -8216  -57072  -17782  166375   43928  -66272   10230 -287634\n",
      "  -11673  -85769   20129  118108    6580  -56508  148652   22280  107735\n",
      "    -689   -8097  -26802  117448    5501 -270365  155776 -108093  -33256\n",
      " -115575  -18597   -2976   62141 -127445  158070 -291998   -9580  181223\n",
      "   89182  -31842 -207531   41908  179913   83644  -77128  -10245 -228676\n",
      "   93760 -117875  -71138   97254  -44827   18844  103949 -114238  -83617\n",
      "  -69640 -118673 -233518 -177370  194811 -235431 -178631 -104165  -82690\n",
      "   42035   71302  115364  163348  -74233  -10140   87219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inc_q:  [ 75  94 105  86  93  92  87  79  79 103 110  84  85  98 102  88  65  88\n",
      "  95  81  91  75 111  86  90 100  76  70  78  88  89 111  85  90  81  93\n",
      "  71  82  84  82  82  97 102 104  81  73 105 100  84  90 115 102  91  93\n",
      " 103  85 104  82  76  82  86  82  98 112  94 100  98  78  76  95  83  81\n",
      "  76  94  80  80  73  85  66  80  91 109  85  94 103  97  84  83 126  98\n",
      "  76  81  91  84  98  88  78  76  87  88  78  82  87  95  86  93  93  68\n",
      "  82  78  76  73  80  81  85  79 105  78  69 102  89 103 113  81  80  91\n",
      "  86  81  89  94  88  85 120  92  90  86 102  92  87  69  91  88  83  80\n",
      "  86  79  87 109  86  85  70  77  92  87  96  98  82  73  84  96 102  78\n",
      "  83 103  92  96  87  80  86  91  83  93  76  93  93  79  94  92  94  76\n",
      "  90  93  80  92  83  86  89  89  99  86  88  84  98  85  69  84  85  68\n",
      "  81  75  86  78  77  87  93  97  97 112  82  84  91  94 100  74  82  92\n",
      "  86 100  79  95  74 102  68  84  82  87 104  81  73  84  94  91  78  85\n",
      "  98  92  94  84  66  96  97  73  97  91  71  85  87 102  91  87  89  88\n",
      "  84  77  96  99  82  87  81 102  92  67  76  82  95  97  95  70  88  91\n",
      "  77  76  96  94  74  95  97  99  80  79  79  89 113  70  66  92  74  87\n",
      "  75  86 102  89  83  79 104  79  99  83  75  85  87  90  63  86 101  85\n",
      "  91  83  97  74  80  84  91 109  81  98  83 104  87  89  77  87  82 101\n",
      "  86  98 102  85  99  82  85  96  81  79  98 112 110  59 103 109 102  75\n",
      "  82  87  75  89  75  72  75  92  79  88  86  97  68  84  98  91 113  78\n",
      "  67  89  79  76  90  99  84  74  68  78  88  81 107 102  89  79  87  91\n",
      "  84  78  85  84  95  96  88 103  80  84  92 107  88  98  77  94  95  73\n",
      " 104  96  89  77  76  94  97  95  74 113  90 105  95 101  82 109  86  83\n",
      "  85 102  83  98  72 112  78  94 102 100  88  90  82  99  89  73  90  73\n",
      "  96  92  81  88  65  80 121  86  87  97  93  93  90  84  84  96 108  79\n",
      " 106  86  72  93  90  95 104  85  98  75  87  89 102  77  88  97  78 118\n",
      " 101  81  76 107  97  95  96  93  95  78  73  86  98  69  87  80  91  96\n",
      "  79 105  80 105  77  89  70  70  86  73  78  88 101  94  91  81  79  96\n",
      "  97  74  87  80  68  84  84  80  78  84 111  84  96  82  93  79  90 100\n",
      "  93  67  92  75  76 115  95  91  84  95  99 122  94  81  82  85  95 113\n",
      "  78 102  85  82  92  95 101 119  83  89  82  87  94  96  87 102  80 102\n",
      "  81  81  87  84  82  84  85 117  92  86 105  92  89  86  90 103  77  83\n",
      "  81  87  89  97  94  94  94  89  82  79  85  88  80  75 113  92  88  79\n",
      "  86 100  90  87  86  92  93  83 110 100 100  76  81 100  93  97  83  86\n",
      "  83 102  84  88 109 106  86  96  79 101  88  83  81 108  78 102 104  90\n",
      "  69  84  86  83  94  82  81  90  95  90  83  97  80  83  82 102  79  89\n",
      " 109  86  86  98  73  88  88  94  90  87  86  80  72  81  83  89  87  94\n",
      "  80  80  83  77  76  79  83  83  87  82 100  91 104  84  88  82 121  69\n",
      " 102  85  87  85  77  86  83  80 109  85  85  98  77 104  85  90  82  88\n",
      "  86  96  64  89  84  71  92  94  71  86  89  74  84  89  85  95  94  95\n",
      "  79  79  95  79  94  77  84  85  78  79  93  84  78 100  88  94 103  93\n",
      "  93  75  88 103  82  79  72  89  77  88  97  92  97  88  94  91  86  86\n",
      " 129  85  84  87  83  72  83  80  99  84  87 102 107  78  98  87  88 100\n",
      "  93  95  84  93  98  84  80  96  95  83  94  72  79 104  82  95 104  96\n",
      " 104 102  85 105  99 113 115  85 101  79  95  94  85  90  80  77  78  92\n",
      "  85  74  77  89  91  68  79  92 103 100  85  86  97  94 110  98 103  78\n",
      " 108  91  80  83  92  82  81 100  85  89  92  87  94  80  79  83  98  85\n",
      " 100  95  78  87  88  77 113 116  76 110  80 110  82  83  71  89  86  86\n",
      "  89 108 114  90  96  90  90  76  88  87  80  94  86  91  99  94 103 101\n",
      "  82  68 100 128  88  90  92  95  74  80  83 106  85  96  76 113  95  72\n",
      "  77  92 101 107 100  99  80 108  79  91  87  98  84  87 101 100  73  80\n",
      " 107  79  76 103  83  90  94  94  93  81  72  88 110  93  77  98  81  90\n",
      "  98  90  66  99  80  91 107  83  81  82  93  65  83  82  83  95  91  83\n",
      "  88  81 109  89  98  82]\n",
      "bias_q:  [  1260   5489    529  -1702  10512   -775   2673 -12593 -10708   -745\n",
      "  -5795  -7148   1915  -6839    609   4064 -14221   2447  -6556   1411\n",
      "   3396 -12961  -5719  -6674   4200   2241 -15725  -8180  -8653  -1988\n",
      "    300   3572  -6273   4024  -2340  -9978  -5339  -2034  -5700   7761\n",
      "  -6416   7850   -304   2757 -16030   -147  -3729   1268 -10487  -4929\n",
      "    828   4172  -3833   6403    796  -6832   3090  -4420  -7670  -3529\n",
      "  -8261  -6612  -5870  -3184  -8026  -1564   4755 -11450  -8201   2321\n",
      "  -1657  -6247   2858   8129  -4313 -12710  -9599    340 -13497   6249\n",
      "   2050   2872  -1704   3863  -4660   2739   1536  -6143   4064   1967\n",
      "  -4488  -1707 -13745   -767  -5891  -6236 -11811   2703    784  -7183\n",
      "  -5922    553   7600  -3112   1423   5272  -2737  -2447  -3265  -4317\n",
      " -11250 -10609  -3607 -13409   4379    843    701  -5422 -11273  -6297\n",
      "  -7790   4781   1337  -8936  -4410 -10738    432  -1891  -4591  -5298\n",
      "   3477  -3913    428   2156  -7504  -4931  -6661  -3694  -6096  -6774\n",
      "  -5462   2762  -2368  -6226  -6930  -4691   9496    908  -8469   2319\n",
      "  -4658  -3193  -9410  -2664  -7829   4676  -2103  -3929  -6721    -36\n",
      "   -339  -3997  -5778   2946  -1561  -3794  -5322   5363  -6536   8368\n",
      "  -7576   2398   -227  -2779    346  -4048  -4503    800   2128 -21635\n",
      " -13904  -1617  -1489   7325  -2927  -5761    716  -3494  -7727  -4338\n",
      "  -8170 -10817   6884    613  -2301    127   8921  -4370  -2026 -12121\n",
      "  -4433 -11694  -7668   7233   2637  -8689   1600   2739  -1136  -3741\n",
      "   -649  -5856    980 -12142    802   2559  -5518  -2723   -681   3444\n",
      "  -1384  -5960  -8347   3918  -2430  -9681   9507   4254  -7015 -10758\n",
      "   3079  -1144 -12039   1394   3688   5125  -4658  -6197  -2053   1092\n",
      "   1480 -15841  -5387  10485  -8606 -10270   1883  -1797  -2397  -6193\n",
      "  -5525 -12850   5333   3483   -227   3404  -2470   2004   4028  -1238\n",
      "   -764 -10247 -14106   8493   8074    561  -1557  -9583   -241  -6191\n",
      "   -202   -621   -968  -2467    723   3199  -7569   8582   5319  -6088\n",
      " -10614  -8276   5524  -1252  -5129  -2248  -1294   -581  -2588  -4087\n",
      "   6639   1665  -3293  12251    541  -4709   4769  -4024 -13550  -1905\n",
      "  -7213   -453 -18310   -579   2417  -4541   2083  -7046    698  -2185\n",
      " -10824  -7752  -1045    379 -15790   2300  -4895   -710  -2640  -7352\n",
      "   1555   1586   -657  -1189  -5646  -1628   6334   3604  -2673   -520\n",
      "   3166  -1605   1641  -6789  -5112  -6741   3874  -3870  -5348   4387\n",
      "   -757  -7365   4183   2956  -6316  -1434 -15724 -11736  -3784  -6879\n",
      " -13562   3177  -8990  -4205  -2663  -2780  -9480  12139  -3376  -6631\n",
      "  -7918   2621   -734  -8201     94  -1691   2135   -326  -3596   9617\n",
      "   -846 -12177   -917   1945  -6201 -14400 -11805  -1485   -940  -3550\n",
      " -10312  -7760  -5023  -4812  -1873   2152  -6084  -3528 -10447   7407\n",
      "   4701  -2026  -5447   2929   -328  -5376  -1438  -2825    877  -1127\n",
      "  -1764  -8273   2908    974 -18471   5434   -279   3700    322   3334\n",
      "  -6512  -3171  -4663  -7370  -2384  -3983  -1411    231 -10488    893\n",
      "  -6309   1558  -1719  -4612   4084   1551  -2160 -14474   2732  -9086\n",
      "  -4698 -12675  -7264  -2586  -5857    989  -3430  -8448   5798  -4885\n",
      "  -5257   -771  -6055    604  -5389 -13818   -201   1634  -2774   7782\n",
      "   3845  -1971 -10254  -3834  -3654  -3261  -4819  -2826  -1868  -5773\n",
      "  -6257  -1237   -128  -7707  -5884   3696   -208   -287  -1791  -8093\n",
      "  -7649  -5838   7378   3910  -4131  -1471  -9323   1720  -3903  -1624\n",
      "    384  -6086    591   2132   1596  -1054  -2126  -5921  -2215   2429\n",
      "   -827  -4743  -8307  -5367 -11067  -8517     70  -4776  -2831   3828\n",
      "     61  -2867 -12553    -39   3767  -7428  -1026   2865  -3209  -4447\n",
      "  -7146  -7243  -6225 -10162   1602   -424  -4203 -10816   -588  -5984\n",
      "  -5921   3690    391  -4052  -8161 -10966  -2723   1140   8499   4068\n",
      "   1223  -9655 -10858   3290  -1179   -411 -10509 -14733   8085   8383\n",
      "  -1749  -1816  -8601 -16565    985   2647   2561  -2269   4698   4524\n",
      "  -9794  -5866  -1967  -1536   3612  -7735 -19198  -7025  -1127  -2513\n",
      "   5185  -3526  -7380   1960   3870    175  -1761    914  -1164  -4614\n",
      "    304  -1185    134  -3700   4687   -691  -6152    472  -3986  -6263\n",
      "  -1958  -4682 -17775    547  -3934  -2640  -2531  -5061 -19750   -888\n",
      "   -328  -2083  -1614  -8025   5819  -1130 -11516  -1650  -4041  -1022\n",
      "  -7863  -9392  -4527   4096  -1442  -7858 -13564   4107  -2261   3045\n",
      "  -5892   4482  -9777  -5654 -11951    414   8110   4511  -5387  -2464\n",
      "  -3505   2434  -5800  -7594 -10720  -3121 -10936  -1332   7311   2585\n",
      "  -3279  -9182  -5834   1489    191 -10293  -2992    578   2766  -5113\n",
      "   3267  -2970 -11350    366 -13141    841  -2250  -8623   2718   2302\n",
      " -10231  -6082  -1527  -1493  -3964  -6406   -624  -7423   1489  -9633\n",
      "  -4717  -4449  -1667  -3630   3284  -4918  -3495  -3081  -6710  -2354\n",
      "   3319   3959   2804   -537   4816  -4684   -856   -884   -687  -8303\n",
      "   -706  -7243  -1947 -11818   7868  -8409 -11237  -6626  -1771  -5943\n",
      "   6673  -7425   -813  -2630  -8710  -1374  -5446  -2057  -7512 -10732\n",
      " -12370  -3599  -3656  -2181 -14916   1000  -2923  -3002 -13028  -2298\n",
      "  -9825  -1360 -14552  -3051  -2910   1950  -6125  -2571   4024  -9087\n",
      "  -9230   4757  -6916  -9459  -1771   2203   6581   2326  -2092 -11569\n",
      "  -1616  -7375  -3707   -770  -9044  -8349  -4456  -3034  -3199  -7635\n",
      "  -1009   5808   6442 -11567  -3114  -9773  -2363  -5542  -2739  -2588\n",
      "  -2621   2615   -849  -5636  -2121   6900   9050  -7550  -5940  -1619\n",
      "   -827  -3806   9048  -1452  -4911   -204  -2460   2688  -4671  -3136\n",
      "  -4692   1590  -9090  -6755   -360    848  -6589 -10707   2272 -10471\n",
      "  -5417   -480   1927 -12020   1128  -5891  -2665  -6949   4090   1230\n",
      "   8113    759  10608  -1047  -1340 -16587  -4551    -33  -2563 -12716\n",
      "  -2872  -4601  -6713  -2438   -822  -2624  -3540 -11174  -6631  -2179\n",
      "  -2680  -2214  -1053   4238  -3648  -6883  -6867  -1558   8277   -584\n",
      "   -573  -3661   1966  -3757  -2658 -12644  -2178   -368  -5481   5274\n",
      "  -1607   6472  -9311   -694  -5164  -3426   -366  -2359    738    328\n",
      "  -8991   5567  -4577  -1781   4644  -7685 -10411   -595  -1016  -3863\n",
      "  -4212  -8137   3064  10247 -12286   1744    216   1713  -5198   2130\n",
      "  -8239   6930   -786   5304 -14588  -2456  -2891  -3587   -343  -4475\n",
      "  -5353  -8178   1082  -7760  -3239  -8291  -1709   -575  -2368  -5473\n",
      "   7936   2156  -7959    153  -8212   3843  -2784  -5073   3490   2393\n",
      "   2605   -642  -3783 -11524  -1390   3345   6415   3373  -2379  -2639\n",
      " -10784  -6648  -1401   2306  -1238   7198  -6232   3154   5484  -4322\n",
      " -10113  -4766  -3234  -3655  -5966    329    112  -5951   3993  -6542\n",
      "  -6714   -363   3234  -8139 -15988   1710    171  -3095  14097   5021\n",
      "   2530  -5736  -5066   4494  -9500  -5565  -3788  -4423  -6016  -5997\n",
      "  -6575  -7035  -2849  -5059  -5404   3089   2099  -9535  -5821   6784\n",
      "   5299  -1089   1604  -7264   2158   4335    456    598  -1195   1098]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inc_q:  [1460 1882 1577 2140 1652 1675 1772 1549 2284 1749 1327 2348 2059 1793\n",
      " 1734 2084 1511 1631 1678 1274 1916 2069 1432 1500 1572 1977 2138 1568\n",
      " 2671 1951 2119 1701 1382 1667 1569 1567 1952 1478 2274 1793 1475 1694\n",
      " 1350 1201 2060 2366 2011 1549 1715 1748 1163 1630 1445 2440 2296 2308\n",
      " 1408 1434 1794 2428 2029 2042 1402 1665 2038 2002 1699 1611 1998 2067\n",
      " 1360 2120 1464 1517 1938 1516 1512 1302 1851 2108 1361 1573 1978 1507\n",
      " 1691 1528 1440 1989 1676 1659 1824 1650 1922 1766 1832 2095 2236 1576\n",
      " 1776 1579 2162 1607 1506 1285 1926 1423 1986 1698 2045 1559 2376 2370\n",
      " 1650 2544 1405 1518 1571 1976 3139 1668 2088 1607 1807 1897 1829 1564\n",
      " 2120 1907 1370 1698 1829 1438 1448 2070 1899 2631 1828 1680 2514 2621\n",
      " 1855 1779 2059 1603 1697 1796 1634 1683 2290 1320 2236 1794 1842 1635\n",
      " 2426 1830 1442 1601 1990 1757 1808 1883 1230 1340 2018 1563 1854 1733\n",
      " 1828 1523 1822 1489 1171 1400 1569 1808 2222 1514 1792 1929 1845 1869\n",
      " 1580 1454 1815 2270 1488 2090 1797 1940 1691 1523 1411 1891 2053 1573\n",
      " 1222 1674 1617 1930 1932 2166 2476 1758 1902 2093 1664 1597 1774 1929\n",
      " 1744 2005 1569 1803 1739 1368 1250 1769 1727 1456 1807 1732 2189 2288\n",
      " 1955 1712 1788 1565 1795 1910 1400 1424 2204 1819 1951 1469 1718 2318\n",
      " 1864 1517 1503 1813 2100 1365 1627 1967 1414 1759 1451 1780 1830 1921\n",
      " 1836 1367 1456 1820 1666 1660 1698 1904 1296 2341 1804 1445 1442 2262\n",
      " 1552 1524 1325 1790 2145 1954 1757 1330 1797 1829 2076 1543 1567 1667\n",
      " 1711 1969 1601 1726 1763 1346 1796 1709 1610 1550 1274 2138 1600 1848\n",
      " 1869 2149 1962 2148 1850 1655 1479 2023 2353 1627 1504 1505 1352 1975\n",
      " 1981 1134 1835 1714 1713 1619 1978 1310 1641 2287 1490 1294 1985 1984\n",
      " 1984 1707 1751 1680 1558 1687 2107 1732 1612 1545 1657 1788 1355 1889\n",
      " 1750 1479 1477 1892 2307 1638 1310 1423 1712 2083 2496 2130 1786 1821\n",
      " 2289 1495 1940 2165 2112 2136 1876 1405 1386 2777 1689 1652 1806 1557\n",
      " 1843 1811 1615 1565 1642 2107 1544 2368 1401 1428 1522 2207 1948 1691\n",
      " 2090 2248 1694 1690 1558 2137 1799 1431 2528 1743 1833 1499 1264 1947\n",
      " 1852 1371 1364 1966 1453 1327 1980 1688 1559 1756 1347 1612 2051 1456\n",
      " 1932 1436 1694 1392 2018 1644 1676 2083 2404 1562 1973 1451 2232 1828\n",
      " 1374 1934 2005 1398 1961 1050 1507 1921 1459 2227 2063 2289 2007 1538\n",
      " 1769 1653 2762 1848 1420 1790 1417 1848 1919 1660 1769 1811 1707 1329\n",
      " 1533 2094 1355 1622 1717 1938 1521 1580 1626 1267 1881 1542 1876 1406\n",
      " 2309 1961 1713 1702 2148 1703 2307 1648 2011 1726 1597 1604 1747 1925\n",
      " 1520 1787 1244 2163 1577 1716 1787 1637 1690 1494 1551 1916 1669 1693\n",
      " 1834 1276 1821 2367 1703 2728 1969 1648 1803 1801 1618 1872 2066 1430\n",
      " 2117 1999 1349 1418 1498 1415 1753 1908 1643 2036 1606 2142 1335 2069\n",
      " 1824 1590 2122 1689 1605 2920 1709 2146 1761 2040 1814 1677 1312 1993\n",
      " 1740 1546 1516 1931 2159 1793 1240 1342 1575 1568 1678 1648 1809 1694\n",
      " 1185 1766 1412 1819 1667 2502 1381 1494 1654 1480 2315 1804 1910 1635\n",
      " 1538 2061 2100 2211 1769 1717 1807 1535 1601 1482 1403 1753 1710 1836\n",
      " 1326 1868 1878 1691 2095 1392 1485 1745 1922 1626 1715 1304 2483 1522\n",
      " 2943 1838 1482 1434 1812 1418 1781 1383 2416 1716 1392 1745 1856 2323\n",
      " 1852 1397 1515 1853 2078 1789 1611 1698 2131 1931 1589 1647 1491 1745\n",
      " 1648 1365 1508 1282 2281 1911 2200 1471 1647 1723 1821 1642 1651 1628\n",
      " 1780 1665 1635 1953 1980 1748 1278 1566 1644 2268 1879 2074 2801 1349\n",
      " 1958 1932 1652 2108 1753 1392 1697 1671 1721 1927 1684 1983 1762 1662\n",
      " 2009 1920 1787 1814 1943 1524 2196 2141 1494 1782 2867 1634 1378 2247\n",
      " 1549 1209 1233 2300 1672 1937 1585 1738 2078 1270 1936 2246 1515 2065\n",
      " 1423 1584 1828 1511 1530 1725 1405 2278 1596 1727 2016 1219 2186 1493\n",
      " 1833 1865 1862 1694 1411 1700 1679 1653 2399 1660 2149 1551 1589 2169\n",
      " 1703 1600 1946 1419 1186 1970 2983 1640 1788 1824 1663 1646 1455 1660\n",
      " 1956 2475 1720 1692 1847 1536 1627 1670 1871 1893 1554 1657 1579 1619\n",
      " 1627 2336 1708 1567 1706 1934 1993 2075 1435 1826 1747 1339 1482 1949\n",
      " 1379 1595 1833 2355 1332 1769 1476 1742 1862 1543 1628 1781 1333 1753\n",
      " 1602 1785 1525 1601 1520 1627 1615 1973 1377 1634 1527 1867 1698 1778\n",
      " 1660 1271 2022 1823 2073 1835 1335 1968 1049 1732 2292 2087 1869 1949\n",
      " 1733 2019 1528 1869 1503 1767 1348 1917 2601 2182 1731 2168 1662 1537\n",
      " 2014 1965 1938 2006 1550 1615 1307 1833 1929 1543 1302 1611 1836 2670\n",
      " 1693 1697 1418 1565 1331 1390 1810 1306 1983 2335 1891 2122 1531 1829\n",
      " 1735 1618 1838 2024 2124 1559 2123 1623 1640 1898 1907 2847 2051 1619\n",
      " 1867 1986 1768 1793 1234 1264 1803 1879 2152 1601 1658 1447 1905 1758\n",
      " 1750 1391 1816 2082 1738 1980 1705 2417 1634 2014 1269 1676 1211 1358\n",
      " 1975 1765 1764 1628 1577 1577 1626 1585 1545 1625 2066 1559 1496 2001\n",
      " 1363 1883 1405 1628 1856 1754 1847 1628 1772 1856 1782 1525 1671 1561\n",
      " 1284 2135 1629 1375 1558 1781 1884 1903 1664 1758 1591 1849 1229 1873\n",
      " 2265 2128 1728 1764 1553 1900 1449 1986 1759 1364 1858 1911 1742 1739\n",
      " 1722 1806 1668 2192 1404 1938 1263 1593 1540 1952 1576 1357 1880 1942\n",
      " 1342 2172 1561 1912 1682 1516 1727 1491]\n",
      "bias_q:  [  34178   48356   18895   10303  118531  159820  166242 -109045  165836\n",
      "  119791  103412 -116831 -149850  -54966    3557   16534  121121  -43345\n",
      "  -29773   34627  193861   -6257  132714  121322   58332   59129 -132761\n",
      "   94985 -152205  146454  -29161  152231  116835  123781 -127449 -102150\n",
      "  -81190 -117256  -51032   12793  -15095   60809 -171934   79665   98922\n",
      "  -62543  162118  126291  158424   10500  103620   68819  -38900 -117829\n",
      "   84449   26240 -157548  127690  110954  -22204  -21373  -42452  144839\n",
      "    2614  -20572 -100132   -4325  -18434 -135356  -95338  166592 -126170\n",
      "  118750   23562  -18347  140985 -142043  139278 -135256 -113465  166235\n",
      "   25500   60170   -4944  145609  -19010  100368  -14878   55199  -93629\n",
      "  -63339  150762  136866   14191   -3847 -136851  152917  -80267  -42078\n",
      "  -98771   40358  134978  133026 -133827   16231  -27858  -80762   30623\n",
      "  -10149   48888  163956  -88975   27980 -128308 -100365  140028  124622\n",
      "  -77345  -60226  -88765  -93539  118816  -57907  -89045   39991  133484\n",
      "  -19245  -11730  139044  -97626   -6252   79695   23944  -47895   14199\n",
      "  -73782  147733   89814  185990 -104947  -71523   23217 -114790  -85658\n",
      "   -2401 -120366 -159852  -65190   12401  128877 -147460  -32441  144199\n",
      "  125664  -78522 -182096  -88422    3359 -121147  157748   32492  128839\n",
      "  117813   10566  -61137   31931  150037  -39302   85301    2433  143144\n",
      " -168623 -156184  135968   46670  -46227  -27312 -128726 -112101 -139502\n",
      "  149276  -75936  -88459  135073  -32647   37501  -10007   -1322  108762\n",
      "  -37825  134030   86065  110120 -114182 -124879  -15252   67561  -30204\n",
      "  131700  -87527  -58486  -59263 -124955   57625   34012 -102791  143140\n",
      "  -21762  -60962  -35020  -11393  -61499  -89938  -74106  -22899   77331\n",
      "   82491  -14293  163259  135295   -5630   42968  152013   -9057  -61177\n",
      "    9876  -50744   61952 -130509   95651 -147049   97651   59885  -76557\n",
      "  -71225    3011 -172131  149090   41130  124094  -76596  -74686   -8963\n",
      "   70396 -123075  141848   77254  138060  103726 -131753 -102498  -91019\n",
      "   24178  148967  115683   10580 -147173   33547   87003  165420  130763\n",
      "  -12065  143397  153728   32874  149189  132813 -101625  127512   88244\n",
      "   87789   24307  136293   58939   64721 -136821   53165   95093 -139347\n",
      "  -17892  158831   26320  -82449  -46650 -170430  -59981  -51157  142175\n",
      "  116009   69923   59763   44448  -63656   56784  -13597  169907   40591\n",
      " -166088 -148875    6536  -94948  -49968 -114727  -50394  -88771  -55607\n",
      "  144581  -16004 -107220   90614  -77433  173585   -2088   -3547  -75931\n",
      "   95504   -2128 -124726 -117303  120212 -136077   79040  -42338  -30804\n",
      "  -93921 -133885    6596  -21299  140802   23158   16716  161025  -79491\n",
      "  107751 -132401 -132823  -23611   78864  126034   -4413 -110581  160415\n",
      "  107491   83599   56327  213863  -79036  -84836  -71378  -81520 -139500\n",
      " -157496  116491  -98848  -27163  -14360  -13928  -17657   65177  -75461\n",
      " -101024  -49496  112119  -37507   -9080      99  -73864 -152988   77321\n",
      "  159197   -9934  108722   90856   82216 -158388 -125750  153749   70688\n",
      "  -34408  -48267  128428  136361  118606  -60851  139483  118400   33715\n",
      "   19146  166349   76094  148138  -19966  -59875  119866  154195  130581\n",
      "   38495  153979  -34893    9520   22245 -125538  141995  -31005  138577\n",
      " -138505  162070  139984   72774  165546  -12983   59788   79161  -16849\n",
      "  -85122  130443   81872   81978  -13565  -55381   93011  -29042   72891\n",
      "  111116  208203  103739  138117  169210   28895 -140330  -88021 -127181\n",
      "  149580   72397   28109  125169  -18613 -143214   98681  -31051  140502\n",
      "  -27706 -138087  117513 -130461  124455  116586  -85704   89307  122602\n",
      "  -26016     527 -113653 -144336   96976  142154   22612  -70878 -101998\n",
      "   80643  -93581   26569  -44538   11050  103683   67273  170603   46127\n",
      "    8975  -86695   21014  148672   75429 -136893  154651  -67474  144824\n",
      "   -3966  -13015 -134760  149084  107366 -101805  160509 -127060  144430\n",
      "  -65354  117470  144474   83101  -26253   98157 -127545  -13764 -143593\n",
      " -107945   -1989  153368  -62429  -82694 -128710  121302 -117830  116900\n",
      "  -67881 -143813  153994   69925 -120733  138121  122790  163584   85295\n",
      " -145175   59085  -33417  115579  -77844   10394  -33553 -119792   16773\n",
      " -171343  -27391   -6792  -79068  -56775    8091  145515  137573  108794\n",
      "   -3030  -43010   -6895   55263 -169986  162479  113836   44655 -113432\n",
      " -121944  128711 -150728 -130123 -162012   68947  114694  102257  143759\n",
      "   89409 -109137 -164335  112092  112661 -109282   88750  149119    7260\n",
      "   81014    9844   93972    9311   16673   -9901    -774  -31873  -56269\n",
      "   63074  -21475  108923  138953 -160720  -75435   -4420    8397  156644\n",
      "  -74003   24303 -107543 -118363 -145036   69198  146308   97202   13689\n",
      "   75786  -61938 -108602  -67305  -16777  103567   59203  -90803 -128520\n",
      "  -71885   97984  -62094    2636  104082   60583  111242 -135186  -26268\n",
      " -185709 -143456  -85104  143640  133660   31988  127501  198141  -62977\n",
      " -135287  106968  -28212  -25887   -2278   10060  114436  118470   18714\n",
      "   97304  -23947  -88926  -94414   -7945  -74490   47446  136020 -194432\n",
      " -109339  -40728  133190 -106662  187862  114960  118879  114420   14778\n",
      " -109589   39033  -33253 -117690  123606  -56939  -28237   86674  -85223\n",
      "  133902 -156115 -125837  -98000  -42816   30224  -15668  158646  -13136\n",
      "   18440 -128744 -127819   75567 -134181 -105007  -12731  168379  -37353\n",
      " -141637  -65626  -56698 -150878  120415  -64646 -153404 -144486  116086\n",
      " -135972 -122396   84938  156014  141988     341 -123641   -1609  171161\n",
      "  -25789  143005  133044  -61675   -9442 -137579   65315  -14769 -127940\n",
      "   -3502  110730  -43959 -144617 -132824    8557  113145  167780  -37488\n",
      "  -52192  -13682  123945  -94314  152583  138741 -139284  -40423  131614\n",
      "   71058  148405 -122355   -5479   17878   56883  136973  122595  -69919\n",
      "  -85993  -96183  -33386   22582  145283  122856   75920  134432  -32689\n",
      "  166723  131703  -82387 -112503   86001  159726  134891  -62155    2898\n",
      "  107291   -8999   95892 -132913  -55724  -88659  104629 -138757   47861\n",
      "  -61817  -41477   70203  -72468 -122515  -94333   91105  135827  -12749\n",
      "   28064  113339  -21331  -48230   75642  160637   86284 -104747   21146\n",
      "  152674  145590  153051   77985  179784 -165160  171027  110215  135043\n",
      "  -12855   33361  -34360  -93493   -5547  128428 -134824  102454  102643\n",
      " -145223   76834  110865  -78400  161427  -19512   70174  105912  -23621\n",
      "  159512   20400 -108268  -32945  131939  -57029 -159445  -94998 -153364\n",
      "  -70965   77527  -83516  -32548  -10375  163617  -72353   -6652   -1761\n",
      "   38799  103881   42524 -109576 -175246   26451  -87914   40518  128770\n",
      "    6093    7887  114995  122124  139355   46289    5224 -100352  -43650\n",
      "  115651  -25202  155841 -106811  -88768 -146608  -14779  -31763  -30683\n",
      "  -60251   96716  142479 -101403  129599  -77784  -74611  161285  129663\n",
      "   -9085 -138334   85319  -68273  -48704  -59368   79250  143332  -33192\n",
      " -106541   71986   54885  112152  113559   99129   17288   76970  -71492\n",
      "  -92715   87363  -33143   27565 -140318 -116107 -140802 -121458  -22279\n",
      "  -21697   -3045   49606   -8123 -121504  112661   62058 -149575  153931\n",
      "  -67757  -25171  147831    9947  137559 -150138 -102288  138193   -2805\n",
      " -148018  -21094  -41402 -155404  -37662   -8087    -791  139788    8219\n",
      " -151659  -41296  -43578  142346   24869  -47442   -7801 -134561  -99427\n",
      "  163318  -54791   20759  119226 -137395  -86061  -25970   -4415   40516\n",
      " -144121   22791   19034  158209  -92190  -35933  -54396  -63234  -20923\n",
      "  -45376 -121929  -27589  160360   27620   -6838 -166027    8184  146780\n",
      "  -14742 -117878 -135319  142616 -128996 -165664  132603    2423   55706\n",
      " -169720 -123013  -59842     170  169108  109280  -39615  110208  -14454\n",
      "   71238  -51391   40519 -127241  -27649   23087]\n",
      "h mod simd != 0\n",
      "inc_q:  [359 256 276 196 264 288 277 329 237 347 184 306 232 427 382 342 295 363\n",
      " 317 348 298 251 202 265 258 385 340 304 288 348 500 193 164 395 298 262\n",
      " 396 149 276 294 576 391 162 300 392 342 325 303 180 334 380 492 256 241\n",
      " 295 279 331 220 416 274 421 301 357 263 173 192 420 187 346 343 305 387\n",
      " 409 167 237 184 315 332 222 424 419 373 268 331 335 182 208 351 199 256\n",
      " 446 205 278 304 330 258 363 275 290 318 148 216 358 323 224 362 313 270\n",
      " 386 260 146 194 260 352 328 183 339 212 180 247 328 322 399 411 329 178\n",
      " 285 135 422 246 287 294 293 259 318 250 304 195 161 409 179 350 256 211\n",
      " 402 337 225 263 221 230 224 267 346 413 229 228 458 326 250 215 264 171\n",
      " 362 239 209 442 231 404 267 474 277 451 356 282 411 260 252 246 326 307\n",
      " 200 275 348 311 196 302 245 299 178 318 328 386 365 172 289 241 415 242\n",
      " 311 406 250 226 377 358 196 242 408 163 207 267 347 305 196 337 409 320\n",
      " 283 297 280 228 257 339 258 218 376 239 324 221 321 237 380 306 316 188\n",
      " 287 387 286 380 259 325 264 177 447 295 188 325 201 180 321 367 209 341\n",
      " 349 245 360 328 305 250 248 302 261 305 381 308 261 171 197 230 241 302\n",
      " 269 249 176 202 196 305 233 286 268 277 202 218 275 274 446 299 423 169\n",
      " 185 331 259 351 253 236 196 184 337 277 255 174 216 203 155 278 215 262\n",
      " 182 419 468 351 225 353 211 268 353 265 274 374 375 324]\n",
      "bias_q:  [  45056 -147809  112687  -83022  -30660  100877   -8653 -105821  115305\n",
      "  -15845  -52326   67842  -32715 -104789   78280   20437  -44919   -1155\n",
      "  163076 -166153  -56774   78083  144529  -52218   92987 -180119   46295\n",
      "   24776  234640  -81384 -192138    4450   77412  125479  -55246  -97119\n",
      "  -86585    6374  -55442  -55188  164096  197182  -54936 -131778  -23767\n",
      "  113411   54710 -182032   55446  -31963   91355 -233774  -37323   10996\n",
      "  -89747  105900   55808  -41650   18173   -7404  146262    2497  201326\n",
      " -188261  -88518  -22471   57158   -2344  -30779 -131645 -137399   -7214\n",
      "  154412   -3483   77570  136352  -23406  122326   -1644   99711  176127\n",
      " -198618   61839  -13765   13467  -84636   55539  -49787   29357  -44784\n",
      "  -68673  -95711   69769  -37368  186046  -70598 -114472    2367 -102644\n",
      " -103689   10270   23874  -33367   -1665  -16043  -43395   76670  115136\n",
      "  -36274   15091  -82886  -54648   25306    6840   84875  143034    5694\n",
      "   36534   65422   -9649   45135  -20563  112408  -33142  111887   39736\n",
      " -143560 -174446  -14097  -94707  -25864   91924   20274    1437  -34473\n",
      " -103575  -63632   50750  -11821 -160089   74885 -113269   33896    8853\n",
      " -135344 -181737  -36716  -95731   12466  -18865   80037   35948  -36526\n",
      "   73040  -34439   44190 -103087  125864  131060   23973 -105907  -47682\n",
      "  -47556   29043  -34260   15510  -29662 -217050  -90247  115614 -102676\n",
      "  -83480  190477   -1648 -196703  -10818  -15457   24461  -22916  -36838\n",
      "  -67809   21175    8771   34440 -133848  -21939   12198  -47998   56410\n",
      " -132876   23587  -45451   16134  -88051  -92005  -26612 -145047  -19367\n",
      "   74386   39700    1956    -590  141767 -173360  188686   92467  -43389\n",
      "  -60699 -126935 -173738  -22301   27097  138748 -250298    9942 -144952\n",
      "   -6942   69846   50054  -39160  -58479  124820 -121023  -44863   96784\n",
      "  -77716  116941   36887 -202789   59458  280792  -74018 -112864  127665\n",
      "     989  -69671  -43709  150618   83599   69679   20605  -60363  -99905\n",
      "    9652  -27227   96953   15228   17280    9100   -6399   69480 -130723\n",
      "  -38736   44694   99026   24082 -237859  -61690   48661   60046   47095\n",
      "  -24902 -193244  218652  -98502  -20543   -9066   -8625  -11044   29345\n",
      "   18285   61119   33911  -86477   64419  -22934    9659  -24825  -54598\n",
      "  -50923  -32698   23640  -38431  156763 -212439  104103 -195892  -55532\n",
      "  -36678  -59375  -42314  149124  138504    -498   53078   74528   50265\n",
      "  105687   -4183   13880  -81981   22201    2401   18495   34788  -62807\n",
      "   28757  174614   14193  -97372   -7205   32210  186009   29280 -167215\n",
      "  160669   99031   35935  267342    8849]\n"
     ]
    }
   ],
   "source": [
    " # conv_0 - 50\n",
    "for i in range(51):\n",
    "    processer = QNNLayerMemProcess('conv_' + str(i), reader, config, w_bit=w_bit[i], in_bit=in_bit[i], out_bit=out_bit[i], l_shift=l_shift[i], pe=pe[i], simd=simd[i])\n",
    "    w, inc, bias = processer.conv()\n",
    "    param_str = processer.layer_param_to_init_str(w, inc, bias)\n",
    "    config_str = processer.conv_config_str()\n",
    "    hls_param_file.write(param_str)\n",
    "    hls_config_file.write(config_str)\n",
    "    \n",
    "# the last conv layer has no BN layer\n",
    "processer = QNNLayerMemProcess('conv_' + str(51), reader, config, w_bit=w_bit[51], in_bit=in_bit[51],\n",
    "                                   out_bit=out_bit[51], l_shift=l_shift[51], pe=pe[51], simd=simd[51])\n",
    "w = processer.last_conv()\n",
    "param_str = processer.last_layer_param_to_init_str(w)\n",
    "config_str = processer.last_conv_config_str()\n",
    "hls_param_file.write(param_str)\n",
    "hls_config_file.write(config_str)\n",
    "\n",
    "hls_param_file.close()\n",
    "hls_config_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ranging-colon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<numpy.lib.npyio.NpzFile at 0x7f5df25c9bd0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict = np.load(\"mobilenetv2_Lite_0.25_Q_4w4a.npz\")\n",
    "param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-mauritius",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
